{"cells":[{"cell_type":"markdown","id":"8b26f5d6","metadata":{"id":"8b26f5d6"},"source":["# YOLO Hyperparameter Tuning\n","\n","- Support for YOLOv8, YOLOv9, YOLOv10, YOLO11, YOLO12"]},{"cell_type":"code","execution_count":1,"id":"f68c7bbf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f68c7bbf","executionInfo":{"status":"ok","timestamp":1764530007964,"user_tz":-180,"elapsed":4,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"35d32437-5c45-4c11-d7d3-32135b3c482a"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì W&B API key loaded from Colab secrets\n"]}],"source":["# Base directories\n","# Detect environment: Colab or local\n","\n","import os\n","from pathlib import Path\n","\n","\n","IS_COLAB = 'COLAB_GPU' in os.environ or os.path.exists('/content')\n","\n","USE_WANDB = True  # Set to False to disable W&B logging\n","\n","\n","\n","if IS_COLAB:\n","    #Mount Google Drive if not already mounted\n","    from google.colab import drive\n","    drive.mount('/content/Drive', force_remount=True)\n","    # Running in Google Colab\n","    BASE_DIR = Path('/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training')\n","\n","    # Configure W&B API key\n","    if USE_WANDB:\n","        # In Colab, get API key from secrets\n","        from google.colab import userdata\n","        wandb_api_key = userdata.get('wandb_api_key')\n","        os.environ['WANDB_API_KEY'] = wandb_api_key\n","        print('‚úì W&B API key loaded from Colab secrets')\n","\n","    DATASET_BASE_DIR = Path('/computer_vision_yolo')\n","\n","else:\n","    # Running locally\n","    BASE_DIR = Path.cwd().parent\n","    if USE_WANDB:\n","        print('‚úì Running locally - W&B will use existing login or prompt')\n","\n","    DATASET_BASE_DIR = Path.cwd().parent\n"]},{"cell_type":"code","execution_count":2,"id":"7c504221","metadata":{"id":"7c504221","executionInfo":{"status":"ok","timestamp":1764530007969,"user_tz":-180,"elapsed":1,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}}},"outputs":[],"source":["# ! cd /content/Drive/MyDrive/ksu_yolo10_tuning_2025 && git clone https://github.com/m3mahdy/yolo_training"]},{"cell_type":"code","execution_count":3,"id":"fde7425c","metadata":{"id":"fde7425c","executionInfo":{"status":"ok","timestamp":1764530007972,"user_tz":-180,"elapsed":0,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}}},"outputs":[],"source":["#  ! cd {BASE_DIR} && pip install -r requirements.txt --quiet"]},{"cell_type":"code","execution_count":4,"id":"92da27e0","metadata":{"id":"92da27e0","executionInfo":{"status":"ok","timestamp":1764530007983,"user_tz":-180,"elapsed":0,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}}},"outputs":[],"source":["# limited dataset\n","# !mkdir {DATASET_BASE_DIR}\n","# !cd {BASE_DIR}/dataset && cp 8_download_extract_other_datasets.py {DATASET_BASE_DIR} && cd {DATASET_BASE_DIR} && python 8_download_extract_other_datasets.py\n"]},{"cell_type":"markdown","id":"109394c4","metadata":{"id":"109394c4"},"source":["## 1. Import Required Libraries"]},{"cell_type":"code","execution_count":5,"id":"fc6f98f1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fc6f98f1","executionInfo":{"status":"ok","timestamp":1764530012286,"user_tz":-180,"elapsed":6,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"62b1905d-fa36-4e5a-e042-e42751218d52"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Libraries imported successfully\n","‚úì Device: cuda\n","  GPU: NVIDIA A100-SXM4-40GB\n","  CUDA Version: 12.6\n","  Available Memory: 42.47 GB\n"]}],"source":["# Install required libraries (uncomment if running in Colab)\n","# !pip install -q ultralytics optuna plotly kaleido wandb pyyaml\n","\n","import os\n","import sys\n","import gc\n","import yaml\n","import json\n","import torch\n","import shutil\n","import warnings\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from pathlib import Path\n","from datetime import datetime\n","from tqdm import tqdm\n","import pickle\n","import platform\n","import psutil\n","\n","import wandb\n","\n","# YOLO and Optuna imports\n","from ultralytics import YOLO\n","import optuna\n","from optuna.visualization import plot_optimization_history, plot_param_importances, plot_slice\n","\n","# ReportLab imports for PDF generation\n","from reportlab.lib.pagesizes import A4\n","from reportlab.lib import colors as rl_colors\n","from reportlab.lib.units import inch\n","from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, Image, PageBreak\n","from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n","from reportlab.lib.enums import TA_CENTER, TA_LEFT\n","from PIL import Image as PILImage\n","\n","warnings.filterwarnings('ignore')\n","\n","# Configure matplotlib for notebook display\n","%matplotlib inline\n","sns.set_style('whitegrid')\n","plt.rcParams['figure.figsize'] = (15, 10)\n","\n","# Check GPU availability\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(f'‚úì Libraries imported successfully')\n","print(f'‚úì Device: {device}')\n","if device == 'cuda':\n","    print(f'  GPU: {torch.cuda.get_device_name(0)}')\n","    print(f'  CUDA Version: {torch.version.cuda}')\n","    print(f'  Available Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')"]},{"cell_type":"code","execution_count":6,"id":"d0915be9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d0915be9","executionInfo":{"status":"ok","timestamp":1764530017632,"user_tz":-180,"elapsed":5200,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"9e030053-3197-4a52-e871-905a6eb87dce"},"outputs":[{"output_type":"stream","name":"stdout","text":["üì¶ Installing kaleido (this may take a moment)...\n","‚úì Kaleido 0.2.1 installed successfully\n","‚úì Kaleido module imported\n","\n","üß™ Testing kaleido with Plotly...\n","‚úì Kaleido is working correctly! (Generated 1637 bytes)\n","‚úÖ PNG export is ready to use\n"]}],"source":["# ============================================================================\n","# INSTALL AND VERIFY KALEIDO (Required for PNG export of Plotly figures)\n","# ============================================================================\n","# Run this cell to ensure kaleido is installed correctly\n","\n","import subprocess\n","import sys\n","\n","# Force reinstall kaleido with a specific compatible version\n","print('üì¶ Installing kaleido (this may take a moment)...')\n","result = subprocess.run(\n","    [sys.executable, '-m', 'pip', 'install', '--upgrade', '--force-reinstall', 'kaleido==0.2.1'],\n","    capture_output=True,\n","    text=True\n",")\n","\n","if result.returncode == 0:\n","    print('‚úì Kaleido 0.2.1 installed successfully')\n","else:\n","    print(f'‚ö†Ô∏è  Installation warning: {result.stderr}')\n","\n","# Try importing kaleido\n","try:\n","    import kaleido\n","    print('‚úì Kaleido module imported')\n","except ImportError as e:\n","    print(f'‚ùå Failed to import kaleido: {e}')\n","    print('   Please restart the runtime: Runtime > Restart Runtime')\n","\n","# Verify kaleido works with plotly\n","print('\\nüß™ Testing kaleido with Plotly...')\n","try:\n","    import plotly.graph_objects as go\n","    import plotly.io as pio\n","\n","    # Create a simple test figure\n","    test_fig = go.Figure(data=[go.Scatter(x=[1, 2, 3], y=[1, 2, 3])])\n","\n","    # Try to convert to PNG bytes (doesn't write to disk)\n","    img_bytes = test_fig.to_image(format=\"png\", width=100, height=100, engine=\"kaleido\")\n","    print(f'‚úì Kaleido is working correctly! (Generated {len(img_bytes)} bytes)')\n","    print('‚úÖ PNG export is ready to use')\n","\n","except Exception as e:\n","    print(f'‚ùå Kaleido test failed: {type(e).__name__}')\n","    print(f'   Error: {e}')\n","    print('\\n‚ö†Ô∏è  ACTION REQUIRED:')\n","    print('   1. Go to: Runtime > Restart Runtime')\n","    print('   2. After restart, run all cells again')\n","    print('   3. Kaleido should work after the runtime restart')\n"]},{"cell_type":"markdown","id":"2eda31f6","metadata":{"id":"2eda31f6"},"source":["## 2. Constants and Enums"]},{"cell_type":"code","execution_count":7,"id":"2031059f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2031059f","executionInfo":{"status":"ok","timestamp":1764530017649,"user_tz":-180,"elapsed":4,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"a7ff5e60-fd13-43f6-ac4a-56c4c0178bd7"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Constants and enums defined\n"]}],"source":["# ============================================================================\n","# CONSTANTS AND ENUMS\n","# ============================================================================\n","\n","class TrialStatus:\n","    \"\"\"Constants for trial execution status\"\"\"\n","    COMPLETED = \"completed\"\n","    FAILED = \"failed\"\n","    PRUNED = \"pruned\"\n","    RUNNING = \"running\"\n","\n","class DatasetSplit:\n","    \"\"\"Constants for dataset split names\"\"\"\n","    TRAIN = \"train\"\n","    VAL = \"val\"\n","    TEST = \"test\"\n","\n","class ModelConfig:\n","    \"\"\"Default model training configuration constants\"\"\"\n","    # Training workers\n","    DEFAULT_WORKERS = 8  # Number of data loading workers\n","\n","    # Early stopping and checkpointing\n","    DEFAULT_PATIENCE = 10  # Epochs to wait before early stopping\n","\n","    # Augmentation timing\n","    CLOSE_MOSAIC_EPOCHS = 10  # Disable mosaic augmentation in last N epochs\n","\n","print('‚úì Constants and enums defined')"]},{"cell_type":"markdown","id":"2659c792","metadata":{"id":"2659c792"},"source":["## 3. Configuration"]},{"cell_type":"code","execution_count":8,"id":"d163f0be","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d163f0be","executionInfo":{"status":"ok","timestamp":1764530017681,"user_tz":-180,"elapsed":4,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"f72e37f6-7687-48d3-98d2-57c295a7d844"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üÜï NEW RUN MODE: Creating new run \"yolo12s_tune_20251130_191337\"\n","================================================================================\n","CONFIGURATION SUMMARY\n","================================================================================\n","Environment: Google Colab\n","Base Directory: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training\n","Model: yolo12s\n","Dataset: bdd100k_yolo_tuning\n","Data YAML: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tmp/yolo12s/data.yaml\n","  Dataset path in YAML: /computer_vision_yolo/bdd100k_yolo_tuning\n","Classes: 10\n","Class Names: {0: 'person', 1: 'rider', 2: 'car', 3: 'truck', 4: 'bus', 5: 'train', 6: 'motor', 7: 'bike', 8: 'traffic light', 9: 'traffic sign'}\n","Device: cuda\n","Optimization Trials: 20\n","Epochs per Trial: 6\n","Batch Size: 96\n","Timeout: 24 hours\n","Tuning Directory: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337\n","W&B Logging: Disabled\n","================================================================================\n"]}],"source":["# CONFIGURATION\n","# ============================================================================\n","\n","\n","# Model Selection - Choose one of the following:\n","MODEL_NAME = \"yolo12s\"\n","\n","#yolov10n is for testing purpose only\n","#Mahdy will work yolov8m\n","\n","\n","# Selected models, to choose from, based on the performance and size:\n","# YOLOv8:  'yolov8s', 'yolov8m'\n","\n","# YOLOv10: 'yolov10s', 'yolov10m'\n","\n","# YOLO12: 'yolo12s'\n","\n","# Directory structure\n","MODELS_DIR = BASE_DIR / 'models' / MODEL_NAME\n","TMP_DIR = BASE_DIR / 'tmp' / MODEL_NAME\n","\n","# Dataset Selection\n","# Option 1: Full dataset (~100k images) - for final optimization: \"bdd100k_yolo\"\n","# Option 2: Limited dataset (representative samples) - for quick tuning: \"bdd100k_yolo_limited\"\n","dataset_name = 'bdd100k_yolo_tuning'\n","\n","\n","YOLO_DATASET_ROOT = DATASET_BASE_DIR / dataset_name\n","\n","# data.yaml path\n","DATA_YAML_PATH = YOLO_DATASET_ROOT / 'data.yaml'\n","\n","# Verify dataset exists\n","if not DATA_YAML_PATH.exists():\n","    raise FileNotFoundError(\n","        f\"Dataset not found: {DATA_YAML_PATH}\\n\"\n","        f\"Please prepare the dataset first using process_bdd100k_to_yolo_dataset.py\"\n","    )\n","\n","# Update data.yaml path field for Colab compatibility\n","with open(DATA_YAML_PATH, 'r') as yaml_file:\n","    data_config = yaml.safe_load(yaml_file)\n","\n","# Validate required keys in data.yaml\n","required_yaml_keys = ['nc', 'names', 'path']\n","missing_keys = [key for key in required_yaml_keys if key not in data_config]\n","if missing_keys:\n","    raise ValueError(f\"Missing required keys in data.yaml: {missing_keys}\")\n","\n","# Update the 'path' field to use BASE_DIR\n","data_config['path'] = str(YOLO_DATASET_ROOT)\n","\n","# Create a temporary data.yaml with corrected paths\n","temp_data_yaml = TMP_DIR / 'data.yaml'\n","TMP_DIR.mkdir(parents=True, exist_ok=True)\n","with open(temp_data_yaml, 'w') as yaml_output_file:\n","    yaml.dump(data_config, yaml_output_file, default_flow_style=False, sort_keys=False)\n","\n","# Use the temporary data.yaml for training\n","DATA_YAML_PATH = temp_data_yaml\n","\n","# Optimization Configuration\n","N_TRIALS = 20  # Number of optimization trials = 50‚Äì70 trials\n","TIMEOUT_HOURS = 24  # Maximum time for optimization (None for no limit)\n","N_STARTUP_TRIALS = 4  # Random exploration trials before optimization =10\n","EPOCHS_PER_TRIAL = 6  # Training epochs per trial = 50\n","BATCH_SIZE = 96  # Batch size for training\n","# for T4 GPU:\n","# 64 for 10n, 1 epoch 30 min\n","# 32 for 8m, 1 epoch 45 min\n","\n","# for A100 GPU:\n","# 64 for 10m 1 epoch 11 min, 5 epochs completed in 0.797 hours.\n","# 96 for 8m , 1 epoch 10 min, 5 epochs completed in 0.866 hours.\n","\n","\n","\n","# Weights & Biases (optional)\n","USE_WANDB = False  # Set to True to enable W&B logging\n","WANDB_PROJECT_TUNING = f\"yolo-{YOLO_DATASET_ROOT.name}-tuning\"\n","\n","# ============================================================================\n","# RUN NAME CONFIGURATION - RESUME OR CREATE NEW\n","# ============================================================================\n","# To RESUME an existing run: Set RESUME_RUN_NAME to the run directory name\n","# To START NEW run: Leave RESUME_RUN_NAME as None or empty string\n","#\n","# Example to resume: RESUME_RUN_NAME = \"yolov10n_tune_20251125_143022\"\n","# ============================================================================\n","\n","RESUME_RUN_NAME = None  # Set to run name to resume, or None to create new run\n","\n","if RESUME_RUN_NAME:\n","    # Resume existing run\n","    RUN_NAME_TUNING = RESUME_RUN_NAME\n","    print(f'\\nüîÑ RESUME MODE: Will attempt to resume run \"{RESUME_RUN_NAME}\"')\n","else:\n","    # Create new run with timestamp\n","    RUN_TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')\n","    RUN_NAME_TUNING = f'{MODEL_NAME}_tune_{RUN_TIMESTAMP}'\n","    print(f'\\nüÜï NEW RUN MODE: Creating new run \"{RUN_NAME_TUNING}\"')\n","\n","RUN_NAME_TRAINING = f'{MODEL_NAME}_train_{RUN_TIMESTAMP if not RESUME_RUN_NAME else RESUME_RUN_NAME}'\n","\n","# Create directories for tuning within tune_train folder\n","# All paths are absolute to ensure consistency across environments (local/Colab)\n","TUNE_TRAIN_BASE = BASE_DIR / 'tune_train'\n","TUNE_DIR = TUNE_TRAIN_BASE / 'tune' / RUN_NAME_TUNING\n","TUNE_DIR.mkdir(parents=True, exist_ok=True)\n","MODELS_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Keep RUN_DIR for backward compatibility (points to tuning)\n","RUN_DIR = TUNE_DIR\n","# Keep RUN_DIR for backward compatibility (points to tuning)\n","# Read dataset configuration\n","NUM_CLASSES = data_config['nc']\n","CLASS_NAMES = {i: name for i, name in enumerate(data_config['names'])}\n","CLASS_NAME_TO_ID = {name: i for i, name in enumerate(data_config['names'])}\n","\n","print('=' * 80)\n","print('CONFIGURATION SUMMARY')\n","print('=' * 80)\n","print(f'Environment: {\"Google Colab\" if \"COLAB_GPU\" in os.environ or os.path.exists(\"/content\") else \"Local\"}')\n","print(f'Base Directory: {BASE_DIR}')\n","print(f'Model: {MODEL_NAME}')\n","print(f'Dataset: {YOLO_DATASET_ROOT.name}')\n","print(f'Data YAML: {DATA_YAML_PATH}')\n","print(f'  Dataset path in YAML: {data_config[\"path\"]}')\n","print(f'Classes: {NUM_CLASSES}')\n","print(f'Class Names: {CLASS_NAMES}')\n","print(f'Device: {device}')\n","print(f'Optimization Trials: {N_TRIALS}')\n","print(f'Epochs per Trial: {EPOCHS_PER_TRIAL}')\n","print(f'Batch Size: {BATCH_SIZE}')\n","print(f'Timeout: {TIMEOUT_HOURS} hours' if TIMEOUT_HOURS else 'No timeout')\n","print(f'Tuning Directory: {TUNE_DIR}')\n","if USE_WANDB:\n","    print(f'W&B Logging: Enabled')\n","    print(f'  Tuning Project: {WANDB_PROJECT_TUNING}')\n","else:\n","    print(f'W&B Logging: Disabled')\n","print('=' * 80)"]},{"cell_type":"markdown","id":"0af35c3f","metadata":{"id":"0af35c3f"},"source":["## 4. Load Base YOLO Model"]},{"cell_type":"code","execution_count":9,"id":"3deeda88","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3deeda88","executionInfo":{"status":"ok","timestamp":1764530017901,"user_tz":-180,"elapsed":67,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"3e20399d-772f-483c-d2b9-fbcbbf863df1"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Model loaded from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/models/yolo12s/yolo12s.pt\n","YOLOv12s summary: 272 layers, 9,285,632 parameters, 0 gradients, 21.7 GFLOPs\n","\n","üìä Model Information:\n","  Model: yolo12s\n","  Classes in model: 80\n","  Task: detect\n","  Parameters: 9.3M\n","  Model Size: 0.0 MB\n","  FLOPs (640x640): 21.69 GFLOPs\n"]}],"source":["# Load YOLO model with automatic download\n","model_path = MODELS_DIR / f'{MODEL_NAME}.pt'\n","\n","if not model_path.exists():\n","    print(f'Model not found at {model_path}')\n","    print(f'Downloading {MODEL_NAME} ...')\n","\n","    try:\n","        # Download model - ensure .pt extension for ultralytics\n","        # Ultralytics expects model names with .pt extension for download\n","        if not MODEL_NAME.endswith('.pt'):\n","            model_name_for_download = MODEL_NAME + '.pt'\n","        else:\n","            model_name_for_download = MODEL_NAME\n","\n","        print(f'  Requesting model: {model_name_for_download}')\n","        model = YOLO(model_name_for_download)\n","\n","        # Create models directory\n","        MODELS_DIR.mkdir(parents=True, exist_ok=True)\n","\n","        # Save model to our directory using export/save\n","        try:\n","            # Try to save using the model's save method\n","            if hasattr(model, 'save'):\n","                model.save(str(model_path))\n","                print(f'‚úì Model downloaded and saved to {model_path}')\n","                print(f'  Size: {model_path.stat().st_size / (1024*1024):.1f} MB')\n","            else:\n","                # Fallback: copy from cache\n","                cache_patterns = [\n","                    str(Path.home() / '.cache' / 'ultralytics' / '**' / f'{MODEL_NAME}.pt'),\n","                    str(Path.home() / '.config' / 'Ultralytics' / '**' / f'{MODEL_NAME}.pt'),\n","                ]\n","\n","                model_found = False\n","                for pattern in cache_patterns:\n","                    cache_paths = glob.glob(pattern, recursive=True)\n","                    if cache_paths:\n","                        shutil.copy(cache_paths[0], model_path)\n","                        print(f'‚úì Model downloaded and saved to {model_path}')\n","                        print(f'  Size: {model_path.stat().st_size / (1024*1024):.1f} MB')\n","                        model_found = True\n","                        break\n","\n","                if not model_found:\n","                    print(f'‚úì Model loaded from ultralytics cache')\n","                    print(f'  Note: Model is in cache, not copied to {model_path}')\n","                    print(f'  This is normal and the model will work correctly')\n","        except Exception as save_error:\n","            print(f'‚ö†Ô∏è  Could not save model to custom location: {save_error}')\n","            print(f'‚úì Model loaded successfully from ultralytics cache')\n","\n","    except Exception as download_error:\n","        print(f'\\n‚ùå Error downloading model: {download_error}')\n","        raise\n","else:\n","    model = YOLO(str(model_path))\n","    print(f'‚úì Model loaded from {model_path}')\n","\n","# Get model information\n","model_info_dict = {}\n","model_info_result = model.info()\n","model_info_keys = [\"layers\", \"params\", \"size(MB)\", \"FLOPs(G)\"]\n","\n","for info_key, info_value in zip(model_info_keys, model_info_result):\n","    model_info_dict[info_key] = info_value\n","\n","model_params = model_info_dict.get(\"params\", 0)\n","model_size_mb = model_info_dict.get(\"size(MB)\", 0)\n","flops_gflops = model_info_dict.get(\"FLOPs(G)\", 0)\n","\n","\n","print(f'\\nüìä Model Information:')\n","print(f'  Model: {MODEL_NAME}')\n","print(f'  Classes in model: {len(model.names)}')\n","print(f'  Task: {model.task}')\n","print(f'  Parameters: {model_params / 1e6:.1f}M')\n","print(f'  Model Size: {model_size_mb:.1f} MB')\n","print(f'  FLOPs (640x640): {flops_gflops:.2f} GFLOPs')"]},{"cell_type":"markdown","id":"5fe0b94d","metadata":{"id":"5fe0b94d"},"source":["## 5. Verify Dataset Structure"]},{"cell_type":"code","execution_count":10,"id":"71b15401","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"71b15401","executionInfo":{"status":"ok","timestamp":1764530018276,"user_tz":-180,"elapsed":320,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"1b9e161f-a643-4d82-90d7-906b044724cd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Verifying YOLO dataset structure...\n","\n","üìÅ Dataset Root: /computer_vision_yolo/bdd100k_yolo_tuning\n","  ‚úì train:  16391 images,  16391 labels\n","  ‚úì val  :  10000 images,  10000 labels\n","  ‚ö†Ô∏è  test : Directory not found\n","\n","üìÑ Configuration: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tmp/yolo12s/data.yaml\n","  Classes: 10\n","  Names: {0: 'person', 1: 'rider', 2: 'car', 3: 'truck', 4: 'bus', 5: 'train', 6: 'motor', 7: 'bike', 8: 'traffic light', 9: 'traffic sign'}\n","\n","‚úì Dataset verified: 26,391 total images\n","‚úì Ready for hyperparameter optimization\n"]}],"source":["# ============================================================================\n","# VERIFY DATASET STRUCTURE\n","# ============================================================================\n","\n","print('Verifying YOLO dataset structure...')\n","print(f'\\nüìÅ Dataset Root: {YOLO_DATASET_ROOT}')\n","\n","# Check all splits using constants\n","dataset_stats = {}\n","for split in [DatasetSplit.TRAIN, DatasetSplit.VAL, DatasetSplit.TEST]:\n","    images_dir = YOLO_DATASET_ROOT / 'images' / split\n","    labels_dir = YOLO_DATASET_ROOT / 'labels' / split\n","\n","    if images_dir.exists() and labels_dir.exists():\n","        num_images = len(list(images_dir.glob('*.jpg'))) + len(list(images_dir.glob('*.png')))\n","        num_labels = len(list(labels_dir.glob('*.txt')))\n","        dataset_stats[split] = {'images': num_images, 'labels': num_labels}\n","        print(f'  ‚úì {split:5s}: {num_images:6d} images, {num_labels:6d} labels')\n","    else:\n","        print(f'  ‚ö†Ô∏è  {split:5s}: Directory not found')\n","        dataset_stats[split] = {'images': 0, 'labels': 0}\n","\n","print(f'\\nüìÑ Configuration: {DATA_YAML_PATH}')\n","print(f'  Classes: {NUM_CLASSES}')\n","print(f'  Names: {CLASS_NAMES}')\n","\n","total_images = sum(stats['images'] for stats in dataset_stats.values())\n","print(f'\\n‚úì Dataset verified: {total_images:,} total images')\n","print('‚úì Ready for hyperparameter optimization')"]},{"cell_type":"markdown","id":"3cf76930","metadata":{"id":"3cf76930"},"source":["## 6. Define Hyperparameter Search Space"]},{"cell_type":"code","execution_count":11,"id":"06d1ae35","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"06d1ae35","executionInfo":{"status":"ok","timestamp":1764530018297,"user_tz":-180,"elapsed":4,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"5e4f603b-bb72-4f6e-d1c5-dcb7aa036c3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Hyperparameter search space defined\n","\n","üìä Focused Search Space Summary:\n","  Strategy: Tune ONLY critical high-impact parameters\n","  üéØ Tuned Parameters (11):\n","    - Image Size (imgsz): 640, 768\n","    - Batch Size: Dynamic (96 for 640, 64 for 768)\n","    - Optimizer: SGD, Adam, AdamW\n","    - Learning Rate (lr0): 1e-4 to 5e-3\n","    - Momentum: 0.85 to 0.97\n","    - Weight Decay: 1e-5 to 1e-3\n","    - Warmup Epochs: 0 to 3\n","    - Warmup Momentum: 0.5 to 0.95\n","    - Warmup Bias LR: 0.0 to 0.1\n","    - Mosaic: 0.5 to 1.0\n","    - Mixup: 0.0 to 0.2\n","  ‚öôÔ∏è  Fixed Parameters:\n","    - Epochs: 6\n","    - Device: cuda\n","  üìå Using YOLO defaults for: HSV augmentation, spatial transforms, loss weights\n"]}],"source":["# ============================================================================\n","# DEFINE FOCUSED HYPERPARAMETER SEARCH SPACE\n","# ============================================================================\n","\n","def define_hyperparameters(trial):\n","    \"\"\"\n","    Focused hyperparameter search for YOLO - only critical high-impact parameters.\n","\n","    Args:\n","        trial: Optuna trial object for sampling hyperparameters\n","\n","    Returns:\n","        dict: Dictionary of hyperparameters for YOLO training\n","\n","    Tuning Strategy:\n","    - Focus ONLY on parameters with proven high impact on performance\n","    - Use YOLO defaults for well-calibrated parameters (HSV, loss weights)\n","    - Reduces search space for faster convergence and better results\n","\n","    Critical Parameters Tuned:\n","    1. Image size (imgsz): 640, 768\n","    2. Batch size: Dynamically adjusted based on image size (96 for 640, 64 for 768)\n","    3. Optimizer choice (SGD/Adam/AdamW)\n","    4. Initial learning rate (lr0): 1e-4 to 5e-3\n","    5. Momentum/beta1: 0.85 to 0.97\n","    6. Weight decay (regularization): 1e-5 to 1e-3\n","    7. Warmup epochs: 0 to 3\n","    8. Warmup momentum: 0.5 to 0.95\n","    9. Warmup bias learning rate: 0.0 to 0.1\n","    10. Mosaic augmentation strength: 0.5 to 1.0\n","    11. Mixup augmentation strength: 0.0 to 0.2\n","    \"\"\"\n","\n","    if trial is None:\n","        raise ValueError(\"Trial object cannot be None\")\n","\n","    # ---------------------------\n","    # 1) Image Size\n","    # ---------------------------\n","    # Test different image sizes to find optimal accuracy/speed tradeoff\n","    image_size = trial.suggest_categorical('imgsz', [640, 768])\n","\n","    # ---------------------------\n","    # 2) Batch Size (Dynamic based on image size)\n","    # ---------------------------\n","    # Larger images require more memory, so reduce batch size accordingly\n","    if image_size == 640:\n","        batch_size = 86  # Standard batch size for 640x640\n","    else:  # 768\n","        batch_size = 56  # Reduced batch size for larger images\n","\n","    # ---------------------------\n","    # 3) Optimizer + Learning Rate\n","    # ---------------------------\n","    optimizer_choice = trial.suggest_categorical('optimizer', ['SGD', 'Adam', 'AdamW'])\n","    lr0 = trial.suggest_float('lr0', 1e-4, 5e-3, log=True)\n","\n","    # ---------------------------\n","    # 4) Regularization\n","    # ---------------------------\n","    momentum = trial.suggest_float('momentum', 0.85, 0.97)\n","    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n","\n","    # ---------------------------\n","    # 5) Warmup Configuration\n","    # ---------------------------\n","    warmup_epochs = trial.suggest_int('warmup_epochs', 0, 3)\n","    warmup_momentum = trial.suggest_float('warmup_momentum', 0.5, 0.95)\n","    warmup_bias_lr = trial.suggest_float('warmup_bias_lr', 0.0, 0.1)\n","\n","    # ---------------------------\n","    # 6) Key Augmentation\n","    # ---------------------------\n","    # Mosaic and mixup have the highest impact on performance\n","    mosaic = trial.suggest_float('mosaic', 0.5, 1.0)\n","    mixup = trial.suggest_float('mixup', 0.0, 0.2)\n","\n","    # ---------------------------\n","    # 7) Compile parameters\n","    # ---------------------------\n","    hyperparams = {\n","        # ===== TUNED PARAMETERS (Critical for performance) =====\n","        'imgsz': image_size,\n","        'batch': batch_size,\n","        'optimizer': optimizer_choice,\n","        'lr0': lr0,\n","        'momentum': momentum,\n","        'weight_decay': weight_decay,\n","        'warmup_epochs': warmup_epochs,\n","        'warmup_momentum': warmup_momentum,\n","        'warmup_bias_lr': warmup_bias_lr,\n","        'mosaic': mosaic,\n","        'mixup': mixup,\n","\n","        # ===== DEFAULT PARAMETERS (YOLO defaults work well) =====\n","        # Learning rate decay: default 0.01 is well-calibrated\n","        # HSV augmentation: defaults (0.015, 0.7, 0.4) are optimal for most cases\n","        # Spatial augmentation: defaults for scale/translate work well\n","        # Loss weights: YOLO defaults (7.5, 0.5, 1.5) are well-balanced\n","\n","        # ===== FIXED PARAMETERS =====\n","        'epochs': EPOCHS_PER_TRIAL,\n","        'device': device,\n","        'val': True,\n","        'patience': ModelConfig.DEFAULT_PATIENCE,\n","        'save': True,\n","        'plots': True,\n","        'cache': False,\n","        'workers': ModelConfig.DEFAULT_WORKERS,\n","        'close_mosaic': ModelConfig.CLOSE_MOSAIC_EPOCHS,\n","        'verbose': True,\n","    }\n","\n","    return hyperparams\n","\n","\n","print('‚úì Hyperparameter search space defined')\n","print('\\nüìä Focused Search Space Summary:')\n","print('  Strategy: Tune ONLY critical high-impact parameters')\n","print('  üéØ Tuned Parameters (11):')\n","print('    - Image Size (imgsz): 640, 768')\n","print('    - Batch Size: Dynamic (96 for 640, 64 for 768)')\n","print('    - Optimizer: SGD, Adam, AdamW')\n","print('    - Learning Rate (lr0): 1e-4 to 5e-3')\n","print('    - Momentum: 0.85 to 0.97')\n","print('    - Weight Decay: 1e-5 to 1e-3')\n","print('    - Warmup Epochs: 0 to 3')\n","print('    - Warmup Momentum: 0.5 to 0.95')\n","print('    - Warmup Bias LR: 0.0 to 0.1')\n","print('    - Mosaic: 0.5 to 1.0')\n","print('    - Mixup: 0.0 to 0.2')\n","print('  ‚öôÔ∏è  Fixed Parameters:')\n","print(f'    - Epochs: {EPOCHS_PER_TRIAL}')\n","print(f'    - Device: {device}')\n","print('  üìå Using YOLO defaults for: HSV augmentation, spatial transforms, loss weights')"]},{"cell_type":"markdown","id":"9a8326b5","metadata":{"id":"9a8326b5"},"source":["## 7. Define Objective Function"]},{"cell_type":"code","execution_count":12,"id":"c5575796","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c5575796","executionInfo":{"status":"ok","timestamp":1764530018317,"user_tz":-180,"elapsed":4,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"228ead17-5a2d-4e6d-8bf1-efbff300defd"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Objective function defined\n","  Returns: mAP@0.5 (validation set)\n","  Goal: Maximize validation performance\n"]}],"source":["# DEFINE OBJECTIVE FUNCTION FOR OPTUNA\n","# ============================================================================\n","\n","def objective(trial):\n","    \"\"\"Objective function for Optuna hyperparameter optimization.\n","\n","    Steps:\n","    1. Sample hyperparameters for the current trial\n","    2. Train a YOLO model with those hyperparameters\n","    3. Evaluate the model on the validation set\n","    4. Return validation mAP@0.5 (to maximize)\n","    \"\"\"\n","    # Get hyperparameters for this trial\n","    hyperparameters = define_hyperparameters(trial)\n","\n","    # Create trial-specific directory (absolute path under BASE_DIR)\n","    trial_dir = TUNE_DIR / f\"trial_{trial.number:03d}\"\n","    trial_dir.mkdir(exist_ok=True, parents=True)\n","\n","    # Initialize W&B if enabled\n","    wandb_run = None\n","    if USE_WANDB:\n","        try:\n","            os.environ['WANDB_DIR'] = str(trial_dir)\n","            wandb_run = wandb.init(\n","                project=WANDB_PROJECT_TUNING,\n","                name=f'{MODEL_NAME}_trial_{trial.number:03d}',\n","                config=hyperparameters,\n","                dir=str(trial_dir),\n","                reinit=True\n","            )\n","        except Exception as wandb_error:\n","            print(f'‚ö†Ô∏è  W&B initialization failed: {wandb_error}')\n","            wandb_run = None\n","\n","    # Print trial information\n","    print(f\"\\n{'=' * 80}\")\n","    print(f\"TRIAL {trial.number}/{N_TRIALS}\")\n","    print(f\"{'=' * 80}\")\n","    print(f\"üéØ Tuned Parameters:\")\n","    print(f\"  Image Size: {hyperparameters['imgsz']}\")\n","    print(f\"  Batch Size: {hyperparameters['batch']} (auto-adjusted for image size)\")\n","    print(f\"  Optimizer: {hyperparameters['optimizer']}\")\n","    print(f\"  Learning Rate: {hyperparameters['lr0']:.6f}\")\n","    print(f\"  Momentum: {hyperparameters['momentum']:.4f}\")\n","    print(f\"  Weight Decay: {hyperparameters['weight_decay']:.6f}\")\n","    print(f\"  Warmup: epochs={hyperparameters['warmup_epochs']}, momentum={hyperparameters['warmup_momentum']:.2f}, bias_lr={hyperparameters['warmup_bias_lr']:.3f}\")\n","    print(f\"  Mosaic: {hyperparameters['mosaic']:.2f}\")\n","    print(f\"  Mixup: {hyperparameters['mixup']:.2f}\")\n","    print(f\"‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\")\n","    print(f\"{'=' * 80}\")\n","\n","    trial_model = None\n","    map50 = 0.001  # Default penalty for failed trials\n","\n","    try:\n","        # Load fresh model for this trial\n","        trial_model = YOLO(str(model_path))\n","\n","        # Train model with hyperparameters (W&B integration via wandb.init)\n","        trial_run_name = f\"{MODEL_NAME}_trial_{trial.number:03d}\"\n","        train_results = trial_model.train(\n","            data=str(DATA_YAML_PATH),\n","            project=str(trial_dir),\n","            name=trial_run_name,\n","            exist_ok=True,\n","            **hyperparameters,\n","        )\n","\n","        # Validate model\n","        validation_results = trial_model.val(\n","            data=str(DATA_YAML_PATH),\n","            split=\"val\",\n","            project=str(trial_dir),\n","            name=\"val\",\n","            verbose=False,\n","        )\n","\n","        # Extract metrics\n","        map50 = float(validation_results.box.map50)\n","        map50_95 = float(validation_results.box.map)\n","        precision = float(validation_results.box.mp)\n","        recall = float(validation_results.box.mr)\n","\n","        # Save training metrics if available\n","        train_metrics = {}\n","        if hasattr(train_results, 'results_dict'):\n","            train_metrics = {key: float(value) if isinstance(value, (int,float,np.floating,np.integer)) else value\n","                             for key,value in train_results.results_dict.items()\n","                             if key not in ['fitness']}\n","\n","        # Save trial results JSON\n","        trial_results = {\n","            \"trial_number\": trial.number,\n","            \"model_name\": MODEL_NAME,\n","            \"dataset\": YOLO_DATASET_ROOT.name,\n","            \"trial_directory\": str(trial_dir),\n","            \"hyperparameters\": {k: float(v) if isinstance(v,(np.floating,np.integer)) else v for k,v in hyperparameters.items()},\n","            \"validation_metrics\": {\"map50\": map50, \"map50_95\": map50_95, \"precision\": precision, \"recall\": recall},\n","            \"training_metrics\": train_metrics,\n","            \"training_config\": {\n","                \"epochs\": EPOCHS_PER_TRIAL,\n","                \"batch_size\": hyperparameters['batch'],\n","                \"image_size\": hyperparameters['imgsz'],\n","                \"device\": device,\n","            },\n","            \"timestamp\": datetime.now().isoformat(),\n","            \"status\": \"completed\"\n","        }\n","\n","        trial_results_path = trial_dir / \"trial_results.json\"\n","        with open(trial_results_path, 'w', encoding='utf-8') as f:\n","            json.dump(trial_results, f, indent=2)\n","\n","        print(f'\\n‚úÖ Trial {trial.number} Completed')\n","        print(f'  mAP@0.5: {map50:.4f}')\n","        print(f'  mAP@0.5:0.95: {map50_95:.4f}')\n","        print(f'  Precision: {precision:.4f}')\n","        print(f'  Recall: {recall:.4f}')\n","\n","    except Exception as error:\n","        print(f'\\n‚ùå Trial {trial.number} Failed: {error}')\n","\n","        # Save error information\n","        trial_results = {\n","            \"trial_number\": trial.number,\n","            \"model_name\": MODEL_NAME,\n","            \"dataset\": YOLO_DATASET_ROOT.name,\n","            \"trial_directory\": str(trial_dir),\n","            \"hyperparameters\": {k: float(v) if isinstance(v,(np.floating,np.integer)) else v for k,v in hyperparameters.items()},\n","            \"error\": str(error),\n","            \"timestamp\": datetime.now().isoformat(),\n","            \"status\": \"failed\"\n","        }\n","\n","        trial_results_path = trial_dir / \"trial_results.json\"\n","        with open(trial_results_path, 'w', encoding='utf-8') as f:\n","            json.dump(trial_results, f, indent=2)\n","\n","        # Return small penalty value instead of raising exception\n","        map50 = 0.001\n","\n","    finally:\n","        # Clean up\n","        if wandb_run is not None:\n","            wandb_run.finish()\n","\n","        # Clean up trial model\n","        if trial_model is not None:\n","            del trial_model\n","\n","        # Force garbage collection\n","        gc.collect()\n","        if device == 'cuda':\n","            torch.cuda.empty_cache()\n","            print(\"üßπ CUDA cache cleared\")\n","\n","    return map50\n","\n","\n","print('‚úì Objective function defined')\n","print('  Returns: mAP@0.5 (validation set)')\n","print('  Goal: Maximize validation performance')"]},{"cell_type":"markdown","id":"b9b2c034","metadata":{"id":"b9b2c034"},"source":["## 8. Run Hyperparameter Optimization"]},{"cell_type":"code","execution_count":13,"id":"e116f130","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["fe0f955ee99240e786be66646cacf53e","a7fce8ea5b85463fbb8e9ef0d7eb0f47","1c93e639122044df94a6d2cfe37344c4","70abeb254ff149a8ba7daf119acaabac","1008697a7526419b9d9e6fb2c4a6421f","c0a89f83671d40eb972634a750df113e","d5370c35d848428ebc72d85425e9989a","0802427f78ea44c899da9657c18037b1","f0d05f9c154948c6b68513f4a7dc6738","53dd489e88704cf5b1119ba38f9deee6","7499f53af276404cb8c8c6bb64ae24df"]},"id":"e116f130","executionInfo":{"status":"ok","timestamp":1764555956052,"user_tz":-180,"elapsed":25937721,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"e173422e-2a50-46c6-976f-44c6c05cd6cb"},"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2025-11-30 19:13:38,667] A new study created in memory with name: yolo12s_optuna_20251130_191337\n"]},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","STARTING HYPERPARAMETER OPTIMIZATION\n","================================================================================\n","Model: yolo12s\n","Dataset: bdd100k_yolo_tuning\n","Number of Trials: 20\n","Epochs per Trial: 6\n","Timeout: 24 hours\n","Device: cuda\n","================================================================================\n","\n","üÜï Creating new optimization study\n","\n","üöÄ Optimization started at 2025-11-30 19:13:38\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe0f955ee99240e786be66646cacf53e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 0/20\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 56 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.000184\n","  Momentum: 0.8570\n","  Weight Decay: 0.000540\n","  Warmup: epochs=2, momentum=0.82, bias_lr=0.002\n","  Mosaic: 0.98\n","  Mixup: 0.17\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=56, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tmp/yolo12s/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=6, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00018408992080552527, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.16648852816008436, mode=train, model=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/models/yolo12s/yolo12s.pt, momentum=0.856970033460184, mosaic=0.9849549260809971, multi_scale=False, name=yolo12s_trial_000, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_000, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_000/yolo12s_trial_000, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0020584494295802446, warmup_epochs=2, warmup_momentum=0.8186326600082204, weight_decay=0.0005399484409787432, workers=8, workspace=None\n","Overriding model.yaml nc=80 with nc=10\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n","  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n","  6                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 4]        \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n","  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 11                  -1  1    345856  ultralytics.nn.modules.block.A2C2f           [768, 256, 1, False, -1]      \n"," 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 14                  -1  1     95104  ultralytics.nn.modules.block.A2C2f           [512, 128, 1, False, -1]      \n"," 15                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 17                  -1  1    296704  ultralytics.nn.modules.block.A2C2f           [384, 256, 1, False, -1]      \n"," 18                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 20                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n"," 21        [14, 17, 20]  1    823278  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n","YOLOv12s summary: 272 layers, 9,257,006 parameters, 9,256,990 gradients, 21.5 GFLOPs\n","\n","Transferred 685/691 items from pretrained weights\n","Freezing layer 'model.21.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1824.8¬±790.6 MB/s, size: 53.9 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 19.8Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 958.9¬±424.2 MB/s, size: 56.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 8.3Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_000/yolo12s_trial_000/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00018408992080552527, momentum=0.856970033460184) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.00047245488585640025), 119 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_000/yolo12s_trial_000\u001b[0m\n","Starting training for 6 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/6      38.2G      1.582       2.28      1.151       1666        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.6it/s 2:58\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 1.7it/s 54.5s\n","                   all      10000     185578      0.384      0.285      0.281      0.159\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/6      37.1G       1.45      1.167      1.083       1773        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:40\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.0it/s 45.0s\n","                   all      10000     185578      0.603      0.367      0.385      0.216\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/6      36.3G      1.416      1.057      1.059       1980        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:40\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 43.4s\n","                   all      10000     185578       0.63      0.382      0.412      0.233\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/6      37.6G      1.403      1.015      1.049       1531        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:40\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 43.3s\n","                   all      10000     185578      0.636      0.392      0.424       0.24\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/6      38.3G      1.394     0.9907      1.045       1914        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:40\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 43.0s\n","                   all      10000     185578      0.641      0.393      0.431      0.243\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/6      36.2G      1.389     0.9788      1.042       1907        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:40\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 43.3s\n","                   all      10000     185578      0.638      0.398      0.434      0.246\n","\n","6 epochs completed in 0.353 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_000/yolo12s_trial_000/weights/last.pt, 18.9MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_000/yolo12s_trial_000/weights/best.pt, 18.9MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_000/yolo12s_trial_000/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 1.7it/s 53.8s\n","                   all      10000     185578      0.639      0.398      0.434      0.246\n","                person       3220      13265      0.689      0.519      0.584      0.298\n","                 rider        515        649      0.534      0.339      0.348      0.175\n","                   car       9879     102540      0.749       0.64      0.718      0.439\n","                 truck       2689       4247      0.571      0.484      0.516      0.369\n","                   bus       1242       1597      0.557      0.468      0.503      0.392\n","                 train         14         15          1          0    0.00681     0.0031\n","                 motor        334        452      0.539      0.325      0.339      0.167\n","                  bike        578       1007       0.48      0.432       0.42      0.205\n","         traffic light       5653      26891      0.621      0.347      0.415      0.151\n","          traffic sign       8221      34915      0.648      0.429      0.495      0.258\n","Speed: 0.1ms preprocess, 0.9ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_000/yolo12s_trial_000\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1308.6¬±586.9 MB/s, size: 64.9 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 14.6Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 10.0it/s 1:02\n","                   all      10000     185578      0.637      0.399      0.435      0.246\n","Speed: 0.5ms preprocess, 1.7ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_000/val\u001b[0m\n","\n","‚úÖ Trial 0 Completed\n","  mAP@0.5: 0.4348\n","  mAP@0.5:0.95: 0.2463\n","  Precision: 0.6371\n","  Recall: 0.3991\n","üßπ CUDA cache cleared\n","[I 2025-11-30 19:37:25,360] Trial 0 finished with value: 0.43484521329474524 and parameters: {'imgsz': 768, 'optimizer': 'SGD', 'lr0': 0.00018408992080552527, 'momentum': 0.856970033460184, 'weight_decay': 0.0005399484409787432, 'warmup_epochs': 2, 'warmup_momentum': 0.8186326600082204, 'warmup_bias_lr': 0.0020584494295802446, 'mosaic': 0.9849549260809971, 'mixup': 0.16648852816008436}. Best is trial 0 with value: 0.43484521329474524.\n","\n","‚úì Completed 1/20 trials\n","\n","================================================================================\n","TRIAL 1/20\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 640\n","  Batch Size: 86 (auto-adjusted for image size)\n","  Optimizer: AdamW\n","  Learning Rate: 0.000542\n","  Momentum: 0.8849\n","  Weight Decay: 0.000167\n","  Warmup: epochs=0, momentum=0.63, bias_lr=0.037\n","  Mosaic: 0.73\n","  Mixup: 0.16\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=86, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tmp/yolo12s/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=6, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005418282319533242, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.15703519227860274, mode=train, model=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/models/yolo12s/yolo12s.pt, momentum=0.8849474968237651, mosaic=0.728034992108518, multi_scale=False, name=yolo12s_trial_001, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_001, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_001/yolo12s_trial_001, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.03663618432936917, warmup_epochs=0, warmup_momentum=0.6314650918408482, weight_decay=0.00016738085788752134, workers=8, workspace=None\n","Overriding model.yaml nc=80 with nc=10\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n","  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n","  6                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 4]        \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n","  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 11                  -1  1    345856  ultralytics.nn.modules.block.A2C2f           [768, 256, 1, False, -1]      \n"," 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 14                  -1  1     95104  ultralytics.nn.modules.block.A2C2f           [512, 128, 1, False, -1]      \n"," 15                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 17                  -1  1    296704  ultralytics.nn.modules.block.A2C2f           [384, 256, 1, False, -1]      \n"," 18                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 20                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n"," 21        [14, 17, 20]  1    823278  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n","YOLOv12s summary: 272 layers, 9,257,006 parameters, 9,256,990 gradients, 21.5 GFLOPs\n","\n","Transferred 685/691 items from pretrained weights\n","Freezing layer 'model.21.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1456.0¬±514.5 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 24.0Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 402.5¬±140.0 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 9.8Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_001/yolo12s_trial_001/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005418282319533242, momentum=0.8849474968237651) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.0002249180277863568), 119 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_001/yolo12s_trial_001\u001b[0m\n","Starting training for 6 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/6      36.8G      1.659      1.556      1.195       2015        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.5it/s 2:09\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.4it/s 43.4s\n","                   all      10000     185578      0.449      0.294      0.256      0.127\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/6      35.8G      1.504      1.065      1.102       1671        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.8it/s 1:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.5it/s 38.2s\n","                   all      10000     185578      0.517      0.329      0.316      0.163\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/6      35.8G      1.452     0.9915      1.074       1889        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.8it/s 1:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.5it/s 38.2s\n","                   all      10000     185578      0.546      0.347      0.342       0.18\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/6      36.7G      1.422     0.9466      1.058       1589        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.8it/s 1:46\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.5it/s 38.6s\n","                   all      10000     185578      0.581      0.369      0.376      0.198\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/6      38.9G      1.397     0.9122      1.045       1813        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.8it/s 1:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.6it/s 37.6s\n","                   all      10000     185578      0.607      0.378      0.398      0.215\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/6      36.2G      1.363     0.8736      1.029       1660        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.8it/s 1:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.6it/s 37.5s\n","                   all      10000     185578      0.631      0.388       0.42      0.229\n","\n","6 epochs completed in 0.253 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_001/yolo12s_trial_001/weights/last.pt, 18.9MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_001/yolo12s_trial_001/weights/best.pt, 18.9MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_001/yolo12s_trial_001/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.2it/s 48.9s\n","                   all      10000     185578      0.632      0.387       0.42      0.229\n","                person       3220      13265      0.678      0.465      0.531      0.255\n","                 rider        515        649      0.489      0.371      0.355      0.164\n","                   car       9879     102540       0.76       0.65      0.721      0.441\n","                 truck       2689       4247      0.562      0.484      0.504      0.351\n","                   bus       1242       1597       0.54      0.436      0.463      0.346\n","                 train         14         15          1          0   0.000301   0.000241\n","                 motor        334        452      0.468      0.281      0.281      0.129\n","                  bike        578       1007      0.415      0.376      0.344      0.157\n","         traffic light       5653      26891      0.683      0.387      0.472      0.172\n","          traffic sign       8221      34915      0.728      0.424      0.528      0.271\n","Speed: 0.1ms preprocess, 0.7ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_001/yolo12s_trial_001\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1421.9¬±540.6 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 14.4Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 11.2it/s 55.8s\n","                   all      10000     185578      0.632      0.389       0.42      0.229\n","Speed: 0.4ms preprocess, 1.2ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_001/val\u001b[0m\n","\n","‚úÖ Trial 1 Completed\n","  mAP@0.5: 0.4203\n","  mAP@0.5:0.95: 0.2294\n","  Precision: 0.6322\n","  Recall: 0.3889\n","üßπ CUDA cache cleared\n","[I 2025-11-30 19:54:43,658] Trial 1 finished with value: 0.4203132949811936 and parameters: {'imgsz': 640, 'optimizer': 'AdamW', 'lr0': 0.0005418282319533242, 'momentum': 0.8849474968237651, 'weight_decay': 0.00016738085788752134, 'warmup_epochs': 0, 'warmup_momentum': 0.6314650918408482, 'warmup_bias_lr': 0.03663618432936917, 'mosaic': 0.728034992108518, 'mixup': 0.15703519227860274}. Best is trial 0 with value: 0.43484521329474524.\n","\n","‚úì Completed 2/20 trials\n","\n","================================================================================\n","TRIAL 2/20\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 56 (auto-adjusted for image size)\n","  Optimizer: AdamW\n","  Learning Rate: 0.000195\n","  Momentum: 0.8578\n","  Weight Decay: 0.000790\n","  Warmup: epochs=3, momentum=0.86, bias_lr=0.030\n","  Mosaic: 0.55\n","  Mixup: 0.14\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=56, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tmp/yolo12s/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=6, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00019485671251272575, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.1368466053024314, mode=train, model=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/models/yolo12s/yolo12s.pt, momentum=0.8578061911582335, mosaic=0.5488360570031919, multi_scale=False, name=yolo12s_trial_002, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_002, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_002/yolo12s_trial_002, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.03046137691733707, warmup_epochs=3, warmup_momentum=0.8637788066524075, weight_decay=0.000790261954970823, workers=8, workspace=None\n","Overriding model.yaml nc=80 with nc=10\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n","  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n","  6                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 4]        \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n","  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 11                  -1  1    345856  ultralytics.nn.modules.block.A2C2f           [768, 256, 1, False, -1]      \n"," 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 14                  -1  1     95104  ultralytics.nn.modules.block.A2C2f           [512, 128, 1, False, -1]      \n"," 15                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 17                  -1  1    296704  ultralytics.nn.modules.block.A2C2f           [384, 256, 1, False, -1]      \n"," 18                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 20                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n"," 21        [14, 17, 20]  1    823278  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n","YOLOv12s summary: 272 layers, 9,257,006 parameters, 9,256,990 gradients, 21.5 GFLOPs\n","\n","Transferred 685/691 items from pretrained weights\n","Freezing layer 'model.21.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1680.3¬±484.6 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 23.8Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 365.2¬±114.3 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 10.2Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_002/yolo12s_trial_002/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00019485671251272575, momentum=0.8578061911582335) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.0006914792105994701), 119 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_002/yolo12s_trial_002\u001b[0m\n","Starting training for 6 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/6      36.1G      1.478       1.27      1.076       1317        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 43.4s\n","                   all      10000     185578      0.585      0.371       0.38      0.207\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/6      34.8G      1.425     0.9691      1.053       1205        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.4s\n","                   all      10000     185578      0.637      0.388      0.428      0.234\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/6      36.3G       1.41     0.9373       1.05       1577        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.6s\n","                   all      10000     185578      0.543      0.404      0.436      0.238\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/6      36.7G      1.398     0.9133      1.042       1201        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.6s\n","                   all      10000     185578      0.666      0.421      0.458      0.254\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/6      34.5G      1.369     0.8696      1.029       1465        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.5s\n","                   all      10000     185578      0.686      0.438      0.479      0.267\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/6      37.6G      1.346     0.8386      1.021       1259        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.1s\n","                   all      10000     185578       0.61      0.452      0.495      0.281\n","\n","6 epochs completed in 0.346 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_002/yolo12s_trial_002/weights/last.pt, 18.9MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_002/yolo12s_trial_002/weights/best.pt, 18.9MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_002/yolo12s_trial_002/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 1.7it/s 53.0s\n","                   all      10000     185578       0.61      0.452      0.495      0.281\n","                person       3220      13265      0.719      0.532      0.613      0.309\n","                 rider        515        649      0.514       0.43      0.423      0.219\n","                   car       9879     102540      0.785      0.671      0.757      0.467\n","                 truck       2689       4247      0.647      0.519      0.579      0.414\n","                   bus       1242       1597      0.593      0.534      0.565      0.435\n","                 train         14         15      0.288     0.0667     0.0328     0.0294\n","                 motor        334        452      0.482      0.414      0.385      0.192\n","                  bike        578       1007      0.627      0.389      0.452      0.227\n","         traffic light       5653      26891      0.702      0.459       0.54      0.203\n","          traffic sign       8221      34915      0.742      0.502      0.602      0.317\n","Speed: 0.1ms preprocess, 0.9ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_002/yolo12s_trial_002\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1352.9¬±466.6 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 12.3Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 10.1it/s 1:02\n","                   all      10000     185578      0.612      0.452      0.495      0.282\n","Speed: 0.5ms preprocess, 1.7ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_002/val\u001b[0m\n","\n","‚úÖ Trial 2 Completed\n","  mAP@0.5: 0.4952\n","  mAP@0.5:0.95: 0.2819\n","  Precision: 0.6117\n","  Recall: 0.4518\n","üßπ CUDA cache cleared\n","[I 2025-11-30 20:17:47,878] Trial 2 finished with value: 0.49519995833717695 and parameters: {'imgsz': 768, 'optimizer': 'AdamW', 'lr0': 0.00019485671251272575, 'momentum': 0.8578061911582335, 'weight_decay': 0.000790261954970823, 'warmup_epochs': 3, 'warmup_momentum': 0.8637788066524075, 'warmup_bias_lr': 0.03046137691733707, 'mosaic': 0.5488360570031919, 'mixup': 0.1368466053024314}. Best is trial 2 with value: 0.49519995833717695.\n","\n","‚úì Completed 3/20 trials\n","\n","================================================================================\n","TRIAL 3/20\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 640\n","  Batch Size: 86 (auto-adjusted for image size)\n","  Optimizer: AdamW\n","  Learning Rate: 0.000275\n","  Momentum: 0.9295\n","  Weight Decay: 0.000042\n","  Warmup: epochs=2, momentum=0.75, bias_lr=0.018\n","  Mosaic: 0.98\n","  Mixup: 0.16\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=86, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tmp/yolo12s/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=6, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00027520696850790545, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.15502656467222292, mode=train, model=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/models/yolo12s/yolo12s.pt, momentum=0.9295026741224778, mosaic=0.9847923138822793, multi_scale=False, name=yolo12s_trial_003, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_003, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_003/yolo12s_trial_003, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.018485445552552705, warmup_epochs=2, warmup_momentum=0.7460196257044758, weight_decay=4.201672054372529e-05, workers=8, workspace=None\n","Overriding model.yaml nc=80 with nc=10\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n","  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n","  6                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 4]        \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n","  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 11                  -1  1    345856  ultralytics.nn.modules.block.A2C2f           [768, 256, 1, False, -1]      \n"," 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 14                  -1  1     95104  ultralytics.nn.modules.block.A2C2f           [512, 128, 1, False, -1]      \n"," 15                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 17                  -1  1    296704  ultralytics.nn.modules.block.A2C2f           [384, 256, 1, False, -1]      \n"," 18                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 20                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n"," 21        [14, 17, 20]  1    823278  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n","YOLOv12s summary: 272 layers, 9,257,006 parameters, 9,256,990 gradients, 21.5 GFLOPs\n","\n","Transferred 685/691 items from pretrained weights\n","Freezing layer 'model.21.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1754.5¬±805.8 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 24.5Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 522.1¬±337.9 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 11.4Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_003/yolo12s_trial_003/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00027520696850790545, momentum=0.9295026741224778) with parameter groups 113 weight(decay=0.0), 120 weight(decay=5.645996823063086e-05), 119 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_003/yolo12s_trial_003\u001b[0m\n","Starting training for 6 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/6      35.1G      1.478      1.376      1.064       2679        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.7it/s 1:50\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.5it/s 38.5s\n","                   all      10000     185578      0.605       0.35      0.372      0.203\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/6      38.1G       1.42     0.9739      1.038       2350        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.8it/s 1:46\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.5it/s 38.1s\n","                   all      10000     185578      0.476       0.37      0.376      0.203\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/6      37.8G      1.401     0.9397       1.03       2017        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.8it/s 1:46\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.6it/s 37.8s\n","                   all      10000     185578      0.625      0.379        0.4      0.218\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/6      38.8G      1.376     0.8997       1.02       2490        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.8it/s 1:46\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.6it/s 37.9s\n","                   all      10000     185578      0.636      0.393      0.421      0.231\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/6        34G      1.353     0.8672      1.009       2586        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.8it/s 1:46\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.6it/s 37.5s\n","                   all      10000     185578      0.652      0.408       0.44      0.245\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/6      36.7G      1.331     0.8342          1       2167        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.8it/s 1:46\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.6it/s 37.9s\n","                   all      10000     185578      0.571      0.413      0.455      0.254\n","\n","6 epochs completed in 0.247 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_003/yolo12s_trial_003/weights/last.pt, 18.9MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_003/yolo12s_trial_003/weights/best.pt, 18.9MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_003/yolo12s_trial_003/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.2it/s 49.3s\n","                   all      10000     185578      0.571      0.414      0.455      0.254\n","                person       3220      13265      0.735      0.464      0.556      0.274\n","                 rider        515        649      0.511      0.404      0.392      0.195\n","                   car       9879     102540      0.791      0.637      0.725      0.445\n","                 truck       2689       4247      0.658      0.472      0.554      0.393\n","                   bus       1242       1597      0.539      0.526      0.532      0.409\n","                 train         14         15          0          0     0.0011   0.000766\n","                 motor        334        452      0.537      0.374      0.351      0.165\n","                  bike        578       1007      0.488      0.431      0.412      0.198\n","         traffic light       5653      26891       0.71      0.388      0.484      0.177\n","          traffic sign       8221      34915      0.738      0.442      0.544      0.282\n","Speed: 0.1ms preprocess, 0.7ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_003/yolo12s_trial_003\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1367.3¬±477.3 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 16.2Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 11.1it/s 56.2s\n","                   all      10000     185578       0.57      0.413      0.454      0.254\n","Speed: 0.4ms preprocess, 1.2ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_003/val\u001b[0m\n","\n","‚úÖ Trial 3 Completed\n","  mAP@0.5: 0.4544\n","  mAP@0.5:0.95: 0.2544\n","  Precision: 0.5704\n","  Recall: 0.4134\n","üßπ CUDA cache cleared\n","[I 2025-11-30 20:34:44,859] Trial 3 finished with value: 0.45441687794687446 and parameters: {'imgsz': 640, 'optimizer': 'AdamW', 'lr0': 0.00027520696850790545, 'momentum': 0.9295026741224778, 'weight_decay': 4.201672054372529e-05, 'warmup_epochs': 2, 'warmup_momentum': 0.7460196257044758, 'warmup_bias_lr': 0.018485445552552705, 'mosaic': 0.9847923138822793, 'mixup': 0.15502656467222292}. Best is trial 2 with value: 0.49519995833717695.\n","\n","‚úì Completed 4/20 trials\n","\n","================================================================================\n","TRIAL 4/20\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 640\n","  Batch Size: 86 (auto-adjusted for image size)\n","  Optimizer: AdamW\n","  Learning Rate: 0.000120\n","  Momentum: 0.8752\n","  Weight Decay: 0.000856\n","  Warmup: epochs=3, momentum=0.83, bias_lr=0.019\n","  Mosaic: 0.57\n","  Mixup: 0.14\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=86, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tmp/yolo12s/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=6, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00012019462074072741, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.14260259077459436, mode=train, model=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/models/yolo12s/yolo12s.pt, momentum=0.8751994424704447, mosaic=0.5719899949745945, multi_scale=False, name=yolo12s_trial_004, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_004, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_004/yolo12s_trial_004, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.01867742913680949, warmup_epochs=3, warmup_momentum=0.8300113009765738, weight_decay=0.0008564246077898465, workers=8, workspace=None\n","Overriding model.yaml nc=80 with nc=10\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n","  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n","  6                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 4]        \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n","  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 11                  -1  1    345856  ultralytics.nn.modules.block.A2C2f           [768, 256, 1, False, -1]      \n"," 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 14                  -1  1     95104  ultralytics.nn.modules.block.A2C2f           [512, 128, 1, False, -1]      \n"," 15                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 17                  -1  1    296704  ultralytics.nn.modules.block.A2C2f           [384, 256, 1, False, -1]      \n"," 18                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 20                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n"," 21        [14, 17, 20]  1    823278  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n","YOLOv12s summary: 272 layers, 9,257,006 parameters, 9,256,990 gradients, 21.5 GFLOPs\n","\n","Transferred 685/691 items from pretrained weights\n","Freezing layer 'model.21.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1625.0¬±692.1 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 22.5Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 436.9¬±98.1 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 9.6Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_004/yolo12s_trial_004/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00012019462074072741, momentum=0.8751994424704447) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.0011508205667176063), 119 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_004/yolo12s_trial_004\u001b[0m\n","Starting training for 6 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/6      38.7G      1.489      1.447      1.059       2025        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.7it/s 1:50\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.5it/s 39.2s\n","                   all      10000     185578      0.578      0.341       0.35      0.196\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/6      37.1G      1.412     0.9663      1.027       1948        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.8it/s 1:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.5it/s 38.2s\n","                   all      10000     185578      0.617      0.359      0.388      0.218\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/6      36.9G      1.388     0.9195      1.017       1748        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.8it/s 1:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.6it/s 37.8s\n","                   all      10000     185578      0.635       0.38      0.416      0.234\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/6      37.2G      1.373     0.8938      1.014       2043        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.8it/s 1:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.6it/s 37.8s\n","                   all      10000     185578      0.639      0.391      0.424      0.236\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/6      32.9G       1.35      0.861      1.003       1627        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.8it/s 1:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.6it/s 38.0s\n","                   all      10000     185578       0.66      0.407      0.439      0.247\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/6      34.1G      1.336     0.8386     0.9961       1977        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.8it/s 1:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.6it/s 37.6s\n","                   all      10000     185578      0.659      0.417      0.451      0.254\n","\n","6 epochs completed in 0.246 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_004/yolo12s_trial_004/weights/last.pt, 18.9MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_004/yolo12s_trial_004/weights/best.pt, 18.9MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_004/yolo12s_trial_004/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.2it/s 49.3s\n","                   all      10000     185578       0.66      0.417      0.451      0.254\n","                person       3220      13265      0.713      0.482      0.559      0.279\n","                 rider        515        649      0.605      0.373       0.39      0.196\n","                   car       9879     102540      0.749      0.648      0.718       0.44\n","                 truck       2689       4247      0.539      0.545      0.537      0.387\n","                   bus       1242       1597      0.571      0.506      0.526      0.406\n","                 train         14         15          1          0    0.00627    0.00572\n","                 motor        334        452      0.529      0.378      0.385      0.186\n","                  bike        578       1007      0.528      0.403       0.41        0.2\n","         traffic light       5653      26891      0.665      0.389      0.453      0.164\n","          traffic sign       8221      34915      0.696       0.45      0.523      0.272\n","Speed: 0.1ms preprocess, 0.7ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_004/yolo12s_trial_004\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1192.4¬±448.6 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 15.1Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 11.0it/s 56.6s\n","                   all      10000     185578      0.661      0.417      0.451      0.254\n","Speed: 0.4ms preprocess, 1.3ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_004/val\u001b[0m\n","\n","‚úÖ Trial 4 Completed\n","  mAP@0.5: 0.4514\n","  mAP@0.5:0.95: 0.2542\n","  Precision: 0.6608\n","  Recall: 0.4172\n","üßπ CUDA cache cleared\n","[I 2025-11-30 20:51:37,693] Trial 4 finished with value: 0.4513530237178009 and parameters: {'imgsz': 640, 'optimizer': 'AdamW', 'lr0': 0.00012019462074072741, 'momentum': 0.8751994424704447, 'weight_decay': 0.0008564246077898465, 'warmup_epochs': 3, 'warmup_momentum': 0.8300113009765738, 'warmup_bias_lr': 0.01867742913680949, 'mosaic': 0.5719899949745945, 'mixup': 0.14260259077459436}. Best is trial 2 with value: 0.49519995833717695.\n","\n","‚úì Completed 5/20 trials\n","\n","================================================================================\n","TRIAL 5/20\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 56 (auto-adjusted for image size)\n","  Optimizer: AdamW\n","  Learning Rate: 0.000464\n","  Momentum: 0.9086\n","  Weight Decay: 0.000711\n","  Warmup: epochs=3, momentum=0.95, bias_lr=0.041\n","  Mosaic: 0.79\n","  Mixup: 0.09\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=56, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tmp/yolo12s/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=6, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00046416276498162026, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.09142805368635637, mode=train, model=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/models/yolo12s/yolo12s.pt, momentum=0.9085534257456573, mosaic=0.7922202551639732, multi_scale=False, name=yolo12s_trial_005, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_005, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_005/yolo12s_trial_005, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.04132450636848238, warmup_epochs=3, warmup_momentum=0.9456949457865867, weight_decay=0.0007114668138090497, workers=8, workspace=None\n","Overriding model.yaml nc=80 with nc=10\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n","  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n","  6                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 4]        \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n","  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 11                  -1  1    345856  ultralytics.nn.modules.block.A2C2f           [768, 256, 1, False, -1]      \n"," 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 14                  -1  1     95104  ultralytics.nn.modules.block.A2C2f           [512, 128, 1, False, -1]      \n"," 15                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 17                  -1  1    296704  ultralytics.nn.modules.block.A2C2f           [384, 256, 1, False, -1]      \n"," 18                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 20                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n"," 21        [14, 17, 20]  1    823278  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n","YOLOv12s summary: 272 layers, 9,257,006 parameters, 9,256,990 gradients, 21.5 GFLOPs\n","\n","Transferred 685/691 items from pretrained weights\n","Freezing layer 'model.21.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1655.9¬±621.7 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 24.2Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 664.3¬±513.3 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 5.4Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_005/yolo12s_trial_005/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00046416276498162026, momentum=0.9085534257456573) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.0006225334620829185), 119 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_005/yolo12s_trial_005\u001b[0m\n","Starting training for 6 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/6        34G      1.461      1.219      1.072       1589        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 43.3s\n","                   all      10000     185578      0.592      0.359      0.376      0.199\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/6      34.4G       1.44     0.9913      1.065       1552        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 43.1s\n","                   all      10000     185578        0.6      0.369      0.389      0.206\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/6      38.6G      1.433       0.97      1.062       1310        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.9s\n","                   all      10000     185578      0.601      0.374      0.386      0.205\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/6      34.1G      1.412      0.939      1.055       1332        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.5s\n","                   all      10000     185578      0.646      0.405      0.437      0.236\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/6      35.3G      1.375     0.8868      1.037       2027        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.3s\n","                   all      10000     185578       0.67      0.428      0.466      0.257\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/6      36.6G      1.344     0.8416      1.022       1515        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.2s\n","                   all      10000     185578      0.671      0.442      0.482      0.269\n","\n","6 epochs completed in 0.347 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_005/yolo12s_trial_005/weights/last.pt, 18.9MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_005/yolo12s_trial_005/weights/best.pt, 18.9MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_005/yolo12s_trial_005/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 1.7it/s 53.1s\n","                   all      10000     185578      0.671      0.442      0.482      0.269\n","                person       3220      13265      0.727      0.505      0.594      0.295\n","                 rider        515        649      0.508      0.419      0.414      0.209\n","                   car       9879     102540      0.803       0.66      0.758      0.466\n","                 truck       2689       4247       0.57      0.553      0.566      0.403\n","                   bus       1242       1597      0.583      0.508      0.537      0.409\n","                 train         14         15          1          0    0.00146   0.000955\n","                 motor        334        452      0.537      0.372      0.371      0.179\n","                  bike        578       1007      0.591       0.38      0.428      0.212\n","         traffic light       5653      26891      0.677      0.492      0.546      0.202\n","          traffic sign       8221      34915      0.715      0.527      0.604      0.318\n","Speed: 0.1ms preprocess, 0.9ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_005/yolo12s_trial_005\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1247.8¬±511.0 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 15.9Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 10.1it/s 1:02\n","                   all      10000     185578      0.673      0.442      0.483       0.27\n","Speed: 0.5ms preprocess, 1.7ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_005/val\u001b[0m\n","\n","‚úÖ Trial 5 Completed\n","  mAP@0.5: 0.4829\n","  mAP@0.5:0.95: 0.2700\n","  Precision: 0.6734\n","  Recall: 0.4417\n","üßπ CUDA cache cleared\n","[I 2025-11-30 21:14:43,027] Trial 5 finished with value: 0.4828743932038234 and parameters: {'imgsz': 768, 'optimizer': 'AdamW', 'lr0': 0.00046416276498162026, 'momentum': 0.9085534257456573, 'weight_decay': 0.0007114668138090497, 'warmup_epochs': 3, 'warmup_momentum': 0.9456949457865867, 'warmup_bias_lr': 0.04132450636848238, 'mosaic': 0.7922202551639732, 'mixup': 0.09142805368635637}. Best is trial 2 with value: 0.49519995833717695.\n","\n","‚úì Completed 6/20 trials\n","\n","================================================================================\n","TRIAL 6/20\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 56 (auto-adjusted for image size)\n","  Optimizer: AdamW\n","  Learning Rate: 0.000797\n","  Momentum: 0.8643\n","  Weight Decay: 0.000399\n","  Warmup: epochs=2, momentum=0.73, bias_lr=0.027\n","  Mosaic: 0.58\n","  Mixup: 0.08\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=56, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tmp/yolo12s/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=6, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0007972913946637024, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.07855187248221054, mode=train, model=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/models/yolo12s/yolo12s.pt, momentum=0.8642533694603853, mosaic=0.5836788629401141, multi_scale=False, name=yolo12s_trial_006, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_006, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_006/yolo12s_trial_006, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.027103902028703965, warmup_epochs=2, warmup_momentum=0.7287380269749706, weight_decay=0.0003991310852882529, workers=8, workspace=None\n","Overriding model.yaml nc=80 with nc=10\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n","  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n","  6                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 4]        \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n","  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 11                  -1  1    345856  ultralytics.nn.modules.block.A2C2f           [768, 256, 1, False, -1]      \n"," 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 14                  -1  1     95104  ultralytics.nn.modules.block.A2C2f           [512, 128, 1, False, -1]      \n"," 15                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 17                  -1  1    296704  ultralytics.nn.modules.block.A2C2f           [384, 256, 1, False, -1]      \n"," 18                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 20                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n"," 21        [14, 17, 20]  1    823278  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n","YOLOv12s summary: 272 layers, 9,257,006 parameters, 9,256,990 gradients, 21.5 GFLOPs\n","\n","Transferred 685/691 items from pretrained weights\n","Freezing layer 'model.21.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1599.8¬±609.9 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 20.8Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 485.4¬±127.1 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 7.1Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_006/yolo12s_trial_006/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0007972913946637024, momentum=0.8642533694603853) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.0003492396996272213), 119 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_006/yolo12s_trial_006\u001b[0m\n","Starting training for 6 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/6      37.7G      1.496      1.251      1.089       1346        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.0it/s 45.7s\n","                   all      10000     185578      0.375      0.343      0.305      0.155\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/6      36.2G      1.515      1.082      1.105       1375        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.4s\n","                   all      10000     185578      0.515      0.314      0.306      0.154\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/6      38.1G      1.487      1.032       1.09       1347        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:40\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 43.0s\n","                   all      10000     185578       0.57       0.36      0.363       0.19\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/6      37.9G      1.436     0.9635      1.066       1292        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.9s\n","                   all      10000     185578       0.62      0.389      0.406      0.217\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/6      34.1G      1.396      0.907      1.047       1136        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.3s\n","                   all      10000     185578      0.638      0.412      0.439       0.24\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/6      37.6G      1.364     0.8623      1.031       1327        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.3s\n","                   all      10000     185578      0.671      0.429       0.47       0.26\n","\n","6 epochs completed in 0.346 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_006/yolo12s_trial_006/weights/last.pt, 18.9MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_006/yolo12s_trial_006/weights/best.pt, 18.9MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_006/yolo12s_trial_006/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 1.7it/s 52.7s\n","                   all      10000     185578      0.671      0.429       0.47      0.261\n","                person       3220      13265      0.722      0.489      0.581      0.286\n","                 rider        515        649      0.584      0.362      0.397      0.198\n","                   car       9879     102540      0.771      0.676      0.754      0.462\n","                 truck       2689       4247      0.527      0.552      0.548      0.386\n","                   bus       1242       1597      0.609      0.492      0.531      0.398\n","                 train         14         15          1          0   0.000468   0.000205\n","                 motor        334        452      0.407      0.396       0.34      0.163\n","                  bike        578       1007      0.679      0.338       0.41      0.203\n","         traffic light       5653      26891      0.691      0.474      0.547        0.2\n","          traffic sign       8221      34915      0.721       0.51      0.593       0.31\n","Speed: 0.1ms preprocess, 0.9ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_006/yolo12s_trial_006\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1357.2¬±440.9 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 15.0Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 10.1it/s 1:02\n","                   all      10000     185578      0.672      0.429       0.47      0.261\n","Speed: 0.5ms preprocess, 1.7ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_006/val\u001b[0m\n","\n","‚úÖ Trial 6 Completed\n","  mAP@0.5: 0.4703\n","  mAP@0.5:0.95: 0.2609\n","  Precision: 0.6724\n","  Recall: 0.4287\n","üßπ CUDA cache cleared\n","[I 2025-11-30 21:37:46,798] Trial 6 finished with value: 0.47032618423038625 and parameters: {'imgsz': 768, 'optimizer': 'AdamW', 'lr0': 0.0007972913946637024, 'momentum': 0.8642533694603853, 'weight_decay': 0.0003991310852882529, 'warmup_epochs': 2, 'warmup_momentum': 0.7287380269749706, 'warmup_bias_lr': 0.027103902028703965, 'mosaic': 0.5836788629401141, 'mixup': 0.07855187248221054}. Best is trial 2 with value: 0.49519995833717695.\n","\n","‚úì Completed 7/20 trials\n","\n","================================================================================\n","TRIAL 7/20\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 640\n","  Batch Size: 86 (auto-adjusted for image size)\n","  Optimizer: Adam\n","  Learning Rate: 0.000207\n","  Momentum: 0.9130\n","  Weight Decay: 0.000382\n","  Warmup: epochs=2, momentum=0.87, bias_lr=0.076\n","  Mosaic: 0.53\n","  Mixup: 0.08\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=86, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tmp/yolo12s/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=6, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00020733019435489495, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.07685297042243353, mode=train, model=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/models/yolo12s/yolo12s.pt, momentum=0.9129593478682302, mosaic=0.5252312452310752, multi_scale=False, name=yolo12s_trial_007, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_007, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_007/yolo12s_trial_007, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.07630371691058041, warmup_epochs=2, warmup_momentum=0.8695154725469569, weight_decay=0.00038165556248635226, workers=8, workspace=None\n","Overriding model.yaml nc=80 with nc=10\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n","  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n","  6                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 4]        \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n","  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 11                  -1  1    345856  ultralytics.nn.modules.block.A2C2f           [768, 256, 1, False, -1]      \n"," 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 14                  -1  1     95104  ultralytics.nn.modules.block.A2C2f           [512, 128, 1, False, -1]      \n"," 15                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 17                  -1  1    296704  ultralytics.nn.modules.block.A2C2f           [384, 256, 1, False, -1]      \n"," 18                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 20                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n"," 21        [14, 17, 20]  1    823278  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n","YOLOv12s summary: 272 layers, 9,257,006 parameters, 9,256,990 gradients, 21.5 GFLOPs\n","\n","Transferred 685/691 items from pretrained weights\n","Freezing layer 'model.21.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1911.8¬±725.3 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 24.8Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 471.6¬±92.7 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 8.9Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_007/yolo12s_trial_007/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.00020733019435489495, momentum=0.9129593478682302) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.0005128496620910359), 119 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_007/yolo12s_trial_007\u001b[0m\n","Starting training for 6 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/6      34.1G      1.469        1.3      1.054       1352        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.7it/s 1:50\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.6it/s 37.9s\n","                   all      10000     185578      0.575       0.32      0.338      0.185\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/6      33.5G      1.413     0.9567      1.033       1522        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.8it/s 1:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.5it/s 38.8s\n","                   all      10000     185578      0.586      0.352      0.371        0.2\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/6      35.8G      1.388     0.9157      1.023       1539        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.8it/s 1:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.6it/s 37.7s\n","                   all      10000     185578      0.638      0.374      0.405       0.22\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/6      36.8G      1.368     0.8783      1.013       1779        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.8it/s 1:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.5it/s 38.3s\n","                   all      10000     185578      0.653      0.388      0.421      0.232\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/6        38G      1.338      0.839      1.001       1503        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.8it/s 1:44\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.6it/s 38.1s\n","                   all      10000     185578      0.655      0.404       0.44      0.245\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/6      35.4G      1.321     0.8153     0.9934       1727        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.8it/s 1:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.6it/s 37.5s\n","                   all      10000     185578      0.653      0.416      0.451      0.253\n","\n","6 epochs completed in 0.245 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_007/yolo12s_trial_007/weights/last.pt, 18.9MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_007/yolo12s_trial_007/weights/best.pt, 18.9MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_007/yolo12s_trial_007/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.2it/s 49.2s\n","                   all      10000     185578      0.653      0.417      0.451      0.253\n","                person       3220      13265      0.714      0.476      0.559      0.276\n","                 rider        515        649      0.559      0.391        0.4      0.192\n","                   car       9879     102540      0.796      0.624      0.722      0.444\n","                 truck       2689       4247      0.652      0.458      0.531      0.384\n","                   bus       1242       1597      0.509      0.525      0.526      0.401\n","                 train         14         15          1          0     0.0014    0.00102\n","                 motor        334        452      0.504      0.356      0.356      0.182\n","                  bike        578       1007      0.473      0.448      0.411      0.197\n","         traffic light       5653      26891      0.662      0.408      0.472      0.173\n","          traffic sign       8221      34915      0.661      0.478      0.531      0.276\n","Speed: 0.1ms preprocess, 0.7ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_007/yolo12s_trial_007\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1388.6¬±497.1 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 17.6Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 11.1it/s 56.2s\n","                   all      10000     185578      0.653      0.416      0.451      0.253\n","Speed: 0.4ms preprocess, 1.2ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_007/val\u001b[0m\n","\n","‚úÖ Trial 7 Completed\n","  mAP@0.5: 0.4506\n","  mAP@0.5:0.95: 0.2531\n","  Precision: 0.6527\n","  Recall: 0.4163\n","üßπ CUDA cache cleared\n","[I 2025-11-30 21:54:37,943] Trial 7 finished with value: 0.45059784127625296 and parameters: {'imgsz': 640, 'optimizer': 'Adam', 'lr0': 0.00020733019435489495, 'momentum': 0.9129593478682302, 'weight_decay': 0.00038165556248635226, 'warmup_epochs': 2, 'warmup_momentum': 0.8695154725469569, 'warmup_bias_lr': 0.07630371691058041, 'mosaic': 0.5252312452310752, 'mixup': 0.07685297042243353}. Best is trial 2 with value: 0.49519995833717695.\n","\n","‚úì Completed 8/20 trials\n","\n","================================================================================\n","TRIAL 8/20\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 56 (auto-adjusted for image size)\n","  Optimizer: AdamW\n","  Learning Rate: 0.000486\n","  Momentum: 0.9150\n","  Weight Decay: 0.000459\n","  Warmup: epochs=2, momentum=0.67, bias_lr=0.066\n","  Mosaic: 0.57\n","  Mixup: 0.20\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=56, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tmp/yolo12s/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=6, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00048582040249237995, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.19612651086969135, mode=train, model=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/models/yolo12s/yolo12s.pt, momentum=0.9150047365325835, mosaic=0.5706004578234427, multi_scale=False, name=yolo12s_trial_008, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_008, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_008/yolo12s_trial_008, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.06605121320956418, warmup_epochs=2, warmup_momentum=0.6731002420462724, weight_decay=0.0004591891660849751, workers=8, workspace=None\n","Overriding model.yaml nc=80 with nc=10\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n","  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n","  6                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 4]        \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n","  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 11                  -1  1    345856  ultralytics.nn.modules.block.A2C2f           [768, 256, 1, False, -1]      \n"," 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 14                  -1  1     95104  ultralytics.nn.modules.block.A2C2f           [512, 128, 1, False, -1]      \n"," 15                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 17                  -1  1    296704  ultralytics.nn.modules.block.A2C2f           [384, 256, 1, False, -1]      \n"," 18                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 20                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n"," 21        [14, 17, 20]  1    823278  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n","YOLOv12s summary: 272 layers, 9,257,006 parameters, 9,256,990 gradients, 21.5 GFLOPs\n","\n","Transferred 685/691 items from pretrained weights\n","Freezing layer 'model.21.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1698.2¬±680.3 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 23.1Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 399.7¬±62.7 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 10.1Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_008/yolo12s_trial_008/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00048582040249237995, momentum=0.9150047365325835) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.00040179052032435317), 119 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_008/yolo12s_trial_008\u001b[0m\n","Starting training for 6 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/6      34.2G      1.513      1.255      1.096       1767        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:46\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 43.6s\n","                   all      10000     185578      0.527      0.326       0.32      0.171\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/6      36.8G      1.505      1.068        1.1       1325        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 43.5s\n","                   all      10000     185578      0.553      0.339      0.341      0.175\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/6      35.4G      1.484      1.025      1.088       1468        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 43.1s\n","                   all      10000     185578      0.597      0.376      0.394      0.207\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/6      36.9G      1.445     0.9673      1.067       1399        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.8s\n","                   all      10000     185578      0.649        0.4      0.432      0.233\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/6        36G      1.408     0.9179      1.053       1396        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.6s\n","                   all      10000     185578      0.668      0.419      0.458       0.25\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/6      38.1G      1.376     0.8734      1.037       1494        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.6s\n","                   all      10000     185578      0.678      0.437      0.479      0.265\n","\n","6 epochs completed in 0.348 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_008/yolo12s_trial_008/weights/last.pt, 18.9MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_008/yolo12s_trial_008/weights/best.pt, 18.9MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_008/yolo12s_trial_008/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 1.7it/s 53.3s\n","                   all      10000     185578      0.678      0.436      0.479      0.265\n","                person       3220      13265      0.795      0.459      0.586      0.292\n","                 rider        515        649      0.505      0.411      0.396      0.197\n","                   car       9879     102540      0.793      0.664      0.756      0.461\n","                 truck       2689       4247      0.598      0.528      0.554      0.391\n","                   bus       1242       1597      0.581      0.512       0.54      0.403\n","                 train         14         15          1          0    0.00217    0.00148\n","                 motor        334        452      0.478      0.413      0.374      0.174\n","                  bike        578       1007      0.581      0.402      0.427       0.21\n","         traffic light       5653      26891      0.715      0.461      0.552      0.206\n","          traffic sign       8221      34915      0.732      0.513      0.604      0.315\n","Speed: 0.1ms preprocess, 0.9ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_008/yolo12s_trial_008\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1115.4¬±571.2 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 12.8Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 10.0it/s 1:03\n","                   all      10000     185578      0.678      0.438       0.48      0.266\n","Speed: 0.5ms preprocess, 1.7ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_008/val\u001b[0m\n","\n","‚úÖ Trial 8 Completed\n","  mAP@0.5: 0.4796\n","  mAP@0.5:0.95: 0.2657\n","  Precision: 0.6777\n","  Recall: 0.4378\n","üßπ CUDA cache cleared\n","[I 2025-11-30 22:17:49,128] Trial 8 finished with value: 0.4796248079552948 and parameters: {'imgsz': 768, 'optimizer': 'AdamW', 'lr0': 0.00048582040249237995, 'momentum': 0.9150047365325835, 'weight_decay': 0.0004591891660849751, 'warmup_epochs': 2, 'warmup_momentum': 0.6731002420462724, 'warmup_bias_lr': 0.06605121320956418, 'mosaic': 0.5706004578234427, 'mixup': 0.19612651086969135}. Best is trial 2 with value: 0.49519995833717695.\n","\n","‚úì Completed 9/20 trials\n","\n","================================================================================\n","TRIAL 9/20\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 56 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.000132\n","  Momentum: 0.8917\n","  Weight Decay: 0.000365\n","  Warmup: epochs=3, momentum=0.71, bias_lr=0.040\n","  Mosaic: 0.50\n","  Mixup: 0.02\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=56, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tmp/yolo12s/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=6, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001315505817621954, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.023307356647408295, mode=train, model=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/models/yolo12s/yolo12s.pt, momentum=0.891670669037609, mosaic=0.5015345090954606, multi_scale=False, name=yolo12s_trial_009, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_009, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_009/yolo12s_trial_009, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.039587848873917364, warmup_epochs=3, warmup_momentum=0.7134500399234733, weight_decay=0.0003654114491446343, workers=8, workspace=None\n","Overriding model.yaml nc=80 with nc=10\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n","  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n","  6                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 4]        \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n","  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 11                  -1  1    345856  ultralytics.nn.modules.block.A2C2f           [768, 256, 1, False, -1]      \n"," 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 14                  -1  1     95104  ultralytics.nn.modules.block.A2C2f           [512, 128, 1, False, -1]      \n"," 15                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 17                  -1  1    296704  ultralytics.nn.modules.block.A2C2f           [384, 256, 1, False, -1]      \n"," 18                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 20                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n"," 21        [14, 17, 20]  1    823278  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n","YOLOv12s summary: 272 layers, 9,257,006 parameters, 9,256,990 gradients, 21.5 GFLOPs\n","\n","Transferred 685/691 items from pretrained weights\n","Freezing layer 'model.21.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1628.3¬±601.9 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 24.2Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 503.9¬±140.9 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 11.9Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_009/yolo12s_trial_009/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0001315505817621954, momentum=0.891670669037609) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.00031973501800155503), 119 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_009/yolo12s_trial_009\u001b[0m\n","Starting training for 6 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/6      38.8G      1.565      2.686      1.132       1282        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 1.8it/s 49.5s\n","                   all      10000     185578      0.234      0.188      0.172     0.0905\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/6      38.8G      1.451      1.283      1.084       1400        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:39\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.0it/s 45.7s\n","                   all      10000     185578      0.418      0.299      0.311      0.175\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/6      37.2G      1.411        1.1      1.057       1016        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.9it/s 2:38\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.0it/s 44.5s\n","                   all      10000     185578      0.606      0.358      0.382      0.214\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/6      37.5G       1.39      1.027      1.042       1253        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:39\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 43.6s\n","                   all      10000     185578      0.621      0.374      0.402      0.227\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/6      38.6G      1.378     0.9944      1.034       1002        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:39\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 43.7s\n","                   all      10000     185578      0.632       0.38      0.412      0.233\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/6      36.9G      1.366     0.9705      1.029       1425        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:39\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 43.1s\n","                   all      10000     185578       0.63      0.381      0.416      0.236\n","\n","6 epochs completed in 0.346 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_009/yolo12s_trial_009/weights/last.pt, 18.9MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_009/yolo12s_trial_009/weights/best.pt, 18.9MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_009/yolo12s_trial_009/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 1.7it/s 53.7s\n","                   all      10000     185578      0.628      0.381      0.416      0.236\n","                person       3220      13265      0.675      0.518      0.577      0.294\n","                 rider        515        649      0.521      0.325       0.33      0.167\n","                   car       9879     102540      0.749      0.627      0.708      0.432\n","                 truck       2689       4247      0.554      0.469      0.493      0.352\n","                   bus       1242       1597      0.512      0.467      0.478      0.377\n","                 train         14         15          1          0    0.00518    0.00292\n","                 motor        334        452      0.554      0.274      0.308       0.15\n","                  bike        578       1007      0.455      0.419        0.4      0.196\n","         traffic light       5653      26891      0.603      0.319      0.388      0.141\n","          traffic sign       8221      34915      0.655      0.394      0.469      0.245\n","Speed: 0.1ms preprocess, 0.9ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_009/yolo12s_trial_009\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1381.1¬±407.9 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 13.5Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 9.9it/s 1:03\n","                   all      10000     185578      0.625      0.383      0.416      0.236\n","Speed: 0.5ms preprocess, 1.7ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_009/val\u001b[0m\n","\n","‚úÖ Trial 9 Completed\n","  mAP@0.5: 0.4161\n","  mAP@0.5:0.95: 0.2364\n","  Precision: 0.6248\n","  Recall: 0.3832\n","üßπ CUDA cache cleared\n","[I 2025-11-30 22:40:53,783] Trial 9 finished with value: 0.4160648676003249 and parameters: {'imgsz': 768, 'optimizer': 'SGD', 'lr0': 0.0001315505817621954, 'momentum': 0.891670669037609, 'weight_decay': 0.0003654114491446343, 'warmup_epochs': 3, 'warmup_momentum': 0.7134500399234733, 'warmup_bias_lr': 0.039587848873917364, 'mosaic': 0.5015345090954606, 'mixup': 0.023307356647408295}. Best is trial 2 with value: 0.49519995833717695.\n","\n","‚úì Completed 10/20 trials\n","\n","================================================================================\n","TRIAL 10/20\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 56 (auto-adjusted for image size)\n","  Optimizer: Adam\n","  Learning Rate: 0.000283\n","  Momentum: 0.8625\n","  Weight Decay: 0.000934\n","  Warmup: epochs=3, momentum=0.75, bias_lr=0.061\n","  Mosaic: 0.67\n","  Mixup: 0.17\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=56, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tmp/yolo12s/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=6, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00028301572154734456, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.1689213722626892, mode=train, model=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/models/yolo12s/yolo12s.pt, momentum=0.8625119185091457, mosaic=0.6700564124086668, multi_scale=False, name=yolo12s_trial_010, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_010, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_010/yolo12s_trial_010, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.061295823352773976, warmup_epochs=3, warmup_momentum=0.7469764584689902, weight_decay=0.0009339471392402201, workers=8, workspace=None\n","Overriding model.yaml nc=80 with nc=10\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n","  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n","  6                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 4]        \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n","  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 11                  -1  1    345856  ultralytics.nn.modules.block.A2C2f           [768, 256, 1, False, -1]      \n"," 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 14                  -1  1     95104  ultralytics.nn.modules.block.A2C2f           [512, 128, 1, False, -1]      \n"," 15                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 17                  -1  1    296704  ultralytics.nn.modules.block.A2C2f           [384, 256, 1, False, -1]      \n"," 18                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 20                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n"," 21        [14, 17, 20]  1    823278  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n","YOLOv12s summary: 272 layers, 9,257,006 parameters, 9,256,990 gradients, 21.5 GFLOPs\n","\n","Transferred 685/691 items from pretrained weights\n","Freezing layer 'model.21.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1739.9¬±696.0 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 24.9Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 294.3¬±79.8 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 10.1Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_010/yolo12s_trial_010/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.00028301572154734456, momentum=0.8625119185091457) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.0008172037468351926), 119 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_010/yolo12s_trial_010\u001b[0m\n","Starting training for 6 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/6      37.4G      1.487      1.244      1.084       1185        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:46\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.9s\n","                   all      10000     185578      0.572      0.332       0.35      0.191\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/6        34G      1.443     0.9972      1.067       1519        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.7s\n","                   all      10000     185578      0.609       0.38      0.397      0.214\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/6      36.8G      1.435     0.9713      1.064       1722        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 43.1s\n","                   all      10000     185578      0.515      0.392      0.414      0.224\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/6        36G      1.418     0.9383      1.055       1417        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.2s\n","                   all      10000     185578      0.634      0.407      0.445      0.243\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/6      36.5G      1.383     0.8914       1.04       1686        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.6s\n","                   all      10000     185578       0.67      0.429      0.469      0.258\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/6      38.7G      1.356     0.8524      1.026       1674        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.3s\n","                   all      10000     185578      0.577      0.449      0.486      0.272\n","\n","6 epochs completed in 0.348 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_010/yolo12s_trial_010/weights/last.pt, 18.9MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_010/yolo12s_trial_010/weights/best.pt, 18.9MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_010/yolo12s_trial_010/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 1.7it/s 53.2s\n","                   all      10000     185578      0.577      0.448      0.486      0.272\n","                person       3220      13265      0.704      0.531      0.602      0.301\n","                 rider        515        649      0.529      0.424      0.414       0.21\n","                   car       9879     102540      0.777      0.667      0.754      0.462\n","                 truck       2689       4247      0.545      0.574      0.564      0.404\n","                   bus       1242       1597      0.592      0.528      0.549      0.417\n","                 train         14         15          0          0    0.00165   0.000826\n","                 motor        334        452      0.611      0.368      0.378      0.186\n","                  bike        578       1007      0.614      0.395      0.446      0.222\n","         traffic light       5653      26891      0.688       0.47      0.543      0.199\n","          traffic sign       8221      34915      0.715      0.527      0.605      0.314\n","Speed: 0.1ms preprocess, 0.9ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_010/yolo12s_trial_010\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1329.5¬±467.6 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 12.6Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 9.7it/s 1:04\n","                   all      10000     185578      0.578      0.449      0.486      0.272\n","Speed: 0.5ms preprocess, 1.7ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_010/val\u001b[0m\n","\n","‚úÖ Trial 10 Completed\n","  mAP@0.5: 0.4862\n","  mAP@0.5:0.95: 0.2722\n","  Precision: 0.5777\n","  Recall: 0.4493\n","üßπ CUDA cache cleared\n","[I 2025-11-30 23:04:05,889] Trial 10 finished with value: 0.48616483718215847 and parameters: {'imgsz': 768, 'optimizer': 'Adam', 'lr0': 0.00028301572154734456, 'momentum': 0.8625119185091457, 'weight_decay': 0.0009339471392402201, 'warmup_epochs': 3, 'warmup_momentum': 0.7469764584689902, 'warmup_bias_lr': 0.061295823352773976, 'mosaic': 0.6700564124086668, 'mixup': 0.1689213722626892}. Best is trial 2 with value: 0.49519995833717695.\n","\n","‚úì Completed 11/20 trials\n","\n","================================================================================\n","TRIAL 11/20\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 56 (auto-adjusted for image size)\n","  Optimizer: Adam\n","  Learning Rate: 0.000101\n","  Momentum: 0.8514\n","  Weight Decay: 0.000353\n","  Warmup: epochs=3, momentum=0.83, bias_lr=0.087\n","  Mosaic: 0.57\n","  Mixup: 0.15\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=56, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tmp/yolo12s/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=6, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00010118662648914812, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.15355229799013026, mode=train, model=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/models/yolo12s/yolo12s.pt, momentum=0.8514082197196229, mosaic=0.5692022195875244, multi_scale=False, name=yolo12s_trial_011, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_011, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_011/yolo12s_trial_011, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.08676501697940245, warmup_epochs=3, warmup_momentum=0.8269144783595105, weight_decay=0.00035330454240099356, workers=8, workspace=None\n","Overriding model.yaml nc=80 with nc=10\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n","  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n","  6                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 4]        \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n","  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 11                  -1  1    345856  ultralytics.nn.modules.block.A2C2f           [768, 256, 1, False, -1]      \n"," 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 14                  -1  1     95104  ultralytics.nn.modules.block.A2C2f           [512, 128, 1, False, -1]      \n"," 15                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 17                  -1  1    296704  ultralytics.nn.modules.block.A2C2f           [384, 256, 1, False, -1]      \n"," 18                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 20                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n"," 21        [14, 17, 20]  1    823278  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n","YOLOv12s summary: 272 layers, 9,257,006 parameters, 9,256,990 gradients, 21.5 GFLOPs\n","\n","Transferred 685/691 items from pretrained weights\n","Freezing layer 'model.21.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1605.4¬±611.1 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 26.0Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 692.9¬±450.3 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 11.4Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_011/yolo12s_trial_011/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.00010118662648914812, momentum=0.8514082197196229) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.0003091414746008694), 119 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_011/yolo12s_trial_011\u001b[0m\n","Starting training for 6 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/6      35.7G      1.495      1.262      1.082       1329        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.0it/s 44.4s\n","                   all      10000     185578      0.538      0.322      0.329      0.178\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/6      35.9G      1.426     0.9807      1.054       1369        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.0it/s 44.2s\n","                   all      10000     185578      0.603      0.371      0.393      0.218\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/6        36G      1.401     0.9318      1.043       1413        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.6s\n","                   all      10000     185578      0.551      0.412       0.45      0.252\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/6      38.7G      1.382     0.8985      1.034       1235        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.7s\n","                   all      10000     185578      0.656      0.428      0.466       0.26\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/6      38.7G      1.362     0.8649      1.021       1438        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.4s\n","                   all      10000     185578      0.705      0.431      0.483      0.272\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/6      38.5G      1.351     0.8427      1.017       1420        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.2s\n","                   all      10000     185578      0.686      0.448      0.499      0.282\n","\n","6 epochs completed in 0.348 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_011/yolo12s_trial_011/weights/last.pt, 18.9MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_011/yolo12s_trial_011/weights/best.pt, 18.9MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_011/yolo12s_trial_011/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 1.7it/s 53.1s\n","                   all      10000     185578      0.687      0.448      0.499      0.282\n","                person       3220      13265      0.706      0.539      0.612      0.312\n","                 rider        515        649      0.626      0.408      0.431      0.223\n","                   car       9879     102540      0.769      0.676      0.754      0.464\n","                 truck       2689       4247      0.618      0.518      0.558      0.405\n","                   bus       1242       1597       0.54      0.555      0.556      0.431\n","                 train         14         15          1          0     0.0682     0.0269\n","                 motor        334        452      0.625      0.363      0.414      0.204\n","                  bike        578       1007        0.6      0.443      0.475      0.241\n","         traffic light       5653      26891      0.701       0.44      0.531      0.199\n","          traffic sign       8221      34915      0.685      0.534      0.588      0.313\n","Speed: 0.1ms preprocess, 0.9ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_011/yolo12s_trial_011\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1151.9¬±514.7 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 13.5Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 10.0it/s 1:03\n","                   all      10000     185578      0.687      0.448      0.499      0.282\n","Speed: 0.5ms preprocess, 1.6ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_011/val\u001b[0m\n","\n","‚úÖ Trial 11 Completed\n","  mAP@0.5: 0.4988\n","  mAP@0.5:0.95: 0.2824\n","  Precision: 0.6869\n","  Recall: 0.4479\n","üßπ CUDA cache cleared\n","[I 2025-11-30 23:27:16,944] Trial 11 finished with value: 0.4988368790854956 and parameters: {'imgsz': 768, 'optimizer': 'Adam', 'lr0': 0.00010118662648914812, 'momentum': 0.8514082197196229, 'weight_decay': 0.00035330454240099356, 'warmup_epochs': 3, 'warmup_momentum': 0.8269144783595105, 'warmup_bias_lr': 0.08676501697940245, 'mosaic': 0.5692022195875244, 'mixup': 0.15355229799013026}. Best is trial 11 with value: 0.4988368790854956.\n","\n","‚úì Completed 12/20 trials\n","\n","================================================================================\n","TRIAL 12/20\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 56 (auto-adjusted for image size)\n","  Optimizer: AdamW\n","  Learning Rate: 0.000258\n","  Momentum: 0.8573\n","  Weight Decay: 0.000056\n","  Warmup: epochs=2, momentum=0.85, bias_lr=0.065\n","  Mosaic: 0.64\n","  Mixup: 0.19\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=56, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tmp/yolo12s/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=6, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0002581312357680321, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.19438832444123538, mode=train, model=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/models/yolo12s/yolo12s.pt, momentum=0.8572661913383784, mosaic=0.6410064580534052, multi_scale=False, name=yolo12s_trial_012, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_012, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_012/yolo12s_trial_012, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.06522360346616196, warmup_epochs=2, warmup_momentum=0.8534200605965067, weight_decay=5.622432185034556e-05, workers=8, workspace=None\n","Overriding model.yaml nc=80 with nc=10\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n","  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n","  6                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 4]        \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n","  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 11                  -1  1    345856  ultralytics.nn.modules.block.A2C2f           [768, 256, 1, False, -1]      \n"," 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 14                  -1  1     95104  ultralytics.nn.modules.block.A2C2f           [512, 128, 1, False, -1]      \n"," 15                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 17                  -1  1    296704  ultralytics.nn.modules.block.A2C2f           [384, 256, 1, False, -1]      \n"," 18                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 20                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n"," 21        [14, 17, 20]  1    823278  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n","YOLOv12s summary: 272 layers, 9,257,006 parameters, 9,256,990 gradients, 21.5 GFLOPs\n","\n","Transferred 685/691 items from pretrained weights\n","Freezing layer 'model.21.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1923.8¬±675.6 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 20.2Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 389.7¬±121.8 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 10.7Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_012/yolo12s_trial_012/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0002581312357680321, momentum=0.8572661913383784) with parameter groups 113 weight(decay=0.0), 120 weight(decay=4.9196281619052366e-05), 119 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_012/yolo12s_trial_012\u001b[0m\n","Starting training for 6 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/6      38.9G      1.496      1.246      1.085       1428        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:46\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.8s\n","                   all      10000     185578      0.579       0.35      0.365      0.197\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/6      37.4G      1.461      1.013      1.077       1713        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 43.4s\n","                   all      10000     185578      0.607      0.376      0.398      0.209\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/6        37G      1.437     0.9701      1.063       2015        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 41.9s\n","                   all      10000     185578      0.625      0.394      0.423      0.229\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/6        34G       1.41     0.9275      1.049       1283        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.8s\n","                   all      10000     185578      0.655      0.422      0.458      0.252\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/6      38.8G      1.383     0.8892      1.037       1592        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.3s\n","                   all      10000     185578       0.68       0.43      0.478      0.266\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/6      36.6G      1.361     0.8554      1.027       1271        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.1s\n","                   all      10000     185578      0.684      0.456      0.493      0.278\n","\n","6 epochs completed in 0.347 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_012/yolo12s_trial_012/weights/last.pt, 18.9MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_012/yolo12s_trial_012/weights/best.pt, 18.9MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_012/yolo12s_trial_012/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 1.7it/s 52.9s\n","                   all      10000     185578      0.685      0.457      0.494      0.278\n","                person       3220      13265      0.701      0.535      0.606      0.304\n","                 rider        515        649      0.561      0.435      0.436      0.221\n","                   car       9879     102540      0.797      0.667      0.761      0.468\n","                 truck       2689       4247      0.597      0.557      0.563      0.406\n","                   bus       1242       1597      0.565       0.55      0.564       0.43\n","                 train         14         15          1          0    0.00559    0.00391\n","                 motor        334        452      0.592      0.388      0.386      0.196\n","                  bike        578       1007      0.649      0.402      0.456      0.229\n","         traffic light       5653      26891      0.685      0.488      0.554      0.207\n","          traffic sign       8221      34915        0.7      0.544      0.605      0.319\n","Speed: 0.1ms preprocess, 0.9ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_012/yolo12s_trial_012\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1376.9¬±408.8 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 14.8Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 10.1it/s 1:02\n","                   all      10000     185578      0.687      0.456      0.494      0.279\n","Speed: 0.5ms preprocess, 1.6ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_012/val\u001b[0m\n","\n","‚úÖ Trial 12 Completed\n","  mAP@0.5: 0.4942\n","  mAP@0.5:0.95: 0.2787\n","  Precision: 0.6865\n","  Recall: 0.4565\n","üßπ CUDA cache cleared\n","[I 2025-11-30 23:50:24,798] Trial 12 finished with value: 0.49424874771185223 and parameters: {'imgsz': 768, 'optimizer': 'AdamW', 'lr0': 0.0002581312357680321, 'momentum': 0.8572661913383784, 'weight_decay': 5.622432185034556e-05, 'warmup_epochs': 2, 'warmup_momentum': 0.8534200605965067, 'warmup_bias_lr': 0.06522360346616196, 'mosaic': 0.6410064580534052, 'mixup': 0.19438832444123538}. Best is trial 11 with value: 0.4988368790854956.\n","\n","‚úì Completed 13/20 trials\n","\n","================================================================================\n","TRIAL 13/20\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 56 (auto-adjusted for image size)\n","  Optimizer: AdamW\n","  Learning Rate: 0.000238\n","  Momentum: 0.8592\n","  Weight Decay: 0.000324\n","  Warmup: epochs=3, momentum=0.86, bias_lr=0.054\n","  Mosaic: 0.50\n","  Mixup: 0.10\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=56, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tmp/yolo12s/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=6, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00023828070218441419, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.10304833452181744, mode=train, model=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/models/yolo12s/yolo12s.pt, momentum=0.8591714717956058, mosaic=0.50194791734856, multi_scale=False, name=yolo12s_trial_013, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_013, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_013/yolo12s_trial_013, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.05406337265506802, warmup_epochs=3, warmup_momentum=0.8610152809930884, weight_decay=0.00032392015532818575, workers=8, workspace=None\n","Overriding model.yaml nc=80 with nc=10\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n","  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n","  6                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 4]        \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n","  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 11                  -1  1    345856  ultralytics.nn.modules.block.A2C2f           [768, 256, 1, False, -1]      \n"," 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 14                  -1  1     95104  ultralytics.nn.modules.block.A2C2f           [512, 128, 1, False, -1]      \n"," 15                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 17                  -1  1    296704  ultralytics.nn.modules.block.A2C2f           [384, 256, 1, False, -1]      \n"," 18                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 20                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n"," 21        [14, 17, 20]  1    823278  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n","YOLOv12s summary: 272 layers, 9,257,006 parameters, 9,256,990 gradients, 21.5 GFLOPs\n","\n","Transferred 685/691 items from pretrained weights\n","Freezing layer 'model.21.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1598.7¬±641.4 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 19.4Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 506.6¬±137.5 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 11.4Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_013/yolo12s_trial_013/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00023828070218441419, momentum=0.8591714717956058) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.00028343013591216253), 119 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_013/yolo12s_trial_013\u001b[0m\n","Starting training for 6 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/6        34G      1.476      1.235      1.076       1337        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:44\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.0it/s 44.3s\n","                   all      10000     185578      0.591      0.361      0.376      0.203\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/6      35.7G      1.426     0.9683      1.056       1222        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.2s\n","                   all      10000     185578      0.618       0.38      0.409      0.223\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/6      38.4G      1.415     0.9442      1.052       1418        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:40\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.5s\n","                   all      10000     185578      0.636      0.395      0.424       0.23\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/6      36.9G      1.397     0.9124      1.043       1188        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:40\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.5s\n","                   all      10000     185578      0.662      0.412      0.451      0.248\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/6      35.3G       1.37     0.8701      1.031       1462        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.4s\n","                   all      10000     185578      0.691      0.425       0.47       0.26\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/6      34.6G      1.345     0.8346      1.018       1159        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.0s\n","                   all      10000     185578      0.693       0.45      0.494      0.276\n","\n","6 epochs completed in 0.345 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_013/yolo12s_trial_013/weights/last.pt, 18.9MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_013/yolo12s_trial_013/weights/best.pt, 18.9MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_013/yolo12s_trial_013/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 1.7it/s 53.5s\n","                   all      10000     185578      0.692      0.449      0.493      0.276\n","                person       3220      13265      0.747      0.512      0.608      0.306\n","                 rider        515        649      0.576      0.414      0.427       0.22\n","                   car       9879     102540      0.805      0.663      0.759      0.465\n","                 truck       2689       4247      0.545      0.575      0.565      0.404\n","                   bus       1242       1597       0.67      0.469      0.541      0.408\n","                 train         14         15          1          0    0.00538     0.0042\n","                 motor        334        452      0.547       0.44      0.412      0.201\n","                  bike        578       1007      0.604      0.425      0.468      0.229\n","         traffic light       5653      26891      0.699      0.477      0.547      0.205\n","          traffic sign       8221      34915      0.729      0.518      0.602      0.317\n","Speed: 0.1ms preprocess, 0.9ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_013/yolo12s_trial_013\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1283.5¬±465.1 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 14.5Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 10.1it/s 1:02\n","                   all      10000     185578      0.693       0.45      0.494      0.277\n","Speed: 0.5ms preprocess, 1.7ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_013/val\u001b[0m\n","\n","‚úÖ Trial 13 Completed\n","  mAP@0.5: 0.4937\n","  mAP@0.5:0.95: 0.2766\n","  Precision: 0.6928\n","  Recall: 0.4498\n","üßπ CUDA cache cleared\n","[I 2025-12-01 00:13:26,577] Trial 13 finished with value: 0.49369979189156926 and parameters: {'imgsz': 768, 'optimizer': 'AdamW', 'lr0': 0.00023828070218441419, 'momentum': 0.8591714717956058, 'weight_decay': 0.00032392015532818575, 'warmup_epochs': 3, 'warmup_momentum': 0.8610152809930884, 'warmup_bias_lr': 0.05406337265506802, 'mosaic': 0.50194791734856, 'mixup': 0.10304833452181744}. Best is trial 11 with value: 0.4988368790854956.\n","\n","‚úì Completed 14/20 trials\n","\n","================================================================================\n","TRIAL 14/20\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 56 (auto-adjusted for image size)\n","  Optimizer: Adam\n","  Learning Rate: 0.000103\n","  Momentum: 0.8595\n","  Weight Decay: 0.000216\n","  Warmup: epochs=2, momentum=0.83, bias_lr=0.089\n","  Mosaic: 0.85\n","  Mixup: 0.09\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=56, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tmp/yolo12s/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=6, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00010296295701265204, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.09401425469969821, mode=train, model=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/models/yolo12s/yolo12s.pt, momentum=0.8595336383710444, mosaic=0.8450373653024943, multi_scale=False, name=yolo12s_trial_014, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_014, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_014/yolo12s_trial_014, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.08937271460237181, warmup_epochs=2, warmup_momentum=0.827684640035661, weight_decay=0.00021633449801145105, workers=8, workspace=None\n","Overriding model.yaml nc=80 with nc=10\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n","  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n","  6                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 4]        \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n","  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 11                  -1  1    345856  ultralytics.nn.modules.block.A2C2f           [768, 256, 1, False, -1]      \n"," 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 14                  -1  1     95104  ultralytics.nn.modules.block.A2C2f           [512, 128, 1, False, -1]      \n"," 15                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 17                  -1  1    296704  ultralytics.nn.modules.block.A2C2f           [384, 256, 1, False, -1]      \n"," 18                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 20                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n"," 21        [14, 17, 20]  1    823278  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n","YOLOv12s summary: 272 layers, 9,257,006 parameters, 9,256,990 gradients, 21.5 GFLOPs\n","\n","Transferred 685/691 items from pretrained weights\n","Freezing layer 'model.21.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1324.8¬±546.5 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 23.3Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 463.3¬±126.7 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 10.0Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_014/yolo12s_trial_014/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.00010296295701265204, momentum=0.8595336383710444) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.00018929268576001968), 119 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_014/yolo12s_trial_014\u001b[0m\n","Starting training for 6 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/6      38.2G       1.46       1.22      1.068       1623        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:46\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.0it/s 44.3s\n","                   all      10000     185578      0.568      0.332       0.35      0.189\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/6      38.1G      1.395     0.9454      1.041       1720        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.4s\n","                   all      10000     185578      0.638      0.394      0.431       0.24\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/6      37.8G       1.37     0.8986      1.032       1542        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.4s\n","                   all      10000     185578      0.674       0.41      0.456      0.253\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/6        35G       1.35     0.8658      1.022       1203        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.6s\n","                   all      10000     185578       0.68      0.434      0.473      0.264\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/6      38.7G      1.335     0.8411      1.014       1385        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.3s\n","                   all      10000     185578      0.686      0.441      0.493      0.281\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/6        34G      1.316     0.8152      1.006       1639        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.3s\n","                   all      10000     185578      0.687      0.445      0.497      0.283\n","\n","6 epochs completed in 0.347 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_014/yolo12s_trial_014/weights/last.pt, 18.9MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_014/yolo12s_trial_014/weights/best.pt, 18.9MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_014/yolo12s_trial_014/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 1.7it/s 53.1s\n","                   all      10000     185578      0.687      0.446      0.497      0.283\n","                person       3220      13265      0.731      0.523      0.613      0.311\n","                 rider        515        649      0.571      0.439      0.435      0.225\n","                   car       9879     102540      0.807      0.658      0.758      0.466\n","                 truck       2689       4247      0.603      0.532      0.559      0.406\n","                   bus       1242       1597      0.645      0.501      0.557      0.422\n","                 train         14         15          1          0     0.0669     0.0591\n","                 motor        334        452      0.508      0.407      0.386      0.197\n","                  bike        578       1007      0.559      0.453      0.463      0.235\n","         traffic light       5653      26891      0.718      0.434      0.535      0.199\n","          traffic sign       8221      34915      0.732      0.508      0.595      0.315\n","Speed: 0.1ms preprocess, 0.9ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_014/yolo12s_trial_014\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1373.3¬±459.0 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 14.8Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 10.0it/s 1:02\n","                   all      10000     185578      0.687      0.446      0.497      0.284\n","Speed: 0.5ms preprocess, 1.7ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_014/val\u001b[0m\n","\n","‚úÖ Trial 14 Completed\n","  mAP@0.5: 0.4972\n","  mAP@0.5:0.95: 0.2841\n","  Precision: 0.6870\n","  Recall: 0.4458\n","üßπ CUDA cache cleared\n","[I 2025-12-01 00:36:35,875] Trial 14 finished with value: 0.49718201016154107 and parameters: {'imgsz': 768, 'optimizer': 'Adam', 'lr0': 0.00010296295701265204, 'momentum': 0.8595336383710444, 'weight_decay': 0.00021633449801145105, 'warmup_epochs': 2, 'warmup_momentum': 0.827684640035661, 'warmup_bias_lr': 0.08937271460237181, 'mosaic': 0.8450373653024943, 'mixup': 0.09401425469969821}. Best is trial 11 with value: 0.4988368790854956.\n","\n","‚úì Completed 15/20 trials\n","\n","================================================================================\n","TRIAL 15/20\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 56 (auto-adjusted for image size)\n","  Optimizer: Adam\n","  Learning Rate: 0.000122\n","  Momentum: 0.8889\n","  Weight Decay: 0.000034\n","  Warmup: epochs=2, momentum=0.78, bias_lr=0.074\n","  Mosaic: 0.75\n","  Mixup: 0.07\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=56, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tmp/yolo12s/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=6, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00012192021890239396, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.06813130521919572, mode=train, model=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/models/yolo12s/yolo12s.pt, momentum=0.8888996841929279, mosaic=0.7510576170263057, multi_scale=False, name=yolo12s_trial_015, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_015, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_015/yolo12s_trial_015, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.07369622770237041, warmup_epochs=2, warmup_momentum=0.7753369681596541, weight_decay=3.4214299147447924e-05, workers=8, workspace=None\n","Overriding model.yaml nc=80 with nc=10\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n","  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n","  6                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 4]        \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n","  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 11                  -1  1    345856  ultralytics.nn.modules.block.A2C2f           [768, 256, 1, False, -1]      \n"," 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 14                  -1  1     95104  ultralytics.nn.modules.block.A2C2f           [512, 128, 1, False, -1]      \n"," 15                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 17                  -1  1    296704  ultralytics.nn.modules.block.A2C2f           [384, 256, 1, False, -1]      \n"," 18                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 20                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n"," 21        [14, 17, 20]  1    823278  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n","YOLOv12s summary: 272 layers, 9,257,006 parameters, 9,256,990 gradients, 21.5 GFLOPs\n","\n","Transferred 685/691 items from pretrained weights\n","Freezing layer 'model.21.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1819.8¬±790.6 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 23.7Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 499.7¬±150.9 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 11.7Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_015/yolo12s_trial_015/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.00012192021890239396, momentum=0.8888996841929279) with parameter groups 113 weight(decay=0.0), 120 weight(decay=2.993751175401693e-05), 119 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_015/yolo12s_trial_015\u001b[0m\n","Starting training for 6 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/6      37.3G       1.45      1.203      1.064       1384        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.7s\n","                   all      10000     185578      0.608       0.36      0.387      0.212\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/6      34.1G      1.395     0.9409      1.041       1356        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 43.1s\n","                   all      10000     185578      0.646      0.402      0.429      0.235\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/6      38.3G       1.37     0.8979      1.032       1881        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.5s\n","                   all      10000     185578      0.558      0.419      0.456      0.248\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/6      34.6G      1.351     0.8615      1.021       1558        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.2s\n","                   all      10000     185578      0.674      0.439      0.478      0.263\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/6      38.8G      1.331     0.8356      1.014       1543        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.9s\n","                   all      10000     185578      0.598      0.445      0.489      0.274\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/6      34.9G      1.314      0.808      1.005       1622        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 41.9s\n","                   all      10000     185578      0.712      0.448        0.5      0.281\n","\n","6 epochs completed in 0.347 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_015/yolo12s_trial_015/weights/last.pt, 18.9MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_015/yolo12s_trial_015/weights/best.pt, 18.9MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_015/yolo12s_trial_015/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 1.7it/s 52.5s\n","                   all      10000     185578      0.715      0.447        0.5      0.281\n","                person       3220      13265      0.752      0.523      0.618      0.315\n","                 rider        515        649      0.693      0.404      0.447      0.231\n","                   car       9879     102540      0.826      0.649      0.759      0.469\n","                 truck       2689       4247      0.686      0.495      0.575      0.414\n","                   bus       1242       1597       0.59      0.534      0.563      0.434\n","                 train         14         15          1          0    0.00239    0.00145\n","                 motor        334        452      0.579      0.429      0.421      0.196\n","                  bike        578       1007      0.607       0.43      0.465      0.232\n","         traffic light       5653      26891        0.7      0.475      0.543      0.202\n","          traffic sign       8221      34915      0.717      0.528      0.603      0.319\n","Speed: 0.1ms preprocess, 0.9ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_015/yolo12s_trial_015\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1339.8¬±366.1 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 15.0Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 10.1it/s 1:02\n","                   all      10000     185578      0.713      0.448        0.5      0.282\n","Speed: 0.5ms preprocess, 1.7ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_015/val\u001b[0m\n","\n","‚úÖ Trial 15 Completed\n","  mAP@0.5: 0.5002\n","  mAP@0.5:0.95: 0.2818\n","  Precision: 0.7129\n","  Recall: 0.4476\n","üßπ CUDA cache cleared\n","[I 2025-12-01 00:59:41,064] Trial 15 finished with value: 0.5002439377495521 and parameters: {'imgsz': 768, 'optimizer': 'Adam', 'lr0': 0.00012192021890239396, 'momentum': 0.8888996841929279, 'weight_decay': 3.4214299147447924e-05, 'warmup_epochs': 2, 'warmup_momentum': 0.7753369681596541, 'warmup_bias_lr': 0.07369622770237041, 'mosaic': 0.7510576170263057, 'mixup': 0.06813130521919572}. Best is trial 15 with value: 0.5002439377495521.\n","\n","‚úì Completed 16/20 trials\n","\n","================================================================================\n","TRIAL 16/20\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 56 (auto-adjusted for image size)\n","  Optimizer: Adam\n","  Learning Rate: 0.000278\n","  Momentum: 0.8657\n","  Weight Decay: 0.000033\n","  Warmup: epochs=3, momentum=0.62, bias_lr=0.095\n","  Mosaic: 0.61\n","  Mixup: 0.16\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=56, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tmp/yolo12s/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=6, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00027838272655938826, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.15580060558237022, mode=train, model=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/models/yolo12s/yolo12s.pt, momentum=0.865713023471312, mosaic=0.6118290774947986, multi_scale=False, name=yolo12s_trial_016, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_016, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_016/yolo12s_trial_016, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0946625734899615, warmup_epochs=3, warmup_momentum=0.6236547885084676, weight_decay=3.263640122653622e-05, workers=8, workspace=None\n","Overriding model.yaml nc=80 with nc=10\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n","  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n","  6                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 4]        \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n","  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 11                  -1  1    345856  ultralytics.nn.modules.block.A2C2f           [768, 256, 1, False, -1]      \n"," 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 14                  -1  1     95104  ultralytics.nn.modules.block.A2C2f           [512, 128, 1, False, -1]      \n"," 15                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 17                  -1  1    296704  ultralytics.nn.modules.block.A2C2f           [384, 256, 1, False, -1]      \n"," 18                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 20                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n"," 21        [14, 17, 20]  1    823278  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n","YOLOv12s summary: 272 layers, 9,257,006 parameters, 9,256,990 gradients, 21.5 GFLOPs\n","\n","Transferred 685/691 items from pretrained weights\n","Freezing layer 'model.21.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1846.8¬±804.6 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 24.2Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 537.7¬±153.2 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 9.9Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_016/yolo12s_trial_016/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.00027838272655938826, momentum=0.865713023471312) with parameter groups 113 weight(decay=0.0), 120 weight(decay=2.8556851073219192e-05), 119 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_016/yolo12s_trial_016\u001b[0m\n","Starting training for 6 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/6      36.8G      1.495      1.244      1.086       1667        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:46\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.2it/s 41.6s\n","                   all      10000     185578      0.531      0.265      0.275      0.147\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/6        34G      1.446     0.9997      1.067       1110        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.3s\n","                   all      10000     185578      0.611      0.365      0.394      0.213\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/6      36.1G      1.434     0.9695      1.061       1553        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 43.1s\n","                   all      10000     185578      0.628      0.389      0.408       0.22\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/6      37.2G      1.413     0.9334      1.052       1392        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.7s\n","                   all      10000     185578      0.648      0.419      0.447      0.243\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/6      34.8G       1.38      0.884      1.037       1140        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 41.9s\n","                   all      10000     185578      0.671      0.427       0.47       0.26\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/6      36.8G      1.352      0.847      1.025       1583        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.1s\n","                   all      10000     185578      0.682       0.45      0.491      0.276\n","\n","6 epochs completed in 0.346 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_016/yolo12s_trial_016/weights/last.pt, 18.9MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_016/yolo12s_trial_016/weights/best.pt, 18.9MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_016/yolo12s_trial_016/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 1.7it/s 53.3s\n","                   all      10000     185578      0.679      0.453      0.491      0.276\n","                person       3220      13265      0.726      0.527      0.606      0.305\n","                 rider        515        649      0.538       0.44      0.412      0.213\n","                   car       9879     102540      0.762      0.687      0.758      0.467\n","                 truck       2689       4247      0.607      0.541      0.571      0.409\n","                   bus       1242       1597      0.596      0.525      0.555      0.417\n","                 train         14         15          1          0    0.00489    0.00322\n","                 motor        334        452      0.547        0.4      0.403      0.202\n","                  bike        578       1007      0.595      0.406      0.448      0.219\n","         traffic light       5653      26891      0.719       0.46      0.552      0.204\n","          traffic sign       8221      34915      0.699       0.54      0.603      0.317\n","Speed: 0.1ms preprocess, 0.9ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_016/yolo12s_trial_016\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1381.9¬±439.5 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 16.2Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 10.1it/s 1:02\n","                   all      10000     185578      0.681      0.452      0.492      0.277\n","Speed: 0.5ms preprocess, 1.7ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_016/val\u001b[0m\n","\n","‚úÖ Trial 16 Completed\n","  mAP@0.5: 0.4918\n","  mAP@0.5:0.95: 0.2765\n","  Precision: 0.6814\n","  Recall: 0.4515\n","üßπ CUDA cache cleared\n","[I 2025-12-01 01:22:46,637] Trial 16 finished with value: 0.491777936938033 and parameters: {'imgsz': 768, 'optimizer': 'Adam', 'lr0': 0.00027838272655938826, 'momentum': 0.865713023471312, 'weight_decay': 3.263640122653622e-05, 'warmup_epochs': 3, 'warmup_momentum': 0.6236547885084676, 'warmup_bias_lr': 0.0946625734899615, 'mosaic': 0.6118290774947986, 'mixup': 0.15580060558237022}. Best is trial 15 with value: 0.5002439377495521.\n","\n","‚úì Completed 17/20 trials\n","\n","================================================================================\n","TRIAL 17/20\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 56 (auto-adjusted for image size)\n","  Optimizer: Adam\n","  Learning Rate: 0.000413\n","  Momentum: 0.9183\n","  Weight Decay: 0.000016\n","  Warmup: epochs=2, momentum=0.77, bias_lr=0.097\n","  Mosaic: 0.70\n","  Mixup: 0.06\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=56, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tmp/yolo12s/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=6, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00041263520115668436, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.05670264821395519, mode=train, model=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/models/yolo12s/yolo12s.pt, momentum=0.9183480039077738, mosaic=0.6979925246933499, multi_scale=False, name=yolo12s_trial_017, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_017, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_017/yolo12s_trial_017, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.09735460872124413, warmup_epochs=2, warmup_momentum=0.770635246942724, weight_decay=1.5740681056021985e-05, workers=8, workspace=None\n","Overriding model.yaml nc=80 with nc=10\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n","  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n","  6                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 4]        \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n","  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 11                  -1  1    345856  ultralytics.nn.modules.block.A2C2f           [768, 256, 1, False, -1]      \n"," 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 14                  -1  1     95104  ultralytics.nn.modules.block.A2C2f           [512, 128, 1, False, -1]      \n"," 15                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 17                  -1  1    296704  ultralytics.nn.modules.block.A2C2f           [384, 256, 1, False, -1]      \n"," 18                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 20                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n"," 21        [14, 17, 20]  1    823278  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n","YOLOv12s summary: 272 layers, 9,257,006 parameters, 9,256,990 gradients, 21.5 GFLOPs\n","\n","Transferred 685/691 items from pretrained weights\n","Freezing layer 'model.21.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1787.6¬±756.7 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 24.8Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 486.1¬±220.3 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 8.5Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_017/yolo12s_trial_017/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.00041263520115668436, momentum=0.9183480039077738) with parameter groups 113 weight(decay=0.0), 120 weight(decay=1.3773095924019236e-05), 119 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_017/yolo12s_trial_017\u001b[0m\n","Starting training for 6 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/6      35.5G      1.475      1.206      1.076       1546        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:46\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 43.3s\n","                   all      10000     185578      0.575      0.339      0.341      0.183\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/6      34.8G       1.45      1.008      1.071       1278        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.9s\n","                   all      10000     185578      0.561      0.358      0.359      0.186\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/6      34.1G       1.43     0.9641       1.06       1432        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 43.2s\n","                   all      10000     185578      0.607      0.392      0.411      0.219\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/6      38.4G      1.393     0.9106      1.043       1274        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.5s\n","                   all      10000     185578      0.664      0.407      0.447      0.245\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/6        35G      1.363     0.8681      1.028       1418        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.7s\n","                   all      10000     185578      0.649      0.422      0.457      0.253\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/6      35.2G      1.334     0.8295      1.015       1616        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.4s\n","                   all      10000     185578      0.678      0.442      0.487      0.273\n","\n","6 epochs completed in 0.347 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_017/yolo12s_trial_017/weights/last.pt, 18.9MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_017/yolo12s_trial_017/weights/best.pt, 18.9MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_017/yolo12s_trial_017/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 1.7it/s 53.3s\n","                   all      10000     185578      0.678      0.442      0.487      0.273\n","                person       3220      13265      0.727      0.516      0.604      0.302\n","                 rider        515        649      0.498      0.416      0.426       0.22\n","                   car       9879     102540       0.78      0.679       0.76      0.467\n","                 truck       2689       4247      0.664      0.473       0.55      0.383\n","                   bus       1242       1597      0.568      0.524      0.541      0.415\n","                 train         14         15          1          0   0.000357    0.00025\n","                 motor        334        452      0.554      0.381      0.381      0.196\n","                  bike        578       1007       0.61      0.385      0.441      0.219\n","         traffic light       5653      26891      0.662      0.516      0.559      0.206\n","          traffic sign       8221      34915      0.715      0.526      0.605      0.318\n","Speed: 0.1ms preprocess, 0.9ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_017/yolo12s_trial_017\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1372.2¬±460.6 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 14.0Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 10.1it/s 1:02\n","                   all      10000     185578       0.68      0.441      0.487      0.273\n","Speed: 0.5ms preprocess, 1.7ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_017/val\u001b[0m\n","\n","‚úÖ Trial 17 Completed\n","  mAP@0.5: 0.4869\n","  mAP@0.5:0.95: 0.2731\n","  Precision: 0.6803\n","  Recall: 0.4406\n","üßπ CUDA cache cleared\n","[I 2025-12-01 01:45:53,918] Trial 17 finished with value: 0.4869266728788178 and parameters: {'imgsz': 768, 'optimizer': 'Adam', 'lr0': 0.00041263520115668436, 'momentum': 0.9183480039077738, 'weight_decay': 1.5740681056021985e-05, 'warmup_epochs': 2, 'warmup_momentum': 0.770635246942724, 'warmup_bias_lr': 0.09735460872124413, 'mosaic': 0.6979925246933499, 'mixup': 0.05670264821395519}. Best is trial 15 with value: 0.5002439377495521.\n","\n","‚úì Completed 18/20 trials\n","\n","================================================================================\n","TRIAL 18/20\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 640\n","  Batch Size: 86 (auto-adjusted for image size)\n","  Optimizer: Adam\n","  Learning Rate: 0.000109\n","  Momentum: 0.8808\n","  Weight Decay: 0.000043\n","  Warmup: epochs=2, momentum=0.82, bias_lr=0.083\n","  Mosaic: 0.56\n","  Mixup: 0.15\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=86, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tmp/yolo12s/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=6, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00010868283028325681, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.15056203668349555, mode=train, model=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/models/yolo12s/yolo12s.pt, momentum=0.880751382254641, mosaic=0.5601569636128313, multi_scale=False, name=yolo12s_trial_018, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_018, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_018/yolo12s_trial_018, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.08336988722241398, warmup_epochs=2, warmup_momentum=0.8191386459098908, weight_decay=4.263436279094774e-05, workers=8, workspace=None\n","Overriding model.yaml nc=80 with nc=10\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n","  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n","  6                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 4]        \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n","  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 11                  -1  1    345856  ultralytics.nn.modules.block.A2C2f           [768, 256, 1, False, -1]      \n"," 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 14                  -1  1     95104  ultralytics.nn.modules.block.A2C2f           [512, 128, 1, False, -1]      \n"," 15                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 17                  -1  1    296704  ultralytics.nn.modules.block.A2C2f           [384, 256, 1, False, -1]      \n"," 18                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 20                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n"," 21        [14, 17, 20]  1    823278  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n","YOLOv12s summary: 272 layers, 9,257,006 parameters, 9,256,990 gradients, 21.5 GFLOPs\n","\n","Transferred 685/691 items from pretrained weights\n","Freezing layer 'model.21.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1808.8¬±802.7 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 24.3Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 355.6¬±105.9 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 9.7Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_018/yolo12s_trial_018/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.00010868283028325681, momentum=0.880751382254641) with parameter groups 113 weight(decay=0.0), 120 weight(decay=5.7289925000336025e-05), 119 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_018/yolo12s_trial_018\u001b[0m\n","Starting training for 6 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/6      38.3G      1.497      1.326      1.063       2088        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.7it/s 1:50\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.6it/s 38.0s\n","                   all      10000     185578       0.57      0.299       0.31      0.172\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/6      37.4G      1.419     0.9672      1.033       1596        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.8it/s 1:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.6it/s 38.0s\n","                   all      10000     185578      0.607      0.363      0.379      0.213\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/6      38.8G      1.388     0.9144      1.022       1808        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.8it/s 1:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.5it/s 38.6s\n","                   all      10000     185578      0.532      0.384       0.41      0.228\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/6      37.8G      1.373     0.8866      1.014       1572        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.8it/s 1:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.6it/s 37.7s\n","                   all      10000     185578      0.559      0.391      0.426      0.239\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/6      38.3G       1.35      0.856      1.002       1640        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.8it/s 1:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.6it/s 37.8s\n","                   all      10000     185578      0.672        0.4      0.441      0.247\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/6      38.9G      1.342     0.8402     0.9995       2067        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 191/191 1.8it/s 1:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.6it/s 38.0s\n","                   all      10000     185578      0.664      0.411      0.448      0.254\n","\n","6 epochs completed in 0.246 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_018/yolo12s_trial_018/weights/last.pt, 18.9MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_018/yolo12s_trial_018/weights/best.pt, 18.9MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_018/yolo12s_trial_018/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 59/59 1.2it/s 49.6s\n","                   all      10000     185578      0.662      0.413      0.449      0.254\n","                person       3220      13265      0.734      0.471      0.563       0.28\n","                 rider        515        649      0.551      0.384      0.388      0.199\n","                   car       9879     102540       0.77      0.639      0.717      0.441\n","                 truck       2689       4247       0.66      0.463       0.54      0.388\n","                   bus       1242       1597      0.497      0.537       0.52        0.4\n","                 train         14         15          1          0     0.0134     0.0119\n","                 motor        334        452      0.531      0.396      0.362      0.181\n","                  bike        578       1007      0.505      0.404      0.403      0.195\n","         traffic light       5653      26891      0.659      0.396      0.458      0.167\n","          traffic sign       8221      34915       0.71       0.44      0.522      0.272\n","Speed: 0.1ms preprocess, 0.7ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_018/yolo12s_trial_018\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1315.1¬±534.2 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 14.3Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 11.1it/s 56.4s\n","                   all      10000     185578      0.664      0.413       0.45      0.254\n","Speed: 0.4ms preprocess, 1.2ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_018/val\u001b[0m\n","\n","‚úÖ Trial 18 Completed\n","  mAP@0.5: 0.4496\n","  mAP@0.5:0.95: 0.2541\n","  Precision: 0.6641\n","  Recall: 0.4130\n","üßπ CUDA cache cleared\n","[I 2025-12-01 02:02:48,254] Trial 18 finished with value: 0.44957300675590606 and parameters: {'imgsz': 640, 'optimizer': 'Adam', 'lr0': 0.00010868283028325681, 'momentum': 0.880751382254641, 'weight_decay': 4.263436279094774e-05, 'warmup_epochs': 2, 'warmup_momentum': 0.8191386459098908, 'warmup_bias_lr': 0.08336988722241398, 'mosaic': 0.5601569636128313, 'mixup': 0.15056203668349555}. Best is trial 15 with value: 0.5002439377495521.\n","\n","‚úì Completed 19/20 trials\n","\n","================================================================================\n","TRIAL 19/20\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 56 (auto-adjusted for image size)\n","  Optimizer: Adam\n","  Learning Rate: 0.000112\n","  Momentum: 0.9064\n","  Weight Decay: 0.000125\n","  Warmup: epochs=2, momentum=0.79, bias_lr=0.057\n","  Mosaic: 0.69\n","  Mixup: 0.12\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=56, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tmp/yolo12s/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=6, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00011238911120900159, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.11597246328188607, mode=train, model=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/models/yolo12s/yolo12s.pt, momentum=0.9063791258472338, mosaic=0.6872134603197738, multi_scale=False, name=yolo12s_trial_019, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_019, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_019/yolo12s_trial_019, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.05712022338379076, warmup_epochs=2, warmup_momentum=0.789644291939959, weight_decay=0.0001250956947385644, workers=8, workspace=None\n","Overriding model.yaml nc=80 with nc=10\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n","  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n","  6                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 4]        \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n","  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 11                  -1  1    345856  ultralytics.nn.modules.block.A2C2f           [768, 256, 1, False, -1]      \n"," 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 14                  -1  1     95104  ultralytics.nn.modules.block.A2C2f           [512, 128, 1, False, -1]      \n"," 15                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 17                  -1  1    296704  ultralytics.nn.modules.block.A2C2f           [384, 256, 1, False, -1]      \n"," 18                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 20                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n"," 21        [14, 17, 20]  1    823278  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n","YOLOv12s summary: 272 layers, 9,257,006 parameters, 9,256,990 gradients, 21.5 GFLOPs\n","\n","Transferred 685/691 items from pretrained weights\n","Freezing layer 'model.21.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1511.7¬±603.9 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 24.5Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 577.4¬±109.5 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 8.9Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_019/yolo12s_trial_019/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.00011238911120900159, momentum=0.9063791258472338) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.00010945873289624385), 119 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_019/yolo12s_trial_019\u001b[0m\n","Starting training for 6 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/6      36.8G      1.469       1.24      1.073       1654        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.0it/s 44.2s\n","                   all      10000     185578      0.588      0.358       0.38      0.208\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/6      35.7G      1.409     0.9574      1.047       1497        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.8s\n","                   all      10000     185578      0.618      0.398      0.422      0.231\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/6      35.2G      1.382      0.909      1.035       1841        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.6s\n","                   all      10000     185578      0.572       0.42      0.463      0.257\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/6      36.1G      1.366     0.8749      1.028       1557        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.6s\n","                   all      10000     185578      0.667      0.438       0.47      0.263\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/6        36G      1.344     0.8484      1.018       1326        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.0s\n","                   all      10000     185578      0.698      0.438      0.487      0.274\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/6      35.7G      1.328     0.8228      1.011       1280        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 293/293 1.8it/s 2:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 2.1it/s 42.2s\n","                   all      10000     185578      0.587      0.455      0.496       0.28\n","\n","6 epochs completed in 0.347 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_019/yolo12s_trial_019/weights/last.pt, 18.9MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_019/yolo12s_trial_019/weights/best.pt, 18.9MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_019/yolo12s_trial_019/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 90/90 1.7it/s 52.8s\n","                   all      10000     185578      0.587      0.455      0.496       0.28\n","                person       3220      13265      0.681      0.561      0.616      0.314\n","                 rider        515        649      0.575      0.436      0.434      0.215\n","                   car       9879     102540      0.798      0.667      0.758      0.468\n","                 truck       2689       4247      0.663      0.511      0.574      0.411\n","                   bus       1242       1597      0.555      0.554      0.556      0.431\n","                 train         14         15          0          0    0.00313    0.00163\n","                 motor        334        452      0.623        0.4      0.416      0.213\n","                  bike        578       1007      0.567      0.427       0.46       0.23\n","         traffic light       5653      26891      0.687      0.472       0.54        0.2\n","          traffic sign       8221      34915       0.72      0.523      0.602      0.317\n","Speed: 0.1ms preprocess, 0.9ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_019/yolo12s_trial_019\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","YOLOv12s summary (fused): 159 layers, 9,234,750 parameters, 0 gradients, 21.2 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1342.6¬±461.0 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 12.0Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 10.0it/s 1:02\n","                   all      10000     185578       0.59      0.455      0.496      0.281\n","Speed: 0.5ms preprocess, 1.6ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trial_019/val\u001b[0m\n","\n","‚úÖ Trial 19 Completed\n","  mAP@0.5: 0.4964\n","  mAP@0.5:0.95: 0.2805\n","  Precision: 0.5896\n","  Recall: 0.4548\n","üßπ CUDA cache cleared\n","[I 2025-12-01 02:25:55,927] Trial 19 finished with value: 0.49642713154511187 and parameters: {'imgsz': 768, 'optimizer': 'Adam', 'lr0': 0.00011238911120900159, 'momentum': 0.9063791258472338, 'weight_decay': 0.0001250956947385644, 'warmup_epochs': 2, 'warmup_momentum': 0.789644291939959, 'warmup_bias_lr': 0.05712022338379076, 'mosaic': 0.6872134603197738, 'mixup': 0.11597246328188607}. Best is trial 15 with value: 0.5002439377495521.\n","\n","‚úì Completed 20/20 trials\n","\n","================================================================================\n","OPTIMIZATION COMPLETED\n","================================================================================\n","Started: 2025-11-30 19:13:38\n","Ended: 2025-12-01 02:25:56\n","Duration: 7:12:17.512343\n","Total Trials: 20\n","Completed Trials: 20\n","Pruned Trials: 0\n","Failed Trials: 0\n","\n","Best Trial: 15\n","Best mAP@0.5: 0.5002\n","================================================================================\n"]}],"source":["# RUN HYPERPARAMETER OPTIMIZATION WITH OPTUNA\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('STARTING HYPERPARAMETER OPTIMIZATION')\n","print('=' * 80)\n","print(f'Model: {MODEL_NAME}')\n","print(f'Dataset: {YOLO_DATASET_ROOT.name}')\n","print(f'Number of Trials: {N_TRIALS}')\n","print(f'Epochs per Trial: {EPOCHS_PER_TRIAL}')\n","print(f'Timeout: {TIMEOUT_HOURS} hours' if TIMEOUT_HOURS else 'No timeout')\n","print(f'Device: {device}')\n","print('=' * 80)\n","\n","# Check if resuming from previous run\n","study_pkl_path = TUNE_DIR / 'optuna_study.pkl'\n","checkpoint_log_path = TUNE_DIR / 'checkpoint_log.json'\n","is_resuming = study_pkl_path.exists()\n","\n","if is_resuming:\n","    # Load existing study\n","    print('\\n' + '=' * 80)\n","    print('üîÑ RESUMING PREVIOUS OPTIMIZATION')\n","    print('=' * 80)\n","\n","    with open(study_pkl_path, 'rb') as f:\n","        study = pickle.load(f)\n","\n","    # Load checkpoint log\n","    checkpoint_data = []\n","    if checkpoint_log_path.exists():\n","        with open(checkpoint_log_path, 'r', encoding='utf-8') as f:\n","            checkpoint_data = json.load(f)\n","\n","    # Display resume information\n","    completed_trials = len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])\n","    pruned_trials = len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])\n","    failed_trials = len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL])\n","    total_previous_trials = len(study.trials)\n","\n","    print(f'\\nüìä Previous Run Summary:')\n","    print(f'  Completed Trials: {completed_trials}')\n","    print(f'  Pruned Trials: {pruned_trials}')\n","    print(f'  Failed Trials: {failed_trials}')\n","    print(f'  Total Previous Trials: {total_previous_trials}')\n","\n","    if completed_trials > 0:\n","        best_trial = study.best_trial\n","        print(f'\\nüèÜ Best Result So Far:')\n","        print(f'  Trial: {best_trial.number}')\n","        print(f'  mAP@0.5: {best_trial.value:.4f}')\n","\n","        # Show top 3 completed trials\n","        completed_trial_list = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n","        sorted_trials = sorted(completed_trial_list, key=lambda t: t.value, reverse=True)\n","        top_3_trials = sorted_trials[:3]\n","\n","        print(f'\\nüìà Top 3 Trials:')\n","        for idx, trial in enumerate(top_3_trials, 1):\n","            print(f'  {idx}. Trial {trial.number}: mAP@0.5 = {trial.value:.4f}')\n","\n","    # Show last checkpoint info\n","    if checkpoint_data:\n","        last_checkpoint = checkpoint_data[-1]\n","        print(f'\\nüïê Last Checkpoint:')\n","        print(f'  Timestamp: {last_checkpoint[\"timestamp\"]}')\n","        print(f'  Last Trial: {last_checkpoint[\"trial_number\"]}')\n","        print(f'  Current Best mAP: {last_checkpoint[\"best_map\"]:.4f}')\n","\n","    remaining_trials = N_TRIALS - total_previous_trials\n","    print(f'\\n‚û°Ô∏è  Continuing optimization: {remaining_trials} trials remaining (of {N_TRIALS} total)')\n","    print('=' * 80)\n","\n","    # Store remaining trials for optimization\n","    trials_to_run = remaining_trials\n","\n","else:\n","    # Create new Optuna study\n","    print('\\nüÜï Creating new optimization study')\n","\n","    study = optuna.create_study(\n","        study_name=f'{MODEL_NAME}_optuna_{RUN_TIMESTAMP}',\n","        direction='maximize',  # Maximize mAP@0.5\n","        sampler=optuna.samplers.TPESampler(\n","            seed=42,\n","            n_startup_trials=N_STARTUP_TRIALS,  # Random trials before optimization\n","            multivariate=True,  # Consider parameter interactions\n","            group=True  # Group related parameters\n","        ),\n","        pruner=optuna.pruners.MedianPruner(\n","            n_startup_trials=N_STARTUP_TRIALS,\n","            n_warmup_steps=15,  # Wait before pruning\n","            interval_steps=5  # Check every 5 steps\n","        )\n","    )\n","\n","    # Initialize checkpoint log\n","    checkpoint_data = []\n","\n","    # Store trials to run for new study\n","    trials_to_run = N_TRIALS\n","\n","# Run optimization\n","start_time = datetime.now()\n","print(f'\\nüöÄ Optimization started at {start_time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n","\n","# Define checkpoint callback\n","def checkpoint_callback(study, trial):\n","    \"\"\"Save checkpoint after each trial completion\"\"\"\n","    print(f'\\n‚úì Completed {len(study.trials)}/{N_TRIALS} trials')\n","\n","    # Update checkpoint log\n","    checkpoint_entry = {\n","        'trial_number': trial.number,\n","        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n","        'trial_state': trial.state.name,\n","        'best_map': study.best_value if len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]) > 0 else 0.0,\n","        'completed_trials': len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]),\n","        'total_trials': len(study.trials)\n","    }\n","    checkpoint_data.append(checkpoint_entry)\n","\n","    # Save checkpoint log\n","    with open(checkpoint_log_path, 'w', encoding='utf-8') as f:\n","        json.dump(checkpoint_data, f, indent=2)\n","\n","    # Save study object\n","    with open(study_pkl_path, 'wb') as f:\n","        pickle.dump(study, f)\n","\n","    # Force garbage collection\n","    gc.collect()\n","\n","try:\n","    study.optimize(\n","        objective,\n","        n_trials=trials_to_run,  # Use calculated remaining trials when resuming\n","        timeout=TIMEOUT_HOURS * 3600 if TIMEOUT_HOURS else None,\n","        show_progress_bar=True,\n","        callbacks=[checkpoint_callback]\n","    )\n","except KeyboardInterrupt:\n","    print('\\n‚ö†Ô∏è  Optimization interrupted by user')\n","    print(f'üíæ Progress saved to: {TUNE_DIR}')\n","    print(f'   - Study checkpoint: {study_pkl_path.name}')\n","    print(f'   - Checkpoint log: {checkpoint_log_path.name}')\n","    print(f'\\nüîÑ To resume: Simply re-run this notebook')\n","except Exception as e:\n","    print(f'\\n‚ùå Optimization failed: {e}')\n","    import traceback\n","    traceback.print_exc()\n","\n","end_time = datetime.now()\n","duration = end_time - start_time\n","\n","print('\\n' + '=' * 80)\n","print('OPTIMIZATION COMPLETED')\n","print('=' * 80)\n","print(f'Started: {start_time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n","print(f'Ended: {end_time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n","print(f'Duration: {duration}')\n","print(f'Total Trials: {len(study.trials)}')\n","print(f'Completed Trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}')\n","print(f'Pruned Trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}')\n","print(f'Failed Trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL])}')\n","print(f'\\nBest Trial: {study.best_trial.number}')\n","print(f'Best mAP@0.5: {study.best_value:.4f}')\n","print('=' * 80)"]},{"cell_type":"markdown","id":"c5ab4d62","metadata":{"id":"c5ab4d62"},"source":["## 9. Save All Trials Summary"]},{"cell_type":"code","execution_count":14,"id":"0a3c5d31","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0a3c5d31","executionInfo":{"status":"ok","timestamp":1764555956127,"user_tz":-180,"elapsed":6,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"5970f91f-840a-43fb-d320-34b94a8756da"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","SAVING CONSOLIDATED TRIAL SUMMARY\n","================================================================================\n","‚úì Consolidated JSON summary saved: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/yolo12s_all_trials_summary.json\n","  Total trials saved: 20\n","‚úì CSV summary saved: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/yolo12s_all_trials_summary.csv\n","  Columns: 29, Rows: 20\n","================================================================================\n","\n","üìä Trial Summary Statistics:\n","  Completed Trials: 20\n","  Failed Trials: 0\n","\n","  mAP@0.5 Statistics:\n","    Best: 0.5002 (Trial 15)\n","    Worst: 0.4161\n","    Mean: 0.4725\n","    Std: 0.0273\n","    Median: 0.4845\n","================================================================================\n"]}],"source":["# SAVE CONSOLIDATED SUMMARY OF ALL TRIALS\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('SAVING CONSOLIDATED TRIAL SUMMARY')\n","print('=' * 80)\n","\n","# Collect all trial results dynamically from study\n","all_trials_data = []\n","\n","for trial in study.trials:\n","    trial_dir = TUNE_DIR / f\"trial_{trial.number:03d}\"\n","    results_file = trial_dir / \"trial_results.json\"\n","\n","    if results_file.exists():\n","        try:\n","            with open(results_file, 'r') as f:\n","                trial_data = json.load(f)\n","                all_trials_data.append(trial_data)\n","        except Exception as e:\n","            print(f\"‚ö†Ô∏è  Could not read trial {trial.number} results: {e}\")\n","    else:\n","        print(f\"‚ö†Ô∏è  No results file found for trial {trial.number}\")\n","\n","# Create comprehensive summary\n","optimization_summary = {\n","    \"model_name\": MODEL_NAME,\n","    \"dataset\": YOLO_DATASET_ROOT.name,\n","    \"optimization_config\": {\n","        \"n_trials\": N_TRIALS,\n","        \"epochs_per_trial\": EPOCHS_PER_TRIAL,\n","        \"timeout_hours\": TIMEOUT_HOURS,\n","        \"n_startup_trials\": N_STARTUP_TRIALS,\n","    },\n","    \"optimization_results\": {\n","        \"start_time\": start_time.isoformat(),\n","        \"end_time\": end_time.isoformat(),\n","        \"duration_seconds\": duration.total_seconds(),\n","        \"total_trials\": len(study.trials),\n","        \"completed_trials\": len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]),\n","        \"pruned_trials\": len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]),\n","        \"failed_trials\": len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL]),\n","        \"best_trial_number\": study.best_trial.number,\n","        \"best_map50\": study.best_value,\n","    },\n","    \"best_hyperparameters\": study.best_params,\n","    \"all_trials\": all_trials_data,\n","    \"timestamp\": datetime.now().isoformat(),\n","}\n","\n","# Save consolidated summary as JSON\n","summary_path = TUNE_DIR / f\"{MODEL_NAME}_all_trials_summary.json\"\n","with open(summary_path, 'w') as f:\n","    json.dump(optimization_summary, f, indent=2)\n","\n","print(f'‚úì Consolidated JSON summary saved: {summary_path}')\n","print(f'  Total trials saved: {len(all_trials_data)}')\n","\n","# Create CSV summary for easy analysis\n","csv_data = []\n","for trial_data in all_trials_data:\n","    row = {\n","        'trial_number': trial_data.get('trial_number'),\n","        'status': trial_data.get('status'),\n","        'map50': trial_data.get('validation_metrics', {}).get('map50'),\n","        'map50_95': trial_data.get('validation_metrics', {}).get('map50_95'),\n","        'precision': trial_data.get('validation_metrics', {}).get('precision'),\n","        'recall': trial_data.get('validation_metrics', {}).get('recall'),\n","        'error_type': trial_data.get('error_type', '')  # Include error type if failed\n","    }\n","    # Add hyperparameters\n","    for key, value in trial_data.get('hyperparameters', {}).items():\n","        row[f'hp_{key}'] = value\n","    # Flag best trial\n","    row['best_trial'] = trial_data.get('trial_number') == study.best_trial.number\n","    csv_data.append(row)\n","\n","df_trials = pd.DataFrame(csv_data)\n","\n","# Sort CSV by mAP@0.5 descending (best first)\n","df_trials.sort_values(by='map50', ascending=False, inplace=True)\n","\n","# Save CSV\n","csv_path = TUNE_DIR / f\"{MODEL_NAME}_all_trials_summary.csv\"\n","df_trials.to_csv(csv_path, index=False)\n","\n","print(f'‚úì CSV summary saved: {csv_path}')\n","print(f'  Columns: {len(df_trials.columns)}, Rows: {len(df_trials)}')\n","print('=' * 80)\n","\n","# Display summary statistics\n","if len(df_trials) > 0:\n","    print('\\nüìä Trial Summary Statistics:')\n","    print(f'  Completed Trials: {len(df_trials[df_trials[\"status\"] == \"completed\"])}')\n","    print(f'  Failed Trials: {len(df_trials[df_trials[\"status\"] == \"failed\"])}')\n","\n","    completed_trials = df_trials[df_trials['status'] == 'completed']\n","    if len(completed_trials) > 0:\n","        best_trial_row = completed_trials.loc[completed_trials[\"map50\"].idxmax()]\n","        print(f'\\n  mAP@0.5 Statistics:')\n","        print(f'    Best: {best_trial_row[\"map50\"]:.4f} (Trial {best_trial_row[\"trial_number\"]})')\n","        print(f'    Worst: {completed_trials[\"map50\"].min():.4f}')\n","        print(f'    Mean: {completed_trials[\"map50\"].mean():.4f}')\n","        print(f'    Std: {completed_trials[\"map50\"].std():.4f}')\n","        print(f'    Median: {completed_trials[\"map50\"].median():.4f}')\n","print('=' * 80)"]},{"cell_type":"markdown","id":"923833ab","metadata":{"id":"923833ab"},"source":["## 10. Save Best Hyperparameters"]},{"cell_type":"code","execution_count":15,"id":"58d702ef","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"58d702ef","executionInfo":{"status":"ok","timestamp":1764555956149,"user_tz":-180,"elapsed":5,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"0d8cb402-11a3-4af1-ec69-a1c5d9b9e272"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","SAVING BEST HYPERPARAMETERS\n","================================================================================\n","\n","üèÜ Best Trial: 15\n","   Best mAP@0.5: 0.5002\n","\n","üìã Best Hyperparameters:\n","   imgsz: 768\n","   optimizer: Adam\n","   lr0: 0.00012192021890239396\n","   momentum: 0.8888996841929279\n","   weight_decay: 3.4214299147447924e-05\n","   warmup_epochs: 2\n","   warmup_momentum: 0.7753369681596541\n","   warmup_bias_lr: 0.07369622770237041\n","   mosaic: 0.7510576170263057\n","   mixup: 0.06813130521919572\n","\n","‚úì Best hyperparameters saved to: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/best_hyperparameters.json\n","‚úì Best hyperparameters saved to: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/best_hyperparameters.yaml\n","\n","üìã Best Hyperparameters Summary:\n","  Optimizer: Adam\n","  Learning Rate: 0.000122\n","  Momentum: 0.8889\n","  Weight Decay: 0.000034\n","================================================================================\n"]}],"source":["# SAVE BEST HYPERPARAMETERS\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('SAVING BEST HYPERPARAMETERS')\n","print('=' * 80)\n","\n","# Extract best parameters from study\n","best_params = study.best_params\n","best_trial = study.best_trial\n","\n","print(f'\\nüèÜ Best Trial: {best_trial.number}')\n","print(f'   Best mAP@0.5: {study.best_value:.4f}')\n","print('\\nüìã Best Hyperparameters:')\n","for param_name, param_value in best_params.items():\n","    print(f'   {param_name}: {param_value}')\n","\n","# Save best hyperparameters to JSON\n","best_params_json = TUNE_DIR / 'best_hyperparameters.json'\n","with open(best_params_json, 'w') as f:\n","    json.dump({\n","        'model': MODEL_NAME,\n","        'dataset_root': str(YOLO_DATASET_ROOT),\n","        'data_yaml_path': str(DATA_YAML_PATH),\n","        'optimization_results': {\n","            'best_trial': study.best_trial.number,\n","            'best_map50': study.best_value,\n","            'total_trials': len(study.trials),\n","            'optimization_duration': str(duration),\n","        },\n","        'hyperparameters': best_params,\n","        'timestamp': datetime.now().isoformat(),\n","        'notes': 'Use these hyperparameters for training. Add epochs, batch, imgsz, device, and other training settings.'\n","    }, f, indent=2)\n","\n","print(f'\\n‚úì Best hyperparameters saved to: {best_params_json}')\n","\n","# Save to YAML format (ready for YOLO training)\n","best_params_yaml = TUNE_DIR / 'best_hyperparameters.yaml'\n","with open(best_params_yaml, 'w') as f:\n","    yaml.dump(best_params, f, default_flow_style=False, sort_keys=False)\n","\n","print(f'‚úì Best hyperparameters saved to: {best_params_yaml}')\n","\n","print('\\nüìã Best Hyperparameters Summary:')\n","print(f'  Optimizer: {best_params.get(\"optimizer\", \"N/A\")}')\n","print(f'  Learning Rate: {best_params.get(\"lr0\", 0):.6f}')\n","print(f'  Momentum: {best_params.get(\"momentum\", 0):.4f}')\n","print(f'  Weight Decay: {best_params.get(\"weight_decay\", 0):.6f}')\n","\n","print('=' * 80)"]},{"cell_type":"markdown","id":"24aed975","metadata":{"id":"24aed975"},"source":["## 11. Visualize Optimization Results"]},{"cell_type":"code","execution_count":16,"id":"2abf24a7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2abf24a7","executionInfo":{"status":"ok","timestamp":1764555956166,"user_tz":-180,"elapsed":3,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"602ffccc-5821-4326-e09d-70386983e883"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì PNG conversion workaround functions loaded\n","  Use save_plotly_as_png_alternative(fig, path) to save PNG files\n"]}],"source":["# ============================================================================\n","# WORKAROUND: Convert Plotly figures to PNG without kaleido\n","# ============================================================================\n","# This cell provides an alternative to save PNG images when kaleido doesn't work\n","\n","def save_plotly_as_png_alternative(fig, output_path, width=1200, height=800):\n","    \"\"\"\n","    Alternative method to save Plotly figure as PNG without kaleido.\n","    Uses matplotlib as a fallback by converting through static image.\n","    \"\"\"\n","    try:\n","        # Method 1: Try orca (older engine, might be available)\n","        try:\n","            fig.write_image(str(output_path), width=width, height=height, scale=2, engine=\"orca\")\n","            return True, \"orca\"\n","        except:\n","            pass\n","\n","        # Method 2: Save as SVG then convert (requires cairosvg)\n","        try:\n","            import cairosvg\n","            svg_path = str(output_path).replace('.png', '_temp.svg')\n","            fig.write_image(svg_path, width=width, height=height, format='svg')\n","            cairosvg.svg2png(url=svg_path, write_to=str(output_path), output_width=width, output_height=height)\n","            os.remove(svg_path)\n","            return True, \"svg+cairosvg\"\n","        except:\n","            pass\n","\n","        # Method 3: Use selenium/chrome (Colab has chrome)\n","        try:\n","            import plotly.io as pio\n","            pio.kaleido.scope.chromium_args = tuple([arg for arg in pio.kaleido.scope.chromium_args if arg != \"--disable-dev-shm-usage\"])\n","            fig.write_image(str(output_path), width=width, height=height, scale=2)\n","            return True, \"kaleido-fixed\"\n","        except:\n","            pass\n","\n","        # Method 4: Just save high-quality HTML (can be converted later)\n","        html_path = str(output_path).replace('.png', '_hq.html')\n","        fig.write_html(\n","            html_path,\n","            config={'toImageButtonOptions': {'format': 'png', 'width': width, 'height': height, 'scale': 2}}\n","        )\n","        print(f'   ‚ÑπÔ∏è  Saved high-quality HTML instead: {html_path}')\n","        print(f'      You can open it and use the camera icon to download PNG')\n","        return False, \"html-fallback\"\n","\n","    except Exception as e:\n","        print(f'   ‚ùå All conversion methods failed: {e}')\n","        return False, \"failed\"\n","\n","print('‚úì PNG conversion workaround functions loaded')\n","print('  Use save_plotly_as_png_alternative(fig, path) to save PNG files')\n"]},{"cell_type":"code","execution_count":17,"id":"6162db87","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6162db87","executionInfo":{"status":"ok","timestamp":1764555956179,"user_tz":-180,"elapsed":6,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"f296e34f-1808-4fcd-e2c5-fe470421ee78"},"outputs":[{"output_type":"stream","name":"stdout","text":["üìä Your visualization files:\n","================================================================================\n","\n","================================================================================\n","üìù To download PNG files:\n","  1. Open each HTML file by double-clicking it in the Files panel\n","  2. The interactive plot will open in a new tab\n","  3. Hover over the plot and click the camera icon (üì∑) in the toolbar\n","  4. The PNG will download automatically\n","\n","üí° Alternative: Run the plots again after restarting runtime\n","   (Your study results are saved in the .pkl file, so they won't be lost!)\n"]}],"source":["# ============================================================================\n","# SIMPLE SOLUTION: Manually download PNGs from the interactive plots above\n","# ============================================================================\n","# Since kaleido isn't working, here's what to do:\n","#\n","# 1. Scroll up to the interactive Plotly visualizations displayed above\n","# 2. Hover over each plot and you'll see a camera icon in the top-right\n","# 3. Click the camera icon to download the PNG file\n","# 4. The files will be saved to your Downloads folder\n","# 5. Upload them to your Colab files or Drive if needed\n","#\n","# Or, use this cell to get download links for the HTML files:\n","\n","print('üìä Your visualization files:')\n","print('=' * 80)\n","\n","# Find the latest HTML files\n","import glob\n","from pathlib import Path\n","\n","tune_dir = Path(TUNE_DIR)\n","html_files = {\n","    'Optimization History': sorted(tune_dir.glob('optimization_history_*.html'))[-1:],\n","    'Parameter Importance': sorted(tune_dir.glob('parameter_importance_*.html'))[-1:],\n","    'Parameter Slice': sorted(tune_dir.glob('parameter_slice_*.html'))[-1:]\n","}\n","\n","for title, files in html_files.items():\n","    if files:\n","        file_path = files[0]\n","        print(f'\\n{title}:')\n","        print(f'  üìÅ {file_path}')\n","        print(f'  üí° Open this file in Colab and click the camera icon to download PNG')\n","\n","print('\\n' + '=' * 80)\n","print('üìù To download PNG files:')\n","print('  1. Open each HTML file by double-clicking it in the Files panel')\n","print('  2. The interactive plot will open in a new tab')\n","print('  3. Hover over the plot and click the camera icon (üì∑) in the toolbar')\n","print('  4. The PNG will download automatically')\n","print('\\nüí° Alternative: Run the plots again after restarting runtime')\n","print('   (Your study results are saved in the .pkl file, so they won\\'t be lost!)')\n"]},{"cell_type":"code","execution_count":18,"id":"26d33d0e","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"26d33d0e","executionInfo":{"status":"ok","timestamp":1764555960588,"user_tz":-180,"elapsed":4360,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"18c87bfd-a341-41c6-f64e-3f383428f2bc"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","GENERATING OPTIMIZATION VISUALIZATIONS\n","================================================================================\n","\n","üìà Creating optimization history plot...\n"]},{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"0531cc4d-f038-4a78-9e3c-49eb876cc597\" class=\"plotly-graph-div\" style=\"height:600px; width:1200px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0531cc4d-f038-4a78-9e3c-49eb876cc597\")) {                    Plotly.newPlot(                        \"0531cc4d-f038-4a78-9e3c-49eb876cc597\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"y\":[0.43484521329474524,0.4203132949811936,0.49519995833717695,0.45441687794687446,0.4513530237178009,0.4828743932038234,0.47032618423038625,0.45059784127625296,0.4796248079552948,0.4160648676003249,0.48616483718215847,0.4988368790854956,0.49424874771185223,0.49369979189156926,0.49718201016154107,0.5002439377495521,0.491777936938033,0.4869266728788178,0.44957300675590606,0.49642713154511187],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"y\":[0.43484521329474524,0.43484521329474524,0.49519995833717695,0.49519995833717695,0.49519995833717695,0.49519995833717695,0.49519995833717695,0.49519995833717695,0.49519995833717695,0.49519995833717695,0.49519995833717695,0.4988368790854956,0.4988368790854956,0.4988368790854956,0.4988368790854956,0.5002439377495521,0.5002439377495521,0.5002439377495521,0.5002439377495521,0.5002439377495521],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"yolo12s - Hyperparameter Optimization History\"},\"xaxis\":{\"title\":{\"text\":\"Trial Number\"}},\"yaxis\":{\"title\":{\"text\":\"mAP@0.5\"}},\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"width\":1200,\"height\":600},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('0531cc4d-f038-4a78-9e3c-49eb876cc597');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["‚úì HTML saved to: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/optimization_history_20251201_022556.html\n","\n","üìä Creating parameter importance plot...\n"]},{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"f07fc059-5c42-4be3-8bad-a47469c9f2ec\" class=\"plotly-graph-div\" style=\"height:800px; width:1200px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f07fc059-5c42-4be3-8bad-a47469c9f2ec\")) {                    Plotly.newPlot(                        \"f07fc059-5c42-4be3-8bad-a47469c9f2ec\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"warmup_epochs (IntDistribution): 0.01643349001681771\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"lr0 (FloatDistribution): 0.021462612649811492\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"mixup (FloatDistribution): 0.023893707533577935\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"momentum (FloatDistribution): 0.025805531843786478\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"weight_decay (FloatDistribution): 0.02917030443825439\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"mosaic (FloatDistribution): 0.06406925856317247\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"warmup_momentum (FloatDistribution): 0.10234330951882357\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"optimizer (CategoricalDistribution): 0.15305959242970119\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"warmup_bias_lr (FloatDistribution): 0.20285789563741402\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"imgsz (CategoricalDistribution): 0.36090429736864077\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"],\"name\":\"Objective Value\",\"orientation\":\"h\",\"text\":[\"0.02\",\"0.02\",\"0.02\",\"0.03\",\"0.03\",\"0.06\",\"0.10\",\"0.15\",\"0.20\",\"0.36\"],\"textposition\":\"outside\",\"x\":[0.01643349001681771,0.021462612649811492,0.023893707533577935,0.025805531843786478,0.02917030443825439,0.06406925856317247,0.10234330951882357,0.15305959242970119,0.20285789563741402,0.36090429736864077],\"y\":[\"warmup_epochs\",\"lr0\",\"mixup\",\"momentum\",\"weight_decay\",\"mosaic\",\"warmup_momentum\",\"optimizer\",\"warmup_bias_lr\",\"imgsz\"],\"type\":\"bar\"}],                        {\"title\":{\"text\":\"yolo12s - Hyperparameter Importance\"},\"xaxis\":{\"title\":{\"text\":\"Importance\"}},\"yaxis\":{\"title\":{\"text\":\"Parameter\"}},\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"width\":1200,\"height\":800},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('f07fc059-5c42-4be3-8bad-a47469c9f2ec');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["‚úì HTML saved to: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/parameter_importance_20251201_022556.html\n","‚úì PNG saved to: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/parameter_importance_20251201_022556.png\n","‚úì PNG saved to: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/parameter_importance.png (for PDF report)\n","\n","üîç Creating parameter slice plots...\n"]},{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"4bba31be-ea29-490c-892e-34e4c6ca3c0f\" class=\"plotly-graph-div\" style=\"height:1000px; width:1400px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4bba31be-ea29-490c-892e-34e4c6ca3c0f\")) {                    Plotly.newPlot(                        \"4bba31be-ea29-490c-892e-34e4c6ca3c0f\",                        [{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":true},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[768,640,768,640,640,768,768,640,768,768,768,768,768,768,768,768,768,768,640,768],\"y\":[0.43484521329474524,0.4203132949811936,0.49519995833717695,0.45441687794687446,0.4513530237178009,0.4828743932038234,0.47032618423038625,0.45059784127625296,0.4796248079552948,0.4160648676003249,0.48616483718215847,0.4988368790854956,0.49424874771185223,0.49369979189156926,0.49718201016154107,0.5002439377495521,0.491777936938033,0.4869266728788178,0.44957300675590606,0.49642713154511187],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[0.00018408992080552527,0.0005418282319533242,0.00019485671251272575,0.00027520696850790545,0.00012019462074072741,0.00046416276498162026,0.0007972913946637024,0.00020733019435489495,0.00048582040249237995,0.0001315505817621954,0.00028301572154734456,0.00010118662648914812,0.0002581312357680321,0.00023828070218441419,0.00010296295701265204,0.00012192021890239396,0.00027838272655938826,0.00041263520115668436,0.00010868283028325681,0.00011238911120900159],\"y\":[0.43484521329474524,0.4203132949811936,0.49519995833717695,0.45441687794687446,0.4513530237178009,0.4828743932038234,0.47032618423038625,0.45059784127625296,0.4796248079552948,0.4160648676003249,0.48616483718215847,0.4988368790854956,0.49424874771185223,0.49369979189156926,0.49718201016154107,0.5002439377495521,0.491777936938033,0.4869266728788178,0.44957300675590606,0.49642713154511187],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[0.16648852816008436,0.15703519227860274,0.1368466053024314,0.15502656467222292,0.14260259077459436,0.09142805368635637,0.07855187248221054,0.07685297042243353,0.19612651086969135,0.023307356647408295,0.1689213722626892,0.15355229799013026,0.19438832444123538,0.10304833452181744,0.09401425469969821,0.06813130521919572,0.15580060558237022,0.05670264821395519,0.15056203668349555,0.11597246328188607],\"y\":[0.43484521329474524,0.4203132949811936,0.49519995833717695,0.45441687794687446,0.4513530237178009,0.4828743932038234,0.47032618423038625,0.45059784127625296,0.4796248079552948,0.4160648676003249,0.48616483718215847,0.4988368790854956,0.49424874771185223,0.49369979189156926,0.49718201016154107,0.5002439377495521,0.491777936938033,0.4869266728788178,0.44957300675590606,0.49642713154511187],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[0.856970033460184,0.8849474968237651,0.8578061911582335,0.9295026741224778,0.8751994424704447,0.9085534257456573,0.8642533694603853,0.9129593478682302,0.9150047365325835,0.891670669037609,0.8625119185091457,0.8514082197196229,0.8572661913383784,0.8591714717956058,0.8595336383710444,0.8888996841929279,0.865713023471312,0.9183480039077738,0.880751382254641,0.9063791258472338],\"y\":[0.43484521329474524,0.4203132949811936,0.49519995833717695,0.45441687794687446,0.4513530237178009,0.4828743932038234,0.47032618423038625,0.45059784127625296,0.4796248079552948,0.4160648676003249,0.48616483718215847,0.4988368790854956,0.49424874771185223,0.49369979189156926,0.49718201016154107,0.5002439377495521,0.491777936938033,0.4869266728788178,0.44957300675590606,0.49642713154511187],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[0.9849549260809971,0.728034992108518,0.5488360570031919,0.9847923138822793,0.5719899949745945,0.7922202551639732,0.5836788629401141,0.5252312452310752,0.5706004578234427,0.5015345090954606,0.6700564124086668,0.5692022195875244,0.6410064580534052,0.50194791734856,0.8450373653024943,0.7510576170263057,0.6118290774947986,0.6979925246933499,0.5601569636128313,0.6872134603197738],\"y\":[0.43484521329474524,0.4203132949811936,0.49519995833717695,0.45441687794687446,0.4513530237178009,0.4828743932038234,0.47032618423038625,0.45059784127625296,0.4796248079552948,0.4160648676003249,0.48616483718215847,0.4988368790854956,0.49424874771185223,0.49369979189156926,0.49718201016154107,0.5002439377495521,0.491777936938033,0.4869266728788178,0.44957300675590606,0.49642713154511187],\"type\":\"scatter\",\"xaxis\":\"x5\",\"yaxis\":\"y5\"},{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[\"SGD\",\"AdamW\",\"AdamW\",\"AdamW\",\"AdamW\",\"AdamW\",\"AdamW\",\"Adam\",\"AdamW\",\"SGD\",\"Adam\",\"Adam\",\"AdamW\",\"AdamW\",\"Adam\",\"Adam\",\"Adam\",\"Adam\",\"Adam\",\"Adam\"],\"y\":[0.43484521329474524,0.4203132949811936,0.49519995833717695,0.45441687794687446,0.4513530237178009,0.4828743932038234,0.47032618423038625,0.45059784127625296,0.4796248079552948,0.4160648676003249,0.48616483718215847,0.4988368790854956,0.49424874771185223,0.49369979189156926,0.49718201016154107,0.5002439377495521,0.491777936938033,0.4869266728788178,0.44957300675590606,0.49642713154511187],\"type\":\"scatter\",\"xaxis\":\"x6\",\"yaxis\":\"y6\"},{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[0.0020584494295802446,0.03663618432936917,0.03046137691733707,0.018485445552552705,0.01867742913680949,0.04132450636848238,0.027103902028703965,0.07630371691058041,0.06605121320956418,0.039587848873917364,0.061295823352773976,0.08676501697940245,0.06522360346616196,0.05406337265506802,0.08937271460237181,0.07369622770237041,0.0946625734899615,0.09735460872124413,0.08336988722241398,0.05712022338379076],\"y\":[0.43484521329474524,0.4203132949811936,0.49519995833717695,0.45441687794687446,0.4513530237178009,0.4828743932038234,0.47032618423038625,0.45059784127625296,0.4796248079552948,0.4160648676003249,0.48616483718215847,0.4988368790854956,0.49424874771185223,0.49369979189156926,0.49718201016154107,0.5002439377495521,0.491777936938033,0.4869266728788178,0.44957300675590606,0.49642713154511187],\"type\":\"scatter\",\"xaxis\":\"x7\",\"yaxis\":\"y7\"},{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[2,0,3,2,3,3,2,2,2,3,3,3,2,3,2,2,3,2,2,2],\"y\":[0.43484521329474524,0.4203132949811936,0.49519995833717695,0.45441687794687446,0.4513530237178009,0.4828743932038234,0.47032618423038625,0.45059784127625296,0.4796248079552948,0.4160648676003249,0.48616483718215847,0.4988368790854956,0.49424874771185223,0.49369979189156926,0.49718201016154107,0.5002439377495521,0.491777936938033,0.4869266728788178,0.44957300675590606,0.49642713154511187],\"type\":\"scatter\",\"xaxis\":\"x8\",\"yaxis\":\"y8\"},{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[0.8186326600082204,0.6314650918408482,0.8637788066524075,0.7460196257044758,0.8300113009765738,0.9456949457865867,0.7287380269749706,0.8695154725469569,0.6731002420462724,0.7134500399234733,0.7469764584689902,0.8269144783595105,0.8534200605965067,0.8610152809930884,0.827684640035661,0.7753369681596541,0.6236547885084676,0.770635246942724,0.8191386459098908,0.789644291939959],\"y\":[0.43484521329474524,0.4203132949811936,0.49519995833717695,0.45441687794687446,0.4513530237178009,0.4828743932038234,0.47032618423038625,0.45059784127625296,0.4796248079552948,0.4160648676003249,0.48616483718215847,0.4988368790854956,0.49424874771185223,0.49369979189156926,0.49718201016154107,0.5002439377495521,0.491777936938033,0.4869266728788178,0.44957300675590606,0.49642713154511187],\"type\":\"scatter\",\"xaxis\":\"x9\",\"yaxis\":\"y9\"},{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[0.0005399484409787432,0.00016738085788752134,0.000790261954970823,0.00004201672054372529,0.0008564246077898465,0.0007114668138090497,0.0003991310852882529,0.00038165556248635226,0.0004591891660849751,0.0003654114491446343,0.0009339471392402201,0.00035330454240099356,0.00005622432185034556,0.00032392015532818575,0.00021633449801145105,0.000034214299147447924,0.00003263640122653622,0.000015740681056021985,0.00004263436279094774,0.0001250956947385644],\"y\":[0.43484521329474524,0.4203132949811936,0.49519995833717695,0.45441687794687446,0.4513530237178009,0.4828743932038234,0.47032618423038625,0.45059784127625296,0.4796248079552948,0.4160648676003249,0.48616483718215847,0.4988368790854956,0.49424874771185223,0.49369979189156926,0.49718201016154107,0.5002439377495521,0.491777936938033,0.4869266728788178,0.44957300675590606,0.49642713154511187],\"type\":\"scatter\",\"xaxis\":\"x10\",\"yaxis\":\"y10\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.082],\"title\":{\"text\":\"imgsz\"},\"type\":\"category\",\"categoryorder\":\"array\",\"categoryarray\":[640,768]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Objective Value\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.10200000000000001,0.184],\"title\":{\"text\":\"lr0\"},\"type\":\"log\"},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.20400000000000001,0.28600000000000003],\"title\":{\"text\":\"mixup\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.306,0.388],\"title\":{\"text\":\"momentum\"}},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis5\":{\"anchor\":\"y5\",\"domain\":[0.40800000000000003,0.49000000000000005],\"title\":{\"text\":\"mosaic\"}},\"yaxis5\":{\"anchor\":\"x5\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis6\":{\"anchor\":\"y6\",\"domain\":[0.51,0.592],\"title\":{\"text\":\"optimizer\"},\"type\":\"category\",\"categoryorder\":\"array\",\"categoryarray\":[\"SGD\",\"Adam\",\"AdamW\"]},\"yaxis6\":{\"anchor\":\"x6\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis7\":{\"anchor\":\"y7\",\"domain\":[0.612,0.694],\"title\":{\"text\":\"warmup_bias_lr\"}},\"yaxis7\":{\"anchor\":\"x7\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis8\":{\"anchor\":\"y8\",\"domain\":[0.7140000000000001,0.796],\"title\":{\"text\":\"warmup_epochs\"}},\"yaxis8\":{\"anchor\":\"x8\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis9\":{\"anchor\":\"y9\",\"domain\":[0.8160000000000001,0.898],\"title\":{\"text\":\"warmup_momentum\"}},\"yaxis9\":{\"anchor\":\"x9\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis10\":{\"anchor\":\"y10\",\"domain\":[0.9179999999999999,0.9999999999999999],\"title\":{\"text\":\"weight_decay\"},\"type\":\"log\"},\"yaxis10\":{\"anchor\":\"x10\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"title\":{\"text\":\"yolo12s - Parameter Slice Plot\"},\"width\":1400,\"height\":1000},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('4bba31be-ea29-490c-892e-34e4c6ca3c0f');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["‚úì HTML saved to: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/parameter_slice_20251201_022556.html\n","‚úì PNG saved to: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/parameter_slice_20251201_022556.png\n","‚úì PNG saved to: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/parameter_slice.png (for PDF report)\n"]}],"source":["# ============================================================================\n","# VISUALIZE OPTIMIZATION RESULTS: HISTORY, PARAMETER IMPORTANCE, SLICE PLOTS\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('GENERATING OPTIMIZATION VISUALIZATIONS')\n","print('=' * 80)\n","\n","if len(study.trials) == 0:\n","    print(\"‚ö†Ô∏è  No trials found in study, skipping visualization.\")\n","else:\n","    timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')\n","\n","    # -----------------------------\n","    # 1Ô∏è‚É£ Optimization History Plot\n","    # -----------------------------\n","    try:\n","        print('\\nüìà Creating optimization history plot...')\n","        fig_history = plot_optimization_history(study)\n","        fig_history.update_layout(\n","            title=f'{MODEL_NAME} - Hyperparameter Optimization History',\n","            xaxis_title='Trial Number',\n","            yaxis_title='mAP@0.5',\n","            template='plotly_white',\n","            width=1200,\n","            height=600\n","        )\n","        fig_history.show()\n","\n","        # Save HTML with timestamp\n","        optimization_history_path = TUNE_DIR / f'optimization_history_{timestamp_str}.html'\n","        fig_history.write_html(str(optimization_history_path))\n","        print(f'‚úì HTML saved to: {optimization_history_path}')\n","\n","    except Exception as history_error:\n","        print(f'‚ùå Failed to create optimization history plot: {history_error}')\n","\n","    # -----------------------------\n","    # 2Ô∏è‚É£ Parameter Importance Plot\n","    # -----------------------------\n","    try:\n","        print('\\nüìä Creating parameter importance plot...')\n","        fig_importance = plot_param_importances(study)\n","        fig_importance.update_layout(\n","            title=f'{MODEL_NAME} - Hyperparameter Importance',\n","            xaxis_title='Importance',\n","            yaxis_title='Parameter',\n","            template='plotly_white',\n","            width=1200,\n","            height=800\n","        )\n","        fig_importance.show()\n","\n","        # Save HTML with timestamp\n","        param_importance_path = TUNE_DIR / f'parameter_importance_{timestamp_str}.html'\n","        fig_importance.write_html(str(param_importance_path))\n","        print(f'‚úì HTML saved to: {param_importance_path}')\n","\n","        # Save PNG with timestamp AND consistent name\n","        try:\n","            # Try kaleido first\n","            param_importance_img_ts = TUNE_DIR / f'parameter_importance_{timestamp_str}.png'\n","            fig_importance.write_image(str(param_importance_img_ts), width=1200, height=800, scale=2)\n","            print(f'‚úì PNG saved to: {param_importance_img_ts}')\n","\n","            # Consistent name for PDF report\n","            param_importance_img = TUNE_DIR / 'parameter_importance.png'\n","            fig_importance.write_image(str(param_importance_img), width=1200, height=800, scale=2)\n","            print(f'‚úì PNG saved to: {param_importance_img} (for PDF report)')\n","        except Exception as png_error:\n","            print(f'‚ö†Ô∏è  Could not save PNG: {png_error}')\n","            print(f'   Error type: {type(png_error).__name__}')\n","            import traceback\n","            print(f'   Details: {traceback.format_exc()}')\n","            param_importance_img = None\n","\n","    except (RuntimeError, ValueError) as importance_error:\n","        print(f'‚ö†Ô∏è  Could not generate parameter importance plot: {importance_error}')\n","        print('  (This can happen when trials have insufficient data variation)')\n","        param_importance_img = None\n","\n","    # -----------------------------\n","    # 3Ô∏è‚É£ Parameter Slice Plots\n","    # -----------------------------\n","    try:\n","        print('\\nüîç Creating parameter slice plots...')\n","        fig_slice = plot_slice(study)\n","        fig_slice.update_layout(\n","            title=f'{MODEL_NAME} - Parameter Slice Plot',\n","            template='plotly_white',\n","            width=1400,\n","            height=1000\n","        )\n","        fig_slice.show()\n","\n","        # Save HTML with timestamp\n","        slice_path = TUNE_DIR / f'parameter_slice_{timestamp_str}.html'\n","        fig_slice.write_html(str(slice_path))\n","        print(f'‚úì HTML saved to: {slice_path}')\n","\n","        # Save PNG with timestamp AND consistent name\n","        try:\n","            # Try kaleido\n","            slice_img_path_ts = TUNE_DIR / f'parameter_slice_{timestamp_str}.png'\n","            fig_slice.write_image(str(slice_img_path_ts), width=1400, height=1000, scale=2)\n","            print(f'‚úì PNG saved to: {slice_img_path_ts}')\n","\n","            # Consistent name for PDF report\n","            slice_img_path = TUNE_DIR / 'parameter_slice.png'\n","            fig_slice.write_image(str(slice_img_path), width=1400, height=1000, scale=2)\n","            print(f'‚úì PNG saved to: {slice_img_path} (for PDF report)')\n","        except Exception as png_error:\n","            print(f'‚ö†Ô∏è  Could not save PNG: {png_error}')\n","            print(f'   Error type: {type(png_error).__name__}')\n","            import traceback\n","            print(f'   Details: {traceback.format_exc()}')\n","\n","    except Exception as slice_error:\n","        print(f'‚ö†Ô∏è  Could not generate parameter slice plot: {slice_error}')"]},{"cell_type":"markdown","id":"585a97a5","metadata":{"id":"585a97a5"},"source":["## 12. Generate Tuning PDF Report\n","\n","Create a comprehensive PDF report with optimization results, visualizations, and model performance."]},{"cell_type":"code","execution_count":19,"id":"6e3c3580","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6e3c3580","executionInfo":{"status":"ok","timestamp":1764555964864,"user_tz":-180,"elapsed":4077,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"e50afb12-bd59-4661-cea2-7c0204af6203"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","GENERATING COMPREHENSIVE TUNING PDF REPORT\n","================================================================================\n","\n","üìä Preparing comprehensive report with 20 trials\n","   Best Trial: 15\n","   Best mAP@0.5: 0.5002\n","\n","üìã Compiling trials data for report...\n","‚úì Compiled 20 trials for report\n","   Available columns: ['trial', 'state', 'mAP@0.5', 'imgsz', 'optimizer', 'lr0', 'momentum', 'weight_decay', 'warmup_epochs', 'warmup_momentum', 'warmup_bias_lr', 'mosaic', 'mixup']\n","‚úì Executive summary generated\n","   DataFrame columns: ['trial', 'state', 'mAP@0.5', 'imgsz', 'optimizer', 'lr0', 'momentum', 'weight_decay', 'warmup_epochs', 'warmup_momentum', 'warmup_bias_lr', 'mosaic', 'mixup']\n","   Sample row keys: ['trial', 'state', 'mAP@0.5', 'imgsz', 'optimizer', 'lr0', 'momentum', 'weight_decay', 'warmup_epochs', 'warmup_momentum', 'warmup_bias_lr', 'mosaic', 'mixup']\n","   Creating detailed params for top 5 trials...\n","   ‚úì Top 5 trials details added\n","\n","üìä Generating custom visualizations for PDF report...\n","   Completed trials: 20\n","   Columns available: ['trial', 'state', 'mAP@0.5', 'imgsz', 'optimizer', 'lr0', 'momentum', 'weight_decay', 'warmup_epochs', 'warmup_momentum', 'warmup_bias_lr', 'mosaic', 'mixup']\n","   Creating performance distribution box plot...\n","‚úì Performance distribution chart saved: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/report_performance_distribution.png\n","   Creating parameter correlation heatmap...\n","‚úì Correlation heatmap saved: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/report_correlation_heatmap.png\n","   Creating optimization timeline chart...\n","‚úì Optimization timeline chart saved: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/report_optimization_timeline.png\n","‚úì mAP progress chart saved: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/report_map_progress.png\n","   Creating learning rate impact chart...\n","‚úì Learning rate impact chart saved: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/report_lr_impact.png\n","   Creating optimizer comparison chart...\n","‚úì Optimizer comparison chart saved: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/report_optimizer_comparison.png\n","   Available augmentation params: ['mixup', 'mosaic']\n","‚úì Augmentation impact chart saved: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/report_augmentation_impact.png\n","   Creating regularization impact chart...\n","‚úì Regularization impact chart saved: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/report_regularization_impact.png\n","   Creating image size impact chart...\n","‚úì Image size impact chart saved: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/report_imgsz_impact.png\n","‚úì All custom visualizations generated for PDF report\n","   Generating key insights and recommendations...\n","‚úì Insights and recommendations section completed\n","\n","‚úì Comprehensive PDF report generated: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/yolo12s_tuning_report.pdf\n","  Size: 0.8 MB\n","  Sections: Overview, Executive Summary, Best Hyperparameters, Top 20 Trials,\n","            Performance Analysis (10 advanced visualizations), Key Insights,\n","            Production Recommendations, All Trials Summary\n","  Charts: Distribution, Correlation, Timeline, mAP Progress, Learning Rate,\n","          Optimizer, Augmentation, Regularization, Image Size\n","================================================================================\n"]}],"source":["# GENERATE Tuning PDF REPORT\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('GENERATING COMPREHENSIVE TUNING PDF REPORT')\n","print('=' * 80)\n","\n","# Use already extracted best parameters and trial data from previous sections\n","best_params = study.best_params\n","best_trial = study.best_trial\n","\n","print(f'\\nüìä Preparing comprehensive report with {len(study.trials)} trials')\n","print(f'   Best Trial: {best_trial.number}')\n","print(f'   Best mAP@0.5: {study.best_value:.4f}')\n","\n","# Compile all trials data into DataFrame for PDF report\n","print('\\nüìã Compiling trials data for report...')\n","trials_data_for_pdf = []\n","\n","for trial in study.trials:\n","    # Create row with trial info and hyperparameters directly from trial.params\n","    row_data = {\n","        'trial': trial.number,\n","        'state': trial.state.name,\n","        'mAP@0.5': trial.value if trial.value is not None else 0.0,\n","    }\n","\n","    # Add all hyperparameters directly from trial.params\n","    row_data.update(trial.params)\n","\n","    trials_data_for_pdf.append(row_data)\n","\n","# Create DataFrame and sort by mAP@0.5\n","df_trials = pd.DataFrame(trials_data_for_pdf)\n","df_trials_sorted = df_trials.sort_values('mAP@0.5', ascending=False)\n","\n","print(f'‚úì Compiled {len(df_trials)} trials for report')\n","print(f'   Available columns: {list(df_trials.columns)}')\n","\n","# Create tuning PDF report\n","pdf_report_path = TUNE_DIR / f'{MODEL_NAME}_tuning_report.pdf'\n","\n","doc = SimpleDocTemplate(str(pdf_report_path), pagesize=A4,\n","                       rightMargin=30, leftMargin=30,\n","                       topMargin=30, bottomMargin=30)\n","\n","story = []\n","styles = getSampleStyleSheet()\n","\n","# Custom styles\n","title_style = ParagraphStyle(\n","    'CustomTitle',\n","    parent=styles['Heading1'],\n","    fontSize=18,\n","    textColor=rl_colors.HexColor('#2c3e50'),\n","    spaceAfter=30,\n","    alignment=TA_CENTER\n",")\n","\n","heading_style = ParagraphStyle(\n","    'CustomHeading',\n","    parent=styles['Heading2'],\n","    fontSize=16,\n","    textColor=rl_colors.HexColor('#34495e'),\n","    spaceAfter=12,\n","    spaceBefore=20\n",")\n","\n","small_style = ParagraphStyle(\n","    'SmallText',\n","    parent=styles['Normal'],\n","    fontSize=7,\n","    wordWrap='CJK'\n",")\n","\n","# Title\n","story.append(Paragraph(f'{MODEL_NAME} Hyperparameter Tuning Report', title_style))\n","story.append(Paragraph(f'Generated: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}', styles['Normal']))\n","story.append(Spacer(1, 20))\n","\n","# ===== SECTION 1: OVERVIEW =====\n","story.append(Paragraph('1. Optimization Overview', heading_style))\n","\n","info_data = [\n","    ['Property', 'Value'],\n","    ['Model', MODEL_NAME],\n","    ['Dataset', YOLO_DATASET_ROOT.name],\n","    ['Total Trials', str(len(study.trials))],\n","    ['Completed Trials', str(len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]))],\n","    ['Failed Trials', str(len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL]))],\n","    ['Best Trial', str(study.best_trial.number)],\n","    ['Best mAP@0.5', f'{study.best_value:.4f}'],\n","    ['Optimization Duration', str(duration)],\n","]\n","\n","info_table = Table(info_data, colWidths=[2.5*inch, 3.5*inch])\n","info_table.setStyle(TableStyle([\n","    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#2c3e50')),\n","    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","    ('BACKGROUND', (0, 1), (-1, -1), rl_colors.HexColor('#ecf0f1')),\n","    ('TEXTCOLOR', (0, 1), (-1, -1), rl_colors.black),\n","    ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n","    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","    ('FONTNAME', (0, 1), (0, -1), 'Helvetica-Bold'),\n","    ('FONTSIZE', (0, 0), (-1, -1), 10),\n","    ('BOTTOMPADDING', (0, 0), (-1, -1), 8),\n","    ('TOPPADDING', (0, 0), (-1, -1), 8),\n","    ('GRID', (0, 0), (-1, -1), 1, rl_colors.grey)\n","]))\n","story.append(info_table)\n","story.append(Spacer(1, 20))\n","\n","# ===== SECTION 2: CONFIGURATION =====\n","story.append(Paragraph('2. Optimization Configuration', heading_style))\n","\n","opt_config_data = [\n","    ['Parameter', 'Value'],\n","    ['Total Trials', str(N_TRIALS)],\n","    ['Epochs per Trial', str(EPOCHS_PER_TRIAL)],\n","    ['Batch Size', str(BATCH_SIZE)],\n","    ['Startup Trials (TPE)', str(N_STARTUP_TRIALS)],\n","    ['Device', device],\n","    ['Number of Classes', str(NUM_CLASSES)],\n","    ['Train Images', str(dataset_stats.get('train', {}).get('images', 'N/A'))],\n","    ['Val Images', str(dataset_stats.get('val', {}).get('images', 'N/A'))],\n","]\n","\n","opt_config_table = Table(opt_config_data, colWidths=[3*inch, 3*inch])\n","opt_config_table.setStyle(TableStyle([\n","    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#95a5a6')),\n","    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n","    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","    ('FONTSIZE', (0, 0), (-1, 0), 11),\n","    ('FONTSIZE', (0, 1), (-1, -1), 9),\n","    ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n","    ('TOPPADDING', (0, 0), (-1, -1), 6),\n","    ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n","    ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n","]))\n","story.append(opt_config_table)\n","story.append(Spacer(1, 20))\n","\n","# ===== SECTION 2.5: EXECUTIVE SUMMARY & KEY FINDINGS =====\n","story.append(PageBreak())\n","story.append(Paragraph('2.5 Executive Summary & Key Findings', heading_style))\n","\n","# Calculate key statistics\n","completed_df_summary = df_trials_sorted[df_trials_sorted['state'] == 'COMPLETE']\n","best_map = completed_df_summary['mAP@0.5'].max()\n","worst_map = completed_df_summary['mAP@0.5'].min()\n","mean_map = completed_df_summary['mAP@0.5'].mean()\n","improvement_pct = ((best_map - worst_map) / worst_map) * 100 if worst_map > 0 else 0\n","\n","# Calculate optimizer statistics\n","if 'optimizer' in completed_df_summary.columns:\n","    opt_stats = completed_df_summary.groupby('optimizer')['mAP@0.5'].agg(['mean', 'count'])\n","    best_opt = opt_stats['mean'].idxmax()\n","    best_opt_mean = opt_stats.loc[best_opt, 'mean']\n","else:\n","    best_opt = 'N/A'\n","    best_opt_mean = 0\n","\n","# Calculate image size impact\n","if 'imgsz' in completed_df_summary.columns:\n","    img_stats = completed_df_summary.groupby('imgsz')['mAP@0.5'].mean()\n","    best_imgsz = img_stats.idxmax()\n","    imgsz_improvement = ((img_stats.max() - img_stats.min()) / img_stats.min()) * 100 if len(img_stats) > 1 else 0\n","else:\n","    best_imgsz = 'N/A'\n","    imgsz_improvement = 0\n","\n","# Create findings summary\n","findings_data = [\n","    ['Metric', 'Value'],\n","    ['üèÜ Best Performance', f'Trial #{study.best_trial.number}: mAP@0.5 = {best_map:.4f}'],\n","    ['üìä Performance Range', f'{worst_map:.4f} to {best_map:.4f} ({improvement_pct:.1f}% improvement)'],\n","    ['üìà Mean Performance', f'{mean_map:.4f} across {len(completed_df_summary)} trials'],\n","    ['‚ö° Best Optimizer', f'{best_opt} (mean: {best_opt_mean:.4f})'],\n","    ['üñºÔ∏è Optimal Image Size', f'{int(best_imgsz)}px ({imgsz_improvement:.2f}% better)' if best_imgsz != 'N/A' else 'N/A'],\n","    ['‚è±Ô∏è Optimization Time', str(duration)],\n","    ['‚úÖ Success Rate', f'{len(completed_df_summary)}/{len(study.trials)} trials ({len(completed_df_summary)/len(study.trials)*100:.1f}%)'],\n","]\n","\n","findings_table = Table(findings_data, colWidths=[2.5*inch, 3.5*inch])\n","findings_table.setStyle(TableStyle([\n","    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#27ae60')),\n","    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","    ('BACKGROUND', (0, 1), (-1, -1), rl_colors.HexColor('#ecf9f2')),\n","    ('ALIGN', (0, 0), (-1, 0), 'CENTER'),\n","    ('ALIGN', (0, 1), (0, -1), 'LEFT'),\n","    ('ALIGN', (1, 1), (1, -1), 'LEFT'),\n","    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","    ('FONTSIZE', (0, 0), (-1, 0), 11),\n","    ('FONTSIZE', (0, 1), (-1, -1), 9),\n","    ('BOTTOMPADDING', (0, 0), (-1, -1), 8),\n","    ('TOPPADDING', (0, 0), (-1, -1), 8),\n","    ('GRID', (0, 0), (-1, -1), 1, rl_colors.black),\n","    ('LINEBELOW', (0, 0), (-1, 0), 2, rl_colors.HexColor('#27ae60'))\n","]))\n","story.append(findings_table)\n","story.append(Spacer(1, 15))\n","\n","# Add key insights text\n","insights_text = f\"\"\"\n","<b>Key Insights:</b><br/>\n","‚Ä¢ The optimization process successfully explored {len(study.trials)} trials, achieving a {improvement_pct:.1f}% performance improvement from worst to best.<br/>\n","‚Ä¢ <b>{best_opt}</b> optimizer demonstrated superior performance with mean mAP@0.5 of {best_opt_mean:.4f}.<br/>\n","‚Ä¢ Image size of <b>{int(best_imgsz)}px</b> provided optimal accuracy-efficiency tradeoff.<br/>\n","‚Ä¢ High consistency achieved: mean performance ({mean_map:.4f}) close to best ({best_map:.4f}), indicating robust hyperparameter space.\n","\"\"\"\n","story.append(Paragraph(insights_text, styles['Normal']))\n","story.append(Spacer(1, 20))\n","\n","print(f'‚úì Executive summary generated')\n","\n","# ===== SECTION 3: BEST HYPERPARAMETERS =====\n","story.append(PageBreak())\n","story.append(Paragraph('3. Best Hyperparameters', heading_style))\n","\n","hyperparam_data = [['Parameter', 'Value', 'Description']]\n","param_descriptions = {\n","    'optimizer': 'Optimization algorithm',\n","    'lr0': 'Initial learning rate',\n","    'lrf': 'Final learning rate factor',\n","    'momentum': 'SGD momentum / Adam beta1',\n","    'weight_decay': 'Weight decay (L2 penalty)',\n","    'warmup_epochs': 'Warmup epochs',\n","    'warmup_momentum': 'Warmup momentum',\n","    'box': 'Box loss gain',\n","    'cls': 'Classification loss gain',\n","    'dfl': 'Distribution focal loss gain',\n","    'hsv_h': 'HSV-Hue augmentation',\n","    'hsv_s': 'HSV-Saturation augmentation',\n","    'hsv_v': 'HSV-Value augmentation',\n","    'degrees': 'Rotation augmentation',\n","    'translate': 'Translation augmentation',\n","    'scale': 'Scale augmentation',\n","    'shear': 'Shear augmentation',\n","    'perspective': 'Perspective augmentation',\n","    'flipud': 'Vertical flip probability',\n","    'fliplr': 'Horizontal flip probability',\n","    'mosaic': 'Mosaic augmentation',\n","    'mixup': 'Mixup augmentation',\n","    'copy_paste': 'Copy-paste augmentation',\n","}\n","\n","for param_key, param_value in best_params.items():\n","    desc = param_descriptions.get(param_key, '')\n","    formatted_value = f'{param_value:.6f}' if isinstance(param_value, float) else str(param_value)\n","    hyperparam_data.append([param_key, formatted_value, desc])\n","\n","hyperparam_table = Table(hyperparam_data, colWidths=[1.8*inch, 1.5*inch, 2.7*inch])\n","hyperparam_table.setStyle(TableStyle([\n","    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#3498db')),\n","    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","    ('ALIGN', (0, 0), (1, -1), 'CENTER'),\n","    ('ALIGN', (2, 1), (2, -1), 'LEFT'),\n","    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","    ('FONTSIZE', (0, 0), (-1, 0), 10),\n","    ('FONTSIZE', (0, 1), (-1, -1), 8),\n","    ('BOTTOMPADDING', (0, 0), (-1, -1), 5),\n","    ('TOPPADDING', (0, 0), (-1, -1), 5),\n","    ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n","    ('GRID', (0, 0), (-1, -1), 1, rl_colors.black),\n","    ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n","]))\n","story.append(hyperparam_table)\n","story.append(Spacer(1, 20))\n","\n","# ===== SECTION 4: TOP 20 TRIALS WITH HYPERPARAMETERS =====\n","story.append(PageBreak())\n","story.append(Paragraph('4. Top 20 Trials Performance', heading_style))\n","\n","# Create detailed top trials table with key hyperparameters\n","print(f'   DataFrame columns: {list(df_trials_sorted.columns)}')\n","print(f'   Sample row keys: {list(df_trials_sorted.head(1).iloc[0].keys())}')\n","\n","top_trials_data = [['#', 'mAP@0.5', 'ImgSz', 'Opt', 'lr0', 'mom', 'mixup', 'mosaic']]\n","for idx, (_, row) in enumerate(df_trials_sorted.head(20).iterrows(), 1):\n","    # Use pd.notna() to check if value exists and is not NaN\n","    img_val = str(int(row['imgsz'])) if 'imgsz' in row and pd.notna(row['imgsz']) else 'N/A'\n","    opt_val = row.get('optimizer', 'N/A')\n","    lr0_val = f\"{row['lr0']:.4f}\" if 'lr0' in row and pd.notna(row['lr0']) else 'N/A'\n","    mom_val = f\"{row['momentum']:.3f}\" if 'momentum' in row and pd.notna(row['momentum']) else 'N/A'\n","    mix_val = f\"{row['mixup']:.2f}\" if 'mixup' in row and pd.notna(row['mixup']) else 'N/A'\n","    mos_val = f\"{row['mosaic']:.2f}\" if 'mosaic' in row and pd.notna(row['mosaic']) else 'N/A'\n","\n","    top_trials_data.append([\n","        str(idx),\n","        f\"{row['mAP@0.5']:.4f}\",\n","        img_val,\n","        str(opt_val)[:4] if opt_val != 'N/A' else 'N/A',\n","        lr0_val,\n","        mom_val,\n","        mix_val,\n","        mos_val,\n","    ])\n","\n","top_trials_table = Table(top_trials_data, colWidths=[0.3*inch, 0.8*inch, 0.6*inch, 0.6*inch, 0.7*inch, 0.7*inch, 0.7*inch, 0.7*inch])\n","top_trials_table.setStyle(TableStyle([\n","    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#27ae60')),\n","    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n","    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","    ('FONTSIZE', (0, 0), (-1, 0), 9),\n","    ('FONTSIZE', (0, 1), (-1, -1), 7),\n","    ('BOTTOMPADDING', (0, 0), (-1, -1), 4),\n","    ('TOPPADDING', (0, 0), (-1, -1), 4),\n","    ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n","    ('GRID', (0, 0), (-1, -1), 0.5, rl_colors.black)\n","]))\n","story.append(top_trials_table)\n","story.append(Spacer(1, 15))\n","\n","# Detailed hyperparameters for top 5 trials\n","story.append(PageBreak())\n","story.append(Paragraph('4.1 Detailed Hyperparameters - Top 5 Trials', heading_style))\n","\n","print(f'   Creating detailed params for top 5 trials...')\n","for rank, (_, row) in enumerate(df_trials_sorted.head(5).iterrows(), 1):\n","    story.append(Paragraph(f'<b>Rank {rank}: Trial {int(row[\"trial\"])} (mAP@0.5: {row[\"mAP@0.5\"]:.4f})</b>', styles['Normal']))\n","\n","    trial_params_text = []\n","    # Get all parameter columns (exclude trial, state, mAP@0.5)\n","    param_cols = [col for col in df_trials_sorted.columns if col not in ['trial', 'state', 'mAP@0.5']]\n","\n","    for param_key in sorted(param_cols):\n","        if param_key in row and pd.notna(row[param_key]):\n","            value = row[param_key]\n","            formatted_val = f'{value:.6f}' if isinstance(value, float) else str(value)\n","            trial_params_text.append(f'{param_key}={formatted_val}')\n","\n","    if trial_params_text:\n","        params_str = ', '.join(trial_params_text)\n","        story.append(Paragraph(params_str, small_style))\n","    else:\n","        story.append(Paragraph('No parameter data available', small_style))\n","    story.append(Spacer(1, 10))\n","\n","print(f'   ‚úì Top 5 trials details added')\n","\n","# ===== SECTION 5: OPTIMIZATION VISUALIZATIONS =====\n","story.append(PageBreak())\n","story.append(Paragraph('5. Optimization Visualizations & Analysis', heading_style))\n","\n","print('\\nüìä Generating custom visualizations for PDF report...')\n","\n","# Prepare data for completed trials only\n","completed_trials_df = df_trials_sorted[df_trials_sorted['state'] == 'COMPLETE'].copy()\n","\n","print(f'   Completed trials: {len(completed_trials_df)}')\n","print(f'   Columns available: {list(completed_trials_df.columns)}')\n","\n","if len(completed_trials_df) == 0:\n","    story.append(Paragraph('No completed trials available for visualization.', styles['Normal']))\n","    print('   ‚ö†Ô∏è No completed trials found!')\n","else:\n","    # 5.0 Performance Distribution Box Plot\n","    story.append(Paragraph('5.0 Performance Distribution Analysis', styles['Heading3']))\n","\n","    print(f'   Creating performance distribution box plot...')\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n","\n","    # Box plot for overall distribution\n","    bp = ax1.boxplot([completed_trials_df['mAP@0.5']], vert=True, patch_artist=True,\n","                     labels=['All Trials'], widths=0.5)\n","    bp['boxes'][0].set_facecolor('#3498db')\n","    bp['boxes'][0].set_alpha(0.7)\n","    bp['medians'][0].set_color('#e74c3c')\n","    bp['medians'][0].set_linewidth(2)\n","\n","    # Add statistics annotations\n","    q1 = completed_trials_df['mAP@0.5'].quantile(0.25)\n","    median = completed_trials_df['mAP@0.5'].median()\n","    q3 = completed_trials_df['mAP@0.5'].quantile(0.75)\n","\n","    ax1.text(1.3, q1, f'Q1: {q1:.4f}', fontsize=9, va='center')\n","    ax1.text(1.3, median, f'Median: {median:.4f}', fontsize=9, va='center', fontweight='bold', color='#e74c3c')\n","    ax1.text(1.3, q3, f'Q3: {q3:.4f}', fontsize=9, va='center')\n","    ax1.text(1.3, completed_trials_df['mAP@0.5'].min(), f'Min: {completed_trials_df[\"mAP@0.5\"].min():.4f}',\n","            fontsize=8, va='center', color='gray')\n","    ax1.text(1.3, completed_trials_df['mAP@0.5'].max(), f'Max: {completed_trials_df[\"mAP@0.5\"].max():.4f}',\n","            fontsize=8, va='center', color='gray')\n","\n","    ax1.set_ylabel('mAP@0.5', fontsize=12, fontweight='bold')\n","    ax1.set_title('Overall Performance Distribution', fontsize=13, fontweight='bold')\n","    ax1.grid(True, alpha=0.3, axis='y')\n","\n","    # Histogram with KDE\n","    ax2.hist(completed_trials_df['mAP@0.5'], bins=15, alpha=0.7, color='#3498db',\n","            edgecolor='black', linewidth=1)\n","    ax2.axvline(median, color='#e74c3c', linestyle='--', linewidth=2, label=f'Median: {median:.4f}')\n","    ax2.axvline(study.best_value, color='#27ae60', linestyle='--', linewidth=2, label=f'Best: {study.best_value:.4f}')\n","    ax2.set_xlabel('mAP@0.5', fontsize=12, fontweight='bold')\n","    ax2.set_ylabel('Frequency', fontsize=12, fontweight='bold')\n","    ax2.set_title('Performance Histogram', fontsize=13, fontweight='bold')\n","    ax2.legend(fontsize=10)\n","    ax2.grid(True, alpha=0.3, axis='y')\n","\n","    plt.tight_layout()\n","\n","    perf_dist_img = TUNE_DIR / 'report_performance_distribution.png'\n","    plt.savefig(perf_dist_img, dpi=150, bbox_inches='tight')\n","    plt.close()\n","\n","    story.append(Image(str(perf_dist_img), width=6.5*inch, height=2.7*inch))\n","    story.append(Spacer(1, 15))\n","    print(f'‚úì Performance distribution chart saved: {perf_dist_img}')\n","\n","    # Add distribution statistics table\n","    dist_stats_data = [\n","        ['Statistic', 'Value'],\n","        ['Mean', f'{completed_trials_df[\"mAP@0.5\"].mean():.4f}'],\n","        ['Median', f'{median:.4f}'],\n","        ['Std Dev', f'{completed_trials_df[\"mAP@0.5\"].std():.4f}'],\n","        ['IQR (Q3-Q1)', f'{q3-q1:.4f}'],\n","        ['Range', f'{completed_trials_df[\"mAP@0.5\"].max() - completed_trials_df[\"mAP@0.5\"].min():.4f}'],\n","    ]\n","\n","    dist_table = Table(dist_stats_data, colWidths=[2*inch, 2*inch])\n","    dist_table.setStyle(TableStyle([\n","        ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#3498db')),\n","        ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n","        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","        ('FONTSIZE', (0, 0), (-1, 0), 10),\n","        ('FONTSIZE', (0, 1), (-1, -1), 9),\n","        ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n","        ('TOPPADDING', (0, 0), (-1, -1), 6),\n","        ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n","        ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n","    ]))\n","    story.append(dist_table)\n","    story.append(Spacer(1, 15))\n","\n","    # 5.1 Parameter Correlation Heatmap\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.1 Parameter Correlation Analysis', styles['Heading3']))\n","\n","    print(f'   Creating parameter correlation heatmap...')\n","\n","    # Select numeric columns for correlation\n","    numeric_cols = ['mAP@0.5']\n","    param_cols = ['lr0', 'momentum', 'weight_decay', 'mixup', 'mosaic']\n","    available_params = [col for col in param_cols if col in completed_trials_df.columns and completed_trials_df[col].notna().any()]\n","\n","    if len(available_params) >= 2:\n","        corr_cols = numeric_cols + available_params\n","        corr_data = completed_trials_df[corr_cols].corr()\n","\n","        fig, ax = plt.subplots(figsize=(10, 8))\n","        im = ax.imshow(corr_data, cmap='RdYlGn', aspect='auto', vmin=-1, vmax=1)\n","\n","        # Set ticks and labels\n","        ax.set_xticks(range(len(corr_cols)))\n","        ax.set_yticks(range(len(corr_cols)))\n","        ax.set_xticklabels(corr_cols, rotation=45, ha='right', fontsize=10)\n","        ax.set_yticklabels(corr_cols, fontsize=10)\n","\n","        # Add correlation values as text\n","        for i in range(len(corr_cols)):\n","            for j in range(len(corr_cols)):\n","                value = corr_data.iloc[i, j]\n","                color = 'white' if abs(value) > 0.5 else 'black'\n","                ax.text(j, i, f'{value:.2f}', ha='center', va='center',\n","                       color=color, fontsize=9, fontweight='bold')\n","\n","        # Add colorbar\n","        cbar = plt.colorbar(im, ax=ax)\n","        cbar.set_label('Correlation Coefficient', fontsize=11, fontweight='bold')\n","\n","        ax.set_title(f'{MODEL_NAME} - Parameter Correlation with Performance',\n","                    fontsize=13, fontweight='bold', pad=20)\n","        plt.tight_layout()\n","\n","        corr_img = TUNE_DIR / 'report_correlation_heatmap.png'\n","        plt.savefig(corr_img, dpi=150, bbox_inches='tight')\n","        plt.close()\n","\n","        story.append(Image(str(corr_img), width=6*inch, height=4.8*inch))\n","        story.append(Spacer(1, 15))\n","        print(f'‚úì Correlation heatmap saved: {corr_img}')\n","\n","        # Add interpretation\n","        map_corr = corr_data['mAP@0.5'].drop('mAP@0.5')\n","        strongest_pos = map_corr.idxmax() if map_corr.max() > 0 else None\n","        strongest_neg = map_corr.idxmin() if map_corr.min() < 0 else None\n","\n","        corr_text = f\"<b>Correlation Insights:</b><br/>\"\n","        if strongest_pos:\n","            corr_text += f\"‚Ä¢ Strongest positive correlation: <b>{strongest_pos}</b> ({map_corr[strongest_pos]:.3f}) - Higher values tend to improve performance.<br/>\"\n","        if strongest_neg:\n","            corr_text += f\"‚Ä¢ Strongest negative correlation: <b>{strongest_neg}</b> ({map_corr[strongest_neg]:.3f}) - Higher values tend to decrease performance.<br/>\"\n","        corr_text += f\"‚Ä¢ Green cells indicate positive correlation, red cells indicate negative correlation.\"\n","\n","        story.append(Paragraph(corr_text, styles['Normal']))\n","        story.append(Spacer(1, 15))\n","\n","    # 5.2 Optimization Timeline & Convergence\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.2 Optimization Timeline & Convergence', styles['Heading3']))\n","\n","    print(f'   Creating optimization timeline chart...')\n","    fig, ax = plt.subplots(figsize=(12, 5))\n","\n","    # Sort by trial number for timeline\n","    timeline_df = completed_trials_df.sort_values('trial')\n","\n","    # Plot actual performance\n","    ax.plot(timeline_df['trial'], timeline_df['mAP@0.5'],\n","            marker='o', linestyle='-', linewidth=1.5, markersize=5,\n","            color='#95a5a6', alpha=0.5, label='Trial Performance')\n","\n","    # Calculate and plot moving average (window=5)\n","    window = min(5, len(timeline_df))\n","    if window > 1:\n","        moving_avg = timeline_df['mAP@0.5'].rolling(window=window, min_periods=1).mean()\n","        ax.plot(timeline_df['trial'], moving_avg,\n","               linewidth=3, color='#3498db', label=f'{window}-Trial Moving Average')\n","\n","    # Calculate and plot cumulative best\n","    cumulative_best = timeline_df['mAP@0.5'].cummax()\n","    ax.plot(timeline_df['trial'], cumulative_best,\n","           linewidth=2.5, color='#27ae60', linestyle='--',\n","           label='Cumulative Best', marker='*', markersize=8, markevery=cumulative_best.diff().fillna(1) != 0)\n","\n","    # Mark best trial\n","    best_trial_idx = timeline_df[timeline_df['mAP@0.5'] == study.best_value].iloc[0]\n","    ax.scatter([best_trial_idx['trial']], [study.best_value],\n","              s=300, color='#e74c3c', marker='*', zorder=5,\n","              edgecolors='black', linewidth=2, label=f'Best Trial #{int(best_trial_idx[\"trial\"])}')\n","    ax.annotate(f'Best: {study.best_value:.4f}',\n","               xy=(best_trial_idx['trial'], study.best_value),\n","               xytext=(10, 10), textcoords='offset points',\n","               fontsize=10, fontweight='bold',\n","               bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.7),\n","               arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0', lw=2))\n","\n","    ax.set_xlabel('Trial Number', fontsize=12, fontweight='bold')\n","    ax.set_ylabel('mAP@0.5', fontsize=12, fontweight='bold')\n","    ax.set_title(f'{MODEL_NAME} - Optimization Progress & Convergence', fontsize=14, fontweight='bold')\n","    ax.legend(fontsize=10, loc='lower right')\n","    ax.grid(True, alpha=0.3)\n","\n","    plt.tight_layout()\n","\n","    timeline_img = TUNE_DIR / 'report_optimization_timeline.png'\n","    plt.savefig(timeline_img, dpi=150, bbox_inches='tight')\n","    plt.close()\n","\n","    story.append(Image(str(timeline_img), width=6.5*inch, height=2.7*inch))\n","    story.append(Spacer(1, 15))\n","    print(f'‚úì Optimization timeline chart saved: {timeline_img}')\n","\n","    # Add convergence analysis\n","    best_found_at = int(best_trial_idx['trial'])\n","    total_trials = len(timeline_df)\n","    convergence_pct = (best_found_at / total_trials) * 100\n","\n","    convergence_text = f\"\"\"<b>Convergence Analysis:</b><br/>\n","‚Ä¢ Best solution found at trial <b>#{best_found_at}</b> ({convergence_pct:.1f}% through optimization).<br/>\n","‚Ä¢ Moving average shows {'rapid early convergence' if convergence_pct < 40 else 'gradual improvement' if convergence_pct < 70 else 'late discovery'} pattern.<br/>\n","‚Ä¢ Cumulative best curve indicates {'efficient' if convergence_pct < 50 else 'moderate'} exploration of hyperparameter space.\n","\"\"\"\n","    story.append(Paragraph(convergence_text, styles['Normal']))\n","    story.append(Spacer(1, 15))\n","\n","    # 5.3 mAP@0.5 Progress Over Trials (original chart)\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.3 mAP@0.5 Progress Over Trials', styles['Heading3']))\n","\n","    fig, ax = plt.subplots(figsize=(10, 5))\n","    ax.plot(completed_trials_df['trial'], completed_trials_df['mAP@0.5'],\n","            marker='o', linestyle='-', linewidth=2, markersize=6, color='#3498db', alpha=0.7)\n","    ax.axhline(y=study.best_value, color='#e74c3c', linestyle='--', linewidth=2,\n","               label=f'Best: {study.best_value:.4f}')\n","    ax.set_xlabel('Trial Number', fontsize=12, fontweight='bold')\n","    ax.set_ylabel('mAP@0.5', fontsize=12, fontweight='bold')\n","    ax.set_title(f'{MODEL_NAME} - mAP@0.5 Progress', fontsize=14, fontweight='bold')\n","    ax.grid(True, alpha=0.3)\n","    ax.legend(fontsize=10)\n","    plt.tight_layout()\n","\n","    map_progress_img = TUNE_DIR / 'report_map_progress.png'\n","    plt.savefig(map_progress_img, dpi=150, bbox_inches='tight')\n","    plt.close()\n","\n","    story.append(Image(str(map_progress_img), width=6.5*inch, height=3.25*inch))\n","    story.append(Spacer(1, 15))\n","    print(f'‚úì mAP progress chart saved: {map_progress_img}')\n","\n","    # 5.4 Learning Rate vs mAP@0.5\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.4 Learning Rate Impact on Performance', styles['Heading3']))\n","\n","    if 'lr0' in completed_trials_df.columns and completed_trials_df['lr0'].notna().any():\n","        print(f'   Creating learning rate impact chart...')\n","        fig, ax = plt.subplots(figsize=(10, 5))\n","        scatter = ax.scatter(completed_trials_df['lr0'], completed_trials_df['mAP@0.5'],\n","                           c=completed_trials_df['mAP@0.5'], cmap='RdYlGn',\n","                           s=100, alpha=0.6, edgecolors='black', linewidth=0.5)\n","        ax.set_xlabel('Learning Rate (lr0)', fontsize=12, fontweight='bold')\n","        ax.set_ylabel('mAP@0.5', fontsize=12, fontweight='bold')\n","        ax.set_title(f'{MODEL_NAME} - Learning Rate vs Performance', fontsize=14, fontweight='bold')\n","        ax.grid(True, alpha=0.3)\n","        cbar = plt.colorbar(scatter, ax=ax)\n","        cbar.set_label('mAP@0.5', fontsize=10)\n","        plt.tight_layout()\n","\n","        lr_impact_img = TUNE_DIR / 'report_lr_impact.png'\n","        plt.savefig(lr_impact_img, dpi=150, bbox_inches='tight')\n","        plt.close()\n","\n","        story.append(Image(str(lr_impact_img), width=6.5*inch, height=3.25*inch))\n","        story.append(Spacer(1, 15))\n","        print(f'‚úì Learning rate impact chart saved: {lr_impact_img}')\n","    else:\n","        story.append(Paragraph('Learning rate data not available for visualization.', styles['Normal']))\n","        story.append(Spacer(1, 15))\n","        print(f'   ‚ö†Ô∏è lr0 column not found or empty')\n","\n","    # 5.5 Optimizer Comparison\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.5 Optimizer Performance Comparison', styles['Heading3']))\n","\n","    if 'optimizer' in completed_trials_df.columns and completed_trials_df['optimizer'].notna().any():\n","        print(f'   Creating optimizer comparison chart...')\n","        fig, ax = plt.subplots(figsize=(12, 6))\n","\n","        # Calculate comprehensive statistics\n","        optimizer_stats = completed_trials_df.groupby('optimizer')['mAP@0.5'].agg(['mean', 'max', 'min', 'std', 'count'])\n","        optimizer_stats = optimizer_stats.sort_values('mean', ascending=False)\n","\n","        x_pos = range(len(optimizer_stats))\n","\n","        # Create bars with gradient effect\n","        bars = ax.bar(x_pos, optimizer_stats['mean'], alpha=0.8,\n","                     color=['#2ecc71', '#3498db', '#9b59b6', '#e67e22'][:len(optimizer_stats)],\n","                     edgecolor='black', linewidth=1.5, width=0.6)\n","\n","        # Add max and min markers\n","        ax.scatter(x_pos, optimizer_stats['max'], color='#27ae60', s=150,\n","                  label='Max mAP@0.5', zorder=5, edgecolors='black', linewidth=1.5, marker='^')\n","        ax.scatter(x_pos, optimizer_stats['min'], color='#e74c3c', s=150,\n","                  label='Min mAP@0.5', zorder=5, edgecolors='black', linewidth=1.5, marker='v')\n","\n","        # Add error bars for standard deviation\n","        ax.errorbar(x_pos, optimizer_stats['mean'], yerr=optimizer_stats['std'],\n","                   fmt='none', ecolor='gray', alpha=0.5, capsize=5, capthick=2, linewidth=2)\n","\n","        ax.set_xlabel('Optimizer Type', fontsize=13, fontweight='bold')\n","        ax.set_ylabel('mAP@0.5', fontsize=13, fontweight='bold')\n","        ax.set_title(f'{MODEL_NAME} - Optimizer Performance Comparison (Mean ¬± Std Dev)',\n","                    fontsize=14, fontweight='bold')\n","        ax.set_xticks(x_pos)\n","        ax.set_xticklabels([])\n","        ax.legend(fontsize=11, loc='lower left', framealpha=0.9, ncol=2)\n","        ax.grid(True, alpha=0.3, axis='y', linestyle='--')\n","\n","        # Add optimizer names inside bars\n","        for i, (opt, row) in enumerate(optimizer_stats.iterrows()):\n","            # Optimizer name inside bar (centered vertically)\n","            ax.text(i, row['mean'] / 2, opt.upper(),\n","                   ha='center', va='center', fontsize=12, fontweight='bold',\n","                   color='white', rotation=0)\n","\n","            # Mean value below optimizer name in bar\n","            ax.text(i, row['mean'] / 2 - 0.02, f\"{row['mean']:.4f}\",\n","                   ha='center', va='top', fontsize=9, fontweight='bold',\n","                   color='white', alpha=0.9)\n","\n","            # Trial count above max point\n","            ax.text(i, row['max'] - 0.05, f\"n={int(row['count'])}\",\n","                   ha='center', va='bottom', fontsize=10, fontweight='bold',\n","                   bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7, edgecolor='black'))\n","\n","        plt.tight_layout()\n","\n","        optimizer_comp_img = TUNE_DIR / 'report_optimizer_comparison.png'\n","        plt.savefig(optimizer_comp_img, dpi=150, bbox_inches='tight')\n","        plt.close()\n","\n","        story.append(Image(str(optimizer_comp_img), width=6.5*inch, height=3.25*inch))\n","        story.append(Spacer(1, 15))\n","        print(f'‚úì Optimizer comparison chart saved: {optimizer_comp_img}')\n","\n","        # Add detailed statistics table for optimizers\n","        optimizer_table_data = [['Optimizer', 'Mean', 'Max', 'Min', 'Std Dev', 'Trials']]\n","        for opt, row in optimizer_stats.iterrows():\n","            optimizer_table_data.append([\n","                opt.upper(),\n","                f\"{row['mean']:.4f}\",\n","                f\"{row['max']:.4f}\",\n","                f\"{row['min']:.4f}\",\n","                f\"{row['std']:.4f}\",\n","                str(int(row['count']))\n","            ])\n","\n","        opt_table = Table(optimizer_table_data, colWidths=[1.2*inch, 1.0*inch, 1.0*inch, 1.0*inch, 1.0*inch, 0.8*inch])\n","        opt_table.setStyle(TableStyle([\n","            ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#3498db')),\n","            ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n","            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","            ('FONTSIZE', (0, 0), (-1, 0), 10),\n","            ('FONTSIZE', (0, 1), (-1, -1), 9),\n","            ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n","            ('TOPPADDING', (0, 0), (-1, -1), 6),\n","            ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n","            ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n","        ]))\n","        story.append(opt_table)\n","        story.append(Spacer(1, 15))\n","\n","        # Add interpretation text\n","        best_optimizer = optimizer_stats.index[0]\n","        best_mean = optimizer_stats.iloc[0]['mean']\n","        interpretation = f\"<b>Analysis:</b> {best_optimizer.upper()} achieved the highest mean performance ({best_mean:.4f}) across {int(optimizer_stats.iloc[0]['count'])} trials. The error bars show the standard deviation, indicating performance consistency.\"\n","        story.append(Paragraph(interpretation, styles['Normal']))\n","        story.append(Spacer(1, 15))\n","    else:\n","        story.append(Paragraph('Optimizer data not available for visualization.', styles['Normal']))\n","        story.append(Spacer(1, 15))\n","        print(f'   ‚ö†Ô∏è optimizer column not found or empty')\n","\n","    # 5.6 Augmentation Parameters vs Performance\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.6 Augmentation Parameters Impact', styles['Heading3']))\n","\n","    # Create 2x2 subplot for key augmentation parameters\n","    aug_params = ['mixup', 'mosaic', 'degrees', 'scale']\n","    available_aug_params = [p for p in aug_params if p in completed_trials_df.columns and completed_trials_df[p].notna().any()]\n","\n","    print(f'   Available augmentation params: {available_aug_params}')\n","\n","    if len(available_aug_params) >= 2:\n","        n_plots = min(len(available_aug_params), 4)\n","        fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n","        axes = axes.flatten()\n","\n","        for idx, param in enumerate(available_aug_params[:4]):\n","            ax = axes[idx]\n","            scatter = ax.scatter(completed_trials_df[param], completed_trials_df['mAP@0.5'],\n","                               c=completed_trials_df['mAP@0.5'], cmap='RdYlGn',\n","                               s=60, alpha=0.6, edgecolors='black', linewidth=0.5)\n","            ax.set_xlabel(param, fontsize=10, fontweight='bold')\n","            ax.set_ylabel('mAP@0.5', fontsize=10, fontweight='bold')\n","            ax.set_title(f'{param.capitalize()} Impact', fontsize=11, fontweight='bold')\n","            ax.grid(True, alpha=0.3)\n","\n","        # Hide unused subplots\n","        for idx in range(len(available_aug_params), 4):\n","            axes[idx].axis('off')\n","\n","        plt.tight_layout()\n","\n","        aug_impact_img = TUNE_DIR / 'report_augmentation_impact.png'\n","        plt.savefig(aug_impact_img, dpi=150, bbox_inches='tight')\n","        plt.close()\n","\n","        story.append(Image(str(aug_impact_img), width=6.5*inch, height=5.2*inch))\n","        story.append(Spacer(1, 15))\n","        print(f'‚úì Augmentation impact chart saved: {aug_impact_img}')\n","    else:\n","        story.append(Paragraph(f'Insufficient augmentation parameter data for visualization. Found: {available_aug_params}', styles['Normal']))\n","        story.append(Spacer(1, 15))\n","        print(f'   ‚ö†Ô∏è Not enough augmentation params available')\n","\n","    # 5.7 Weight Decay and Momentum vs Performance\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.7 Regularization Parameters Impact', styles['Heading3']))\n","\n","    has_weight_decay = 'weight_decay' in completed_trials_df.columns and completed_trials_df['weight_decay'].notna().any()\n","    has_momentum = 'momentum' in completed_trials_df.columns and completed_trials_df['momentum'].notna().any()\n","\n","    if has_weight_decay and has_momentum:\n","        print(f'   Creating regularization impact chart...')\n","        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n","\n","        # Weight Decay\n","        scatter1 = ax1.scatter(completed_trials_df['weight_decay'], completed_trials_df['mAP@0.5'],\n","                              c=completed_trials_df['mAP@0.5'], cmap='RdYlGn',\n","                              s=80, alpha=0.6, edgecolors='black', linewidth=0.5)\n","        ax1.set_xlabel('Weight Decay', fontsize=11, fontweight='bold')\n","        ax1.set_ylabel('mAP@0.5', fontsize=11, fontweight='bold')\n","        ax1.set_title('Weight Decay Impact', fontsize=12, fontweight='bold')\n","        ax1.grid(True, alpha=0.3)\n","\n","        # Momentum\n","        scatter2 = ax2.scatter(completed_trials_df['momentum'], completed_trials_df['mAP@0.5'],\n","                              c=completed_trials_df['mAP@0.5'], cmap='RdYlGn',\n","                              s=80, alpha=0.6, edgecolors='black', linewidth=0.5)\n","        ax2.set_xlabel('Momentum', fontsize=11, fontweight='bold')\n","        ax2.set_ylabel('mAP@0.5', fontsize=11, fontweight='bold')\n","        ax2.set_title('Momentum Impact', fontsize=12, fontweight='bold')\n","        ax2.grid(True, alpha=0.3)\n","\n","        plt.tight_layout()\n","\n","        reg_impact_img = TUNE_DIR / 'report_regularization_impact.png'\n","        plt.savefig(reg_impact_img, dpi=150, bbox_inches='tight')\n","        plt.close()\n","\n","        story.append(Image(str(reg_impact_img), width=6.5*inch, height=2.6*inch))\n","        story.append(Spacer(1, 15))\n","        print(f'‚úì Regularization impact chart saved: {reg_impact_img}')\n","    else:\n","        story.append(Paragraph(f'Regularization parameter data not available. weight_decay: {has_weight_decay}, momentum: {has_momentum}', styles['Normal']))\n","        story.append(Spacer(1, 15))\n","        print(f'   ‚ö†Ô∏è weight_decay or momentum columns not found or empty')\n","\n","    # 5.8 Image Size Impact on Performance\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.8 Image Size Impact on Performance', styles['Heading3']))\n","\n","    if 'imgsz' in completed_trials_df.columns and completed_trials_df['imgsz'].notna().any():\n","        print(f'   Creating image size impact chart...')\n","        fig, ax = plt.subplots(figsize=(10, 5))\n","\n","        # Group by image size and calculate statistics\n","        imgsz_stats = completed_trials_df.groupby('imgsz')['mAP@0.5'].agg(['mean', 'max', 'min', 'count'])\n","        imgsz_stats = imgsz_stats.sort_index()\n","\n","        x_pos = range(len(imgsz_stats))\n","        bars = ax.bar(x_pos, imgsz_stats['mean'], alpha=0.7, color='#9b59b6',\n","               label='Mean mAP@0.5', edgecolor='black', linewidth=1.5, width=0.6)\n","        ax.scatter(x_pos, imgsz_stats['max'], color='#27ae60', s=120,\n","                  label='Max mAP@0.5', zorder=5, edgecolors='black', linewidth=1, marker='^')\n","        ax.scatter(x_pos, imgsz_stats['min'], color='#e74c3c', s=120,\n","                  label='Min mAP@0.5', zorder=5, edgecolors='black', linewidth=1, marker='v')\n","\n","        ax.set_xlabel('Image Size (pixels)', fontsize=12, fontweight='bold')\n","        ax.set_ylabel('mAP@0.5', fontsize=12, fontweight='bold')\n","        ax.set_title(f'{MODEL_NAME} - Image Size Impact on Performance', fontsize=14, fontweight='bold')\n","        ax.set_xticks(x_pos)\n","        ax.set_xticklabels([int(idx) for idx in imgsz_stats.index], fontsize=11, fontweight='bold')\n","        ax.legend(fontsize=10, loc='best')\n","        ax.grid(True, alpha=0.3, axis='y')\n","\n","        # Add count and mean value annotations\n","        for i, (imgsz, row) in enumerate(imgsz_stats.iterrows()):\n","            # Mean value inside bar\n","            ax.text(i, row['mean'] / 2, f\"{row['mean']:.4f}\",\n","                   ha='center', va='center', fontsize=10, fontweight='bold', color='white')\n","            # Count above bar\n","            ax.text(i, row['max'] + 0.003, f\"n={int(row['count'])}\",\n","                   ha='center', va='bottom', fontsize=9)\n","\n","        plt.tight_layout()\n","\n","        imgsz_impact_img = TUNE_DIR / 'report_imgsz_impact.png'\n","        plt.savefig(imgsz_impact_img, dpi=150, bbox_inches='tight')\n","        plt.close()\n","\n","        story.append(Image(str(imgsz_impact_img), width=6.5*inch, height=3.25*inch))\n","        story.append(Spacer(1, 15))\n","        print(f'‚úì Image size impact chart saved: {imgsz_impact_img}')\n","\n","        # Add statistics table for image sizes\n","        imgsz_table_data = [['Image Size', 'Mean mAP@0.5', 'Max mAP@0.5', 'Min mAP@0.5', 'Trials']]\n","        for imgsz, row in imgsz_stats.iterrows():\n","            imgsz_table_data.append([\n","                str(int(imgsz)),\n","                f\"{row['mean']:.4f}\",\n","                f\"{row['max']:.4f}\",\n","                f\"{row['min']:.4f}\",\n","                str(int(row['count']))\n","            ])\n","\n","        imgsz_table = Table(imgsz_table_data, colWidths=[1.2*inch, 1.2*inch, 1.2*inch, 1.2*inch, 0.8*inch])\n","        imgsz_table.setStyle(TableStyle([\n","            ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#9b59b6')),\n","            ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n","            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","            ('FONTSIZE', (0, 0), (-1, 0), 10),\n","            ('FONTSIZE', (0, 1), (-1, -1), 9),\n","            ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n","            ('TOPPADDING', (0, 0), (-1, -1), 6),\n","            ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n","            ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n","        ]))\n","        story.append(imgsz_table)\n","        story.append(Spacer(1, 15))\n","    else:\n","        story.append(Paragraph('Image size data not available for visualization.', styles['Normal']))\n","        story.append(Spacer(1, 15))\n","        print(f'   ‚ö†Ô∏è imgsz column not found or empty')\n","\n","    print('‚úì All custom visualizations generated for PDF report')\n","\n","# ===== SECTION 5.9: KEY INSIGHTS & RECOMMENDATIONS =====\n","story.append(PageBreak())\n","story.append(Paragraph('5.9 Key Insights & Production Recommendations', styles['Heading3']))\n","\n","print('   Generating key insights and recommendations...')\n","\n","# Generate comprehensive recommendations based on best trial\n","best_trial_row = completed_trials_df[completed_trials_df['trial'] == study.best_trial.number].iloc[0]\n","\n","recommendations_text = f\"\"\"\n","<b>üéØ Optimal Configuration for Production Deployment:</b><br/><br/>\n","\n","<b>1. Image Processing:</b><br/>\n","   ‚Ä¢ Use <b>{int(best_trial_row.get('imgsz', 'N/A'))}px</b> input resolution for optimal accuracy<br/>\n","   ‚Ä¢ Expected performance: <b>mAP@0.5 = {study.best_value:.4f}</b><br/>\n","   ‚Ä¢ Tradeoff: Higher resolution improves accuracy but increases inference time<br/><br/>\n","\n","<b>2. Optimizer Configuration:</b><br/>\n","   ‚Ä¢ Algorithm: <b>{best_trial_row.get('optimizer', 'N/A')}</b><br/>\n","   ‚Ä¢ Learning rate (lr0): <b>{best_trial_row.get('lr0', 0):.6f}</b><br/>\n","   ‚Ä¢ Momentum: <b>{best_trial_row.get('momentum', 0):.4f}</b><br/>\n","   ‚Ä¢ Weight decay: <b>{best_trial_row.get('weight_decay', 0):.6f}</b><br/><br/>\n","\n","<b>3. Training Warmup:</b><br/>\n","   ‚Ä¢ Warmup epochs: <b>{int(best_trial_row.get('warmup_epochs', 0))}</b><br/>\n","   ‚Ä¢ Warmup momentum: <b>{best_trial_row.get('warmup_momentum', 0):.4f}</b><br/>\n","   ‚Ä¢ Warmup bias lr: <b>{best_trial_row.get('warmup_bias_lr', 0):.6f}</b><br/><br/>\n","\n","<b>4. Data Augmentation:</b><br/>\n","   ‚Ä¢ Mosaic augmentation: <b>{best_trial_row.get('mosaic', 0):.4f}</b> (strong augmentation for robustness)<br/>\n","   ‚Ä¢ Mixup augmentation: <b>{best_trial_row.get('mixup', 0):.4f}</b> (light augmentation)<br/>\n","   ‚Ä¢ Recommendation: Use these exact values for similar datasets<br/><br/>\n","\n","<b>5. Performance Metrics:</b><br/>\n","   ‚Ä¢ Best trial found at <b>#{int(best_trial_row['trial'])}</b> out of {len(study.trials)} trials<br/>\n","   ‚Ä¢ Performance improvement: <b>{improvement_pct:.1f}%</b> over worst trial<br/>\n","   ‚Ä¢ Consistency: Mean mAP@0.5 = {mean_map:.4f} (Std = {completed_df_summary[\"mAP@0.5\"].std():.4f})<br/><br/>\n","\n","<b>6. Deployment Recommendations:</b><br/>\n","\"\"\"\n","\n","# Add optimizer-specific recommendations\n","if 'optimizer' in completed_df_summary.columns:\n","    opt_comparison = completed_df_summary.groupby('optimizer')['mAP@0.5'].agg(['mean', 'std', 'count'])\n","    recommendations_text += f\"   ‚Ä¢ <b>{best_opt}</b> optimizer demonstrated best performance (mean: {best_opt_mean:.4f})<br/>\"\n","\n","    if len(opt_comparison) > 1:\n","        other_opts = opt_comparison[opt_comparison.index != best_opt]\n","        if len(other_opts) > 0:\n","            worst_opt = other_opts['mean'].idxmin()\n","            diff_pct = ((best_opt_mean - other_opts.loc[worst_opt, 'mean']) / other_opts.loc[worst_opt, 'mean']) * 100\n","            recommendations_text += f\"   ‚Ä¢ <b>{best_opt}</b> outperformed {worst_opt} by {diff_pct:.1f}%<br/>\"\n","\n","# Add image size recommendations\n","if 'imgsz' in completed_df_summary.columns and len(completed_df_summary['imgsz'].unique()) > 1:\n","    imgsz_comparison = completed_df_summary.groupby('imgsz')['mAP@0.5'].mean()\n","    recommendations_text += f\"   ‚Ä¢ For maximum accuracy, use {int(best_imgsz)}px images<br/>\"\n","    if len(imgsz_comparison) > 1:\n","        smaller_sizes = imgsz_comparison[imgsz_comparison.index < best_imgsz]\n","        if len(smaller_sizes) > 0:\n","            recommendations_text += f\"   ‚Ä¢ For faster inference with slight accuracy trade-off, consider {int(smaller_sizes.index[-1])}px (mAP: {smaller_sizes.iloc[-1]:.4f})<br/>\"\n","\n","recommendations_text += f\"\"\"<br/>\n","<b>7. Next Steps:</b><br/>\n","   ‚Ä¢ Train full model with these hyperparameters <br/>\n","   ‚Ä¢ Monitor validation metrics for overfitting<br/>\n","   ‚Ä¢ Consider ensemble methods for further improvement<br/><br/>\n","\n","<b>üìä Confidence Level:</b><br/>\n","   ‚Ä¢ Based on {len(completed_df_summary)} successful trials<br/>\n","   ‚Ä¢ Optimization converged {'early' if convergence_pct < 40 else 'steadily'} (best at {convergence_pct:.1f}% through search)<br/>\n","   ‚Ä¢ Standard deviation ({completed_df_summary['mAP@0.5'].std():.4f}) indicates {'high' if completed_df_summary['mAP@0.5'].std() < 0.02 else 'moderate'} consistency\n","\"\"\"\n","\n","story.append(Paragraph(recommendations_text, styles['Normal']))\n","story.append(Spacer(1, 20))\n","\n","# Add comparison table: Best vs Mean vs Worst\n","comparison_data = [\n","    ['Metric', 'Best Trial', 'Mean Performance', 'Worst Trial'],\n","    ['mAP@0.5', f'{best_map:.4f}', f'{mean_map:.4f}', f'{worst_map:.4f}'],\n","    ['Trial #', f'#{int(best_trial_row[\"trial\"])}', '-', f'#{int(completed_df_summary.loc[completed_df_summary[\"mAP@0.5\"].idxmin(), \"trial\"])}'],\n","]\n","\n","# Add key parameters\n","if 'lr0' in best_trial_row:\n","    worst_trial_row = completed_df_summary.loc[completed_df_summary['mAP@0.5'].idxmin()]\n","    comparison_data.append(['Learning Rate', f'{best_trial_row[\"lr0\"]:.6f}',\n","                           f'{completed_df_summary[\"lr0\"].mean():.6f}', f'{worst_trial_row[\"lr0\"]:.6f}'])\n","if 'momentum' in best_trial_row:\n","    comparison_data.append(['Momentum', f'{best_trial_row[\"momentum\"]:.4f}',\n","                           f'{completed_df_summary[\"momentum\"].mean():.4f}', f'{worst_trial_row[\"momentum\"]:.4f}'])\n","\n","comparison_table = Table(comparison_data, colWidths=[1.5*inch, 1.5*inch, 1.5*inch, 1.5*inch])\n","comparison_table.setStyle(TableStyle([\n","    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#e74c3c')),\n","    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","    ('BACKGROUND', (1, 1), (1, -1), rl_colors.HexColor('#d5f4e6')),  # Highlight best column\n","    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n","    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","    ('FONTSIZE', (0, 0), (-1, 0), 10),\n","    ('FONTSIZE', (0, 1), (-1, -1), 9),\n","    ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n","    ('TOPPADDING', (0, 0), (-1, -1), 6),\n","    ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n","]))\n","story.append(comparison_table)\n","story.append(Spacer(1, 20))\n","\n","print('‚úì Insights and recommendations section completed')\n","\n","# ===== SECTION 6: ALL TRIALS SUMMARY =====\n","story.append(PageBreak())\n","story.append(Paragraph('6. All Trials Summary', heading_style))\n","\n","# Statistics\n","completed_df = df_trials_sorted[df_trials_sorted['state'] == 'COMPLETE']\n","if len(completed_df) > 0:\n","    stats_data = [\n","        ['Metric', 'Value'],\n","        ['Completed Trials', str(len(completed_df))],\n","        ['Best mAP@0.5', f\"{completed_df['mAP@0.5'].max():.4f}\"],\n","        ['Worst mAP@0.5', f\"{completed_df['mAP@0.5'].min():.4f}\"],\n","        ['Mean mAP@0.5', f\"{completed_df['mAP@0.5'].mean():.4f}\"],\n","        ['Std Dev mAP@0.5', f\"{completed_df['mAP@0.5'].std():.4f}\"],\n","        ['Median mAP@0.5', f\"{completed_df['mAP@0.5'].median():.4f}\"],\n","    ]\n","\n","    stats_table = Table(stats_data, colWidths=[2.5*inch, 3.5*inch])\n","    stats_table.setStyle(TableStyle([\n","        ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#e74c3c')),\n","        ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n","        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","        ('FONTSIZE', (0, 0), (-1, -1), 10),\n","        ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n","        ('TOPPADDING', (0, 0), (-1, -1), 6),\n","        ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n","        ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n","    ]))\n","    story.append(stats_table)\n","\n","# Build PDF\n","try:\n","    doc.build(story)\n","    print(f'\\n‚úì Comprehensive PDF report generated: {pdf_report_path}')\n","    print(f'  Size: {pdf_report_path.stat().st_size / (1024*1024):.1f} MB')\n","    print(f'  Sections: Overview, Executive Summary, Best Hyperparameters, Top 20 Trials,')\n","    print(f'            Performance Analysis (10 advanced visualizations), Key Insights,')\n","    print(f'            Production Recommendations, All Trials Summary')\n","    print(f'  Charts: Distribution, Correlation, Timeline, mAP Progress, Learning Rate,')\n","    print(f'          Optimizer, Augmentation, Regularization, Image Size')\n","except Exception as pdf_error:\n","    print(f'\\n‚ö†Ô∏è  Error generating PDF: {pdf_error}')\n","    import traceback\n","    traceback.print_exc()\n","\n","print('=' * 80)"]},{"cell_type":"markdown","id":"c5ff99f5","metadata":{"id":"c5ff99f5"},"source":["## 13. Analyze Best Hyperparameters"]},{"cell_type":"code","execution_count":20,"id":"f3823505","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f3823505","executionInfo":{"status":"ok","timestamp":1764555964872,"user_tz":-180,"elapsed":6,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"c9bbe68a-7392-4e89-a088-8c5b3f7946a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","BEST HYPERPARAMETERS\n","================================================================================\n","\n","Best Trial Number: 15\n","Best mAP@0.5: 0.5002\n","\n","Optimized Hyperparameters:\n","{\n","  \"imgsz\": 768,\n","  \"optimizer\": \"Adam\",\n","  \"lr0\": 0.00012192021890239396,\n","  \"momentum\": 0.8888996841929279,\n","  \"weight_decay\": 3.4214299147447924e-05,\n","  \"warmup_epochs\": 2,\n","  \"warmup_momentum\": 0.7753369681596541,\n","  \"warmup_bias_lr\": 0.07369622770237041,\n","  \"mosaic\": 0.7510576170263057,\n","  \"mixup\": 0.06813130521919572\n","}\n","================================================================================\n"]}],"source":["# DISPLAY BEST HYPERPARAMETERS\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('BEST HYPERPARAMETERS')\n","print('=' * 80)\n","\n","print(f'\\nBest Trial Number: {study.best_trial.number}')\n","print(f'Best mAP@0.5: {study.best_value:.4f}')\n","print('\\nOptimized Hyperparameters:')\n","print(json.dumps(study.best_params, indent=2))\n","print('=' * 80)"]},{"cell_type":"markdown","id":"1900ad83","metadata":{"id":"1900ad83"},"source":["## 13. Create Trials Summary"]},{"cell_type":"code","execution_count":21,"id":"2c210c33","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2c210c33","executionInfo":{"status":"ok","timestamp":1764555964897,"user_tz":-180,"elapsed":3,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"3e0860ea-df8f-4a99-9f85-c98b92b3c25d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIALS SUMMARY\n","================================================================================\n","\n","üìä TOP 10 TRIALS:\n","================================================================================\n"," trial  mAP@0.5    state optimizer      lr0  momentum  weight_decay    mixup\n","    15 0.500244 COMPLETE      Adam 0.000122  0.888900      0.000034 0.068131\n","    11 0.498837 COMPLETE      Adam 0.000101  0.851408      0.000353 0.153552\n","    14 0.497182 COMPLETE      Adam 0.000103  0.859534      0.000216 0.094014\n","    19 0.496427 COMPLETE      Adam 0.000112  0.906379      0.000125 0.115972\n","     2 0.495200 COMPLETE     AdamW 0.000195  0.857806      0.000790 0.136847\n","    12 0.494249 COMPLETE     AdamW 0.000258  0.857266      0.000056 0.194388\n","    13 0.493700 COMPLETE     AdamW 0.000238  0.859171      0.000324 0.103048\n","    16 0.491778 COMPLETE      Adam 0.000278  0.865713      0.000033 0.155801\n","    17 0.486927 COMPLETE      Adam 0.000413  0.918348      0.000016 0.056703\n","    10 0.486165 COMPLETE      Adam 0.000283  0.862512      0.000934 0.168921\n","================================================================================\n","\n","‚úì Complete trials summary saved to: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/trials_summary.csv\n","‚úì Optuna study object saved to: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/optuna_study.pkl\n","================================================================================\n"]}],"source":["# CREATE TRIALS SUMMARY AND DATAFRAME (SHARED RESOURCE)\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('TRIALS SUMMARY')\n","print('=' * 80)\n","\n","# Compile all trial data (used by multiple sections)\n","trials_data = []\n","for trial in study.trials:\n","    trial_info = {\n","        'trial': trial.number,\n","        'mAP@0.5': trial.value if trial.value else 0.0,\n","        'state': trial.state.name,\n","        'duration_seconds': (trial.datetime_complete - trial.datetime_start).total_seconds() if trial.datetime_complete else None,\n","    }\n","    # Add all parameters\n","    trial_info.update(trial.params)\n","    trials_data.append(trial_info)\n","\n","# Create DataFrame and sort by performance (used by PDF report and display)\n","df_trials = pd.DataFrame(trials_data)\n","df_trials_sorted = df_trials.sort_values('mAP@0.5', ascending=False)\n","\n","print('\\nüìä TOP 10 TRIALS:')\n","print('=' * 80)\n","# Display top 10 with selected columns\n","display_cols = ['trial', 'mAP@0.5', 'state', 'optimizer', 'lr0', 'momentum', 'weight_decay', 'mixup']\n","available_cols = [col for col in display_cols if col in df_trials_sorted.columns]\n","print(df_trials_sorted[available_cols].head(10).to_string(index=False))\n","print('=' * 80)\n","\n","# Save complete trials summary\n","trials_csv_path = TUNE_DIR / 'trials_summary.csv'\n","df_trials_sorted.to_csv(trials_csv_path, index=False)\n","print(f'\\n‚úì Complete trials summary saved to: {trials_csv_path}')\n","\n","# Save study object\n","study_path = TUNE_DIR / 'optuna_study.pkl'\n","with open(study_path, 'wb') as f:\n","    pickle.dump(study, f)\n","print(f'‚úì Optuna study object saved to: {study_path}')\n","\n","print('=' * 80)"]},{"cell_type":"markdown","id":"7d09278e","metadata":{"id":"7d09278e"},"source":["## 14. Final summary\n"]},{"cell_type":"code","execution_count":22,"id":"9e9576f4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9e9576f4","executionInfo":{"status":"ok","timestamp":1764555965553,"user_tz":-180,"elapsed":200,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"16e54ad5-6dfa-43ad-f17e-a9b965eeec6e"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\n","================================================================================\n","HYPERPARAMETER OPTIMIZATION COMPLETE!\n","================================================================================\n","\n","üìä Project: yolo12s on bdd100k_yolo_tuning\n","üìÖ Date: 2025-12-01 02:26:05\n","\n","üî¨ Optimization Summary:\n","  Total Trials: 20\n","  Completed: 20\n","  Best Trial: 15\n","  Best Trial mAP@0.5: 0.5002\n","  Duration: 7:12:17.512343\n","\n","üìÅ Generated Files:\n","\n","  üìä Tuning Results (in /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337):\n","    - best_hyperparameters.json\n","    - best_hyperparameters.yaml\n","    - trials_summary.csv\n","    - optuna_study.pkl\n","  üìà Tuning Visualizations:\n","    - optimization_history.html / .png\n","    - parameter_importance.html / .png\n","    - parameter_slice.html / .png\n","  üìÑ Tuning PDF Report:\n","    - yolo12s_tuning_report.pdf\n","\n","üìÇ All results saved to:\n","  Tuning: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337\n","\n","üéì Top 5 Hyperparameters (by importance):\n","  1. imgsz: 0.4288\n","  2. warmup_bias_lr: 0.1947\n","  3. optimizer: 0.1728\n","  4. mosaic: 0.0685\n","  5. mixup: 0.0566\n","\n","üöÄ Next Steps:\n","  1. Review tuning PDF report: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337/yolo12s_tuning_report.pdf\n","  2. Review optimization visualizations in: /content/Drive/MyDrive/ksu_yolo10_tuning_2025/yolo_training/tune_train/tune/yolo12s_tune_20251130_191337\n","  3. Use best_hyperparameters.yaml for training in a separate notebook\n","\n","================================================================================\n","SUCCESS! ‚úì\n","================================================================================\n"]}],"source":["# FINAL SUMMARY\n","# ============================================================================\n","\n","print('\\n\\n')\n","print('=' * 80)\n","print('HYPERPARAMETER OPTIMIZATION COMPLETE!')\n","print('=' * 80)\n","\n","print(f'\\nüìä Project: {MODEL_NAME} on {YOLO_DATASET_ROOT.name}')\n","print(f'üìÖ Date: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n","\n","print(f'\\nüî¨ Optimization Summary:')\n","print(f'  Total Trials: {len(study.trials)}')\n","print(f'  Completed: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}')\n","print(f'  Best Trial: {study.best_trial.number}')\n","print(f'  Best Trial mAP@0.5: {study.best_value:.4f}')\n","print(f'  Duration: {duration}')\n","\n","if 'final_metrics' in globals():\n","    print(f'\\nüéØ Final Model Performance:')\n","    print(f'  mAP@0.5: {final_metrics[\"map50\"]:.4f}')\n","    print(f'  mAP@0.5:0.95: {final_metrics[\"map50_95\"]:.4f}')\n","    print(f'  Precision: {final_metrics[\"precision\"]:.4f}')\n","    print(f'  Recall: {final_metrics[\"recall\"]:.4f}')\n","\n","print(f'\\nüìÅ Generated Files:')\n","print(f'\\n  üìä Tuning Results (in {TUNE_DIR}):')\n","print(f'    - best_hyperparameters.json')\n","print(f'    - best_hyperparameters.yaml')\n","print(f'    - trials_summary.csv')\n","print(f'    - optuna_study.pkl')\n","print(f'  üìà Tuning Visualizations:')\n","print(f'    - optimization_history.html / .png')\n","print(f'    - parameter_importance.html / .png')\n","print(f'    - parameter_slice.html / .png')\n","print(f'  üìÑ Tuning PDF Report:')\n","print(f'    - {MODEL_NAME}_tuning_report.pdf')\n","\n","print(f'\\nüìÇ All results saved to:')\n","print(f'  Tuning: {TUNE_DIR}')\n","\n","print(f'\\nüéì Top 5 Hyperparameters (by importance):')\n","try:\n","    importances = optuna.importance.get_param_importances(study)\n","    for i, (param, importance) in enumerate(list(importances.items())[:5], 1):\n","        print(f'  {i}. {param}: {importance:.4f}')\n","except:\n","    print('  (Not available - requires completed trials with variation)')\n","\n","print(f'\\nüöÄ Next Steps:')\n","print(f'  1. Review tuning PDF report: {TUNE_DIR / f\"{MODEL_NAME}_tuning_report.pdf\"}')\n","print(f'  2. Review optimization visualizations in: {TUNE_DIR}')\n","print(f'  3. Use best_hyperparameters.yaml for training in a separate notebook')\n","\n","print('\\n' + '=' * 80)\n","print('SUCCESS! ‚úì')\n","print('=' * 80)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"colab":{"provenance":[],"gpuType":"A100"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"fe0f955ee99240e786be66646cacf53e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a7fce8ea5b85463fbb8e9ef0d7eb0f47","IPY_MODEL_1c93e639122044df94a6d2cfe37344c4","IPY_MODEL_70abeb254ff149a8ba7daf119acaabac"],"layout":"IPY_MODEL_1008697a7526419b9d9e6fb2c4a6421f"}},"a7fce8ea5b85463fbb8e9ef0d7eb0f47":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0a89f83671d40eb972634a750df113e","placeholder":"‚Äã","style":"IPY_MODEL_d5370c35d848428ebc72d85425e9989a","value":"Best‚Äátrial:‚Äá15.‚ÄáBest‚Äávalue:‚Äá0.500244:‚Äá100%"}},"1c93e639122044df94a6d2cfe37344c4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0802427f78ea44c899da9657c18037b1","max":20,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f0d05f9c154948c6b68513f4a7dc6738","value":20}},"70abeb254ff149a8ba7daf119acaabac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53dd489e88704cf5b1119ba38f9deee6","placeholder":"‚Äã","style":"IPY_MODEL_7499f53af276404cb8c8c6bb64ae24df","value":"‚Äá20/20‚Äá[7:12:17&lt;00:00,‚Äá1306.10s/it,‚Äá25937.50/86400‚Äáseconds]"}},"1008697a7526419b9d9e6fb2c4a6421f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0a89f83671d40eb972634a750df113e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5370c35d848428ebc72d85425e9989a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0802427f78ea44c899da9657c18037b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0d05f9c154948c6b68513f4a7dc6738":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"53dd489e88704cf5b1119ba38f9deee6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7499f53af276404cb8c8c6bb64ae24df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}