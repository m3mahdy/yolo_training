{"cells":[{"cell_type":"markdown","id":"8b26f5d6","metadata":{"id":"8b26f5d6"},"source":["# YOLO Hyperparameter Tuning\n","\n","- Support for YOLOv8, YOLOv9, YOLOv10, YOLO11, YOLO12"]},{"cell_type":"code","execution_count":1,"id":"f68c7bbf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f68c7bbf","executionInfo":{"status":"ok","timestamp":1764284616620,"user_tz":-180,"elapsed":4634,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"0d7d6ddd-4da4-4e4f-dbc4-16a97953f4ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/Drive\n","‚úì W&B API key loaded from Colab secrets\n"]}],"source":["# Base directories\n","# Detect environment: Colab or local\n","\n","import os\n","from pathlib import Path\n","\n","\n","IS_COLAB = 'COLAB_GPU' in os.environ or os.path.exists('/content')\n","\n","USE_WANDB = True  # Set to False to disable W&B logging\n","\n","\n","\n","if IS_COLAB:\n","    #Mount Google Drive if not already mounted\n","    from google.colab import drive\n","    drive.mount('/content/Drive', force_remount=True)\n","    # Running in Google Colab\n","    BASE_DIR = Path('/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo')\n","\n","    # Configure W&B API key\n","    if USE_WANDB:\n","        # In Colab, get API key from secrets\n","        from google.colab import userdata\n","        wandb_api_key = userdata.get('wandb_api_key')\n","        os.environ['WANDB_API_KEY'] = wandb_api_key\n","        print('‚úì W&B API key loaded from Colab secrets')\n","\n","    DATASET_BASE_DIR = Path('/computer_vision_yolo')\n","\n","else:\n","    # Running locally\n","    BASE_DIR = Path.cwd().parent\n","    if USE_WANDB:\n","        print('‚úì Running locally - W&B will use existing login or prompt')\n","\n","    DATASET_BASE_DIR = Path.cwd().parent\n"]},{"cell_type":"code","execution_count":2,"id":"7c504221","metadata":{"id":"7c504221","executionInfo":{"status":"ok","timestamp":1764284616673,"user_tz":-180,"elapsed":51,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}}},"outputs":[],"source":["# ! cd /content/Drive/MyDrive/ksu_yolo_tuning_2025 && git clone https://github.com/m3mahdy/computer_vision_yolo"]},{"cell_type":"code","execution_count":3,"id":"fde7425c","metadata":{"id":"fde7425c","executionInfo":{"status":"ok","timestamp":1764284616675,"user_tz":-180,"elapsed":1,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}}},"outputs":[],"source":["# ! cd {BASE_DIR} && pip install -r requirements.txt --quiet"]},{"cell_type":"code","execution_count":4,"id":"92da27e0","metadata":{"id":"92da27e0","executionInfo":{"status":"ok","timestamp":1764284616677,"user_tz":-180,"elapsed":0,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}}},"outputs":[],"source":["# limited dataset\n","# !mkdir {DATASET_BASE_DIR}\n","# !cd {BASE_DIR}/dataset && cp 8_download_extract_other_datasets.py {DATASET_BASE_DIR} && cd {DATASET_BASE_DIR} && python 8_download_extract_other_datasets.py\n"]},{"cell_type":"markdown","id":"109394c4","metadata":{"id":"109394c4"},"source":["## 1. Import Required Libraries"]},{"cell_type":"code","execution_count":5,"id":"fc6f98f1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fc6f98f1","executionInfo":{"status":"ok","timestamp":1764284620714,"user_tz":-180,"elapsed":4035,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"b0cc70ae-9f03-45c4-eedd-0020e95f97c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Libraries imported successfully\n","‚úì Device: cuda\n","  GPU: NVIDIA A100-SXM4-40GB\n","  CUDA Version: 12.6\n","  Available Memory: 42.47 GB\n"]}],"source":["# Install required libraries (uncomment if running in Colab)\n","# !pip install -q ultralytics optuna plotly kaleido wandb pyyaml\n","\n","import os\n","import sys\n","import gc\n","import yaml\n","import json\n","import torch\n","import shutil\n","import warnings\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from pathlib import Path\n","from datetime import datetime\n","from tqdm import tqdm\n","import pickle\n","import platform\n","import psutil\n","\n","import wandb\n","\n","# YOLO and Optuna imports\n","from ultralytics import YOLO\n","import optuna\n","from optuna.visualization import plot_optimization_history, plot_param_importances, plot_slice\n","\n","# ReportLab imports for PDF generation\n","from reportlab.lib.pagesizes import A4\n","from reportlab.lib import colors as rl_colors\n","from reportlab.lib.units import inch\n","from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, Image, PageBreak\n","from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n","from reportlab.lib.enums import TA_CENTER, TA_LEFT\n","from PIL import Image as PILImage\n","\n","warnings.filterwarnings('ignore')\n","\n","# Configure matplotlib for notebook display\n","%matplotlib inline\n","sns.set_style('whitegrid')\n","plt.rcParams['figure.figsize'] = (15, 10)\n","\n","# Check GPU availability\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(f'‚úì Libraries imported successfully')\n","print(f'‚úì Device: {device}')\n","if device == 'cuda':\n","    print(f'  GPU: {torch.cuda.get_device_name(0)}')\n","    print(f'  CUDA Version: {torch.version.cuda}')\n","    print(f'  Available Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')"]},{"cell_type":"markdown","id":"2eda31f6","metadata":{"id":"2eda31f6"},"source":["## 2. Constants and Enums"]},{"cell_type":"code","execution_count":6,"id":"2031059f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2031059f","executionInfo":{"status":"ok","timestamp":1764284620743,"user_tz":-180,"elapsed":23,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"ca8b3958-ebc1-4ce6-9582-7f28d53d8fb4"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Constants and enums defined\n"]}],"source":["# ============================================================================\n","# CONSTANTS AND ENUMS\n","# ============================================================================\n","\n","class TrialStatus:\n","    \"\"\"Constants for trial execution status\"\"\"\n","    COMPLETED = \"completed\"\n","    FAILED = \"failed\"\n","    PRUNED = \"pruned\"\n","    RUNNING = \"running\"\n","\n","class DatasetSplit:\n","    \"\"\"Constants for dataset split names\"\"\"\n","    TRAIN = \"train\"\n","    VAL = \"val\"\n","    TEST = \"test\"\n","\n","class ModelConfig:\n","    \"\"\"Default model training configuration constants\"\"\"\n","    # Training workers\n","    DEFAULT_WORKERS = 8  # Number of data loading workers\n","\n","    # Early stopping and checkpointing\n","    DEFAULT_PATIENCE = 20  # Epochs to wait before early stopping\n","\n","    # Augmentation timing\n","    CLOSE_MOSAIC_EPOCHS = 10  # Disable mosaic augmentation in last N epochs\n","\n","print('‚úì Constants and enums defined')"]},{"cell_type":"markdown","id":"2659c792","metadata":{"id":"2659c792"},"source":["## 3. Configuration"]},{"cell_type":"code","execution_count":7,"id":"d163f0be","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d163f0be","executionInfo":{"status":"ok","timestamp":1764284620747,"user_tz":-180,"elapsed":4,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"38e1cecd-d52d-4198-f0d0-97e9ff546e37"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üÜï NEW RUN MODE: Creating new run \"yolov8m_finetuned_1_tune_20251127_230340\"\n","================================================================================\n","CONFIGURATION SUMMARY\n","================================================================================\n","Environment: Google Colab\n","Base Directory: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo\n","Model: yolov8m_finetuned_1\n","Dataset: bdd100k_yolo_tuning\n","Data YAML: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml\n","  Dataset path in YAML: /computer_vision_yolo/bdd100k_yolo_tuning\n","Classes: 10\n","Class Names: {0: 'person', 1: 'rider', 2: 'car', 3: 'truck', 4: 'bus', 5: 'train', 6: 'motor', 7: 'bike', 8: 'traffic light', 9: 'traffic sign'}\n","Device: cuda\n","Optimization Trials: 40\n","Epochs per Trial: 8\n","Batch Size: 96\n","Timeout: 24 hours\n","Tuning Directory: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340\n","W&B Logging: Enabled\n","  Tuning Project: yolo-bdd100k_yolo_tuning-tuning\n","================================================================================\n"]}],"source":["# CONFIGURATION\n","# ============================================================================\n","\n","\n","# Model Selection - Choose one of the following:\n","MODEL_NAME = \"yolov8m_finetuned_1\"\n","\n","#yolov10n is for testing purpose only\n","#Mahdy will work yolov8m\n","\n","\n","# Selected models, to choose from, based on the performance and size:\n","# YOLOv8:  'yolov8s', 'yolov8m'\n","\n","# YOLOv10: 'yolov10s', 'yolov10m'\n","\n","# YOLO12: 'yolo12s'\n","\n","# Directory structure\n","MODELS_DIR = BASE_DIR / 'models' / MODEL_NAME\n","TMP_DIR = BASE_DIR / 'tmp' / MODEL_NAME\n","\n","# Dataset Selection\n","# Option 1: Full dataset (~100k images) - for final optimization: \"bdd100k_yolo\"\n","# Option 2: Limited dataset (representative samples) - for quick tuning: \"bdd100k_yolo_limited\"\n","dataset_name = 'bdd100k_yolo_tuning'\n","\n","\n","YOLO_DATASET_ROOT = DATASET_BASE_DIR / dataset_name\n","\n","# data.yaml path\n","DATA_YAML_PATH = YOLO_DATASET_ROOT / 'data.yaml'\n","\n","# Verify dataset exists\n","if not DATA_YAML_PATH.exists():\n","    raise FileNotFoundError(\n","        f\"Dataset not found: {DATA_YAML_PATH}\\n\"\n","        f\"Please prepare the dataset first using process_bdd100k_to_yolo_dataset.py\"\n","    )\n","\n","# Update data.yaml path field for Colab compatibility\n","with open(DATA_YAML_PATH, 'r') as yaml_file:\n","    data_config = yaml.safe_load(yaml_file)\n","\n","# Validate required keys in data.yaml\n","required_yaml_keys = ['nc', 'names', 'path']\n","missing_keys = [key for key in required_yaml_keys if key not in data_config]\n","if missing_keys:\n","    raise ValueError(f\"Missing required keys in data.yaml: {missing_keys}\")\n","\n","# Update the 'path' field to use BASE_DIR\n","data_config['path'] = str(YOLO_DATASET_ROOT)\n","\n","# Create a temporary data.yaml with corrected paths\n","temp_data_yaml = TMP_DIR / 'data.yaml'\n","TMP_DIR.mkdir(parents=True, exist_ok=True)\n","with open(temp_data_yaml, 'w') as yaml_output_file:\n","    yaml.dump(data_config, yaml_output_file, default_flow_style=False, sort_keys=False)\n","\n","# Use the temporary data.yaml for training\n","DATA_YAML_PATH = temp_data_yaml\n","\n","# Optimization Configuration\n","N_TRIALS = 40  # Number of optimization trials = 50‚Äì70 trials\n","TIMEOUT_HOURS = 24  # Maximum time for optimization (None for no limit)\n","N_STARTUP_TRIALS = 10  # Random exploration trials before optimization =10\n","EPOCHS_PER_TRIAL = 8  # Training epochs per trial = 50\n","BATCH_SIZE = 96  # Batch size for training\n","# for T4 GPU:\n","# 64 for 10n, 1 epoch 30 min\n","# 32 for 8m, 1 epoch 45 min\n","\n","# for A100 GPU:\n","# 64 for 10m 1 epoch 11 min, 5 epochs completed in 0.797 hours.\n","# 96 for 8m , 1 epoch 10 min, 5 epochs completed in 0.866 hours.\n","\n","\n","\n","# Weights & Biases (optional)\n","USE_WANDB = True  # Set to True to enable W&B logging\n","WANDB_PROJECT_TUNING = f\"yolo-{YOLO_DATASET_ROOT.name}-tuning\"\n","\n","# ============================================================================\n","# RUN NAME CONFIGURATION - RESUME OR CREATE NEW\n","# ============================================================================\n","# To RESUME an existing run: Set RESUME_RUN_NAME to the run directory name\n","# To START NEW run: Leave RESUME_RUN_NAME as None or empty string\n","#\n","# Example to resume: RESUME_RUN_NAME = \"yolov10n_tune_20251125_143022\"\n","# ============================================================================\n","\n","RESUME_RUN_NAME = None  # Set to run name to resume, or None to create new run\n","\n","if RESUME_RUN_NAME:\n","    # Resume existing run\n","    RUN_NAME_TUNING = RESUME_RUN_NAME\n","    print(f'\\nüîÑ RESUME MODE: Will attempt to resume run \"{RESUME_RUN_NAME}\"')\n","else:\n","    # Create new run with timestamp\n","    RUN_TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')\n","    RUN_NAME_TUNING = f'{MODEL_NAME}_tune_{RUN_TIMESTAMP}'\n","    print(f'\\nüÜï NEW RUN MODE: Creating new run \"{RUN_NAME_TUNING}\"')\n","\n","RUN_NAME_TRAINING = f'{MODEL_NAME}_train_{RUN_TIMESTAMP if not RESUME_RUN_NAME else RESUME_RUN_NAME}'\n","\n","# Create directories for tuning within tune_train folder\n","# All paths are absolute to ensure consistency across environments (local/Colab)\n","TUNE_TRAIN_BASE = BASE_DIR / 'tune_train'\n","TUNE_DIR = TUNE_TRAIN_BASE / 'tune' / RUN_NAME_TUNING\n","TUNE_DIR.mkdir(parents=True, exist_ok=True)\n","MODELS_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Keep RUN_DIR for backward compatibility (points to tuning)\n","RUN_DIR = TUNE_DIR\n","# Keep RUN_DIR for backward compatibility (points to tuning)\n","# Read dataset configuration\n","NUM_CLASSES = data_config['nc']\n","CLASS_NAMES = {i: name for i, name in enumerate(data_config['names'])}\n","CLASS_NAME_TO_ID = {name: i for i, name in enumerate(data_config['names'])}\n","\n","print('=' * 80)\n","print('CONFIGURATION SUMMARY')\n","print('=' * 80)\n","print(f'Environment: {\"Google Colab\" if \"COLAB_GPU\" in os.environ or os.path.exists(\"/content\") else \"Local\"}')\n","print(f'Base Directory: {BASE_DIR}')\n","print(f'Model: {MODEL_NAME}')\n","print(f'Dataset: {YOLO_DATASET_ROOT.name}')\n","print(f'Data YAML: {DATA_YAML_PATH}')\n","print(f'  Dataset path in YAML: {data_config[\"path\"]}')\n","print(f'Classes: {NUM_CLASSES}')\n","print(f'Class Names: {CLASS_NAMES}')\n","print(f'Device: {device}')\n","print(f'Optimization Trials: {N_TRIALS}')\n","print(f'Epochs per Trial: {EPOCHS_PER_TRIAL}')\n","print(f'Batch Size: {BATCH_SIZE}')\n","print(f'Timeout: {TIMEOUT_HOURS} hours' if TIMEOUT_HOURS else 'No timeout')\n","print(f'Tuning Directory: {TUNE_DIR}')\n","if USE_WANDB:\n","    print(f'W&B Logging: Enabled')\n","    print(f'  Tuning Project: {WANDB_PROJECT_TUNING}')\n","else:\n","    print(f'W&B Logging: Disabled')\n","print('=' * 80)"]},{"cell_type":"markdown","id":"0af35c3f","metadata":{"id":"0af35c3f"},"source":["## 4. Load Base YOLO Model"]},{"cell_type":"code","execution_count":8,"id":"3deeda88","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3deeda88","executionInfo":{"status":"ok","timestamp":1764284620964,"user_tz":-180,"elapsed":214,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"6f26070d-1b20-413e-928f-d792559dd03b"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Model loaded from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt\n","Model summary: 169 layers, 25,862,110 parameters, 0 gradients, 79.1 GFLOPs\n","\n","üìä Model Information:\n","  Model: yolov8m_finetuned_1\n","  Classes in model: 10\n","  Task: detect\n","  Parameters: 25.9M\n","  Model Size: 0.0 MB\n","  FLOPs (640x640): 79.09 GFLOPs\n"]}],"source":["# Load YOLO model with automatic download\n","model_path = MODELS_DIR / f'{MODEL_NAME}.pt'\n","\n","if not model_path.exists():\n","    print(f'Model not found at {model_path}')\n","    print(f'Downloading {MODEL_NAME} ...')\n","\n","    try:\n","        # Download model - ensure .pt extension for ultralytics\n","        # Ultralytics expects model names with .pt extension for download\n","        if not MODEL_NAME.endswith('.pt'):\n","            model_name_for_download = MODEL_NAME + '.pt'\n","        else:\n","            model_name_for_download = MODEL_NAME\n","\n","        print(f'  Requesting model: {model_name_for_download}')\n","        model = YOLO(model_name_for_download)\n","\n","        # Create models directory\n","        MODELS_DIR.mkdir(parents=True, exist_ok=True)\n","\n","        # Save model to our directory using export/save\n","        try:\n","            # Try to save using the model's save method\n","            if hasattr(model, 'save'):\n","                model.save(str(model_path))\n","                print(f'‚úì Model downloaded and saved to {model_path}')\n","                print(f'  Size: {model_path.stat().st_size / (1024*1024):.1f} MB')\n","            else:\n","                # Fallback: copy from cache\n","                cache_patterns = [\n","                    str(Path.home() / '.cache' / 'ultralytics' / '**' / f'{MODEL_NAME}.pt'),\n","                    str(Path.home() / '.config' / 'Ultralytics' / '**' / f'{MODEL_NAME}.pt'),\n","                ]\n","\n","                model_found = False\n","                for pattern in cache_patterns:\n","                    cache_paths = glob.glob(pattern, recursive=True)\n","                    if cache_paths:\n","                        shutil.copy(cache_paths[0], model_path)\n","                        print(f'‚úì Model downloaded and saved to {model_path}')\n","                        print(f'  Size: {model_path.stat().st_size / (1024*1024):.1f} MB')\n","                        model_found = True\n","                        break\n","\n","                if not model_found:\n","                    print(f'‚úì Model loaded from ultralytics cache')\n","                    print(f'  Note: Model is in cache, not copied to {model_path}')\n","                    print(f'  This is normal and the model will work correctly')\n","        except Exception as save_error:\n","            print(f'‚ö†Ô∏è  Could not save model to custom location: {save_error}')\n","            print(f'‚úì Model loaded successfully from ultralytics cache')\n","\n","    except Exception as download_error:\n","        print(f'\\n‚ùå Error downloading model: {download_error}')\n","        raise\n","else:\n","    model = YOLO(str(model_path))\n","    print(f'‚úì Model loaded from {model_path}')\n","\n","# Get model information\n","model_info_dict = {}\n","model_info_result = model.info()\n","model_info_keys = [\"layers\", \"params\", \"size(MB)\", \"FLOPs(G)\"]\n","\n","for info_key, info_value in zip(model_info_keys, model_info_result):\n","    model_info_dict[info_key] = info_value\n","\n","model_params = model_info_dict.get(\"params\", 0)\n","model_size_mb = model_info_dict.get(\"size(MB)\", 0)\n","flops_gflops = model_info_dict.get(\"FLOPs(G)\", 0)\n","\n","\n","print(f'\\nüìä Model Information:')\n","print(f'  Model: {MODEL_NAME}')\n","print(f'  Classes in model: {len(model.names)}')\n","print(f'  Task: {model.task}')\n","print(f'  Parameters: {model_params / 1e6:.1f}M')\n","print(f'  Model Size: {model_size_mb:.1f} MB')\n","print(f'  FLOPs (640x640): {flops_gflops:.2f} GFLOPs')"]},{"cell_type":"markdown","id":"5fe0b94d","metadata":{"id":"5fe0b94d"},"source":["## 5. Verify Dataset Structure"]},{"cell_type":"code","execution_count":9,"id":"71b15401","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"71b15401","executionInfo":{"status":"ok","timestamp":1764284621315,"user_tz":-180,"elapsed":347,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"4c3f604a-6465-4d9f-9c66-0e3f395512f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Verifying YOLO dataset structure...\n","\n","üìÅ Dataset Root: /computer_vision_yolo/bdd100k_yolo_tuning\n","  ‚úì train:  16391 images,  16391 labels\n","  ‚úì val  :  10000 images,  10000 labels\n","  ‚ö†Ô∏è  test : Directory not found\n","\n","üìÑ Configuration: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml\n","  Classes: 10\n","  Names: {0: 'person', 1: 'rider', 2: 'car', 3: 'truck', 4: 'bus', 5: 'train', 6: 'motor', 7: 'bike', 8: 'traffic light', 9: 'traffic sign'}\n","\n","‚úì Dataset verified: 26,391 total images\n","‚úì Ready for hyperparameter optimization\n"]}],"source":["# ============================================================================\n","# VERIFY DATASET STRUCTURE\n","# ============================================================================\n","\n","print('Verifying YOLO dataset structure...')\n","print(f'\\nüìÅ Dataset Root: {YOLO_DATASET_ROOT}')\n","\n","# Check all splits using constants\n","dataset_stats = {}\n","for split in [DatasetSplit.TRAIN, DatasetSplit.VAL, DatasetSplit.TEST]:\n","    images_dir = YOLO_DATASET_ROOT / 'images' / split\n","    labels_dir = YOLO_DATASET_ROOT / 'labels' / split\n","\n","    if images_dir.exists() and labels_dir.exists():\n","        num_images = len(list(images_dir.glob('*.jpg'))) + len(list(images_dir.glob('*.png')))\n","        num_labels = len(list(labels_dir.glob('*.txt')))\n","        dataset_stats[split] = {'images': num_images, 'labels': num_labels}\n","        print(f'  ‚úì {split:5s}: {num_images:6d} images, {num_labels:6d} labels')\n","    else:\n","        print(f'  ‚ö†Ô∏è  {split:5s}: Directory not found')\n","        dataset_stats[split] = {'images': 0, 'labels': 0}\n","\n","print(f'\\nüìÑ Configuration: {DATA_YAML_PATH}')\n","print(f'  Classes: {NUM_CLASSES}')\n","print(f'  Names: {CLASS_NAMES}')\n","\n","total_images = sum(stats['images'] for stats in dataset_stats.values())\n","print(f'\\n‚úì Dataset verified: {total_images:,} total images')\n","print('‚úì Ready for hyperparameter optimization')"]},{"cell_type":"markdown","id":"3cf76930","metadata":{"id":"3cf76930"},"source":["## 6. Define Hyperparameter Search Space"]},{"cell_type":"code","execution_count":10,"id":"06d1ae35","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"06d1ae35","executionInfo":{"status":"ok","timestamp":1764284621338,"user_tz":-180,"elapsed":3,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"ee2800ab-285d-4da2-ec98-387fdc5d290c"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Hyperparameter search space defined\n","\n","üìä Focused Search Space Summary:\n","  Strategy: Tune ONLY critical high-impact parameters\n","  üéØ Tuned Parameters (11):\n","    - Image Size (imgsz): 640, 800, 1024\n","    - Batch Size: Dynamic (96 for 640, 64 for 800+)\n","    - Optimizer: SGD, Adam, AdamW\n","    - Learning Rate (lr0): 1e-4 to 5e-3\n","    - Momentum: 0.85 to 0.97\n","    - Weight Decay: 1e-5 to 1e-3\n","    - Warmup Epochs: 0 to 3\n","    - Warmup Momentum: 0.5 to 0.95\n","    - Warmup Bias LR: 0.0 to 0.1\n","    - Mosaic: 0.5 to 1.0\n","    - Mixup: 0.0 to 0.2\n","  ‚öôÔ∏è  Fixed Parameters:\n","    - Epochs: 8\n","    - Device: cuda\n","  üìå Using YOLO defaults for: HSV augmentation, spatial transforms, loss weights\n"]}],"source":["# ============================================================================\n","# DEFINE FOCUSED HYPERPARAMETER SEARCH SPACE\n","# ============================================================================\n","\n","def define_hyperparameters(trial):\n","    \"\"\"\n","    Focused hyperparameter search for YOLO - only critical high-impact parameters.\n","\n","    Args:\n","        trial: Optuna trial object for sampling hyperparameters\n","\n","    Returns:\n","        dict: Dictionary of hyperparameters for YOLO training\n","\n","    Tuning Strategy:\n","    - Focus ONLY on parameters with proven high impact on performance\n","    - Use YOLO defaults for well-calibrated parameters (HSV, loss weights)\n","    - Reduces search space for faster convergence and better results\n","\n","    Critical Parameters Tuned:\n","    1. Image size (imgsz): 640, 800, 1024\n","    2. Batch size: Dynamically adjusted based on image size (96 for 640, 64 for 800+)\n","    3. Optimizer choice (SGD/Adam/AdamW)\n","    4. Initial learning rate (lr0): 1e-4 to 5e-3\n","    5. Momentum/beta1: 0.85 to 0.97\n","    6. Weight decay (regularization): 1e-5 to 1e-3\n","    7. Warmup epochs: 0 to 3\n","    8. Warmup momentum: 0.5 to 0.95\n","    9. Warmup bias learning rate: 0.0 to 0.1\n","    10. Mosaic augmentation strength: 0.5 to 1.0\n","    11. Mixup augmentation strength: 0.0 to 0.2\n","    \"\"\"\n","\n","    if trial is None:\n","        raise ValueError(\"Trial object cannot be None\")\n","\n","    # ---------------------------\n","    # 1) Image Size\n","    # ---------------------------\n","    # Test different image sizes to find optimal accuracy/speed tradeoff\n","    image_size = trial.suggest_categorical('imgsz', [640, 768])\n","\n","    # ---------------------------\n","    # 2) Batch Size (Dynamic based on image size)\n","    # ---------------------------\n","    # Larger images require more memory, so reduce batch size accordingly\n","    if image_size == 640:\n","        batch_size = 96  # Standard batch size for 640x640\n","    else:  # 768\n","        batch_size = 64  # Reduced batch size for larger images\n","\n","    # ---------------------------\n","    # 3) Optimizer + Learning Rate\n","    # ---------------------------\n","    optimizer_choice = trial.suggest_categorical('optimizer', ['SGD', 'Adam', 'AdamW'])\n","    lr0 = trial.suggest_float('lr0', 1e-4, 5e-3, log=True)\n","\n","    # ---------------------------\n","    # 4) Regularization\n","    # ---------------------------\n","    momentum = trial.suggest_float('momentum', 0.85, 0.97)\n","    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n","\n","    # ---------------------------\n","    # 5) Warmup Configuration\n","    # ---------------------------\n","    warmup_epochs = trial.suggest_int('warmup_epochs', 0, 3)\n","    warmup_momentum = trial.suggest_float('warmup_momentum', 0.5, 0.95)\n","    warmup_bias_lr = trial.suggest_float('warmup_bias_lr', 0.0, 0.1)\n","\n","    # ---------------------------\n","    # 6) Key Augmentation\n","    # ---------------------------\n","    # Mosaic and mixup have the highest impact on performance\n","    mosaic = trial.suggest_float('mosaic', 0.5, 1.0)\n","    mixup = trial.suggest_float('mixup', 0.0, 0.2)\n","\n","    # ---------------------------\n","    # 7) Compile parameters\n","    # ---------------------------\n","    hyperparams = {\n","        # ===== TUNED PARAMETERS (Critical for performance) =====\n","        'imgsz': image_size,\n","        'batch': batch_size,\n","        'optimizer': optimizer_choice,\n","        'lr0': lr0,\n","        'momentum': momentum,\n","        'weight_decay': weight_decay,\n","        'warmup_epochs': warmup_epochs,\n","        'warmup_momentum': warmup_momentum,\n","        'warmup_bias_lr': warmup_bias_lr,\n","        'mosaic': mosaic,\n","        'mixup': mixup,\n","\n","        # ===== DEFAULT PARAMETERS (YOLO defaults work well) =====\n","        # Learning rate decay: default 0.01 is well-calibrated\n","        # HSV augmentation: defaults (0.015, 0.7, 0.4) are optimal for most cases\n","        # Spatial augmentation: defaults for scale/translate work well\n","        # Loss weights: YOLO defaults (7.5, 0.5, 1.5) are well-balanced\n","\n","        # ===== FIXED PARAMETERS =====\n","        'epochs': EPOCHS_PER_TRIAL,\n","        'device': device,\n","        'val': True,\n","        'patience': ModelConfig.DEFAULT_PATIENCE,\n","        'save': True,\n","        'plots': True,\n","        'cache': False,\n","        'workers': ModelConfig.DEFAULT_WORKERS,\n","        'close_mosaic': ModelConfig.CLOSE_MOSAIC_EPOCHS,\n","        'verbose': True,\n","    }\n","\n","    return hyperparams\n","\n","\n","print('‚úì Hyperparameter search space defined')\n","print('\\nüìä Focused Search Space Summary:')\n","print('  Strategy: Tune ONLY critical high-impact parameters')\n","print('  üéØ Tuned Parameters (11):')\n","print('    - Image Size (imgsz): 640, 800, 1024')\n","print('    - Batch Size: Dynamic (96 for 640, 64 for 800+)')\n","print('    - Optimizer: SGD, Adam, AdamW')\n","print('    - Learning Rate (lr0): 1e-4 to 5e-3')\n","print('    - Momentum: 0.85 to 0.97')\n","print('    - Weight Decay: 1e-5 to 1e-3')\n","print('    - Warmup Epochs: 0 to 3')\n","print('    - Warmup Momentum: 0.5 to 0.95')\n","print('    - Warmup Bias LR: 0.0 to 0.1')\n","print('    - Mosaic: 0.5 to 1.0')\n","print('    - Mixup: 0.0 to 0.2')\n","print('  ‚öôÔ∏è  Fixed Parameters:')\n","print(f'    - Epochs: {EPOCHS_PER_TRIAL}')\n","print(f'    - Device: {device}')\n","print('  üìå Using YOLO defaults for: HSV augmentation, spatial transforms, loss weights')"]},{"cell_type":"markdown","id":"9a8326b5","metadata":{"id":"9a8326b5"},"source":["## 7. Define Objective Function"]},{"cell_type":"code","execution_count":11,"id":"c5575796","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c5575796","executionInfo":{"status":"ok","timestamp":1764284621355,"user_tz":-180,"elapsed":6,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"c4eed283-3b90-4fb8-ed1e-924cc4b88f04"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Objective function defined\n","  Returns: mAP@0.5 (validation set)\n","  Goal: Maximize validation performance\n"]}],"source":["# DEFINE OBJECTIVE FUNCTION FOR OPTUNA\n","# ============================================================================\n","\n","def objective(trial):\n","    \"\"\"Objective function for Optuna hyperparameter optimization.\n","\n","    Steps:\n","    1. Sample hyperparameters for the current trial\n","    2. Train a YOLO model with those hyperparameters\n","    3. Evaluate the model on the validation set\n","    4. Return validation mAP@0.5 (to maximize)\n","    \"\"\"\n","    # Get hyperparameters for this trial\n","    hyperparameters = define_hyperparameters(trial)\n","\n","    # Create trial-specific directory (absolute path under BASE_DIR)\n","    trial_dir = TUNE_DIR / f\"trial_{trial.number:03d}\"\n","    trial_dir.mkdir(exist_ok=True, parents=True)\n","\n","    # Initialize W&B if enabled\n","    wandb_run = None\n","    if USE_WANDB:\n","        try:\n","            os.environ['WANDB_DIR'] = str(trial_dir)\n","            wandb_run = wandb.init(\n","                project=WANDB_PROJECT_TUNING,\n","                name=f'{MODEL_NAME}_trial_{trial.number:03d}',\n","                config=hyperparameters,\n","                dir=str(trial_dir),\n","                reinit=True\n","            )\n","        except Exception as wandb_error:\n","            print(f'‚ö†Ô∏è  W&B initialization failed: {wandb_error}')\n","            wandb_run = None\n","\n","    # Print trial information\n","    print(f\"\\n{'=' * 80}\")\n","    print(f\"TRIAL {trial.number}/{N_TRIALS}\")\n","    print(f\"{'=' * 80}\")\n","    print(f\"üéØ Tuned Parameters:\")\n","    print(f\"  Image Size: {hyperparameters['imgsz']}\")\n","    print(f\"  Batch Size: {hyperparameters['batch']} (auto-adjusted for image size)\")\n","    print(f\"  Optimizer: {hyperparameters['optimizer']}\")\n","    print(f\"  Learning Rate: {hyperparameters['lr0']:.6f}\")\n","    print(f\"  Momentum: {hyperparameters['momentum']:.4f}\")\n","    print(f\"  Weight Decay: {hyperparameters['weight_decay']:.6f}\")\n","    print(f\"  Warmup: epochs={hyperparameters['warmup_epochs']}, momentum={hyperparameters['warmup_momentum']:.2f}, bias_lr={hyperparameters['warmup_bias_lr']:.3f}\")\n","    print(f\"  Mosaic: {hyperparameters['mosaic']:.2f}\")\n","    print(f\"  Mixup: {hyperparameters['mixup']:.2f}\")\n","    print(f\"‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\")\n","    print(f\"{'=' * 80}\")\n","\n","    trial_model = None\n","    map50 = 0.001  # Default penalty for failed trials\n","\n","    try:\n","        # Load fresh model for this trial\n","        trial_model = YOLO(str(model_path))\n","\n","        # Train model with hyperparameters (W&B integration via wandb.init)\n","        trial_run_name = f\"{MODEL_NAME}_trial_{trial.number:03d}\"\n","        train_results = trial_model.train(\n","            data=str(DATA_YAML_PATH),\n","            project=str(trial_dir),\n","            name=trial_run_name,\n","            exist_ok=True,\n","            **hyperparameters,\n","        )\n","\n","        # Validate model\n","        validation_results = trial_model.val(\n","            data=str(DATA_YAML_PATH),\n","            split=\"val\",\n","            project=str(trial_dir),\n","            name=\"val\",\n","            verbose=False,\n","        )\n","\n","        # Extract metrics\n","        map50 = float(validation_results.box.map50)\n","        map50_95 = float(validation_results.box.map)\n","        precision = float(validation_results.box.mp)\n","        recall = float(validation_results.box.mr)\n","\n","        # Save training metrics if available\n","        train_metrics = {}\n","        if hasattr(train_results, 'results_dict'):\n","            train_metrics = {key: float(value) if isinstance(value, (int,float,np.floating,np.integer)) else value\n","                             for key,value in train_results.results_dict.items()\n","                             if key not in ['fitness']}\n","\n","        # Save trial results JSON\n","        trial_results = {\n","            \"trial_number\": trial.number,\n","            \"model_name\": MODEL_NAME,\n","            \"dataset\": YOLO_DATASET_ROOT.name,\n","            \"trial_directory\": str(trial_dir),\n","            \"hyperparameters\": {k: float(v) if isinstance(v,(np.floating,np.integer)) else v for k,v in hyperparameters.items()},\n","            \"validation_metrics\": {\"map50\": map50, \"map50_95\": map50_95, \"precision\": precision, \"recall\": recall},\n","            \"training_metrics\": train_metrics,\n","            \"training_config\": {\n","                \"epochs\": EPOCHS_PER_TRIAL,\n","                \"batch_size\": hyperparameters['batch'],\n","                \"image_size\": hyperparameters['imgsz'],\n","                \"device\": device,\n","            },\n","            \"timestamp\": datetime.now().isoformat(),\n","            \"status\": \"completed\"\n","        }\n","\n","        trial_results_path = trial_dir / \"trial_results.json\"\n","        with open(trial_results_path, 'w', encoding='utf-8') as f:\n","            json.dump(trial_results, f, indent=2)\n","\n","        print(f'\\n‚úÖ Trial {trial.number} Completed')\n","        print(f'  mAP@0.5: {map50:.4f}')\n","        print(f'  mAP@0.5:0.95: {map50_95:.4f}')\n","        print(f'  Precision: {precision:.4f}')\n","        print(f'  Recall: {recall:.4f}')\n","\n","    except Exception as error:\n","        print(f'\\n‚ùå Trial {trial.number} Failed: {error}')\n","\n","        # Save error information\n","        trial_results = {\n","            \"trial_number\": trial.number,\n","            \"model_name\": MODEL_NAME,\n","            \"dataset\": YOLO_DATASET_ROOT.name,\n","            \"trial_directory\": str(trial_dir),\n","            \"hyperparameters\": {k: float(v) if isinstance(v,(np.floating,np.integer)) else v for k,v in hyperparameters.items()},\n","            \"error\": str(error),\n","            \"timestamp\": datetime.now().isoformat(),\n","            \"status\": \"failed\"\n","        }\n","\n","        trial_results_path = trial_dir / \"trial_results.json\"\n","        with open(trial_results_path, 'w', encoding='utf-8') as f:\n","            json.dump(trial_results, f, indent=2)\n","\n","        # Return small penalty value instead of raising exception\n","        map50 = 0.001\n","\n","    finally:\n","        # Clean up\n","        if wandb_run is not None:\n","            wandb_run.finish()\n","\n","        # Clean up trial model\n","        if trial_model is not None:\n","            del trial_model\n","\n","        # Force garbage collection\n","        gc.collect()\n","        if device == 'cuda':\n","            torch.cuda.empty_cache()\n","            print(\"üßπ CUDA cache cleared\")\n","\n","    return map50\n","\n","\n","print('‚úì Objective function defined')\n","print('  Returns: mAP@0.5 (validation set)')\n","print('  Goal: Maximize validation performance')"]},{"cell_type":"markdown","id":"b9b2c034","metadata":{"id":"b9b2c034"},"source":["## 8. Run Hyperparameter Optimization"]},{"cell_type":"code","execution_count":null,"id":"e116f130","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a4113552084d48fc9cddd83157a14742","5b98d15ccaef487a89b7acad61b1cdb6","7fd22f9eabec4486b052e9fe12e243ac","da9f96b09dee45fe9b2566052330249e","90440937d77948be9943453b82e702e4","16549873e2564293b91e8911068ea0f1","98b71aeace5b4e8d86358d727fc950de","247c0d2c39984077be9612391592939d","08a4b8062a5c4539b2e4132f85df6019","9212e0e54afd46c18bf835df5662538f","36bf390499164cc3a3b848287760d4bb"]},"id":"e116f130","outputId":"a84035c5-5955-47a3-bbd4-9f34d0a2efab"},"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2025-11-27 23:03:41,385] A new study created in memory with name: yolov8m_finetuned_1_optuna_20251127_230340\n"]},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","STARTING HYPERPARAMETER OPTIMIZATION\n","================================================================================\n","Model: yolov8m_finetuned_1\n","Dataset: bdd100k_yolo_tuning\n","Number of Trials: 40\n","Epochs per Trial: 8\n","Timeout: 24 hours\n","Device: cuda\n","================================================================================\n","\n","üÜï Creating new optimization study\n","\n","üöÄ Optimization started at 2025-11-27 23:03:41\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/40 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4113552084d48fc9cddd83157a14742"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mm3mahdy\u001b[0m (\u001b[33mm3mahdy-king-saud-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_000/wandb/run-20251127_230343-u4ft0m5r</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/u4ft0m5r' target=\"_blank\">yolov8m_finetuned_1_trial_000</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/u4ft0m5r' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/u4ft0m5r</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 0/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.000184\n","  Momentum: 0.8570\n","  Weight Decay: 0.000540\n","  Warmup: epochs=2, momentum=0.82, bias_lr=0.002\n","  Mosaic: 0.98\n","  Mixup: 0.17\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00018408992080552527, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.16648852816008436, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.856970033460184, mosaic=0.9849549260809971, multi_scale=False, name=yolov8m_finetuned_1_trial_000, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_000, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_000/yolov8m_finetuned_1_trial_000, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0020584494295802446, warmup_epochs=2, warmup_momentum=0.8186326600082204, weight_decay=0.0005399484409787432, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1779.4¬±593.7 MB/s, size: 53.9 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 14.5Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1174.9¬±509.4 MB/s, size: 56.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 6.2Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_000/yolov8m_finetuned_1_trial_000/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00018408992080552527, momentum=0.856970033460184) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005399484409787432), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_000/yolov8m_finetuned_1_trial_000\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      37.7G      1.223     0.6785     0.9999        508        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.7it/s 2:28\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.7s\n","                   all      10000     185578      0.606      0.542      0.572      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      35.9G      1.211      0.669     0.9918        343        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.0s\n","                   all      10000     185578      0.631      0.529      0.575      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      38.8G      1.205     0.6637     0.9851        278        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.4s\n","                   all      10000     185578      0.637      0.526      0.576      0.333\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      37.4G      1.207     0.6636     0.9841        250        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.1s\n","                   all      10000     185578       0.63      0.529      0.576      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      35.4G      1.203     0.6603     0.9831        372        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.0s\n","                   all      10000     185578      0.635      0.526      0.576      0.333\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      35.4G      1.203      0.661     0.9834        519        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.2s\n","                   all      10000     185578      0.632      0.528      0.576      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8        35G      1.202     0.6616     0.9817        440        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.1s\n","                   all      10000     185578      0.632      0.528      0.575      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      36.5G      1.201     0.6585     0.9816        166        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.1s\n","                   all      10000     185578      0.635      0.525      0.575      0.332\n","\n","8 epochs completed in 0.426 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_000/yolov8m_finetuned_1_trial_000/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_000/yolov8m_finetuned_1_trial_000/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_000/yolov8m_finetuned_1_trial_000/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.5it/s 53.9s\n","                   all      10000     185578      0.638      0.526      0.576      0.333\n","                person       3220      13265      0.784      0.587      0.688      0.358\n","                 rider        515        649      0.642      0.504      0.519      0.279\n","                   car       9879     102540      0.846      0.725      0.815      0.511\n","                 truck       2689       4247      0.658       0.62      0.656       0.48\n","                   bus       1242       1597      0.679      0.595      0.655      0.506\n","                 train         14         15          0          0     0.0111    0.00409\n","                 motor        334        452       0.62      0.504      0.499      0.261\n","                  bike        578       1007      0.639       0.52      0.549      0.288\n","         traffic light       5653      26891      0.755      0.568      0.654      0.258\n","          traffic sign       8221      34915      0.755      0.631      0.711      0.382\n","Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_000/yolov8m_finetuned_1_trial_000\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1541.8¬±586.3 MB/s, size: 64.9 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 7.6Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 9.5it/s 1:06\n","                   all      10000     185578      0.639      0.526      0.577      0.333\n","Speed: 0.5ms preprocess, 2.1ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_000/val\u001b[0m\n","\n","‚úÖ Trial 0 Completed\n","  mAP@0.5: 0.5769\n","  mAP@0.5:0.95: 0.3335\n","  Precision: 0.6390\n","  Recall: 0.5259\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_000</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/u4ft0m5r' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/u4ft0m5r</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_000/wandb/run-20251127_230343-u4ft0m5r/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-27 23:31:57,529] Trial 0 finished with value: 0.5769275868120581 and parameters: {'imgsz': 768, 'optimizer': 'SGD', 'lr0': 0.00018408992080552527, 'momentum': 0.856970033460184, 'weight_decay': 0.0005399484409787432, 'warmup_epochs': 2, 'warmup_momentum': 0.8186326600082204, 'warmup_bias_lr': 0.0020584494295802446, 'mosaic': 0.9849549260809971, 'mixup': 0.16648852816008436}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 1/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_001/wandb/run-20251127_233157-vo74wubl</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/vo74wubl' target=\"_blank\">yolov8m_finetuned_1_trial_001</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/vo74wubl' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/vo74wubl</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 1/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 640\n","  Batch Size: 96 (auto-adjusted for image size)\n","  Optimizer: AdamW\n","  Learning Rate: 0.000542\n","  Momentum: 0.8849\n","  Weight Decay: 0.000167\n","  Warmup: epochs=0, momentum=0.63, bias_lr=0.037\n","  Mosaic: 0.73\n","  Mixup: 0.16\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=96, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005418282319533242, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.15703519227860274, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.8849474968237651, mosaic=0.728034992108518, multi_scale=False, name=yolov8m_finetuned_1_trial_001, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_001, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_001/yolov8m_finetuned_1_trial_001, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.03663618432936917, warmup_epochs=0, warmup_momentum=0.6314650918408482, weight_decay=0.00016738085788752134, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1736.0¬±502.3 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 11.1Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 578.9¬±159.4 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 6.7Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_001/yolov8m_finetuned_1_trial_001/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005418282319533242, momentum=0.8849474968237651) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.000251071286831282), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_001/yolov8m_finetuned_1_trial_001\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      38.4G      1.255     0.7548     0.9949       2927        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.6it/s 1:49\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.4s\n","                   all      10000     185578      0.588      0.449       0.49      0.271\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      37.4G      1.252     0.7409     0.9939       2486        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.1s\n","                   all      10000     185578      0.704      0.463      0.506      0.282\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      37.5G       1.24     0.7215     0.9876       2642        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.5s\n","                   all      10000     185578      0.596      0.468      0.509      0.284\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8        38G      1.233     0.7133     0.9827       2159        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.3it/s 39.3s\n","                   all      10000     185578      0.703       0.47      0.514      0.287\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8        37G      1.219      0.694     0.9773       2476        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.4s\n","                   all      10000     185578      0.615      0.483      0.526      0.296\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      36.9G      1.207     0.6777     0.9698       2379        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.3s\n","                   all      10000     185578      0.616      0.487      0.532      0.301\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8        39G      1.196     0.6642     0.9659       2565        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.5s\n","                   all      10000     185578      0.726      0.485      0.538      0.304\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      36.6G      1.189     0.6549     0.9647       2244        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.0s\n","                   all      10000     185578      0.729      0.483      0.539      0.305\n","\n","8 epochs completed in 0.322 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_001/yolov8m_finetuned_1_trial_001/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_001/yolov8m_finetuned_1_trial_001/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_001/yolov8m_finetuned_1_trial_001/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.1it/s 49.5s\n","                   all      10000     185578      0.728      0.484      0.539      0.305\n","                person       3220      13265      0.782      0.543      0.645      0.329\n","                 rider        515        649      0.619       0.48      0.489      0.247\n","                   car       9879     102540       0.84      0.696      0.787      0.493\n","                 truck       2689       4247      0.645      0.579      0.614      0.441\n","                   bus       1242       1597      0.704      0.541      0.619      0.474\n","                 train         14         15          1          0    0.00952    0.00175\n","                 motor        334        452      0.626      0.444      0.467       0.23\n","                  bike        578       1007      0.551      0.506      0.508      0.257\n","         traffic light       5653      26891      0.761      0.486      0.596       0.23\n","          traffic sign       8221      34915      0.756      0.569      0.658      0.349\n","Speed: 0.1ms preprocess, 0.8ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_001/yolov8m_finetuned_1_trial_001\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1434.1¬±429.3 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 8.6Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 10.9it/s 57.4s\n","                   all      10000     185578      0.731      0.484      0.539      0.306\n","Speed: 0.4ms preprocess, 1.4ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_001/val\u001b[0m\n","\n","‚úÖ Trial 1 Completed\n","  mAP@0.5: 0.5393\n","  mAP@0.5:0.95: 0.3059\n","  Precision: 0.7308\n","  Recall: 0.4837\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_001</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/vo74wubl' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/vo74wubl</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_001/wandb/run-20251127_233157-vo74wubl/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-27 23:53:28,376] Trial 1 finished with value: 0.5392655211791706 and parameters: {'imgsz': 640, 'optimizer': 'AdamW', 'lr0': 0.0005418282319533242, 'momentum': 0.8849474968237651, 'weight_decay': 0.00016738085788752134, 'warmup_epochs': 0, 'warmup_momentum': 0.6314650918408482, 'warmup_bias_lr': 0.03663618432936917, 'mosaic': 0.728034992108518, 'mixup': 0.15703519227860274}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 2/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_002/wandb/run-20251127_235328-lzr0jamj</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/lzr0jamj' target=\"_blank\">yolov8m_finetuned_1_trial_002</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/lzr0jamj' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/lzr0jamj</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 2/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: AdamW\n","  Learning Rate: 0.000195\n","  Momentum: 0.8578\n","  Weight Decay: 0.000790\n","  Warmup: epochs=3, momentum=0.86, bias_lr=0.030\n","  Mosaic: 0.55\n","  Mixup: 0.14\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00019485671251272575, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.1368466053024314, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.8578061911582335, mosaic=0.5488360570031919, multi_scale=False, name=yolov8m_finetuned_1_trial_002, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_002, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_002/yolov8m_finetuned_1_trial_002, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.03046137691733707, warmup_epochs=3, warmup_momentum=0.8637788066524075, weight_decay=0.000790261954970823, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1819.3¬±519.3 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 16.0Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 429.9¬±90.8 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 4.8Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_002/yolov8m_finetuned_1_trial_002/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00019485671251272575, momentum=0.8578061911582335) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.000790261954970823), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_002/yolov8m_finetuned_1_trial_002\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      37.8G       1.22     0.6687     0.9853        383        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.7it/s 2:30\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.5s\n","                   all      10000     185578      0.626      0.518      0.561      0.323\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      37.3G      1.223     0.6715     0.9877        298        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.2s\n","                   all      10000     185578      0.614      0.541      0.564      0.321\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      38.7G       1.22     0.6736     0.9873        408        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.1s\n","                   all      10000     185578      0.636      0.552       0.57      0.327\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      37.7G      1.223     0.6748     0.9896        241        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.3s\n","                   all      10000     185578      0.646      0.531      0.566      0.323\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      35.7G      1.215     0.6655      0.986        227        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.2s\n","                   all      10000     185578      0.627      0.537      0.568      0.325\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      36.7G      1.211     0.6567     0.9843        179        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.2s\n","                   all      10000     185578      0.595      0.547      0.565      0.323\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8        37G      1.205     0.6516     0.9817        314        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.2s\n","                   all      10000     185578      0.654      0.524      0.572      0.328\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      36.9G      1.194     0.6404     0.9784        242        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 42.9s\n","                   all      10000     185578      0.629       0.54      0.572      0.328\n","\n","8 epochs completed in 0.426 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_002/yolov8m_finetuned_1_trial_002/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_002/yolov8m_finetuned_1_trial_002/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_002/yolov8m_finetuned_1_trial_002/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.5it/s 53.8s\n","                   all      10000     185578      0.629       0.54      0.572      0.328\n","                person       3220      13265      0.774      0.589      0.682      0.353\n","                 rider        515        649      0.617      0.501      0.506      0.272\n","                   car       9879     102540      0.832      0.731      0.813       0.51\n","                 truck       2689       4247      0.629      0.613      0.633      0.459\n","                   bus       1242       1597      0.653       0.59      0.632      0.486\n","                 train         14         15      0.138      0.133     0.0592     0.0332\n","                 motor        334        452        0.6      0.482      0.502      0.251\n","                  bike        578       1007       0.57      0.537      0.536      0.282\n","         traffic light       5653      26891      0.749      0.573      0.651      0.256\n","          traffic sign       8221      34915      0.724      0.649      0.702      0.376\n","Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_002/yolov8m_finetuned_1_trial_002\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1368.8¬±432.0 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 8.1Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 9.6it/s 1:05\n","                   all      10000     185578       0.63       0.54      0.572      0.329\n","Speed: 0.5ms preprocess, 2.0ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_002/val\u001b[0m\n","\n","‚úÖ Trial 2 Completed\n","  mAP@0.5: 0.5722\n","  mAP@0.5:0.95: 0.3285\n","  Precision: 0.6295\n","  Recall: 0.5401\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_002</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/lzr0jamj' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/lzr0jamj</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_002/wandb/run-20251127_235328-lzr0jamj/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 00:21:25,111] Trial 2 finished with value: 0.572175535486724 and parameters: {'imgsz': 768, 'optimizer': 'AdamW', 'lr0': 0.00019485671251272575, 'momentum': 0.8578061911582335, 'weight_decay': 0.000790261954970823, 'warmup_epochs': 3, 'warmup_momentum': 0.8637788066524075, 'warmup_bias_lr': 0.03046137691733707, 'mosaic': 0.5488360570031919, 'mixup': 0.1368466053024314}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 3/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_003/wandb/run-20251128_002125-7p0h4ag4</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/7p0h4ag4' target=\"_blank\">yolov8m_finetuned_1_trial_003</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/7p0h4ag4' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/7p0h4ag4</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 3/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 640\n","  Batch Size: 96 (auto-adjusted for image size)\n","  Optimizer: AdamW\n","  Learning Rate: 0.000275\n","  Momentum: 0.9295\n","  Weight Decay: 0.000042\n","  Warmup: epochs=2, momentum=0.75, bias_lr=0.018\n","  Mosaic: 0.98\n","  Mixup: 0.16\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=96, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00027520696850790545, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.15502656467222292, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.9295026741224778, mosaic=0.9847923138822793, multi_scale=False, name=yolov8m_finetuned_1_trial_003, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_003, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_003/yolov8m_finetuned_1_trial_003, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.018485445552552705, warmup_epochs=2, warmup_momentum=0.7460196257044758, weight_decay=4.201672054372529e-05, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1551.2¬±585.6 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 13.6Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 365.5¬±66.8 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 4.9Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_003/yolov8m_finetuned_1_trial_003/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00027520696850790545, momentum=0.9295026741224778) with parameter groups 77 weight(decay=0.0), 84 weight(decay=6.302508081558793e-05), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_003/yolov8m_finetuned_1_trial_003\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      37.7G      1.182     0.6566     0.9618       2888        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.6it/s 1:49\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.6s\n","                   all      10000     185578      0.589      0.511      0.542      0.307\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      37.5G       1.19      0.666     0.9624       3023        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.2s\n","                   all      10000     185578      0.593      0.503      0.524      0.294\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      38.1G       1.19     0.6692     0.9647       3049        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.4s\n","                   all      10000     185578      0.612      0.491      0.531      0.298\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      36.7G      1.189     0.6659     0.9649       3939        640: 92% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ 158/171 1.7it/s 1:36<7.8sWARNING ‚ö†Ô∏è CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n","\u001b[K        4/8      36.7G       1.19     0.6667     0.9656       3341        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.6it/s 1:48\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.3s\n","                   all      10000     185578       0.62      0.484      0.532        0.3\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      36.9G      1.181      0.657     0.9599       2947        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.2s\n","                   all      10000     185578      0.613      0.489      0.535      0.303\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      36.7G      1.169     0.6422      0.957       2986        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.4s\n","                   all      10000     185578        0.6      0.493      0.529        0.3\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      37.1G      1.167     0.6379     0.9549       3072        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.2s\n","                   all      10000     185578      0.598      0.512      0.537      0.305\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      37.1G      1.157     0.6259       0.95       2816        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 37.9s\n","                   all      10000     185578      0.597      0.513      0.538      0.306\n","\n","8 epochs completed in 0.323 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_003/yolov8m_finetuned_1_trial_003/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_003/yolov8m_finetuned_1_trial_003/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_003/yolov8m_finetuned_1_trial_003/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.1it/s 49.9s\n","                   all      10000     185578       0.59      0.511      0.542      0.307\n","                person       3220      13265      0.712      0.595      0.651      0.331\n","                 rider        515        649       0.62      0.482      0.507      0.257\n","                   car       9879     102540      0.804      0.723      0.789      0.493\n","                 truck       2689       4247      0.614      0.593       0.61       0.44\n","                   bus       1242       1597      0.622      0.602      0.628      0.481\n","                 train         14         15          0          0     0.0126    0.00864\n","                 motor        334        452      0.526       0.48      0.456      0.233\n","                  bike        578       1007      0.579      0.501      0.506      0.249\n","         traffic light       5653      26891      0.732      0.515      0.599      0.232\n","          traffic sign       8221      34915      0.687      0.622       0.66      0.349\n","Speed: 0.1ms preprocess, 0.8ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_003/yolov8m_finetuned_1_trial_003\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1334.7¬±387.8 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 7.4Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 10.7it/s 58.2s\n","                   all      10000     185578      0.591      0.511      0.542      0.308\n","Speed: 0.4ms preprocess, 1.4ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_003/val\u001b[0m\n","\n","‚úÖ Trial 3 Completed\n","  mAP@0.5: 0.5417\n","  mAP@0.5:0.95: 0.3079\n","  Precision: 0.5905\n","  Recall: 0.5105\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_003</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/7p0h4ag4' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/7p0h4ag4</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_003/wandb/run-20251128_002125-7p0h4ag4/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 00:43:00,347] Trial 3 finished with value: 0.541650867972252 and parameters: {'imgsz': 640, 'optimizer': 'AdamW', 'lr0': 0.00027520696850790545, 'momentum': 0.9295026741224778, 'weight_decay': 4.201672054372529e-05, 'warmup_epochs': 2, 'warmup_momentum': 0.7460196257044758, 'warmup_bias_lr': 0.018485445552552705, 'mosaic': 0.9847923138822793, 'mixup': 0.15502656467222292}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 4/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_004/wandb/run-20251128_004300-tvjz57lq</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/tvjz57lq' target=\"_blank\">yolov8m_finetuned_1_trial_004</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/tvjz57lq' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/tvjz57lq</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 4/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 640\n","  Batch Size: 96 (auto-adjusted for image size)\n","  Optimizer: Adam\n","  Learning Rate: 0.000215\n","  Momentum: 0.8554\n","  Weight Decay: 0.000045\n","  Warmup: epochs=1, momentum=0.62, bias_lr=0.083\n","  Mosaic: 0.68\n","  Mixup: 0.06\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=96, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.000215262809722153, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.05618690193747616, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.8554272746692645, mosaic=0.6783766633467947, multi_scale=False, name=yolov8m_finetuned_1_trial_004, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_004, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_004/yolov8m_finetuned_1_trial_004, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.08287375091519295, warmup_epochs=1, warmup_momentum=0.6221070642982531, weight_decay=4.473636174621264e-05, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1801.8¬±438.7 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 15.3Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 417.3¬±119.6 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 6.1Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_004/yolov8m_finetuned_1_trial_004/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.000215262809722153, momentum=0.8554272746692645) with parameter groups 77 weight(decay=0.0), 84 weight(decay=6.710454261931896e-05), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_004/yolov8m_finetuned_1_trial_004\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      36.7G      1.166     0.6319     0.9513       2589        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.6it/s 1:47\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.2s\n","                   all      10000     185578      0.709      0.489      0.536      0.303\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      36.8G       1.17     0.6392     0.9539       2526        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.2s\n","                   all      10000     185578      0.719       0.48      0.536      0.303\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      38.7G      1.164     0.6303     0.9515       1934        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.3s\n","                   all      10000     185578      0.614      0.487      0.531      0.299\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      38.2G      1.158     0.6253     0.9503       2412        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.2s\n","                   all      10000     185578      0.617      0.489      0.535      0.304\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      36.3G       1.15     0.6132     0.9454       2884        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.2s\n","                   all      10000     185578      0.613      0.495      0.537      0.304\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      37.8G      1.144     0.6063     0.9439       2310        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.4s\n","                   all      10000     185578      0.634      0.503      0.539      0.306\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      36.8G      1.133     0.5967     0.9398       2412        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.1s\n","                   all      10000     185578      0.645      0.505      0.544       0.31\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      37.1G       1.13     0.5914     0.9379       2635        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.4s\n","                   all      10000     185578      0.584      0.548      0.543      0.308\n","\n","8 epochs completed in 0.319 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_004/yolov8m_finetuned_1_trial_004/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_004/yolov8m_finetuned_1_trial_004/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_004/yolov8m_finetuned_1_trial_004/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.1it/s 50.3s\n","                   all      10000     185578      0.645      0.505      0.544       0.31\n","                person       3220      13265      0.772      0.558      0.648      0.329\n","                 rider        515        649      0.657      0.471      0.494      0.251\n","                   car       9879     102540       0.85      0.694      0.792      0.496\n","                 truck       2689       4247      0.625      0.588      0.602      0.435\n","                   bus       1242       1597      0.628      0.596      0.623      0.478\n","                 train         14         15      0.186      0.133     0.0549     0.0349\n","                 motor        334        452      0.627      0.457      0.461      0.233\n","                  bike        578       1007      0.579      0.489      0.492      0.253\n","         traffic light       5653      26891      0.768      0.492      0.608      0.235\n","          traffic sign       8221      34915      0.756      0.572      0.662      0.352\n","Speed: 0.1ms preprocess, 0.8ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_004/yolov8m_finetuned_1_trial_004\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1460.3¬±490.2 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 6.9Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 10.8it/s 58.0s\n","                   all      10000     185578      0.645      0.507      0.544       0.31\n","Speed: 0.4ms preprocess, 1.5ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_004/val\u001b[0m\n","\n","‚úÖ Trial 4 Completed\n","  mAP@0.5: 0.5440\n","  mAP@0.5:0.95: 0.3099\n","  Precision: 0.6445\n","  Recall: 0.5065\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_004</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/tvjz57lq' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/tvjz57lq</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_004/wandb/run-20251128_004300-tvjz57lq/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 01:04:23,359] Trial 4 finished with value: 0.543987769075524 and parameters: {'imgsz': 640, 'optimizer': 'Adam', 'lr0': 0.000215262809722153, 'momentum': 0.8554272746692645, 'weight_decay': 4.473636174621264e-05, 'warmup_epochs': 1, 'warmup_momentum': 0.6221070642982531, 'warmup_bias_lr': 0.08287375091519295, 'mosaic': 0.6783766633467947, 'mixup': 0.05618690193747616}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 5/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_005/wandb/run-20251128_010423-l9eg8ooe</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/l9eg8ooe' target=\"_blank\">yolov8m_finetuned_1_trial_005</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/l9eg8ooe' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/l9eg8ooe</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 5/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 640\n","  Batch Size: 96 (auto-adjusted for image size)\n","  Optimizer: AdamW\n","  Learning Rate: 0.002051\n","  Momentum: 0.8738\n","  Weight Decay: 0.000010\n","  Warmup: epochs=3, momentum=0.82, bias_lr=0.073\n","  Mosaic: 0.89\n","  Mixup: 0.01\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=96, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0020512599422151364, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.014808930346818072, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.8738458817841006, mosaic=0.8856351733429728, multi_scale=False, name=yolov8m_finetuned_1_trial_005, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_005, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_005/yolov8m_finetuned_1_trial_005, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.07290071680409874, warmup_epochs=3, warmup_momentum=0.8180858047314277, weight_decay=1.0257563974185649e-05, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1221.9¬±473.8 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 12.1Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 521.0¬±244.3 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 4.4Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_005/yolov8m_finetuned_1_trial_005/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0020512599422151364, momentum=0.8738458817841006) with parameter groups 77 weight(decay=0.0), 84 weight(decay=1.5386345961278473e-05), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_005/yolov8m_finetuned_1_trial_005\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      38.7G      1.179     0.6604     0.9559       2406        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.6it/s 1:47\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 39.1s\n","                   all      10000     185578       0.55      0.427      0.446      0.242\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      36.6G      1.248     0.7503     0.9899       2416        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.3it/s 39.4s\n","                   all      10000     185578      0.525      0.417      0.433      0.233\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      37.2G       1.28      0.784      1.002       2663        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.3it/s 40.0s\n","                   all      10000     185578       0.53      0.402      0.424      0.222\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      37.9G      1.275     0.7759      1.001       2706        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 39.2s\n","                   all      10000     185578      0.668      0.421      0.458      0.248\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      38.9G      1.248     0.7417     0.9889       2441        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.6s\n","                   all      10000     185578      0.594      0.431      0.478      0.263\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8        38G      1.224     0.7121     0.9788       2483        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.9s\n","                   all      10000     185578        0.7      0.462      0.503      0.279\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      36.6G      1.207     0.6866     0.9733       2341        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.4s\n","                   all      10000     185578      0.704      0.468      0.514      0.289\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      38.2G      1.182     0.6574     0.9615       2697        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.8s\n","                   all      10000     185578      0.605      0.482      0.525      0.297\n","\n","8 epochs completed in 0.322 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_005/yolov8m_finetuned_1_trial_005/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_005/yolov8m_finetuned_1_trial_005/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_005/yolov8m_finetuned_1_trial_005/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.1it/s 50.1s\n","                   all      10000     185578      0.606      0.482      0.525      0.297\n","                person       3220      13265      0.755      0.543      0.632      0.319\n","                 rider        515        649      0.594       0.45      0.463      0.241\n","                   car       9879     102540      0.811      0.701      0.778      0.485\n","                 truck       2689       4247       0.59      0.601      0.606      0.434\n","                   bus       1242       1597      0.704      0.521       0.61      0.463\n","                 train         14         15          0          0    0.00545     0.0028\n","                 motor        334        452       0.61      0.445      0.453      0.229\n","                  bike        578       1007      0.532      0.485      0.477      0.238\n","         traffic light       5653      26891      0.733      0.502      0.585      0.223\n","          traffic sign       8221      34915      0.727      0.571      0.645      0.339\n","Speed: 0.1ms preprocess, 0.8ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_005/yolov8m_finetuned_1_trial_005\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1461.6¬±412.0 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 8.6Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 10.8it/s 58.1s\n","                   all      10000     185578      0.606      0.482      0.526      0.298\n","Speed: 0.4ms preprocess, 1.4ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_005/val\u001b[0m\n","\n","‚úÖ Trial 5 Completed\n","  mAP@0.5: 0.5258\n","  mAP@0.5:0.95: 0.2980\n","  Precision: 0.6059\n","  Recall: 0.4818\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_005</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/l9eg8ooe' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/l9eg8ooe</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_005/wandb/run-20251128_010423-l9eg8ooe/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 01:25:52,910] Trial 5 finished with value: 0.5258322084927844 and parameters: {'imgsz': 640, 'optimizer': 'AdamW', 'lr0': 0.0020512599422151364, 'momentum': 0.8738458817841006, 'weight_decay': 1.0257563974185649e-05, 'warmup_epochs': 3, 'warmup_momentum': 0.8180858047314277, 'warmup_bias_lr': 0.07290071680409874, 'mosaic': 0.8856351733429728, 'mixup': 0.014808930346818072}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 6/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_006/wandb/run-20251128_012553-1d11mmho</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/1d11mmho' target=\"_blank\">yolov8m_finetuned_1_trial_006</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/1d11mmho' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/1d11mmho</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 6/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 640\n","  Batch Size: 96 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.000128\n","  Momentum: 0.8873\n","  Weight Decay: 0.000045\n","  Warmup: epochs=2, momentum=0.79, bias_lr=0.089\n","  Mosaic: 0.74\n","  Mixup: 0.02\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=96, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00012822825454807568, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.02391884918766034, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.8873178786058794, mosaic=0.7361074625809747, multi_scale=False, name=yolov8m_finetuned_1_trial_006, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_006, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_006/yolov8m_finetuned_1_trial_006, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.08872127425763265, warmup_epochs=2, warmup_momentum=0.7869008621098459, weight_decay=4.4706085467784903e-05, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1406.3¬±452.2 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 13.5Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 545.6¬±134.6 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 6.6Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_006/yolov8m_finetuned_1_trial_006/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00012822825454807568, momentum=0.8873178786058794) with parameter groups 77 weight(decay=0.0), 84 weight(decay=6.705912820167735e-05), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_006/yolov8m_finetuned_1_trial_006\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8        36G       1.13     0.5891     0.9381       2730        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.6it/s 1:46\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.5s\n","                   all      10000     185578       0.64      0.512      0.555      0.318\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      36.1G      1.127     0.5862     0.9368       2500        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.4s\n","                   all      10000     185578      0.645      0.509      0.554      0.318\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      38.3G      1.126     0.5823      0.937       2593        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.1s\n","                   all      10000     185578      0.641       0.51      0.554      0.318\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8        38G      1.127     0.5847     0.9365       2290        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.6s\n","                   all      10000     185578      0.645       0.51      0.554      0.318\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      36.3G      1.125     0.5825     0.9367       2618        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.4s\n","                   all      10000     185578      0.648      0.507      0.554      0.318\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      38.6G      1.125     0.5834      0.935       2376        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.3s\n","                   all      10000     185578      0.648      0.507      0.554      0.318\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      38.4G      1.126     0.5811     0.9362       2353        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.5s\n","                   all      10000     185578      0.642       0.51      0.554      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      35.9G      1.124     0.5813     0.9359       2684        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.3s\n","                   all      10000     185578      0.645       0.51      0.554      0.317\n","\n","8 epochs completed in 0.316 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_006/yolov8m_finetuned_1_trial_006/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_006/yolov8m_finetuned_1_trial_006/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_006/yolov8m_finetuned_1_trial_006/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.1it/s 49.7s\n","                   all      10000     185578      0.641       0.51      0.554      0.318\n","                person       3220      13265      0.776      0.564      0.658      0.338\n","                 rider        515        649      0.622      0.489      0.515       0.26\n","                   car       9879     102540      0.841      0.708      0.795        0.5\n","                 truck       2689       4247      0.647      0.602      0.631       0.46\n","                   bus       1242       1597      0.664      0.592      0.636      0.494\n","                 train         14         15      0.161     0.0667     0.0289       0.02\n","                 motor        334        452      0.624      0.471      0.478      0.247\n","                  bike        578       1007      0.573      0.508      0.519      0.267\n","         traffic light       5653      26891      0.758       0.51      0.612      0.238\n","          traffic sign       8221      34915      0.743      0.592      0.669      0.358\n","Speed: 0.1ms preprocess, 0.8ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_006/yolov8m_finetuned_1_trial_006\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1420.8¬±478.4 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 8.6Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 10.8it/s 58.1s\n","                   all      10000     185578      0.642       0.51      0.555      0.319\n","Speed: 0.4ms preprocess, 1.4ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_006/val\u001b[0m\n","\n","‚úÖ Trial 6 Completed\n","  mAP@0.5: 0.5553\n","  mAP@0.5:0.95: 0.3189\n","  Precision: 0.6424\n","  Recall: 0.5104\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_006</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/1d11mmho' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/1d11mmho</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_006/wandb/run-20251128_012553-1d11mmho/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 01:47:03,146] Trial 6 finished with value: 0.5553024646124811 and parameters: {'imgsz': 640, 'optimizer': 'SGD', 'lr0': 0.00012822825454807568, 'momentum': 0.8873178786058794, 'weight_decay': 4.4706085467784903e-05, 'warmup_epochs': 2, 'warmup_momentum': 0.7869008621098459, 'warmup_bias_lr': 0.08872127425763265, 'mosaic': 0.7361074625809747, 'mixup': 0.02391884918766034}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 7/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_007/wandb/run-20251128_014703-wda2apxk</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/wda2apxk' target=\"_blank\">yolov8m_finetuned_1_trial_007</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/wda2apxk' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/wda2apxk</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 7/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: Adam\n","  Learning Rate: 0.000773\n","  Momentum: 0.9013\n","  Weight Decay: 0.000011\n","  Warmup: epochs=0, momentum=0.51, bias_lr=0.064\n","  Mosaic: 0.66\n","  Mixup: 0.10\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0007728716861851782, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.10171413823294057, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.9013049222030259, mosaic=0.6571779905381634, multi_scale=False, name=yolov8m_finetuned_1_trial_007, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_007, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_007/yolov8m_finetuned_1_trial_007, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.06364104112637804, warmup_epochs=0, warmup_momentum=0.5141431335590304, weight_decay=1.1241862095793047e-05, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1479.2¬±503.8 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 11.9Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 502.3¬±148.7 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 7.0Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_007/yolov8m_finetuned_1_trial_007/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.0007728716861851782, momentum=0.9013049222030259) with parameter groups 77 weight(decay=0.0), 84 weight(decay=1.1241862095793047e-05), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_007/yolov8m_finetuned_1_trial_007\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      38.9G      1.323     0.8299      1.044        332        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.7it/s 2:30\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.5s\n","                   all      10000     185578      0.674       0.44      0.479       0.26\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      36.8G      1.309     0.8008      1.037        205        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.3s\n","                   all      10000     185578      0.676      0.467      0.497      0.274\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8        35G      1.293     0.7733      1.025        260        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.2s\n","                   all      10000     185578      0.691       0.48      0.521      0.292\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      36.1G      1.278     0.7531      1.019        317        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.7s\n","                   all      10000     185578      0.702      0.484       0.53      0.296\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8        37G      1.264     0.7354      1.011        250        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.3s\n","                   all      10000     185578      0.617      0.495      0.542      0.306\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8        38G       1.25     0.7166      1.004        325        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.3s\n","                   all      10000     185578      0.709      0.502      0.544       0.31\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      35.5G      1.234      0.695     0.9975        211        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.2s\n","                   all      10000     185578      0.629      0.504      0.558      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      35.2G      1.222     0.6775     0.9914        296        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.2s\n","                   all      10000     185578      0.625      0.513      0.561       0.32\n","\n","8 epochs completed in 0.428 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_007/yolov8m_finetuned_1_trial_007/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_007/yolov8m_finetuned_1_trial_007/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_007/yolov8m_finetuned_1_trial_007/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.5it/s 54.3s\n","                   all      10000     185578      0.625      0.513      0.561       0.32\n","                person       3220      13265      0.786      0.567      0.675      0.348\n","                 rider        515        649      0.612      0.499      0.509      0.264\n","                   car       9879     102540      0.824      0.731      0.809      0.506\n","                 truck       2689       4247      0.623      0.604      0.633      0.457\n","                   bus       1242       1597      0.667      0.567      0.623      0.476\n","                 train         14         15          0          0    0.00629    0.00381\n","                 motor        334        452      0.612       0.48      0.478      0.244\n","                  bike        578       1007      0.627      0.504       0.53      0.273\n","         traffic light       5653      26891      0.755       0.56      0.647      0.253\n","          traffic sign       8221      34915      0.744      0.622      0.696      0.373\n","Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_007/yolov8m_finetuned_1_trial_007\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1434.9¬±432.9 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 7.5Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 9.5it/s 1:06\n","                   all      10000     185578      0.624      0.514      0.561      0.321\n","Speed: 0.5ms preprocess, 2.0ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_007/val\u001b[0m\n","\n","‚úÖ Trial 7 Completed\n","  mAP@0.5: 0.5606\n","  mAP@0.5:0.95: 0.3206\n","  Precision: 0.6237\n","  Recall: 0.5137\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_007</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/wda2apxk' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/wda2apxk</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_007/wandb/run-20251128_014703-wda2apxk/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 02:15:08,381] Trial 7 finished with value: 0.5606027818022772 and parameters: {'imgsz': 768, 'optimizer': 'Adam', 'lr0': 0.0007728716861851782, 'momentum': 0.9013049222030259, 'weight_decay': 1.1241862095793047e-05, 'warmup_epochs': 0, 'warmup_momentum': 0.5141431335590304, 'warmup_bias_lr': 0.06364104112637804, 'mosaic': 0.6571779905381634, 'mixup': 0.10171413823294057}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 8/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_008/wandb/run-20251128_021508-ddenuxaj</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/ddenuxaj' target=\"_blank\">yolov8m_finetuned_1_trial_008</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/ddenuxaj' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/ddenuxaj</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 8/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 640\n","  Batch Size: 96 (auto-adjusted for image size)\n","  Optimizer: Adam\n","  Learning Rate: 0.000135\n","  Momentum: 0.8848\n","  Weight Decay: 0.000021\n","  Warmup: epochs=3, momentum=0.86, bias_lr=0.063\n","  Mosaic: 0.94\n","  Mixup: 0.16\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=96, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00013514082247401428, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.16073441537982291, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.8847701743496521, mosaic=0.9357302950938589, multi_scale=False, name=yolov8m_finetuned_1_trial_008, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_008, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_008/yolov8m_finetuned_1_trial_008, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.06334037565104235, warmup_epochs=3, warmup_momentum=0.8636541708039875, weight_decay=2.101079931010355e-05, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1694.9¬±478.7 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 10.9Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 529.7¬±137.2 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 7.9Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_008/yolov8m_finetuned_1_trial_008/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.00013514082247401428, momentum=0.8847701743496521) with parameter groups 77 weight(decay=0.0), 84 weight(decay=3.151619896515532e-05), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_008/yolov8m_finetuned_1_trial_008\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      36.3G      1.203     0.6777     0.9696       4607        640: 34% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 58/171 1.7it/s 41.5s<1:08WARNING ‚ö†Ô∏è CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n","\u001b[K        1/8      37.7G      1.201     0.6736     0.9682       4032        640: 58% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 100/171 1.6it/s 1:13<43.2sWARNING ‚ö†Ô∏è CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n","\u001b[K        1/8      37.7G      1.195     0.6678     0.9658       3326        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.4it/s 2:00\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.5s\n","                   all      10000     185578      0.601      0.508      0.539      0.307\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      38.6G       1.18      0.656     0.9612       3136        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.3s\n","                   all      10000     185578      0.645      0.503      0.546       0.31\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      37.2G      1.175     0.6464      0.958       3118        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.4s\n","                   all      10000     185578      0.639        0.5      0.541      0.308\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      38.9G      1.177     0.6469     0.9583       3185        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.7s\n","                   all      10000     185578      0.622      0.524      0.547       0.31\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      37.1G      1.168     0.6401     0.9554       3019        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.2s\n","                   all      10000     185578      0.647       0.51      0.545      0.311\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      36.3G      1.169     0.6405     0.9568       3934        640: 26% ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 44/171 1.7it/s 27.5s<1:17WARNING ‚ö†Ô∏è CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n","\u001b[K        6/8      38.7G      1.165     0.6344     0.9549       3252        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.6it/s 1:49\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.6s\n","                   all      10000     185578      0.632      0.507      0.543      0.309\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8        37G      1.161     0.6293     0.9543       2949        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.1s\n","                   all      10000     185578      0.629      0.514      0.546       0.31\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      37.7G       1.16      0.627     0.9521       4027        640: 87% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ 148/171 1.7it/s 1:30<13.8sWARNING ‚ö†Ô∏è CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n","\u001b[K        8/8      38.1G       1.16     0.6271     0.9519       3189        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.6it/s 1:49\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.2s\n","                   all      10000     185578      0.644      0.505      0.547      0.311\n","\n","8 epochs completed in 0.329 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_008/yolov8m_finetuned_1_trial_008/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_008/yolov8m_finetuned_1_trial_008/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_008/yolov8m_finetuned_1_trial_008/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.1it/s 50.0s\n","                   all      10000     185578      0.645      0.505      0.546       0.31\n","                person       3220      13265      0.788      0.545       0.65      0.331\n","                 rider        515        649      0.648      0.487      0.503      0.258\n","                   car       9879     102540      0.851      0.695      0.791      0.496\n","                 truck       2689       4247      0.636      0.586      0.603      0.436\n","                   bus       1242       1597      0.661       0.57      0.623      0.476\n","                 train         14         15      0.125      0.133     0.0481      0.028\n","                 motor        334        452      0.646      0.465      0.472       0.24\n","                  bike        578       1007       0.57      0.504      0.505      0.253\n","         traffic light       5653      26891      0.767      0.489      0.605      0.235\n","          traffic sign       8221      34915      0.756      0.573      0.663      0.351\n","Speed: 0.1ms preprocess, 0.8ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_008/yolov8m_finetuned_1_trial_008\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1333.8¬±395.0 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 7.4Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 10.8it/s 58.1s\n","                   all      10000     185578      0.645      0.505      0.547      0.311\n","Speed: 0.4ms preprocess, 1.5ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_008/val\u001b[0m\n","\n","‚úÖ Trial 8 Completed\n","  mAP@0.5: 0.5471\n","  mAP@0.5:0.95: 0.3114\n","  Precision: 0.6453\n","  Recall: 0.5048\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_008</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/ddenuxaj' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/ddenuxaj</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_008/wandb/run-20251128_021508-ddenuxaj/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 02:37:04,125] Trial 8 finished with value: 0.5470858450892893 and parameters: {'imgsz': 640, 'optimizer': 'Adam', 'lr0': 0.00013514082247401428, 'momentum': 0.8847701743496521, 'weight_decay': 2.101079931010355e-05, 'warmup_epochs': 3, 'warmup_momentum': 0.8636541708039875, 'warmup_bias_lr': 0.06334037565104235, 'mosaic': 0.9357302950938589, 'mixup': 0.16073441537982291}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 9/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_009/wandb/run-20251128_023704-5fwiy2y9</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/5fwiy2y9' target=\"_blank\">yolov8m_finetuned_1_trial_009</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/5fwiy2y9' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/5fwiy2y9</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 9/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: AdamW\n","  Learning Rate: 0.000347\n","  Momentum: 0.8632\n","  Weight Decay: 0.000029\n","  Warmup: epochs=1, momentum=0.87, bias_lr=0.086\n","  Mosaic: 0.50\n","  Mixup: 0.10\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00034695916603302916, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.10214946051551316, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.8632062309433212, mosaic=0.5034760652655954, multi_scale=False, name=yolov8m_finetuned_1_trial_009, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_009, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_009/yolov8m_finetuned_1_trial_009, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.08607305832563435, warmup_epochs=1, warmup_momentum=0.8681066446651219, weight_decay=2.8567374298471872e-05, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1474.8¬±466.0 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 14.0Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 384.1¬±98.4 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 5.2Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_009/yolov8m_finetuned_1_trial_009/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00034695916603302916, momentum=0.8632062309433212) with parameter groups 77 weight(decay=0.0), 84 weight(decay=2.8567374298471872e-05), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_009/yolov8m_finetuned_1_trial_009\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      37.5G      1.239     0.6976     0.9949        234        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.7it/s 2:31\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.5s\n","                   all      10000     185578      0.703      0.487      0.533      0.297\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      36.8G      1.255     0.7215      1.004        213        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 42.9s\n","                   all      10000     185578      0.721      0.499      0.542      0.307\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      38.3G      1.249     0.7107      1.002        198        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.3s\n","                   all      10000     185578      0.719      0.501      0.544      0.306\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      37.5G       1.24     0.6977     0.9953        287        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.3s\n","                   all      10000     185578      0.718      0.506      0.551      0.312\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      36.2G      1.226     0.6826     0.9899        281        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.7s\n","                   all      10000     185578      0.597      0.533      0.556      0.315\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      36.6G      1.221     0.6698      0.987        277        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.5s\n","                   all      10000     185578       0.62      0.515      0.556      0.316\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      37.3G      1.212     0.6583     0.9837        247        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.2s\n","                   all      10000     185578      0.627      0.549      0.564      0.319\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      38.7G      1.202     0.6464     0.9803        202        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.3s\n","                   all      10000     185578      0.652      0.527      0.564      0.322\n","\n","8 epochs completed in 0.427 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_009/yolov8m_finetuned_1_trial_009/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_009/yolov8m_finetuned_1_trial_009/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_009/yolov8m_finetuned_1_trial_009/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.5it/s 54.1s\n","                   all      10000     185578      0.652      0.527      0.564      0.322\n","                person       3220      13265      0.794      0.575       0.68      0.351\n","                 rider        515        649      0.591      0.499      0.489       0.25\n","                   car       9879     102540      0.848      0.718      0.811      0.508\n","                 truck       2689       4247       0.64      0.585      0.628      0.453\n","                   bus       1242       1597       0.67      0.585      0.628      0.485\n","                 train         14         15      0.185      0.133     0.0407     0.0207\n","                 motor        334        452      0.622      0.491      0.486      0.247\n","                  bike        578       1007      0.645      0.504       0.53      0.275\n","         traffic light       5653      26891      0.769      0.554      0.652      0.256\n","          traffic sign       8221      34915      0.753      0.622      0.699      0.375\n","Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_009/yolov8m_finetuned_1_trial_009\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1371.4¬±417.9 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 6.9Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 9.5it/s 1:05\n","                   all      10000     185578      0.651      0.528      0.565      0.323\n","Speed: 0.5ms preprocess, 2.0ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_009/val\u001b[0m\n","\n","‚úÖ Trial 9 Completed\n","  mAP@0.5: 0.5650\n","  mAP@0.5:0.95: 0.3229\n","  Precision: 0.6512\n","  Recall: 0.5280\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_009</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/5fwiy2y9' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/5fwiy2y9</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_009/wandb/run-20251128_023704-5fwiy2y9/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 03:05:03,215] Trial 9 finished with value: 0.5649708908023445 and parameters: {'imgsz': 768, 'optimizer': 'AdamW', 'lr0': 0.00034695916603302916, 'momentum': 0.8632062309433212, 'weight_decay': 2.8567374298471872e-05, 'warmup_epochs': 1, 'warmup_momentum': 0.8681066446651219, 'warmup_bias_lr': 0.08607305832563435, 'mosaic': 0.5034760652655954, 'mixup': 0.10214946051551316}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 10/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_010/wandb/run-20251128_030503-gps56jyh</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/gps56jyh' target=\"_blank\">yolov8m_finetuned_1_trial_010</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/gps56jyh' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/gps56jyh</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 10/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.000101\n","  Momentum: 0.9057\n","  Weight Decay: 0.000853\n","  Warmup: epochs=3, momentum=0.73, bias_lr=0.002\n","  Mosaic: 0.82\n","  Mixup: 0.14\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00010136416726594986, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.14346732790723005, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.905713019081271, mosaic=0.8150206227433663, multi_scale=False, name=yolov8m_finetuned_1_trial_010, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_010, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_010/yolov8m_finetuned_1_trial_010, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0017830306795590628, warmup_epochs=3, warmup_momentum=0.7288507043449868, weight_decay=0.0008532637450534103, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1750.5¬±505.9 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 14.5Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 488.7¬±107.5 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 4.9Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_010/yolov8m_finetuned_1_trial_010/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00010136416726594986, momentum=0.905713019081271) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0008532637450534103), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_010/yolov8m_finetuned_1_trial_010\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      37.7G      1.217     0.6658     0.9952        277        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.7it/s 2:30\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.3s\n","                   all      10000     185578      0.652      0.527       0.57      0.329\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      37.4G      1.217     0.6646     0.9949        400        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.4s\n","                   all      10000     185578      0.647      0.532      0.572       0.33\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8        37G      1.209     0.6602     0.9893        286        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.4s\n","                   all      10000     185578      0.608      0.542      0.574      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      37.2G       1.21     0.6612     0.9857        282        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.3s\n","                   all      10000     185578      0.633      0.526      0.575      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      37.6G      1.203     0.6558     0.9825        183        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.2s\n","                   all      10000     185578      0.633      0.525      0.575      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      38.5G        1.2     0.6533     0.9814        344        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.3s\n","                   all      10000     185578      0.628      0.528      0.574      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      38.5G      1.202     0.6535     0.9815        463        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.3s\n","                   all      10000     185578      0.628      0.529      0.575      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      37.5G        1.2     0.6528     0.9816        170        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.4s\n","                   all      10000     185578      0.632      0.527      0.575      0.332\n","\n","8 epochs completed in 0.427 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_010/yolov8m_finetuned_1_trial_010/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_010/yolov8m_finetuned_1_trial_010/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_010/yolov8m_finetuned_1_trial_010/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.5it/s 54.3s\n","                   all      10000     185578      0.629      0.529      0.575      0.332\n","                person       3220      13265      0.779      0.588      0.688      0.358\n","                 rider        515        649      0.619      0.508      0.515      0.274\n","                   car       9879     102540      0.841      0.728      0.816      0.511\n","                 truck       2689       4247      0.645      0.621      0.655       0.48\n","                   bus       1242       1597      0.669      0.603      0.652      0.504\n","                 train         14         15          0          0     0.0148     0.0065\n","                 motor        334        452       0.62      0.505      0.501       0.26\n","                  bike        578       1007      0.614      0.528      0.548      0.289\n","         traffic light       5653      26891      0.753      0.572      0.653      0.258\n","          traffic sign       8221      34915      0.747      0.637      0.709      0.381\n","Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_010/yolov8m_finetuned_1_trial_010\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1382.8¬±456.2 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 8.7Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 9.5it/s 1:06\n","                   all      10000     185578      0.629       0.53      0.576      0.333\n","Speed: 0.5ms preprocess, 1.9ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_010/val\u001b[0m\n","\n","‚úÖ Trial 10 Completed\n","  mAP@0.5: 0.5760\n","  mAP@0.5:0.95: 0.3331\n","  Precision: 0.6291\n","  Recall: 0.5297\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_010</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/gps56jyh' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/gps56jyh</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_010/wandb/run-20251128_030503-gps56jyh/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 03:33:02,900] Trial 10 finished with value: 0.5759796832336584 and parameters: {'imgsz': 768, 'optimizer': 'SGD', 'lr0': 0.00010136416726594986, 'momentum': 0.905713019081271, 'weight_decay': 0.0008532637450534103, 'warmup_epochs': 3, 'warmup_momentum': 0.7288507043449868, 'warmup_bias_lr': 0.0017830306795590628, 'mosaic': 0.8150206227433663, 'mixup': 0.14346732790723005}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 11/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_011/wandb/run-20251128_033303-068vvnms</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/068vvnms' target=\"_blank\">yolov8m_finetuned_1_trial_011</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/068vvnms' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/068vvnms</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 11/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.000192\n","  Momentum: 0.9256\n","  Weight Decay: 0.000922\n","  Warmup: epochs=2, momentum=0.75, bias_lr=0.002\n","  Mosaic: 0.96\n","  Mixup: 0.19\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00019189188714851022, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.18924351393363523, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.9256140152521548, mosaic=0.9649811229108491, multi_scale=False, name=yolov8m_finetuned_1_trial_011, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_011, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_011/yolov8m_finetuned_1_trial_011, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.002410883116536491, warmup_epochs=2, warmup_momentum=0.7511661798798476, weight_decay=0.0009223691646885691, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1265.7¬±467.2 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 12.5Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 381.9¬±133.9 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 5.0Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_011/yolov8m_finetuned_1_trial_011/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00019189188714851022, momentum=0.9256140152521548) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0009223691646885691), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_011/yolov8m_finetuned_1_trial_011\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      37.4G      1.233     0.6868      1.005        347        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.7it/s 2:31\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.2s\n","                   all      10000     185578      0.608      0.541      0.572      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      38.4G      1.218     0.6762     0.9946        305        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.4s\n","                   all      10000     185578      0.631      0.525      0.574      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      36.6G      1.212     0.6712     0.9871        390        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.4s\n","                   all      10000     185578       0.63      0.528      0.576      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      38.1G      1.209     0.6667     0.9857        254        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.3s\n","                   all      10000     185578      0.634      0.524      0.574      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      37.1G      1.207     0.6649     0.9849        264        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.3s\n","                   all      10000     185578      0.635      0.525      0.574      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      36.2G      1.208     0.6661     0.9849        288        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.5s\n","                   all      10000     185578      0.631      0.527      0.574      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      35.6G      1.208     0.6672     0.9853        389        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.1s\n","                   all      10000     185578      0.635      0.527      0.575      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      36.8G      1.207     0.6645     0.9839        422        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.3s\n","                   all      10000     185578      0.635      0.525      0.574      0.332\n","\n","8 epochs completed in 0.428 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_011/yolov8m_finetuned_1_trial_011/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_011/yolov8m_finetuned_1_trial_011/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_011/yolov8m_finetuned_1_trial_011/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.5it/s 54.3s\n","                   all      10000     185578      0.631      0.528      0.576      0.332\n","                person       3220      13265       0.77      0.598      0.689      0.359\n","                 rider        515        649      0.628      0.507      0.523      0.279\n","                   car       9879     102540      0.838      0.731      0.815      0.511\n","                 truck       2689       4247      0.657      0.615      0.655      0.479\n","                   bus       1242       1597      0.669      0.602      0.653      0.505\n","                 train         14         15          0          0      0.011    0.00488\n","                 motor        334        452      0.627      0.502      0.505      0.259\n","                  bike        578       1007      0.615      0.527      0.548      0.289\n","         traffic light       5653      26891      0.753      0.569      0.652      0.258\n","          traffic sign       8221      34915      0.749      0.634       0.71      0.381\n","Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_011/yolov8m_finetuned_1_trial_011\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1312.8¬±476.7 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 8.3Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 9.5it/s 1:06\n","                   all      10000     185578       0.63       0.53      0.577      0.333\n","Speed: 0.5ms preprocess, 2.0ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_011/val\u001b[0m\n","\n","‚úÖ Trial 11 Completed\n","  mAP@0.5: 0.5765\n","  mAP@0.5:0.95: 0.3332\n","  Precision: 0.6299\n","  Recall: 0.5295\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_011</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/068vvnms' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/068vvnms</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_011/wandb/run-20251128_033303-068vvnms/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 04:01:08,865] Trial 11 finished with value: 0.5765230783717186 and parameters: {'imgsz': 768, 'optimizer': 'SGD', 'lr0': 0.00019189188714851022, 'momentum': 0.9256140152521548, 'weight_decay': 0.0009223691646885691, 'warmup_epochs': 2, 'warmup_momentum': 0.7511661798798476, 'warmup_bias_lr': 0.002410883116536491, 'mosaic': 0.9649811229108491, 'mixup': 0.18924351393363523}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 12/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_012/wandb/run-20251128_040109-qe4fhr8t</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/qe4fhr8t' target=\"_blank\">yolov8m_finetuned_1_trial_012</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/qe4fhr8t' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/qe4fhr8t</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 12/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.000671\n","  Momentum: 0.8788\n","  Weight Decay: 0.000186\n","  Warmup: epochs=2, momentum=0.91, bias_lr=0.030\n","  Mosaic: 0.92\n","  Mixup: 0.12\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0006707573965261709, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.12474316618456899, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.8788032145046235, mosaic=0.9241083394569172, multi_scale=False, name=yolov8m_finetuned_1_trial_012, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_012, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_012/yolov8m_finetuned_1_trial_012, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.030481286712759365, warmup_epochs=2, warmup_momentum=0.9076339798561361, weight_decay=0.00018608446967536654, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1734.9¬±479.1 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 14.9Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 588.6¬±350.9 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 5.1Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_012/yolov8m_finetuned_1_trial_012/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0006707573965261709, momentum=0.8788032145046235) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.00018608446967536654), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_012/yolov8m_finetuned_1_trial_012\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      36.4G      1.203     0.6593      0.986        381        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.7it/s 2:30\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.5s\n","                   all      10000     185578      0.633      0.526      0.574      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      37.2G      1.196     0.6504      0.979        291        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.4s\n","                   all      10000     185578      0.636      0.525      0.573      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8        38G       1.19     0.6442     0.9765        221        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.4s\n","                   all      10000     185578      0.623      0.545      0.574       0.33\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8        38G      1.191     0.6465     0.9755        183        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.3s\n","                   all      10000     185578       0.64      0.522      0.573      0.329\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      37.5G      1.187     0.6423     0.9744        315        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.7s\n","                   all      10000     185578      0.633      0.526      0.573       0.33\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      36.7G      1.185     0.6374     0.9729        393        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.5s\n","                   all      10000     185578      0.633      0.526      0.573      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      35.4G      1.184     0.6382     0.9738        463        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.0s\n","                   all      10000     185578      0.631      0.529      0.574      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      35.6G      1.183     0.6362     0.9716        250        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.1s\n","                   all      10000     185578      0.634      0.527      0.574      0.331\n","\n","8 epochs completed in 0.427 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_012/yolov8m_finetuned_1_trial_012/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_012/yolov8m_finetuned_1_trial_012/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_012/yolov8m_finetuned_1_trial_012/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.4it/s 54.6s\n","                   all      10000     185578      0.631      0.527      0.575      0.331\n","                person       3220      13265      0.779      0.588      0.686      0.357\n","                 rider        515        649       0.61      0.503      0.516      0.276\n","                   car       9879     102540      0.842      0.727      0.816      0.511\n","                 truck       2689       4247      0.652       0.62      0.655      0.479\n","                   bus       1242       1597      0.682      0.602      0.652      0.502\n","                 train         14         15          0          0      0.015    0.00786\n","                 motor        334        452      0.622      0.502      0.506      0.256\n","                  bike        578       1007      0.622      0.516      0.539      0.287\n","         traffic light       5653      26891      0.756      0.569      0.653      0.258\n","          traffic sign       8221      34915      0.746       0.64       0.71      0.381\n","Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_012/yolov8m_finetuned_1_trial_012\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1416.2¬±492.5 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 6.7Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 9.4it/s 1:06\n","                   all      10000     185578      0.633      0.526      0.575      0.332\n","Speed: 0.5ms preprocess, 2.0ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_012/val\u001b[0m\n","\n","‚úÖ Trial 12 Completed\n","  mAP@0.5: 0.5750\n","  mAP@0.5:0.95: 0.3320\n","  Precision: 0.6328\n","  Recall: 0.5264\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_012</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/qe4fhr8t' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/qe4fhr8t</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_012/wandb/run-20251128_040109-qe4fhr8t/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 04:29:09,390] Trial 12 finished with value: 0.5750243795647425 and parameters: {'imgsz': 768, 'optimizer': 'SGD', 'lr0': 0.0006707573965261709, 'momentum': 0.8788032145046235, 'weight_decay': 0.00018608446967536654, 'warmup_epochs': 2, 'warmup_momentum': 0.9076339798561361, 'warmup_bias_lr': 0.030481286712759365, 'mosaic': 0.9241083394569172, 'mixup': 0.12474316618456899}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 13/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_013/wandb/run-20251128_042909-49fywzxi</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/49fywzxi' target=\"_blank\">yolov8m_finetuned_1_trial_013</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/49fywzxi' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/49fywzxi</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 13/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 640\n","  Batch Size: 96 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.000160\n","  Momentum: 0.9326\n","  Weight Decay: 0.000820\n","  Warmup: epochs=1, momentum=0.90, bias_lr=0.022\n","  Mosaic: 0.81\n","  Mixup: 0.15\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=96, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00015956212481414519, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.15498974702628246, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.9325638910516862, mosaic=0.8097286598664397, multi_scale=False, name=yolov8m_finetuned_1_trial_013, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_013, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_013/yolov8m_finetuned_1_trial_013, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.021881343928649495, warmup_epochs=1, warmup_momentum=0.9010023745850442, weight_decay=0.0008202218579862699, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1522.4¬±570.9 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 12.9Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 504.1¬±90.3 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 5.5Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_013/yolov8m_finetuned_1_trial_013/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00015956212481414519, momentum=0.9325638910516862) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0012303327869794048), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_013/yolov8m_finetuned_1_trial_013\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      37.6G       1.18     0.6477     0.9659       2941        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.6it/s 1:49\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.5s\n","                   all      10000     185578      0.606       0.53      0.554      0.318\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      36.7G       1.18     0.6434     0.9605       2938        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.5s\n","                   all      10000     185578      0.617      0.508      0.555      0.318\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      38.7G      1.172     0.6346     0.9563       2732        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.7s\n","                   all      10000     185578      0.603      0.528      0.554      0.316\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      38.9G      1.175     0.6373     0.9587       2606        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.9s\n","                   all      10000     185578      0.629      0.501      0.553      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      38.6G      1.167     0.6345      0.956       2910        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.7s\n","                   all      10000     185578      0.624      0.504      0.553      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      38.7G      1.168     0.6311     0.9546       2667        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.5s\n","                   all      10000     185578      0.594      0.523      0.554      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      38.6G      1.171     0.6339     0.9563       2899        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.6s\n","                   all      10000     185578       0.63        0.5      0.553      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      38.4G      1.169     0.6321     0.9562       2878        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.5s\n","                   all      10000     185578      0.595      0.521      0.553      0.317\n","\n","8 epochs completed in 0.320 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_013/yolov8m_finetuned_1_trial_013/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_013/yolov8m_finetuned_1_trial_013/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_013/yolov8m_finetuned_1_trial_013/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.1it/s 49.9s\n","                   all      10000     185578      0.618      0.508      0.555      0.318\n","                person       3220      13265      0.762      0.571      0.657      0.337\n","                 rider        515        649      0.599      0.498      0.518      0.264\n","                   car       9879     102540      0.832      0.712      0.792      0.497\n","                 truck       2689       4247      0.637      0.612      0.632      0.461\n","                   bus       1242       1597      0.668      0.599      0.639      0.492\n","                 train         14         15          0          0     0.0259      0.018\n","                 motor        334        452      0.619      0.473      0.487       0.25\n","                  bike        578       1007       0.57      0.502      0.517      0.265\n","         traffic light       5653      26891      0.752      0.519       0.61      0.238\n","          traffic sign       8221      34915      0.741      0.593      0.668      0.357\n","Speed: 0.1ms preprocess, 0.8ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_013/yolov8m_finetuned_1_trial_013\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1420.3¬±482.8 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 6.7Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 10.7it/s 58.5s\n","                   all      10000     185578      0.619      0.508      0.555      0.319\n","Speed: 0.4ms preprocess, 1.4ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_013/val\u001b[0m\n","\n","‚úÖ Trial 13 Completed\n","  mAP@0.5: 0.5550\n","  mAP@0.5:0.95: 0.3186\n","  Precision: 0.6186\n","  Recall: 0.5077\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_013</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/49fywzxi' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/49fywzxi</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_013/wandb/run-20251128_042909-49fywzxi/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 04:50:33,972] Trial 13 finished with value: 0.555043105045364 and parameters: {'imgsz': 640, 'optimizer': 'SGD', 'lr0': 0.00015956212481414519, 'momentum': 0.9325638910516862, 'weight_decay': 0.0008202218579862699, 'warmup_epochs': 1, 'warmup_momentum': 0.9010023745850442, 'warmup_bias_lr': 0.021881343928649495, 'mosaic': 0.8097286598664397, 'mixup': 0.15498974702628246}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 14/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_014/wandb/run-20251128_045034-uf3bgnim</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/uf3bgnim' target=\"_blank\">yolov8m_finetuned_1_trial_014</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/uf3bgnim' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/uf3bgnim</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 14/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: Adam\n","  Learning Rate: 0.000365\n","  Momentum: 0.9521\n","  Weight Decay: 0.000573\n","  Warmup: epochs=2, momentum=0.63, bias_lr=0.037\n","  Mosaic: 0.84\n","  Mixup: 0.20\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0003648765624453425, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.19859216786494333, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.9521414385679057, mosaic=0.8441440983974132, multi_scale=False, name=yolov8m_finetuned_1_trial_014, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_014, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_014/yolov8m_finetuned_1_trial_014, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.03694056393169325, warmup_epochs=2, warmup_momentum=0.6289642269316154, weight_decay=0.0005733433450715179, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1739.5¬±494.9 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 12.3Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 369.2¬±110.2 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 6.2Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_014/yolov8m_finetuned_1_trial_014/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.0003648765624453425, momentum=0.9521414385679057) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005733433450715179), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_014/yolov8m_finetuned_1_trial_014\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      38.3G      1.233     0.6995     0.9947        284        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.7it/s 2:32\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 42.9s\n","                   all      10000     185578       0.63      0.506      0.554      0.314\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      38.2G      1.249     0.7232      1.003        298        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:27\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.2s\n","                   all      10000     185578        0.6        0.5      0.539      0.304\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      35.7G      1.257     0.7369      1.009        313        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:27\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.4s\n","                   all      10000     185578      0.621      0.499      0.546      0.307\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      38.8G      1.256     0.7278      1.007        551        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:27\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.0s\n","                   all      10000     185578      0.725      0.501       0.55      0.313\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      38.2G       1.24     0.7083     0.9982        391        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:27\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.2s\n","                   all      10000     185578      0.611      0.507       0.55      0.312\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      38.1G      1.228     0.6957     0.9952        422        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:27\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.3s\n","                   all      10000     185578      0.721      0.516      0.564      0.321\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      36.8G      1.219     0.6822      0.992        302        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.7it/s 2:27\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.1s\n","                   all      10000     185578      0.643      0.521      0.572      0.326\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      35.5G       1.21     0.6679     0.9858        282        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.7it/s 2:27\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.1s\n","                   all      10000     185578      0.639      0.518      0.571      0.326\n","\n","8 epochs completed in 0.430 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_014/yolov8m_finetuned_1_trial_014/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_014/yolov8m_finetuned_1_trial_014/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_014/yolov8m_finetuned_1_trial_014/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.5it/s 54.0s\n","                   all      10000     185578      0.638      0.518      0.571      0.326\n","                person       3220      13265      0.804      0.566       0.68      0.352\n","                 rider        515        649      0.579      0.496      0.498      0.268\n","                   car       9879     102540      0.846       0.72      0.812       0.51\n","                 truck       2689       4247      0.652      0.588      0.628      0.454\n","                   bus       1242       1597      0.667      0.582      0.628      0.482\n","                 train         14         15     0.0711     0.0667     0.0815     0.0384\n","                 motor        334        452      0.634      0.465      0.495      0.247\n","                  bike        578       1007      0.591      0.541       0.54       0.28\n","         traffic light       5653      26891      0.777      0.539      0.651      0.256\n","          traffic sign       8221      34915      0.763      0.614        0.7      0.375\n","Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_014/yolov8m_finetuned_1_trial_014\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1384.4¬±503.4 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 9.7Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 9.6it/s 1:05\n","                   all      10000     185578      0.638      0.519      0.572      0.327\n","Speed: 0.5ms preprocess, 2.0ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_014/val\u001b[0m\n","\n","‚úÖ Trial 14 Completed\n","  mAP@0.5: 0.5721\n","  mAP@0.5:0.95: 0.3271\n","  Precision: 0.6377\n","  Recall: 0.5193\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_014</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/uf3bgnim' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/uf3bgnim</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_014/wandb/run-20251128_045034-uf3bgnim/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 05:18:46,196] Trial 14 finished with value: 0.5720682538193854 and parameters: {'imgsz': 768, 'optimizer': 'Adam', 'lr0': 0.0003648765624453425, 'momentum': 0.9521414385679057, 'weight_decay': 0.0005733433450715179, 'warmup_epochs': 2, 'warmup_momentum': 0.6289642269316154, 'warmup_bias_lr': 0.03694056393169325, 'mosaic': 0.8441440983974132, 'mixup': 0.19859216786494333}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 15/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_015/wandb/run-20251128_051846-ea8mynod</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/ea8mynod' target=\"_blank\">yolov8m_finetuned_1_trial_015</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/ea8mynod' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/ea8mynod</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 15/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: Adam\n","  Learning Rate: 0.000150\n","  Momentum: 0.8597\n","  Weight Decay: 0.000437\n","  Warmup: epochs=1, momentum=0.72, bias_lr=0.021\n","  Mosaic: 0.92\n","  Mixup: 0.10\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001500738887151613, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.1037890785120699, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.8596635892864232, mosaic=0.9188109532508847, multi_scale=False, name=yolov8m_finetuned_1_trial_015, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_015, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_015/yolov8m_finetuned_1_trial_015, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.021051136598623794, warmup_epochs=1, warmup_momentum=0.7248156517196116, weight_decay=0.0004373273933564993, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1908.3¬±696.4 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 14.1Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 531.0¬±137.4 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 7.1Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_015/yolov8m_finetuned_1_trial_015/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.0001500738887151613, momentum=0.8596635892864232) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0004373273933564993), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_015/yolov8m_finetuned_1_trial_015\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      35.5G      1.195     0.6554     0.9798        308        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.7it/s 2:31\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.4s\n","                   all      10000     185578      0.621      0.522      0.562       0.32\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      38.2G      1.205     0.6659     0.9827        384        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.2s\n","                   all      10000     185578       0.63      0.515      0.561      0.318\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      35.1G      1.197     0.6597       0.98        334        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.1s\n","                   all      10000     185578      0.606       0.54      0.562      0.319\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      35.5G      1.193      0.652     0.9769        344        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 42.9s\n","                   all      10000     185578      0.634      0.511      0.561      0.319\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      38.6G      1.186     0.6419     0.9726        173        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.2s\n","                   all      10000     185578      0.611      0.542      0.562       0.32\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      37.7G      1.179     0.6346       0.97        325        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.2s\n","                   all      10000     185578      0.647      0.523      0.566      0.324\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      37.3G      1.174     0.6298      0.969        306        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.3s\n","                   all      10000     185578      0.612      0.535      0.567      0.325\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      36.1G      1.166     0.6215     0.9663        294        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 42.8s\n","                   all      10000     185578      0.645      0.522      0.567      0.324\n","\n","8 epochs completed in 0.428 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_015/yolov8m_finetuned_1_trial_015/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_015/yolov8m_finetuned_1_trial_015/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_015/yolov8m_finetuned_1_trial_015/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.5it/s 54.3s\n","                   all      10000     185578      0.613      0.535      0.567      0.325\n","                person       3220      13265      0.773      0.589       0.68      0.351\n","                 rider        515        649      0.582      0.512      0.508      0.269\n","                   car       9879     102540       0.83      0.734      0.813       0.51\n","                 truck       2689       4247      0.629      0.595      0.621      0.451\n","                   bus       1242       1597      0.652      0.587      0.626      0.482\n","                 train         14         15     0.0851     0.0667     0.0389     0.0215\n","                 motor        334        452      0.538      0.513      0.489      0.251\n","                  bike        578       1007      0.543       0.55      0.539      0.279\n","         traffic light       5653      26891      0.752      0.573      0.651      0.257\n","          traffic sign       8221      34915      0.742      0.635      0.702      0.376\n","Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_015/yolov8m_finetuned_1_trial_015\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1425.9¬±490.5 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 8.3Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 9.5it/s 1:06\n","                   all      10000     185578      0.612      0.536      0.567      0.325\n","Speed: 0.5ms preprocess, 2.0ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_015/val\u001b[0m\n","\n","‚úÖ Trial 15 Completed\n","  mAP@0.5: 0.5668\n","  mAP@0.5:0.95: 0.3254\n","  Precision: 0.6122\n","  Recall: 0.5358\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_015</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/ea8mynod' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/ea8mynod</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_015/wandb/run-20251128_051846-ea8mynod/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 05:46:50,720] Trial 15 finished with value: 0.566847971190009 and parameters: {'imgsz': 768, 'optimizer': 'Adam', 'lr0': 0.0001500738887151613, 'momentum': 0.8596635892864232, 'weight_decay': 0.0004373273933564993, 'warmup_epochs': 1, 'warmup_momentum': 0.7248156517196116, 'warmup_bias_lr': 0.021051136598623794, 'mosaic': 0.9188109532508847, 'mixup': 0.1037890785120699}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 16/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_016/wandb/run-20251128_054651-ymx92laz</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/ymx92laz' target=\"_blank\">yolov8m_finetuned_1_trial_016</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/ymx92laz' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/ymx92laz</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 16/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 640\n","  Batch Size: 96 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.000118\n","  Momentum: 0.8842\n","  Weight Decay: 0.000878\n","  Warmup: epochs=2, momentum=0.72, bias_lr=0.041\n","  Mosaic: 0.96\n","  Mixup: 0.20\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=96, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00011832499546588166, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.1960881301767174, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.884174215072047, mosaic=0.9586224212426746, multi_scale=False, name=yolov8m_finetuned_1_trial_016, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_016, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_016/yolov8m_finetuned_1_trial_016, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.04145292944378984, warmup_epochs=2, warmup_momentum=0.7167381159130815, weight_decay=0.0008783853975174846, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1675.5¬±505.2 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 13.2Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 512.1¬±103.0 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 7.4Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_016/yolov8m_finetuned_1_trial_016/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00011832499546588166, momentum=0.884174215072047) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0013175780962762268), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_016/yolov8m_finetuned_1_trial_016\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      38.8G      1.196     0.6717     0.9752       3394        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.6it/s 1:49\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.9s\n","                   all      10000     185578      0.606      0.534      0.553      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      37.3G      1.192     0.6628     0.9697       2994        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.7s\n","                   all      10000     185578       0.59      0.527      0.553      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8        38G      1.186     0.6566     0.9665       3394        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.5s\n","                   all      10000     185578      0.616      0.509      0.554      0.318\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      36.5G      1.188     0.6592     0.9654       4609        640: 43% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 74/171 1.7it/s 45.5s<58.3sWARNING ‚ö†Ô∏è CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n","\u001b[K        4/8      36.5G      1.187     0.6574     0.9654       4297        640: 62% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 106/171 1.7it/s 1:10<39.1sWARNING ‚ö†Ô∏è CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n","\u001b[K        4/8      36.5G      1.185     0.6555     0.9647       4394        640: 89% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 152/171 1.7it/s 1:42<11.4sWARNING ‚ö†Ô∏è CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n","\u001b[K        4/8      36.5G      1.185     0.6557     0.9646       3310        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.4it/s 1:58\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.5s\n","                   all      10000     185578      0.622      0.506      0.553      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      37.5G      1.185     0.6551     0.9633       3558        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.6s\n","                   all      10000     185578      0.625      0.504      0.553      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      37.4G      1.187     0.6551     0.9661       3164        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.6s\n","                   all      10000     185578      0.626      0.503      0.553      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      38.9G      1.185     0.6542     0.9637       3027        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.7s\n","                   all      10000     185578      0.625      0.504      0.553      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      36.9G      1.184     0.6547     0.9643       3097        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.5s\n","                   all      10000     185578      0.627      0.503      0.553      0.317\n","\n","8 epochs completed in 0.327 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_016/yolov8m_finetuned_1_trial_016/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_016/yolov8m_finetuned_1_trial_016/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_016/yolov8m_finetuned_1_trial_016/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.1it/s 50.1s\n","                   all      10000     185578      0.618      0.508      0.554      0.317\n","                person       3220      13265      0.763      0.571      0.657      0.337\n","                 rider        515        649      0.611      0.496      0.515      0.264\n","                   car       9879     102540      0.831      0.713      0.792      0.497\n","                 truck       2689       4247      0.641      0.609      0.635      0.463\n","                   bus       1242       1597      0.666      0.591       0.64      0.494\n","                 train         14         15          0          0      0.019     0.0115\n","                 motor        334        452      0.612       0.48       0.49       0.25\n","                  bike        578       1007      0.571      0.504      0.515      0.264\n","         traffic light       5653      26891      0.748      0.518      0.609      0.237\n","          traffic sign       8221      34915      0.736      0.596      0.668      0.357\n","Speed: 0.1ms preprocess, 0.8ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_016/yolov8m_finetuned_1_trial_016\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1267.9¬±326.8 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 9.0Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 10.7it/s 58.4s\n","                   all      10000     185578      0.617       0.51      0.555      0.319\n","Speed: 0.4ms preprocess, 1.5ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_016/val\u001b[0m\n","\n","‚úÖ Trial 16 Completed\n","  mAP@0.5: 0.5546\n","  mAP@0.5:0.95: 0.3186\n","  Precision: 0.6168\n","  Recall: 0.5098\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_016</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/ymx92laz' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/ymx92laz</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_016/wandb/run-20251128_054651-ymx92laz/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 06:08:38,507] Trial 16 finished with value: 0.5545956639939752 and parameters: {'imgsz': 640, 'optimizer': 'SGD', 'lr0': 0.00011832499546588166, 'momentum': 0.884174215072047, 'weight_decay': 0.0008783853975174846, 'warmup_epochs': 2, 'warmup_momentum': 0.7167381159130815, 'warmup_bias_lr': 0.04145292944378984, 'mosaic': 0.9586224212426746, 'mixup': 0.1960881301767174}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 17/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_017/wandb/run-20251128_060838-ysc1119a</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/ysc1119a' target=\"_blank\">yolov8m_finetuned_1_trial_017</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/ysc1119a' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/ysc1119a</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 17/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: AdamW\n","  Learning Rate: 0.000538\n","  Momentum: 0.9220\n","  Weight Decay: 0.000625\n","  Warmup: epochs=2, momentum=0.83, bias_lr=0.021\n","  Mosaic: 0.96\n","  Mixup: 0.18\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005375733382750209, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.18419081572099077, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.9220284993100825, mosaic=0.9568487765910555, multi_scale=False, name=yolov8m_finetuned_1_trial_017, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_017, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_017/yolov8m_finetuned_1_trial_017, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.020549542524289362, warmup_epochs=2, warmup_momentum=0.8253358856250237, weight_decay=0.0006245610321427977, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1797.9¬±514.9 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 13.2Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 419.2¬±96.2 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 7.1Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_017/yolov8m_finetuned_1_trial_017/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005375733382750209, momentum=0.9220284993100825) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0006245610321427977), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_017/yolov8m_finetuned_1_trial_017\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      38.8G       1.23     0.7003     0.9948        260        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.7it/s 2:32\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.4s\n","                   all      10000     185578      0.623      0.492      0.538      0.302\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      36.5G      1.261     0.7416      1.009        289        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:27\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.4s\n","                   all      10000     185578      0.588      0.491      0.526      0.293\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      37.9G      1.269     0.7559      1.015        378        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:27\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 42.8s\n","                   all      10000     185578      0.715      0.487      0.532      0.299\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      35.7G      1.258     0.7378      1.009        361        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.2s\n","                   all      10000     185578      0.715      0.497      0.541      0.303\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      38.2G      1.245     0.7214      1.002        284        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:27\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.6s\n","                   all      10000     185578      0.621      0.498      0.548       0.31\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      35.5G      1.235     0.7068     0.9962        334        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:27\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.2s\n","                   all      10000     185578      0.628      0.508      0.555      0.314\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      35.5G      1.224     0.6923     0.9926        232        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:27\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.1s\n","                   all      10000     185578      0.618      0.513      0.558      0.318\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      34.9G      1.212     0.6726     0.9862        388        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:27\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.1s\n","                   all      10000     185578      0.619      0.518      0.561      0.321\n","\n","8 epochs completed in 0.431 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_017/yolov8m_finetuned_1_trial_017/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_017/yolov8m_finetuned_1_trial_017/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_017/yolov8m_finetuned_1_trial_017/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.5it/s 54.1s\n","                   all      10000     185578      0.619      0.518      0.561      0.321\n","                person       3220      13265      0.785      0.573       0.68      0.351\n","                 rider        515        649       0.58       0.51      0.501      0.264\n","                   car       9879     102540      0.835      0.726      0.811      0.507\n","                 truck       2689       4247      0.628      0.601      0.627      0.453\n","                   bus       1242       1597      0.657      0.582      0.624       0.48\n","                 train         14         15          0          0    0.00957    0.00395\n","                 motor        334        452      0.643       0.48      0.485      0.249\n","                  bike        578       1007      0.561      0.531       0.53      0.274\n","         traffic light       5653      26891      0.765      0.544      0.647      0.255\n","          traffic sign       8221      34915      0.738      0.633      0.698      0.374\n","Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_017/yolov8m_finetuned_1_trial_017\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1447.0¬±507.9 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 8.8Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 9.5it/s 1:06\n","                   all      10000     185578      0.621      0.518      0.562      0.322\n","Speed: 0.5ms preprocess, 2.0ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_017/val\u001b[0m\n","\n","‚úÖ Trial 17 Completed\n","  mAP@0.5: 0.5622\n","  mAP@0.5:0.95: 0.3219\n","  Precision: 0.6208\n","  Recall: 0.5184\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_017</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/ysc1119a' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/ysc1119a</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_017/wandb/run-20251128_060838-ysc1119a/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 06:36:52,928] Trial 17 finished with value: 0.5622170624082131 and parameters: {'imgsz': 768, 'optimizer': 'AdamW', 'lr0': 0.0005375733382750209, 'momentum': 0.9220284993100825, 'weight_decay': 0.0006245610321427977, 'warmup_epochs': 2, 'warmup_momentum': 0.8253358856250237, 'warmup_bias_lr': 0.020549542524289362, 'mosaic': 0.9568487765910555, 'mixup': 0.18419081572099077}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 18/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_018/wandb/run-20251128_063653-n14jwjp2</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/n14jwjp2' target=\"_blank\">yolov8m_finetuned_1_trial_018</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/n14jwjp2' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/n14jwjp2</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 18/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.000238\n","  Momentum: 0.9691\n","  Weight Decay: 0.000435\n","  Warmup: epochs=1, momentum=0.73, bias_lr=0.010\n","  Mosaic: 0.94\n","  Mixup: 0.11\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00023763387102495472, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.11390959443328483, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.9690735222899702, mosaic=0.9425716260056852, multi_scale=False, name=yolov8m_finetuned_1_trial_018, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_018, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_018/yolov8m_finetuned_1_trial_018, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.009569797908782101, warmup_epochs=1, warmup_momentum=0.7256297179080418, weight_decay=0.0004345143055119562, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1564.9¬±388.6 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 13.2Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 381.2¬±111.8 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 4.5Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_018/yolov8m_finetuned_1_trial_018/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00023763387102495472, momentum=0.9690735222899702) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0004345143055119562), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_018/yolov8m_finetuned_1_trial_018\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      36.8G      1.202     0.6528     0.9871        287        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.7it/s 2:31\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.3s\n","                   all      10000     185578      0.625      0.531      0.575      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      37.1G      1.197     0.6525     0.9801        423        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.4s\n","                   all      10000     185578      0.635      0.523      0.574       0.33\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      37.1G      1.178     0.6359     0.9711        191        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.3s\n","                   all      10000     185578      0.647      0.529      0.574      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8        38G      1.185     0.6402      0.973       3041        768: 96% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏ 248/257 1.8it/s 2:21<5.1s"]}],"source":["# RUN HYPERPARAMETER OPTIMIZATION WITH OPTUNA\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('STARTING HYPERPARAMETER OPTIMIZATION')\n","print('=' * 80)\n","print(f'Model: {MODEL_NAME}')\n","print(f'Dataset: {YOLO_DATASET_ROOT.name}')\n","print(f'Number of Trials: {N_TRIALS}')\n","print(f'Epochs per Trial: {EPOCHS_PER_TRIAL}')\n","print(f'Timeout: {TIMEOUT_HOURS} hours' if TIMEOUT_HOURS else 'No timeout')\n","print(f'Device: {device}')\n","print('=' * 80)\n","\n","# Check if resuming from previous run\n","study_pkl_path = TUNE_DIR / 'optuna_study.pkl'\n","checkpoint_log_path = TUNE_DIR / 'checkpoint_log.json'\n","is_resuming = study_pkl_path.exists()\n","\n","if is_resuming:\n","    # Load existing study\n","    print('\\n' + '=' * 80)\n","    print('üîÑ RESUMING PREVIOUS OPTIMIZATION')\n","    print('=' * 80)\n","\n","    with open(study_pkl_path, 'rb') as f:\n","        study = pickle.load(f)\n","\n","    # Load checkpoint log\n","    checkpoint_data = []\n","    if checkpoint_log_path.exists():\n","        with open(checkpoint_log_path, 'r', encoding='utf-8') as f:\n","            checkpoint_data = json.load(f)\n","\n","    # Display resume information\n","    completed_trials = len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])\n","    pruned_trials = len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])\n","    failed_trials = len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL])\n","    total_previous_trials = len(study.trials)\n","\n","    print(f'\\nüìä Previous Run Summary:')\n","    print(f'  Completed Trials: {completed_trials}')\n","    print(f'  Pruned Trials: {pruned_trials}')\n","    print(f'  Failed Trials: {failed_trials}')\n","    print(f'  Total Previous Trials: {total_previous_trials}')\n","\n","    if completed_trials > 0:\n","        best_trial = study.best_trial\n","        print(f'\\nüèÜ Best Result So Far:')\n","        print(f'  Trial: {best_trial.number}')\n","        print(f'  mAP@0.5: {best_trial.value:.4f}')\n","\n","        # Show top 3 completed trials\n","        completed_trial_list = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n","        sorted_trials = sorted(completed_trial_list, key=lambda t: t.value, reverse=True)\n","        top_3_trials = sorted_trials[:3]\n","\n","        print(f'\\nüìà Top 3 Trials:')\n","        for idx, trial in enumerate(top_3_trials, 1):\n","            print(f'  {idx}. Trial {trial.number}: mAP@0.5 = {trial.value:.4f}')\n","\n","    # Show last checkpoint info\n","    if checkpoint_data:\n","        last_checkpoint = checkpoint_data[-1]\n","        print(f'\\nüïê Last Checkpoint:')\n","        print(f'  Timestamp: {last_checkpoint[\"timestamp\"]}')\n","        print(f'  Last Trial: {last_checkpoint[\"trial_number\"]}')\n","        print(f'  Current Best mAP: {last_checkpoint[\"best_map\"]:.4f}')\n","\n","    remaining_trials = N_TRIALS - total_previous_trials\n","    print(f'\\n‚û°Ô∏è  Continuing optimization: {remaining_trials} trials remaining (of {N_TRIALS} total)')\n","    print('=' * 80)\n","\n","else:\n","    # Create new Optuna study\n","    print('\\nüÜï Creating new optimization study')\n","\n","    study = optuna.create_study(\n","        study_name=f'{MODEL_NAME}_optuna_{RUN_TIMESTAMP}',\n","        direction='maximize',  # Maximize mAP@0.5\n","        sampler=optuna.samplers.TPESampler(\n","            seed=42,\n","            n_startup_trials=N_STARTUP_TRIALS,  # Random trials before optimization\n","            multivariate=True,  # Consider parameter interactions\n","            group=True  # Group related parameters\n","        ),\n","        pruner=optuna.pruners.MedianPruner(\n","            n_startup_trials=N_STARTUP_TRIALS,\n","            n_warmup_steps=15,  # Wait before pruning\n","            interval_steps=5  # Check every 5 steps\n","        )\n","    )\n","\n","    # Initialize checkpoint log\n","    checkpoint_data = []\n","\n","# Run optimization\n","start_time = datetime.now()\n","print(f'\\nüöÄ Optimization started at {start_time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n","\n","# Define checkpoint callback\n","def checkpoint_callback(study, trial):\n","    \"\"\"Save checkpoint after each trial completion\"\"\"\n","    print(f'\\n‚úì Completed {len(study.trials)}/{N_TRIALS} trials')\n","\n","    # Update checkpoint log\n","    checkpoint_entry = {\n","        'trial_number': trial.number,\n","        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n","        'trial_state': trial.state.name,\n","        'best_map': study.best_value if len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]) > 0 else 0.0,\n","        'completed_trials': len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]),\n","        'total_trials': len(study.trials)\n","    }\n","    checkpoint_data.append(checkpoint_entry)\n","\n","    # Save checkpoint log\n","    with open(checkpoint_log_path, 'w', encoding='utf-8') as f:\n","        json.dump(checkpoint_data, f, indent=2)\n","\n","    # Save study object\n","    with open(study_pkl_path, 'wb') as f:\n","        pickle.dump(study, f)\n","\n","    # Force garbage collection\n","    gc.collect()\n","\n","try:\n","    study.optimize(\n","        objective,\n","        n_trials=N_TRIALS,\n","        timeout=TIMEOUT_HOURS * 3600 if TIMEOUT_HOURS else None,\n","        show_progress_bar=True,\n","        callbacks=[checkpoint_callback]\n","    )\n","except KeyboardInterrupt:\n","    print('\\n‚ö†Ô∏è  Optimization interrupted by user')\n","    print(f'üíæ Progress saved to: {TUNE_DIR}')\n","    print(f'   - Study checkpoint: {study_pkl_path.name}')\n","    print(f'   - Checkpoint log: {checkpoint_log_path.name}')\n","    print(f'\\nüîÑ To resume: Simply re-run this notebook')\n","except Exception as e:\n","    print(f'\\n‚ùå Optimization failed: {e}')\n","    import traceback\n","    traceback.print_exc()\n","\n","end_time = datetime.now()\n","duration = end_time - start_time\n","\n","print('\\n' + '=' * 80)\n","print('OPTIMIZATION COMPLETED')\n","print('=' * 80)\n","print(f'Started: {start_time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n","print(f'Ended: {end_time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n","print(f'Duration: {duration}')\n","print(f'Total Trials: {len(study.trials)}')\n","print(f'Completed Trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}')\n","print(f'Pruned Trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}')\n","print(f'Failed Trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL])}')\n","print(f'\\nBest Trial: {study.best_trial.number}')\n","print(f'Best mAP@0.5: {study.best_value:.4f}')\n","print('=' * 80)"]},{"cell_type":"markdown","id":"c5ab4d62","metadata":{"id":"c5ab4d62"},"source":["## 9. Save All Trials Summary"]},{"cell_type":"code","execution_count":null,"id":"0a3c5d31","metadata":{"id":"0a3c5d31"},"outputs":[],"source":["# SAVE CONSOLIDATED SUMMARY OF ALL TRIALS\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('SAVING CONSOLIDATED TRIAL SUMMARY')\n","print('=' * 80)\n","\n","# Collect all trial results dynamically from study\n","all_trials_data = []\n","\n","for trial in study.trials:\n","    trial_dir = TUNE_DIR / f\"trial_{trial.number:03d}\"\n","    results_file = trial_dir / \"trial_results.json\"\n","\n","    if results_file.exists():\n","        try:\n","            with open(results_file, 'r') as f:\n","                trial_data = json.load(f)\n","                all_trials_data.append(trial_data)\n","        except Exception as e:\n","            print(f\"‚ö†Ô∏è  Could not read trial {trial.number} results: {e}\")\n","    else:\n","        print(f\"‚ö†Ô∏è  No results file found for trial {trial.number}\")\n","\n","# Create comprehensive summary\n","optimization_summary = {\n","    \"model_name\": MODEL_NAME,\n","    \"dataset\": YOLO_DATASET_ROOT.name,\n","    \"optimization_config\": {\n","        \"n_trials\": N_TRIALS,\n","        \"epochs_per_trial\": EPOCHS_PER_TRIAL,\n","        \"batch_size\": BATCH_SIZE,\n","        \"timeout_hours\": TIMEOUT_HOURS,\n","        \"n_startup_trials\": N_STARTUP_TRIALS,\n","    },\n","    \"optimization_results\": {\n","        \"start_time\": start_time.isoformat(),\n","        \"end_time\": end_time.isoformat(),\n","        \"duration_seconds\": duration.total_seconds(),\n","        \"total_trials\": len(study.trials),\n","        \"completed_trials\": len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]),\n","        \"pruned_trials\": len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]),\n","        \"failed_trials\": len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL]),\n","        \"best_trial_number\": study.best_trial.number,\n","        \"best_map50\": study.best_value,\n","    },\n","    \"best_hyperparameters\": study.best_params,\n","    \"all_trials\": all_trials_data,\n","    \"timestamp\": datetime.now().isoformat(),\n","}\n","\n","# Save consolidated summary as JSON\n","summary_path = TUNE_DIR / f\"{MODEL_NAME}_all_trials_summary.json\"\n","with open(summary_path, 'w') as f:\n","    json.dump(optimization_summary, f, indent=2)\n","\n","print(f'‚úì Consolidated JSON summary saved: {summary_path}')\n","print(f'  Total trials saved: {len(all_trials_data)}')\n","\n","# Create CSV summary for easy analysis\n","csv_data = []\n","for trial_data in all_trials_data:\n","    row = {\n","        'trial_number': trial_data.get('trial_number'),\n","        'status': trial_data.get('status'),\n","        'map50': trial_data.get('validation_metrics', {}).get('map50'),\n","        'map50_95': trial_data.get('validation_metrics', {}).get('map50_95'),\n","        'precision': trial_data.get('validation_metrics', {}).get('precision'),\n","        'recall': trial_data.get('validation_metrics', {}).get('recall'),\n","        'error_type': trial_data.get('error_type', '')  # Include error type if failed\n","    }\n","    # Add hyperparameters\n","    for key, value in trial_data.get('hyperparameters', {}).items():\n","        row[f'hp_{key}'] = value\n","    # Flag best trial\n","    row['best_trial'] = trial_data.get('trial_number') == study.best_trial.number\n","    csv_data.append(row)\n","\n","df_trials = pd.DataFrame(csv_data)\n","\n","# Sort CSV by mAP@0.5 descending (best first)\n","df_trials.sort_values(by='map50', ascending=False, inplace=True)\n","\n","# Save CSV\n","csv_path = TUNE_DIR / f\"{MODEL_NAME}_all_trials_summary.csv\"\n","df_trials.to_csv(csv_path, index=False)\n","\n","print(f'‚úì CSV summary saved: {csv_path}')\n","print(f'  Columns: {len(df_trials.columns)}, Rows: {len(df_trials)}')\n","print('=' * 80)\n","\n","# Display summary statistics\n","if len(df_trials) > 0:\n","    print('\\nüìä Trial Summary Statistics:')\n","    print(f'  Completed Trials: {len(df_trials[df_trials[\"status\"] == \"completed\"])}')\n","    print(f'  Failed Trials: {len(df_trials[df_trials[\"status\"] == \"failed\"])}')\n","\n","    completed_trials = df_trials[df_trials['status'] == 'completed']\n","    if len(completed_trials) > 0:\n","        best_trial_row = completed_trials.loc[completed_trials[\"map50\"].idxmax()]\n","        print(f'\\n  mAP@0.5 Statistics:')\n","        print(f'    Best: {best_trial_row[\"map50\"]:.4f} (Trial {best_trial_row[\"trial_number\"]})')\n","        print(f'    Worst: {completed_trials[\"map50\"].min():.4f}')\n","        print(f'    Mean: {completed_trials[\"map50\"].mean():.4f}')\n","        print(f'    Std: {completed_trials[\"map50\"].std():.4f}')\n","        print(f'    Median: {completed_trials[\"map50\"].median():.4f}')\n","print('=' * 80)"]},{"cell_type":"markdown","id":"923833ab","metadata":{"id":"923833ab"},"source":["## 10. Save Best Hyperparameters"]},{"cell_type":"code","execution_count":null,"id":"58d702ef","metadata":{"id":"58d702ef"},"outputs":[],"source":["# SAVE BEST HYPERPARAMETERS\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('SAVING BEST HYPERPARAMETERS')\n","print('=' * 80)\n","\n","# Extract best parameters from study\n","best_params = study.best_params\n","best_trial = study.best_trial\n","\n","print(f'\\nüèÜ Best Trial: {best_trial.number}')\n","print(f'   Best mAP@0.5: {study.best_value:.4f}')\n","print('\\nüìã Best Hyperparameters:')\n","for param_name, param_value in best_params.items():\n","    print(f'   {param_name}: {param_value}')\n","\n","# Save best hyperparameters to JSON\n","best_params_json = TUNE_DIR / 'best_hyperparameters.json'\n","with open(best_params_json, 'w') as f:\n","    json.dump({\n","        'model': MODEL_NAME,\n","        'dataset_root': str(YOLO_DATASET_ROOT),\n","        'data_yaml_path': str(DATA_YAML_PATH),\n","        'optimization_results': {\n","            'best_trial': study.best_trial.number,\n","            'best_map50': study.best_value,\n","            'total_trials': len(study.trials),\n","            'optimization_duration': str(duration),\n","        },\n","        'hyperparameters': best_params,\n","        'timestamp': datetime.now().isoformat(),\n","        'notes': 'Use these hyperparameters for training. Add epochs, batch, imgsz, device, and other training settings.'\n","    }, f, indent=2)\n","\n","print(f'\\n‚úì Best hyperparameters saved to: {best_params_json}')\n","\n","# Save to YAML format (ready for YOLO training)\n","best_params_yaml = TUNE_DIR / 'best_hyperparameters.yaml'\n","with open(best_params_yaml, 'w') as f:\n","    yaml.dump(best_params, f, default_flow_style=False, sort_keys=False)\n","\n","print(f'‚úì Best hyperparameters saved to: {best_params_yaml}')\n","\n","print('\\nüìã Best Hyperparameters Summary:')\n","print(f'  Optimizer: {best_params.get(\"optimizer\", \"N/A\")}')\n","print(f'  Learning Rate: {best_params.get(\"lr0\", 0):.6f}')\n","print(f'  Momentum: {best_params.get(\"momentum\", 0):.4f}')\n","print(f'  Weight Decay: {best_params.get(\"weight_decay\", 0):.6f}')\n","\n","print('=' * 80)"]},{"cell_type":"markdown","id":"24aed975","metadata":{"id":"24aed975"},"source":["## 11. Visualize Optimization Results"]},{"cell_type":"code","execution_count":null,"id":"26d33d0e","metadata":{"id":"26d33d0e"},"outputs":[],"source":["# ============================================================================\n","# VISUALIZE OPTIMIZATION RESULTS: HISTORY, PARAMETER IMPORTANCE, SLICE PLOTS\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('GENERATING OPTIMIZATION VISUALIZATIONS')\n","print('=' * 80)\n","\n","if len(study.trials) == 0:\n","    print(\"‚ö†Ô∏è  No trials found in study, skipping visualization.\")\n","else:\n","    timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')\n","\n","    # -----------------------------\n","    # 1Ô∏è‚É£ Optimization History Plot\n","    # -----------------------------\n","    try:\n","        print('\\nüìà Creating optimization history plot...')\n","        fig_history = plot_optimization_history(study)\n","        fig_history.update_layout(\n","            title=f'{MODEL_NAME} - Hyperparameter Optimization History',\n","            xaxis_title='Trial Number',\n","            yaxis_title='mAP@0.5',\n","            template='plotly_white',\n","            width=1200,\n","            height=600\n","        )\n","        fig_history.show()\n","\n","        # Save HTML with timestamp\n","        optimization_history_path = TUNE_DIR / f'optimization_history_{timestamp_str}.html'\n","        fig_history.write_html(str(optimization_history_path))\n","        print(f'‚úì HTML saved to: {optimization_history_path}')\n","\n","    except Exception as history_error:\n","        print(f'‚ùå Failed to create optimization history plot: {history_error}')\n","\n","    # -----------------------------\n","    # 2Ô∏è‚É£ Parameter Importance Plot\n","    # -----------------------------\n","    try:\n","        print('\\nüìä Creating parameter importance plot...')\n","        fig_importance = plot_param_importances(study)\n","        fig_importance.update_layout(\n","            title=f'{MODEL_NAME} - Hyperparameter Importance',\n","            xaxis_title='Importance',\n","            yaxis_title='Parameter',\n","            template='plotly_white',\n","            width=1200,\n","            height=800\n","        )\n","        fig_importance.show()\n","\n","        # Save HTML with timestamp\n","        param_importance_path = TUNE_DIR / f'parameter_importance_{timestamp_str}.html'\n","        fig_importance.write_html(str(param_importance_path))\n","        print(f'‚úì HTML saved to: {param_importance_path}')\n","\n","        # Save PNG with timestamp AND consistent name\n","        try:\n","            # Try kaleido\n","            param_importance_img_ts = TUNE_DIR / f'parameter_importance_{timestamp_str}.png'\n","            fig_importance.write_image(str(param_importance_img_ts), width=1200, height=800, scale=2)\n","            print(f'‚úì PNG saved to: {param_importance_img_ts}')\n","\n","            # Consistent name for PDF report\n","            param_importance_img = TUNE_DIR / 'parameter_importance.png'\n","            fig_importance.write_image(str(param_importance_img), width=1200, height=800, scale=2)\n","            print(f'‚úì PNG saved to: {param_importance_img} (for PDF report)')\n","        except Exception as png_error:\n","            try:\n","                # Fallback to orca\n","                param_importance_img_ts = TUNE_DIR / f'parameter_importance_{timestamp_str}.png'\n","                fig_importance.write_image(str(param_importance_img_ts), format='png', width=1200, height=800, engine='orca')\n","                print(f'‚úì PNG saved to: {param_importance_img_ts}')\n","\n","                param_importance_img = TUNE_DIR / 'parameter_importance.png'\n","                fig_importance.write_image(str(param_importance_img), format='png', width=1200, height=800, engine='orca')\n","                print(f'‚úì PNG saved to: {param_importance_img} (for PDF report)')\n","            except:\n","                print(f'‚ö†Ô∏è  Could not save PNG: {png_error}')\n","                param_importance_img = None\n","\n","    except (RuntimeError, ValueError) as importance_error:\n","        print(f'‚ö†Ô∏è  Could not generate parameter importance plot: {importance_error}')\n","        print('  (This can happen when trials have insufficient data variation)')\n","        param_importance_img = None\n","\n","    # -----------------------------\n","    # 3Ô∏è‚É£ Parameter Slice Plots\n","    # -----------------------------\n","    except (RuntimeError, ValueError) as importance_error:\n","        print(f'‚ö†Ô∏è  Could not generate parameter importance plot: {importance_error}')\n","        print('  (This can happen when trials have insufficient data variation)')\n","\n","    # -----------------------------\n","    # 3Ô∏è‚É£ Parameter Slice Plots\n","    # -----------------------------\n","    try:\n","        print('\\nüîç Creating parameter slice plots...')\n","        fig_slice = plot_slice(study)\n","        fig_slice.update_layout(\n","            title=f'{MODEL_NAME} - Parameter Slice Plot',\n","            template='plotly_white',\n","            width=1400,\n","            height=1000\n","        )\n","        fig_slice.show()\n","\n","        # Save HTML with timestamp\n","        slice_path = TUNE_DIR / f'parameter_slice_{timestamp_str}.html'\n","        fig_slice.write_html(str(slice_path))\n","        print(f'‚úì HTML saved to: {slice_path}')\n","\n","        # Save PNG with timestamp AND consistent name\n","        try:\n","            # Try kaleido\n","            slice_img_path_ts = TUNE_DIR / f'parameter_slice_{timestamp_str}.png'\n","            fig_slice.write_image(str(slice_img_path_ts), width=1400, height=1000, scale=2)\n","            print(f'‚úì PNG saved to: {slice_img_path_ts}')\n","\n","            # Consistent name for PDF report\n","            slice_img_path = TUNE_DIR / 'parameter_slice.png'\n","            fig_slice.write_image(str(slice_img_path), width=1400, height=1000, scale=2)\n","            print(f'‚úì PNG saved to: {slice_img_path} (for PDF report)')\n","        except Exception as png_error:\n","            try:\n","                # Fallback to orca\n","                slice_img_path_ts = TUNE_DIR / f'parameter_slice_{timestamp_str}.png'\n","                fig_slice.write_image(str(slice_img_path_ts), format='png', width=1400, height=1000, engine='orca')\n","                print(f'‚úì PNG saved to: {slice_img_path_ts}')\n","\n","                slice_img_path = TUNE_DIR / 'parameter_slice.png'\n","                fig_slice.write_image(str(slice_img_path), format='png', width=1400, height=1000, engine='orca')\n","                print(f'‚úì PNG saved to: {slice_img_path} (for PDF report)')\n","            except:\n","                print(f'‚ö†Ô∏è  Could not save PNG: {png_error}')\n","\n","    except Exception as slice_error:\n","        print(f'‚ö†Ô∏è  Could not generate parameter slice plot: {slice_error}')"]},{"cell_type":"markdown","id":"585a97a5","metadata":{"id":"585a97a5"},"source":["## 12. Generate Tuning PDF Report\n","\n","Create a comprehensive PDF report with optimization results, visualizations, and model performance."]},{"cell_type":"code","execution_count":null,"id":"6e3c3580","metadata":{"id":"6e3c3580"},"outputs":[],"source":["# GENERATE Tuning PDF REPORT\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('GENERATING COMPREHENSIVE TUNING PDF REPORT')\n","print('=' * 80)\n","\n","# Use already extracted best parameters and trial data from previous sections\n","best_params = study.best_params\n","best_trial = study.best_trial\n","\n","print(f'\\nüìä Preparing comprehensive report with {len(study.trials)} trials')\n","print(f'   Best Trial: {best_trial.number}')\n","print(f'   Best mAP@0.5: {study.best_value:.4f}')\n","\n","# Compile all trials data into DataFrame for PDF report\n","print('\\nüìã Compiling trials data for report...')\n","trials_data_for_pdf = []\n","\n","for trial in study.trials:\n","    trial_dir = TUNE_DIR / f'trial_{trial.number}'\n","    trial_json_path = trial_dir / 'trial_results.json'\n","\n","    if trial_json_path.exists():\n","        with open(trial_json_path, 'r', encoding='utf-8') as f:\n","            trial_data = json.load(f)\n","\n","        # Extract hyperparameters\n","        hyperparams = trial_data.get('hyperparameters', {})\n","\n","        # Create row with trial info\n","        row_data = {\n","            'trial': trial.number,\n","            'state': trial.state.name,\n","            'mAP@0.5': trial.value if trial.value is not None else 0.0,\n","        }\n","\n","        # Add all hyperparameters\n","        row_data.update(hyperparams)\n","\n","        trials_data_for_pdf.append(row_data)\n","    else:\n","        # Trial without saved data (failed/pruned)\n","        row_data = {\n","            'trial': trial.number,\n","            'state': trial.state.name,\n","            'mAP@0.5': trial.value if trial.value is not None else 0.0,\n","        }\n","        trials_data_for_pdf.append(row_data)\n","\n","# Create DataFrame and sort by mAP@0.5\n","df_trials = pd.DataFrame(trials_data_for_pdf)\n","df_trials_sorted = df_trials.sort_values('mAP@0.5', ascending=False)\n","\n","print(f'‚úì Compiled {len(df_trials)} trials for report')\n","\n","# Create tuning PDF report\n","pdf_report_path = TUNE_DIR / f'{MODEL_NAME}_tuning_report.pdf'\n","\n","doc = SimpleDocTemplate(str(pdf_report_path), pagesize=A4,\n","                       rightMargin=30, leftMargin=30,\n","                       topMargin=30, bottomMargin=30)\n","\n","story = []\n","styles = getSampleStyleSheet()\n","\n","# Custom styles\n","title_style = ParagraphStyle(\n","    'CustomTitle',\n","    parent=styles['Heading1'],\n","    fontSize=24,\n","    textColor=rl_colors.HexColor('#2c3e50'),\n","    spaceAfter=30,\n","    alignment=TA_CENTER\n",")\n","\n","heading_style = ParagraphStyle(\n","    'CustomHeading',\n","    parent=styles['Heading2'],\n","    fontSize=16,\n","    textColor=rl_colors.HexColor('#34495e'),\n","    spaceAfter=12,\n","    spaceBefore=20\n",")\n","\n","small_style = ParagraphStyle(\n","    'SmallText',\n","    parent=styles['Normal'],\n","    fontSize=7,\n","    wordWrap='CJK'\n",")\n","\n","# Title\n","story.append(Paragraph(f'{MODEL_NAME} Hyperparameter Tuning Report', title_style))\n","story.append(Paragraph(f'Generated: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}', styles['Normal']))\n","story.append(Spacer(1, 20))\n","\n","# ===== SECTION 1: OVERVIEW =====\n","story.append(Paragraph('1. Optimization Overview', heading_style))\n","\n","info_data = [\n","    ['Property', 'Value'],\n","    ['Model', MODEL_NAME],\n","    ['Dataset', YOLO_DATASET_ROOT.name],\n","    ['Total Trials', str(len(study.trials))],\n","    ['Completed Trials', str(len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]))],\n","    ['Failed Trials', str(len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL]))],\n","    ['Best Trial', str(study.best_trial.number)],\n","    ['Best mAP@0.5', f'{study.best_value:.4f}'],\n","    ['Optimization Duration', str(duration)],\n","]\n","\n","info_table = Table(info_data, colWidths=[2.5*inch, 3.5*inch])\n","info_table.setStyle(TableStyle([\n","    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#2c3e50')),\n","    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","    ('BACKGROUND', (0, 1), (-1, -1), rl_colors.HexColor('#ecf0f1')),\n","    ('TEXTCOLOR', (0, 1), (-1, -1), rl_colors.black),\n","    ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n","    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","    ('FONTNAME', (0, 1), (0, -1), 'Helvetica-Bold'),\n","    ('FONTSIZE', (0, 0), (-1, -1), 10),\n","    ('BOTTOMPADDING', (0, 0), (-1, -1), 8),\n","    ('TOPPADDING', (0, 0), (-1, -1), 8),\n","    ('GRID', (0, 0), (-1, -1), 1, rl_colors.grey)\n","]))\n","story.append(info_table)\n","story.append(Spacer(1, 20))\n","\n","# ===== SECTION 2: CONFIGURATION =====\n","story.append(Paragraph('2. Optimization Configuration', heading_style))\n","\n","opt_config_data = [\n","    ['Parameter', 'Value'],\n","    ['Total Trials', str(N_TRIALS)],\n","    ['Epochs per Trial', str(EPOCHS_PER_TRIAL)],\n","    ['Batch Size', str(BATCH_SIZE)],\n","    ['Startup Trials (TPE)', str(N_STARTUP_TRIALS)],\n","    ['Device', device],\n","    ['Number of Classes', str(NUM_CLASSES)],\n","    ['Train Images', str(dataset_stats.get('train', {}).get('images', 'N/A'))],\n","    ['Val Images', str(dataset_stats.get('val', {}).get('images', 'N/A'))],\n","]\n","\n","opt_config_table = Table(opt_config_data, colWidths=[3*inch, 3*inch])\n","opt_config_table.setStyle(TableStyle([\n","    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#95a5a6')),\n","    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n","    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","    ('FONTSIZE', (0, 0), (-1, 0), 11),\n","    ('FONTSIZE', (0, 1), (-1, -1), 9),\n","    ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n","    ('TOPPADDING', (0, 0), (-1, -1), 6),\n","    ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n","    ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n","]))\n","story.append(opt_config_table)\n","story.append(Spacer(1, 20))\n","\n","# ===== SECTION 3: BEST HYPERPARAMETERS =====\n","story.append(PageBreak())\n","story.append(Paragraph('3. Best Hyperparameters', heading_style))\n","\n","hyperparam_data = [['Parameter', 'Value', 'Description']]\n","param_descriptions = {\n","    'optimizer': 'Optimization algorithm',\n","    'lr0': 'Initial learning rate',\n","    'lrf': 'Final learning rate factor',\n","    'momentum': 'SGD momentum / Adam beta1',\n","    'weight_decay': 'Weight decay (L2 penalty)',\n","    'warmup_epochs': 'Warmup epochs',\n","    'warmup_momentum': 'Warmup momentum',\n","    'box': 'Box loss gain',\n","    'cls': 'Classification loss gain',\n","    'dfl': 'Distribution focal loss gain',\n","    'hsv_h': 'HSV-Hue augmentation',\n","    'hsv_s': 'HSV-Saturation augmentation',\n","    'hsv_v': 'HSV-Value augmentation',\n","    'degrees': 'Rotation augmentation',\n","    'translate': 'Translation augmentation',\n","    'scale': 'Scale augmentation',\n","    'shear': 'Shear augmentation',\n","    'perspective': 'Perspective augmentation',\n","    'flipud': 'Vertical flip probability',\n","    'fliplr': 'Horizontal flip probability',\n","    'mosaic': 'Mosaic augmentation',\n","    'mixup': 'Mixup augmentation',\n","    'copy_paste': 'Copy-paste augmentation',\n","}\n","\n","for param_key, param_value in best_params.items():\n","    desc = param_descriptions.get(param_key, '')\n","    formatted_value = f'{param_value:.6f}' if isinstance(param_value, float) else str(param_value)\n","    hyperparam_data.append([param_key, formatted_value, desc])\n","\n","hyperparam_table = Table(hyperparam_data, colWidths=[1.8*inch, 1.5*inch, 2.7*inch])\n","hyperparam_table.setStyle(TableStyle([\n","    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#3498db')),\n","    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","    ('ALIGN', (0, 0), (1, -1), 'CENTER'),\n","    ('ALIGN', (2, 1), (2, -1), 'LEFT'),\n","    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","    ('FONTSIZE', (0, 0), (-1, 0), 10),\n","    ('FONTSIZE', (0, 1), (-1, -1), 8),\n","    ('BOTTOMPADDING', (0, 0), (-1, -1), 5),\n","    ('TOPPADDING', (0, 0), (-1, -1), 5),\n","    ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n","    ('GRID', (0, 0), (-1, -1), 1, rl_colors.black),\n","    ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n","]))\n","story.append(hyperparam_table)\n","story.append(Spacer(1, 20))\n","\n","# ===== SECTION 4: TOP 20 TRIALS WITH HYPERPARAMETERS =====\n","story.append(PageBreak())\n","story.append(Paragraph('4. Top 20 Trials Performance', heading_style))\n","\n","# Create detailed top trials table with key hyperparameters\n","top_trials_data = [['#', 'mAP@0.5', 'Optimizer', 'lr0', 'momentum', 'mixup', 'mosaic']]\n","for idx, (_, row) in enumerate(df_trials_sorted.head(20).iterrows(), 1):\n","    top_trials_data.append([\n","        str(idx),\n","        f\"{row['mAP@0.5']:.4f}\",\n","        str(row.get('optimizer', 'N/A'))[:6],\n","        f\"{row.get('lr0', 0):.4f}\" if 'lr0' in row else 'N/A',\n","        f\"{row.get('momentum', 0):.3f}\" if 'momentum' in row else 'N/A',\n","        f\"{row.get('mixup', 0):.2f}\" if 'mixup' in row else 'N/A',\n","        f\"{row.get('mosaic', 0):.2f}\" if 'mosaic' in row else 'N/A',\n","    ])\n","\n","top_trials_table = Table(top_trials_data, colWidths=[0.4*inch, 0.9*inch, 0.9*inch, 0.8*inch, 0.9*inch, 0.8*inch, 0.8*inch])\n","top_trials_table.setStyle(TableStyle([\n","    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#27ae60')),\n","    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n","    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","    ('FONTSIZE', (0, 0), (-1, 0), 9),\n","    ('FONTSIZE', (0, 1), (-1, -1), 7),\n","    ('BOTTOMPADDING', (0, 0), (-1, -1), 4),\n","    ('TOPPADDING', (0, 0), (-1, -1), 4),\n","    ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n","    ('GRID', (0, 0), (-1, -1), 0.5, rl_colors.black)\n","]))\n","story.append(top_trials_table)\n","story.append(Spacer(1, 15))\n","\n","# Detailed hyperparameters for top 5 trials\n","story.append(PageBreak())\n","story.append(Paragraph('4.1 Detailed Hyperparameters - Top 5 Trials', heading_style))\n","for rank, (_, row) in enumerate(df_trials_sorted.head(5).iterrows(), 1):\n","    story.append(Paragraph(f'<b>Rank {rank}: Trial {int(row[\"trial\"])} (mAP@0.5: {row[\"mAP@0.5\"]:.4f})</b>', styles['Normal']))\n","\n","    trial_params_text = []\n","    for param_key in sorted(best_params.keys()):\n","        if param_key in row:\n","            value = row[param_key]\n","            formatted_val = f'{value:.6f}' if isinstance(value, float) else str(value)\n","            trial_params_text.append(f'{param_key}={formatted_val}')\n","\n","    params_str = ', '.join(trial_params_text)\n","    story.append(Paragraph(params_str, small_style))\n","    story.append(Spacer(1, 10))\n","\n","# ===== SECTION 5: OPTIMIZATION VISUALIZATIONS =====\n","story.append(PageBreak())\n","story.append(Paragraph('5. Optimization Visualizations', heading_style))\n","\n","print('\\nüìä Generating custom visualizations for PDF report...')\n","\n","# Prepare data for completed trials only\n","completed_trials_df = df_trials_sorted[df_trials_sorted['state'] == 'COMPLETE'].copy()\n","\n","if len(completed_trials_df) > 0:\n","    # 5.1 mAP@0.5 Progress Over Trials\n","    story.append(Paragraph('5.1 mAP@0.5 Progress Over Trials', styles['Heading3']))\n","\n","    fig, ax = plt.subplots(figsize=(10, 5))\n","    ax.plot(completed_trials_df['trial'], completed_trials_df['mAP@0.5'],\n","            marker='o', linestyle='-', linewidth=2, markersize=6, color='#3498db', alpha=0.7)\n","    ax.axhline(y=study.best_value, color='#e74c3c', linestyle='--', linewidth=2,\n","               label=f'Best: {study.best_value:.4f}')\n","    ax.set_xlabel('Trial Number', fontsize=12, fontweight='bold')\n","    ax.set_ylabel('mAP@0.5', fontsize=12, fontweight='bold')\n","    ax.set_title(f'{MODEL_NAME} - mAP@0.5 Progress', fontsize=14, fontweight='bold')\n","    ax.grid(True, alpha=0.3)\n","    ax.legend(fontsize=10)\n","    plt.tight_layout()\n","\n","    map_progress_img = TUNE_DIR / 'report_map_progress.png'\n","    plt.savefig(map_progress_img, dpi=150, bbox_inches='tight')\n","    plt.close()\n","\n","    story.append(Image(str(map_progress_img), width=6.5*inch, height=3.25*inch))\n","    story.append(Spacer(1, 15))\n","    print(f'‚úì mAP progress chart saved: {map_progress_img}')\n","\n","    # 5.2 Learning Rate vs mAP@0.5\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.2 Learning Rate Impact on Performance', styles['Heading3']))\n","\n","    if 'lr0' in completed_trials_df.columns:\n","        fig, ax = plt.subplots(figsize=(10, 5))\n","        scatter = ax.scatter(completed_trials_df['lr0'], completed_trials_df['mAP@0.5'],\n","                           c=completed_trials_df['mAP@0.5'], cmap='RdYlGn',\n","                           s=100, alpha=0.6, edgecolors='black', linewidth=0.5)\n","        ax.set_xlabel('Learning Rate (lr0)', fontsize=12, fontweight='bold')\n","        ax.set_ylabel('mAP@0.5', fontsize=12, fontweight='bold')\n","        ax.set_title(f'{MODEL_NAME} - Learning Rate vs Performance', fontsize=14, fontweight='bold')\n","        ax.grid(True, alpha=0.3)\n","        cbar = plt.colorbar(scatter, ax=ax)\n","        cbar.set_label('mAP@0.5', fontsize=10)\n","        plt.tight_layout()\n","\n","        lr_impact_img = TUNE_DIR / 'report_lr_impact.png'\n","        plt.savefig(lr_impact_img, dpi=150, bbox_inches='tight')\n","        plt.close()\n","\n","        story.append(Image(str(lr_impact_img), width=6.5*inch, height=3.25*inch))\n","        story.append(Spacer(1, 15))\n","        print(f'‚úì Learning rate impact chart saved: {lr_impact_img}')\n","\n","    # 5.3 Optimizer Comparison\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.3 Optimizer Performance Comparison', styles['Heading3']))\n","\n","    if 'optimizer' in completed_trials_df.columns:\n","        fig, ax = plt.subplots(figsize=(10, 5))\n","\n","        optimizer_stats = completed_trials_df.groupby('optimizer')['mAP@0.5'].agg(['mean', 'max', 'count'])\n","        optimizer_stats = optimizer_stats.sort_values('mean', ascending=False)\n","\n","        x_pos = range(len(optimizer_stats))\n","        ax.bar(x_pos, optimizer_stats['mean'], alpha=0.7, color='#3498db',\n","               label='Mean mAP@0.5', edgecolor='black', linewidth=1)\n","        ax.scatter(x_pos, optimizer_stats['max'], color='#e74c3c', s=100,\n","                  label='Max mAP@0.5', zorder=5, edgecolors='black', linewidth=1)\n","\n","        ax.set_xlabel('Optimizer', fontsize=12, fontweight='bold')\n","        ax.set_ylabel('mAP@0.5', fontsize=12, fontweight='bold')\n","        ax.set_title(f'{MODEL_NAME} - Optimizer Performance Comparison', fontsize=14, fontweight='bold')\n","        ax.set_xticks(x_pos)\n","        ax.set_xticklabels(optimizer_stats.index, rotation=45, ha='right')\n","        ax.legend(fontsize=10)\n","        ax.grid(True, alpha=0.3, axis='y')\n","\n","        # Add count annotations\n","        for i, (opt, row) in enumerate(optimizer_stats.iterrows()):\n","            ax.text(i, row['mean'] + 0.002, f\"n={int(row['count'])}\",\n","                   ha='center', va='bottom', fontsize=9)\n","\n","        plt.tight_layout()\n","\n","        optimizer_comp_img = TUNE_DIR / 'report_optimizer_comparison.png'\n","        plt.savefig(optimizer_comp_img, dpi=150, bbox_inches='tight')\n","        plt.close()\n","\n","        story.append(Image(str(optimizer_comp_img), width=6.5*inch, height=3.25*inch))\n","        story.append(Spacer(1, 15))\n","        print(f'‚úì Optimizer comparison chart saved: {optimizer_comp_img}')\n","\n","    # 5.4 Augmentation Parameters vs Performance\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.4 Augmentation Parameters Impact', styles['Heading3']))\n","\n","    # Create 2x2 subplot for key augmentation parameters\n","    aug_params = ['mixup', 'mosaic', 'degrees', 'scale']\n","    available_aug_params = [p for p in aug_params if p in completed_trials_df.columns]\n","\n","    if len(available_aug_params) >= 2:\n","        n_plots = min(len(available_aug_params), 4)\n","        fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n","        axes = axes.flatten()\n","\n","        for idx, param in enumerate(available_aug_params[:4]):\n","            ax = axes[idx]\n","            scatter = ax.scatter(completed_trials_df[param], completed_trials_df['mAP@0.5'],\n","                               c=completed_trials_df['mAP@0.5'], cmap='RdYlGn',\n","                               s=60, alpha=0.6, edgecolors='black', linewidth=0.5)\n","            ax.set_xlabel(param, fontsize=10, fontweight='bold')\n","            ax.set_ylabel('mAP@0.5', fontsize=10, fontweight='bold')\n","            ax.set_title(f'{param.capitalize()} Impact', fontsize=11, fontweight='bold')\n","            ax.grid(True, alpha=0.3)\n","\n","        # Hide unused subplots\n","        for idx in range(len(available_aug_params), 4):\n","            axes[idx].axis('off')\n","\n","        plt.tight_layout()\n","\n","        aug_impact_img = TUNE_DIR / 'report_augmentation_impact.png'\n","        plt.savefig(aug_impact_img, dpi=150, bbox_inches='tight')\n","        plt.close()\n","\n","        story.append(Image(str(aug_impact_img), width=6.5*inch, height=5.2*inch))\n","        story.append(Spacer(1, 15))\n","        print(f'‚úì Augmentation impact chart saved: {aug_impact_img}')\n","\n","    # 5.5 Weight Decay and Momentum vs Performance\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.5 Regularization Parameters Impact', styles['Heading3']))\n","\n","    if 'weight_decay' in completed_trials_df.columns and 'momentum' in completed_trials_df.columns:\n","        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n","\n","        # Weight Decay\n","        scatter1 = ax1.scatter(completed_trials_df['weight_decay'], completed_trials_df['mAP@0.5'],\n","                              c=completed_trials_df['mAP@0.5'], cmap='RdYlGn',\n","                              s=80, alpha=0.6, edgecolors='black', linewidth=0.5)\n","        ax1.set_xlabel('Weight Decay', fontsize=11, fontweight='bold')\n","        ax1.set_ylabel('mAP@0.5', fontsize=11, fontweight='bold')\n","        ax1.set_title('Weight Decay Impact', fontsize=12, fontweight='bold')\n","        ax1.grid(True, alpha=0.3)\n","\n","        # Momentum\n","        scatter2 = ax2.scatter(completed_trials_df['momentum'], completed_trials_df['mAP@0.5'],\n","                              c=completed_trials_df['mAP@0.5'], cmap='RdYlGn',\n","                              s=80, alpha=0.6, edgecolors='black', linewidth=0.5)\n","        ax2.set_xlabel('Momentum', fontsize=11, fontweight='bold')\n","        ax2.set_ylabel('mAP@0.5', fontsize=11, fontweight='bold')\n","        ax2.set_title('Momentum Impact', fontsize=12, fontweight='bold')\n","        ax2.grid(True, alpha=0.3)\n","\n","        plt.tight_layout()\n","\n","        reg_impact_img = TUNE_DIR / 'report_regularization_impact.png'\n","        plt.savefig(reg_impact_img, dpi=150, bbox_inches='tight')\n","        plt.close()\n","\n","        story.append(Image(str(reg_impact_img), width=6.5*inch, height=2.6*inch))\n","        story.append(Spacer(1, 15))\n","        print(f'‚úì Regularization impact chart saved: {reg_impact_img}')\n","\n","    print('‚úì All custom visualizations generated for PDF report')\n","else:\n","    story.append(Paragraph('No completed trials available for visualization.', styles['Normal']))\n","\n","# ===== SECTION 6: ALL TRIALS SUMMARY =====\n","story.append(PageBreak())\n","story.append(Paragraph('6. All Trials Summary', heading_style))\n","\n","# Statistics\n","completed_df = df_trials_sorted[df_trials_sorted['state'] == 'COMPLETE']\n","if len(completed_df) > 0:\n","    stats_data = [\n","        ['Metric', 'Value'],\n","        ['Completed Trials', str(len(completed_df))],\n","        ['Best mAP@0.5', f\"{completed_df['mAP@0.5'].max():.4f}\"],\n","        ['Worst mAP@0.5', f\"{completed_df['mAP@0.5'].min():.4f}\"],\n","        ['Mean mAP@0.5', f\"{completed_df['mAP@0.5'].mean():.4f}\"],\n","        ['Std Dev mAP@0.5', f\"{completed_df['mAP@0.5'].std():.4f}\"],\n","        ['Median mAP@0.5', f\"{completed_df['mAP@0.5'].median():.4f}\"],\n","    ]\n","\n","    stats_table = Table(stats_data, colWidths=[2.5*inch, 3.5*inch])\n","    stats_table.setStyle(TableStyle([\n","        ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#e74c3c')),\n","        ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n","        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","        ('FONTSIZE', (0, 0), (-1, -1), 10),\n","        ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n","        ('TOPPADDING', (0, 0), (-1, -1), 6),\n","        ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n","        ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n","    ]))\n","    story.append(stats_table)\n","\n","# Build PDF\n","try:\n","    doc.build(story)\n","    print(f'\\n‚úì Comprehensive PDF report generated: {pdf_report_path}')\n","    print(f'  Size: {pdf_report_path.stat().st_size / (1024*1024):.1f} MB')\n","    print(f'  Sections: Overview, Configuration, Best Hyperparameters, Top 10 Trials,')\n","    print(f'            Optimization Visualizations (3 charts), All Trials Summary')\n","except Exception as pdf_error:\n","    print(f'\\n‚ö†Ô∏è  Error generating PDF: {pdf_error}')\n","    import traceback\n","    traceback.print_exc()\n","\n","print('=' * 80)"]},{"cell_type":"markdown","id":"c5ff99f5","metadata":{"id":"c5ff99f5"},"source":["## 13. Analyze Best Hyperparameters"]},{"cell_type":"code","execution_count":null,"id":"f3823505","metadata":{"id":"f3823505"},"outputs":[],"source":["# DISPLAY BEST HYPERPARAMETERS\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('BEST HYPERPARAMETERS')\n","print('=' * 80)\n","\n","print(f'\\nBest Trial Number: {study.best_trial.number}')\n","print(f'Best mAP@0.5: {study.best_value:.4f}')\n","print('\\nOptimized Hyperparameters:')\n","print(json.dumps(study.best_params, indent=2))\n","print('=' * 80)"]},{"cell_type":"markdown","id":"1900ad83","metadata":{"id":"1900ad83"},"source":["## 13. Create Trials Summary"]},{"cell_type":"code","execution_count":null,"id":"2c210c33","metadata":{"id":"2c210c33"},"outputs":[],"source":["# CREATE TRIALS SUMMARY AND DATAFRAME (SHARED RESOURCE)\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('TRIALS SUMMARY')\n","print('=' * 80)\n","\n","# Compile all trial data (used by multiple sections)\n","trials_data = []\n","for trial in study.trials:\n","    trial_info = {\n","        'trial': trial.number,\n","        'mAP@0.5': trial.value if trial.value else 0.0,\n","        'state': trial.state.name,\n","        'duration_seconds': (trial.datetime_complete - trial.datetime_start).total_seconds() if trial.datetime_complete else None,\n","    }\n","    # Add all parameters\n","    trial_info.update(trial.params)\n","    trials_data.append(trial_info)\n","\n","# Create DataFrame and sort by performance (used by PDF report and display)\n","df_trials = pd.DataFrame(trials_data)\n","df_trials_sorted = df_trials.sort_values('mAP@0.5', ascending=False)\n","\n","print('\\nüìä TOP 10 TRIALS:')\n","print('=' * 80)\n","# Display top 10 with selected columns\n","display_cols = ['trial', 'mAP@0.5', 'state', 'optimizer', 'lr0', 'momentum', 'weight_decay', 'mixup']\n","available_cols = [col for col in display_cols if col in df_trials_sorted.columns]\n","print(df_trials_sorted[available_cols].head(10).to_string(index=False))\n","print('=' * 80)\n","\n","# Save complete trials summary\n","trials_csv_path = TUNE_DIR / 'trials_summary.csv'\n","df_trials_sorted.to_csv(trials_csv_path, index=False)\n","print(f'\\n‚úì Complete trials summary saved to: {trials_csv_path}')\n","\n","# Save study object\n","study_path = TUNE_DIR / 'optuna_study.pkl'\n","with open(study_path, 'wb') as f:\n","    pickle.dump(study, f)\n","print(f'‚úì Optuna study object saved to: {study_path}')\n","\n","print('=' * 80)"]},{"cell_type":"markdown","id":"7d09278e","metadata":{"id":"7d09278e"},"source":["## 14. Final summary\n"]},{"cell_type":"code","execution_count":null,"id":"9e9576f4","metadata":{"id":"9e9576f4"},"outputs":[],"source":["# FINAL SUMMARY\n","# ============================================================================\n","\n","print('\\n\\n')\n","print('=' * 80)\n","print('HYPERPARAMETER OPTIMIZATION COMPLETE!')\n","print('=' * 80)\n","\n","print(f'\\nüìä Project: {MODEL_NAME} on {YOLO_DATASET_ROOT.name}')\n","print(f'üìÖ Date: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n","\n","print(f'\\nüî¨ Optimization Summary:')\n","print(f'  Total Trials: {len(study.trials)}')\n","print(f'  Completed: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}')\n","print(f'  Best Trial: {study.best_trial.number}')\n","print(f'  Best Trial mAP@0.5: {study.best_value:.4f}')\n","print(f'  Duration: {duration}')\n","\n","if 'final_metrics' in globals():\n","    print(f'\\nüéØ Final Model Performance:')\n","    print(f'  mAP@0.5: {final_metrics[\"map50\"]:.4f}')\n","    print(f'  mAP@0.5:0.95: {final_metrics[\"map50_95\"]:.4f}')\n","    print(f'  Precision: {final_metrics[\"precision\"]:.4f}')\n","    print(f'  Recall: {final_metrics[\"recall\"]:.4f}')\n","\n","print(f'\\nüìÅ Generated Files:')\n","print(f'\\n  üìä Tuning Results (in {TUNE_DIR}):')\n","print(f'    - best_hyperparameters.json')\n","print(f'    - best_hyperparameters.yaml')\n","print(f'    - trials_summary.csv')\n","print(f'    - optuna_study.pkl')\n","print(f'  üìà Tuning Visualizations:')\n","print(f'    - optimization_history.html / .png')\n","print(f'    - parameter_importance.html / .png')\n","print(f'    - parameter_slice.html / .png')\n","print(f'  üìÑ Tuning PDF Report:')\n","print(f'    - {MODEL_NAME}_tuning_report.pdf')\n","\n","print(f'\\nüìÇ All results saved to:')\n","print(f'  Tuning: {TUNE_DIR}')\n","\n","print(f'\\nüéì Top 5 Hyperparameters (by importance):')\n","try:\n","    importances = optuna.importance.get_param_importances(study)\n","    for i, (param, importance) in enumerate(list(importances.items())[:5], 1):\n","        print(f'  {i}. {param}: {importance:.4f}')\n","except:\n","    print('  (Not available - requires completed trials with variation)')\n","\n","print(f'\\nüöÄ Next Steps:')\n","print(f'  1. Review tuning PDF report: {TUNE_DIR / f\"{MODEL_NAME}_tuning_report.pdf\"}')\n","print(f'  2. Review optimization visualizations in: {TUNE_DIR}')\n","print(f'  3. Use best_hyperparameters.yaml for training in a separate notebook')\n","\n","print('\\n' + '=' * 80)\n","print('SUCCESS! ‚úì')\n","print('=' * 80)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"colab":{"provenance":[],"gpuType":"A100"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"a4113552084d48fc9cddd83157a14742":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5b98d15ccaef487a89b7acad61b1cdb6","IPY_MODEL_7fd22f9eabec4486b052e9fe12e243ac","IPY_MODEL_da9f96b09dee45fe9b2566052330249e"],"layout":"IPY_MODEL_90440937d77948be9943453b82e702e4"}},"5b98d15ccaef487a89b7acad61b1cdb6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16549873e2564293b91e8911068ea0f1","placeholder":"‚Äã","style":"IPY_MODEL_98b71aeace5b4e8d86358d727fc950de","value":"Best‚Äátrial:‚Äá0.‚ÄáBest‚Äávalue:‚Äá0.576928:‚Äá‚Äá45%"}},"7fd22f9eabec4486b052e9fe12e243ac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_247c0d2c39984077be9612391592939d","max":40,"min":0,"orientation":"horizontal","style":"IPY_MODEL_08a4b8062a5c4539b2e4132f85df6019","value":18}},"da9f96b09dee45fe9b2566052330249e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9212e0e54afd46c18bf835df5662538f","placeholder":"‚Äã","style":"IPY_MODEL_36bf390499164cc3a3b848287760d4bb","value":"‚Äá18/40‚Äá[7:33:11&lt;9:35:15,‚Äá1568.90s/it,‚Äá27191.84/86400‚Äáseconds]"}},"90440937d77948be9943453b82e702e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16549873e2564293b91e8911068ea0f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98b71aeace5b4e8d86358d727fc950de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"247c0d2c39984077be9612391592939d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08a4b8062a5c4539b2e4132f85df6019":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9212e0e54afd46c18bf835df5662538f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36bf390499164cc3a3b848287760d4bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}