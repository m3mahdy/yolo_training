{"cells":[{"cell_type":"markdown","id":"8b26f5d6","metadata":{"id":"8b26f5d6"},"source":["# YOLO Hyperparameter Tuning\n","\n","- Support for YOLOv8, YOLOv9, YOLOv10, YOLO11, YOLO12"]},{"cell_type":"code","execution_count":1,"id":"f68c7bbf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f68c7bbf","executionInfo":{"status":"ok","timestamp":1764351550925,"user_tz":-180,"elapsed":50594,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"20e29499-dfb0-4426-cbc2-06f025e69f68"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/Drive\n","âœ“ W&B API key loaded from Colab secrets\n"]}],"source":["# Base directories\n","# Detect environment: Colab or local\n","\n","import os\n","from pathlib import Path\n","\n","\n","IS_COLAB = 'COLAB_GPU' in os.environ or os.path.exists('/content')\n","\n","USE_WANDB = True  # Set to False to disable W&B logging\n","\n","\n","\n","if IS_COLAB:\n","    #Mount Google Drive if not already mounted\n","    from google.colab import drive\n","    drive.mount('/content/Drive', force_remount=True)\n","    # Running in Google Colab\n","    BASE_DIR = Path('/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo')\n","\n","    # Configure W&B API key\n","    if USE_WANDB:\n","        # In Colab, get API key from secrets\n","        from google.colab import userdata\n","        wandb_api_key = userdata.get('wandb_api_key')\n","        os.environ['WANDB_API_KEY'] = wandb_api_key\n","        print('âœ“ W&B API key loaded from Colab secrets')\n","\n","    DATASET_BASE_DIR = Path('/computer_vision_yolo')\n","\n","else:\n","    # Running locally\n","    BASE_DIR = Path.cwd().parent\n","    if USE_WANDB:\n","        print('âœ“ Running locally - W&B will use existing login or prompt')\n","\n","    DATASET_BASE_DIR = Path.cwd().parent\n"]},{"cell_type":"code","execution_count":2,"id":"7c504221","metadata":{"id":"7c504221","executionInfo":{"status":"ok","timestamp":1764351550930,"user_tz":-180,"elapsed":3,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}}},"outputs":[],"source":["# !cd /content/Drive/MyDrive/ksu_yolo_tuning_2025 && git clone https://github.com/m3mahdy/computer_vision_yolo"]},{"cell_type":"code","execution_count":3,"id":"fde7425c","metadata":{"id":"fde7425c","executionInfo":{"status":"ok","timestamp":1764351561050,"user_tz":-180,"elapsed":10118,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"11e93125-5513-41a0-e4d4-f61970a2c592"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/329.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m329.5/329.5 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/404.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/69.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/49.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["! cd {BASE_DIR} && pip install -r requirements.txt --quiet"]},{"cell_type":"code","execution_count":4,"id":"92da27e0","metadata":{"id":"92da27e0","executionInfo":{"status":"ok","timestamp":1764351627311,"user_tz":-180,"elapsed":66254,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"992d90c5-648d-4cb6-dd14-0cdce7b059c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","BDD100K DATASET DOWNLOAD & EXTRACT\n","======================================================================\n","\n","Available datasets:\n","\n","[1] Full Dataset Source Files\n","    Original BDD100K images and labels (requires processing)\n","    Size: ~5.28GB, ~180MB\n","\n","[2] Limited Dataset (YOLO Ready)\n","    Balanced limited dataset - 30-40% coverage (~25K train)\n","    Size: ~3.3GB\n","\n","[3] Tuning Dataset (YOLO Ready)\n","    Tuning dataset - 20% coverage (~14K train)\n","    Size: ~1.58GB\n","\n","[4] Tiny Dataset (YOLO Ready)\n","    Tiny dataset - ~500 train, ~1K total (fast testing)\n","    Size: ~100MB\n","\n","[5] Test Split Only (YOLO Ready)\n","    Test split only for validation (20K images)\n","    Size: ~1.1GB\n","\n","[0] Exit\n","======================================================================\n","\n","Select dataset (0-5): 3\n","\n","======================================================================\n","Processing: Tuning Dataset (YOLO Ready)\n","======================================================================\n","\n","ğŸ“¥ Downloading from Google Drive...\n","   File ID: 1QccaQ1tI_N3zXzp08Nemw13wl_02gUWG\n","   Destination: bdd100k_yolo_tuning.zip\n","Downloading...\n","From (original): https://drive.google.com/uc?id=1QccaQ1tI_N3zXzp08Nemw13wl_02gUWG\n","From (redirected): https://drive.google.com/uc?id=1QccaQ1tI_N3zXzp08Nemw13wl_02gUWG&confirm=t&uuid=e0e0eb62-4de6-44d2-9590-63460a835825\n","To: /bdd100k_limited_datasets_zipped/bdd100k_yolo_tuning.zip\n","100% 1.58G/1.58G [00:28<00:00, 55.4MB/s]\n","âœ“ Download complete: 1510.3 MB\n","\n","ğŸ“¦ Extracting bdd100k_yolo_tuning.zip...\n","  Extracting: 100% 52785/52785 [00:15<00:00, 3390.05files/s] \n","âœ“ Extracted to: /computer_vision_yolo\n","\n","======================================================================\n","âœ… Tuning Dataset (YOLO Ready) ready!\n","======================================================================\n","\n","\n","Download another dataset? (y/n): n\n"]}],"source":["# limited dataset\n","!mkdir {DATASET_BASE_DIR}\n","!cd {BASE_DIR}/dataset && cp 8_download_extract_other_datasets.py {DATASET_BASE_DIR} && cd {DATASET_BASE_DIR} && python 8_download_extract_other_datasets.py\n"]},{"cell_type":"markdown","id":"109394c4","metadata":{"id":"109394c4"},"source":["## 1. Import Required Libraries"]},{"cell_type":"code","execution_count":5,"id":"fc6f98f1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fc6f98f1","executionInfo":{"status":"ok","timestamp":1764351636130,"user_tz":-180,"elapsed":8817,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"4db8a370-7d21-43be-da5c-90395d0d62e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file âœ… \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","âœ“ Libraries imported successfully\n","âœ“ Device: cuda\n","  GPU: NVIDIA A100-SXM4-40GB\n","  CUDA Version: 12.6\n","  Available Memory: 42.47 GB\n"]}],"source":["# Install required libraries (uncomment if running in Colab)\n","# !pip install -q ultralytics optuna plotly kaleido wandb pyyaml\n","\n","import os\n","import sys\n","import gc\n","import yaml\n","import json\n","import torch\n","import shutil\n","import warnings\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from pathlib import Path\n","from datetime import datetime\n","from tqdm import tqdm\n","import pickle\n","import platform\n","import psutil\n","\n","import wandb\n","\n","# YOLO and Optuna imports\n","from ultralytics import YOLO\n","import optuna\n","from optuna.visualization import plot_optimization_history, plot_param_importances, plot_slice\n","\n","# ReportLab imports for PDF generation\n","from reportlab.lib.pagesizes import A4\n","from reportlab.lib import colors as rl_colors\n","from reportlab.lib.units import inch\n","from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, Image, PageBreak\n","from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n","from reportlab.lib.enums import TA_CENTER, TA_LEFT\n","from PIL import Image as PILImage\n","\n","warnings.filterwarnings('ignore')\n","\n","# Configure matplotlib for notebook display\n","%matplotlib inline\n","sns.set_style('whitegrid')\n","plt.rcParams['figure.figsize'] = (15, 10)\n","\n","# Check GPU availability\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(f'âœ“ Libraries imported successfully')\n","print(f'âœ“ Device: {device}')\n","if device == 'cuda':\n","    print(f'  GPU: {torch.cuda.get_device_name(0)}')\n","    print(f'  CUDA Version: {torch.version.cuda}')\n","    print(f'  Available Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')"]},{"cell_type":"markdown","id":"2eda31f6","metadata":{"id":"2eda31f6"},"source":["## 2. Constants and Enums"]},{"cell_type":"code","execution_count":6,"id":"2031059f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2031059f","executionInfo":{"status":"ok","timestamp":1764351636159,"user_tz":-180,"elapsed":26,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"98e72d7a-4c4e-417c-9d7a-2782183d1dab"},"outputs":[{"output_type":"stream","name":"stdout","text":["âœ“ Constants and enums defined\n"]}],"source":["# ============================================================================\n","# CONSTANTS AND ENUMS\n","# ============================================================================\n","\n","class TrialStatus:\n","    \"\"\"Constants for trial execution status\"\"\"\n","    COMPLETED = \"completed\"\n","    FAILED = \"failed\"\n","    PRUNED = \"pruned\"\n","    RUNNING = \"running\"\n","\n","class DatasetSplit:\n","    \"\"\"Constants for dataset split names\"\"\"\n","    TRAIN = \"train\"\n","    VAL = \"val\"\n","    TEST = \"test\"\n","\n","class ModelConfig:\n","    \"\"\"Default model training configuration constants\"\"\"\n","    # Training workers\n","    DEFAULT_WORKERS = 8  # Number of data loading workers\n","\n","    # Early stopping and checkpointing\n","    DEFAULT_PATIENCE = 20  # Epochs to wait before early stopping\n","\n","    # Augmentation timing\n","    CLOSE_MOSAIC_EPOCHS = 10  # Disable mosaic augmentation in last N epochs\n","\n","print('âœ“ Constants and enums defined')"]},{"cell_type":"markdown","id":"2659c792","metadata":{"id":"2659c792"},"source":["## 3. Configuration"]},{"cell_type":"code","execution_count":7,"id":"d163f0be","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d163f0be","executionInfo":{"status":"ok","timestamp":1764351638960,"user_tz":-180,"elapsed":2793,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"53152a49-6ee2-4e9f-c25f-0319ba8807f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ğŸ”„ RESUME MODE: Will attempt to resume run \"yolov8m_finetuned_1_tune_20251127_230340\"\n","================================================================================\n","CONFIGURATION SUMMARY\n","================================================================================\n","Environment: Google Colab\n","Base Directory: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo\n","Model: yolov8m_finetuned_1\n","Dataset: bdd100k_yolo_tuning\n","Data YAML: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml\n","  Dataset path in YAML: /computer_vision_yolo/bdd100k_yolo_tuning\n","Classes: 10\n","Class Names: {0: 'person', 1: 'rider', 2: 'car', 3: 'truck', 4: 'bus', 5: 'train', 6: 'motor', 7: 'bike', 8: 'traffic light', 9: 'traffic sign'}\n","Device: cuda\n","Optimization Trials: 40\n","Epochs per Trial: 8\n","Batch Size: 96\n","Timeout: 24 hours\n","Tuning Directory: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340\n","W&B Logging: Enabled\n","  Tuning Project: yolo-bdd100k_yolo_tuning-tuning\n","================================================================================\n"]}],"source":["# CONFIGURATION\n","# ============================================================================\n","\n","\n","# Model Selection - Choose one of the following:\n","MODEL_NAME = \"yolov8m_finetuned_1\"\n","\n","#yolov10n is for testing purpose only\n","#Mahdy will work yolov8m\n","\n","\n","# Selected models, to choose from, based on the performance and size:\n","# YOLOv8:  'yolov8s', 'yolov8m'\n","\n","# YOLOv10: 'yolov10s', 'yolov10m'\n","\n","# YOLO12: 'yolo12s'\n","\n","# Directory structure\n","MODELS_DIR = BASE_DIR / 'models' / MODEL_NAME\n","TMP_DIR = BASE_DIR / 'tmp' / MODEL_NAME\n","\n","# Dataset Selection\n","# Option 1: Full dataset (~100k images) - for final optimization: \"bdd100k_yolo\"\n","# Option 2: Limited dataset (representative samples) - for quick tuning: \"bdd100k_yolo_limited\"\n","dataset_name = 'bdd100k_yolo_tuning'\n","\n","\n","YOLO_DATASET_ROOT = DATASET_BASE_DIR / dataset_name\n","\n","# data.yaml path\n","DATA_YAML_PATH = YOLO_DATASET_ROOT / 'data.yaml'\n","\n","# Verify dataset exists\n","if not DATA_YAML_PATH.exists():\n","    raise FileNotFoundError(\n","        f\"Dataset not found: {DATA_YAML_PATH}\\n\"\n","        f\"Please prepare the dataset first using process_bdd100k_to_yolo_dataset.py\"\n","    )\n","\n","# Update data.yaml path field for Colab compatibility\n","with open(DATA_YAML_PATH, 'r') as yaml_file:\n","    data_config = yaml.safe_load(yaml_file)\n","\n","# Validate required keys in data.yaml\n","required_yaml_keys = ['nc', 'names', 'path']\n","missing_keys = [key for key in required_yaml_keys if key not in data_config]\n","if missing_keys:\n","    raise ValueError(f\"Missing required keys in data.yaml: {missing_keys}\")\n","\n","# Update the 'path' field to use BASE_DIR\n","data_config['path'] = str(YOLO_DATASET_ROOT)\n","\n","# Create a temporary data.yaml with corrected paths\n","temp_data_yaml = TMP_DIR / 'data.yaml'\n","TMP_DIR.mkdir(parents=True, exist_ok=True)\n","with open(temp_data_yaml, 'w') as yaml_output_file:\n","    yaml.dump(data_config, yaml_output_file, default_flow_style=False, sort_keys=False)\n","\n","# Use the temporary data.yaml for training\n","DATA_YAML_PATH = temp_data_yaml\n","\n","# Optimization Configuration\n","N_TRIALS = 40  # Number of optimization trials = 50â€“70 trials\n","TIMEOUT_HOURS = 24  # Maximum time for optimization (None for no limit)\n","N_STARTUP_TRIALS = 10  # Random exploration trials before optimization =10\n","EPOCHS_PER_TRIAL = 8  # Training epochs per trial = 50\n","BATCH_SIZE = 96  # Batch size for training\n","# for T4 GPU:\n","# 64 for 10n, 1 epoch 30 min\n","# 32 for 8m, 1 epoch 45 min\n","\n","# for A100 GPU:\n","# 64 for 10m 1 epoch 11 min, 5 epochs completed in 0.797 hours.\n","# 96 for 8m , 1 epoch 10 min, 5 epochs completed in 0.866 hours.\n","\n","\n","\n","# Weights & Biases (optional)\n","USE_WANDB = True  # Set to True to enable W&B logging\n","WANDB_PROJECT_TUNING = f\"yolo-{YOLO_DATASET_ROOT.name}-tuning\"\n","\n","# ============================================================================\n","# RUN NAME CONFIGURATION - RESUME OR CREATE NEW\n","# ============================================================================\n","# To RESUME an existing run: Set RESUME_RUN_NAME to the run directory name\n","# To START NEW run: Leave RESUME_RUN_NAME as None or empty string\n","#\n","# Example to resume: RESUME_RUN_NAME = \"yolov10n_tune_20251125_143022\"\n","# ============================================================================\n","\n","RESUME_RUN_NAME = \"yolov8m_finetuned_1_tune_20251127_230340\"  # Set to run name to resume, or None to create new run\n","\n","if RESUME_RUN_NAME:\n","    # Resume existing run\n","    RUN_NAME_TUNING = RESUME_RUN_NAME\n","    print(f'\\nğŸ”„ RESUME MODE: Will attempt to resume run \"{RESUME_RUN_NAME}\"')\n","else:\n","    # Create new run with timestamp\n","    RUN_TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')\n","    RUN_NAME_TUNING = f'{MODEL_NAME}_tune_{RUN_TIMESTAMP}'\n","    print(f'\\nğŸ†• NEW RUN MODE: Creating new run \"{RUN_NAME_TUNING}\"')\n","\n","RUN_NAME_TRAINING = f'{MODEL_NAME}_train_{RUN_TIMESTAMP if not RESUME_RUN_NAME else RESUME_RUN_NAME}'\n","\n","# Create directories for tuning within tune_train folder\n","# All paths are absolute to ensure consistency across environments (local/Colab)\n","TUNE_TRAIN_BASE = BASE_DIR / 'tune_train'\n","TUNE_DIR = TUNE_TRAIN_BASE / 'tune' / RUN_NAME_TUNING\n","TUNE_DIR.mkdir(parents=True, exist_ok=True)\n","MODELS_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Keep RUN_DIR for backward compatibility (points to tuning)\n","RUN_DIR = TUNE_DIR\n","# Keep RUN_DIR for backward compatibility (points to tuning)\n","# Read dataset configuration\n","NUM_CLASSES = data_config['nc']\n","CLASS_NAMES = {i: name for i, name in enumerate(data_config['names'])}\n","CLASS_NAME_TO_ID = {name: i for i, name in enumerate(data_config['names'])}\n","\n","print('=' * 80)\n","print('CONFIGURATION SUMMARY')\n","print('=' * 80)\n","print(f'Environment: {\"Google Colab\" if \"COLAB_GPU\" in os.environ or os.path.exists(\"/content\") else \"Local\"}')\n","print(f'Base Directory: {BASE_DIR}')\n","print(f'Model: {MODEL_NAME}')\n","print(f'Dataset: {YOLO_DATASET_ROOT.name}')\n","print(f'Data YAML: {DATA_YAML_PATH}')\n","print(f'  Dataset path in YAML: {data_config[\"path\"]}')\n","print(f'Classes: {NUM_CLASSES}')\n","print(f'Class Names: {CLASS_NAMES}')\n","print(f'Device: {device}')\n","print(f'Optimization Trials: {N_TRIALS}')\n","print(f'Epochs per Trial: {EPOCHS_PER_TRIAL}')\n","print(f'Batch Size: {BATCH_SIZE}')\n","print(f'Timeout: {TIMEOUT_HOURS} hours' if TIMEOUT_HOURS else 'No timeout')\n","print(f'Tuning Directory: {TUNE_DIR}')\n","if USE_WANDB:\n","    print(f'W&B Logging: Enabled')\n","    print(f'  Tuning Project: {WANDB_PROJECT_TUNING}')\n","else:\n","    print(f'W&B Logging: Disabled')\n","print('=' * 80)"]},{"cell_type":"markdown","id":"0af35c3f","metadata":{"id":"0af35c3f"},"source":["## 4. Load Base YOLO Model"]},{"cell_type":"code","execution_count":8,"id":"3deeda88","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3deeda88","executionInfo":{"status":"ok","timestamp":1764351644016,"user_tz":-180,"elapsed":5054,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"e479d687-fc5f-4865-95bc-122c6f7dc556"},"outputs":[{"output_type":"stream","name":"stdout","text":["âœ“ Model loaded from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt\n","Model summary: 169 layers, 25,862,110 parameters, 0 gradients, 79.1 GFLOPs\n","\n","ğŸ“Š Model Information:\n","  Model: yolov8m_finetuned_1\n","  Classes in model: 10\n","  Task: detect\n","  Parameters: 25.9M\n","  Model Size: 0.0 MB\n","  FLOPs (640x640): 79.09 GFLOPs\n"]}],"source":["# Load YOLO model with automatic download\n","model_path = MODELS_DIR / f'{MODEL_NAME}.pt'\n","\n","if not model_path.exists():\n","    print(f'Model not found at {model_path}')\n","    print(f'Downloading {MODEL_NAME} ...')\n","\n","    try:\n","        # Download model - ensure .pt extension for ultralytics\n","        # Ultralytics expects model names with .pt extension for download\n","        if not MODEL_NAME.endswith('.pt'):\n","            model_name_for_download = MODEL_NAME + '.pt'\n","        else:\n","            model_name_for_download = MODEL_NAME\n","\n","        print(f'  Requesting model: {model_name_for_download}')\n","        model = YOLO(model_name_for_download)\n","\n","        # Create models directory\n","        MODELS_DIR.mkdir(parents=True, exist_ok=True)\n","\n","        # Save model to our directory using export/save\n","        try:\n","            # Try to save using the model's save method\n","            if hasattr(model, 'save'):\n","                model.save(str(model_path))\n","                print(f'âœ“ Model downloaded and saved to {model_path}')\n","                print(f'  Size: {model_path.stat().st_size / (1024*1024):.1f} MB')\n","            else:\n","                # Fallback: copy from cache\n","                cache_patterns = [\n","                    str(Path.home() / '.cache' / 'ultralytics' / '**' / f'{MODEL_NAME}.pt'),\n","                    str(Path.home() / '.config' / 'Ultralytics' / '**' / f'{MODEL_NAME}.pt'),\n","                ]\n","\n","                model_found = False\n","                for pattern in cache_patterns:\n","                    cache_paths = glob.glob(pattern, recursive=True)\n","                    if cache_paths:\n","                        shutil.copy(cache_paths[0], model_path)\n","                        print(f'âœ“ Model downloaded and saved to {model_path}')\n","                        print(f'  Size: {model_path.stat().st_size / (1024*1024):.1f} MB')\n","                        model_found = True\n","                        break\n","\n","                if not model_found:\n","                    print(f'âœ“ Model loaded from ultralytics cache')\n","                    print(f'  Note: Model is in cache, not copied to {model_path}')\n","                    print(f'  This is normal and the model will work correctly')\n","        except Exception as save_error:\n","            print(f'âš ï¸  Could not save model to custom location: {save_error}')\n","            print(f'âœ“ Model loaded successfully from ultralytics cache')\n","\n","    except Exception as download_error:\n","        print(f'\\nâŒ Error downloading model: {download_error}')\n","        raise\n","else:\n","    model = YOLO(str(model_path))\n","    print(f'âœ“ Model loaded from {model_path}')\n","\n","# Get model information\n","model_info_dict = {}\n","model_info_result = model.info()\n","model_info_keys = [\"layers\", \"params\", \"size(MB)\", \"FLOPs(G)\"]\n","\n","for info_key, info_value in zip(model_info_keys, model_info_result):\n","    model_info_dict[info_key] = info_value\n","\n","model_params = model_info_dict.get(\"params\", 0)\n","model_size_mb = model_info_dict.get(\"size(MB)\", 0)\n","flops_gflops = model_info_dict.get(\"FLOPs(G)\", 0)\n","\n","\n","print(f'\\nğŸ“Š Model Information:')\n","print(f'  Model: {MODEL_NAME}')\n","print(f'  Classes in model: {len(model.names)}')\n","print(f'  Task: {model.task}')\n","print(f'  Parameters: {model_params / 1e6:.1f}M')\n","print(f'  Model Size: {model_size_mb:.1f} MB')\n","print(f'  FLOPs (640x640): {flops_gflops:.2f} GFLOPs')"]},{"cell_type":"markdown","id":"5fe0b94d","metadata":{"id":"5fe0b94d"},"source":["## 5. Verify Dataset Structure"]},{"cell_type":"code","execution_count":9,"id":"71b15401","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"71b15401","executionInfo":{"status":"ok","timestamp":1764351644349,"user_tz":-180,"elapsed":331,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"8599818d-f180-4b7a-dd5d-18f7f31906cb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Verifying YOLO dataset structure...\n","\n","ğŸ“ Dataset Root: /computer_vision_yolo/bdd100k_yolo_tuning\n","  âœ“ train:  16391 images,  16391 labels\n","  âœ“ val  :  10000 images,  10000 labels\n","  âš ï¸  test : Directory not found\n","\n","ğŸ“„ Configuration: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml\n","  Classes: 10\n","  Names: {0: 'person', 1: 'rider', 2: 'car', 3: 'truck', 4: 'bus', 5: 'train', 6: 'motor', 7: 'bike', 8: 'traffic light', 9: 'traffic sign'}\n","\n","âœ“ Dataset verified: 26,391 total images\n","âœ“ Ready for hyperparameter optimization\n"]}],"source":["# ============================================================================\n","# VERIFY DATASET STRUCTURE\n","# ============================================================================\n","\n","print('Verifying YOLO dataset structure...')\n","print(f'\\nğŸ“ Dataset Root: {YOLO_DATASET_ROOT}')\n","\n","# Check all splits using constants\n","dataset_stats = {}\n","for split in [DatasetSplit.TRAIN, DatasetSplit.VAL, DatasetSplit.TEST]:\n","    images_dir = YOLO_DATASET_ROOT / 'images' / split\n","    labels_dir = YOLO_DATASET_ROOT / 'labels' / split\n","\n","    if images_dir.exists() and labels_dir.exists():\n","        num_images = len(list(images_dir.glob('*.jpg'))) + len(list(images_dir.glob('*.png')))\n","        num_labels = len(list(labels_dir.glob('*.txt')))\n","        dataset_stats[split] = {'images': num_images, 'labels': num_labels}\n","        print(f'  âœ“ {split:5s}: {num_images:6d} images, {num_labels:6d} labels')\n","    else:\n","        print(f'  âš ï¸  {split:5s}: Directory not found')\n","        dataset_stats[split] = {'images': 0, 'labels': 0}\n","\n","print(f'\\nğŸ“„ Configuration: {DATA_YAML_PATH}')\n","print(f'  Classes: {NUM_CLASSES}')\n","print(f'  Names: {CLASS_NAMES}')\n","\n","total_images = sum(stats['images'] for stats in dataset_stats.values())\n","print(f'\\nâœ“ Dataset verified: {total_images:,} total images')\n","print('âœ“ Ready for hyperparameter optimization')"]},{"cell_type":"markdown","id":"3cf76930","metadata":{"id":"3cf76930"},"source":["## 6. Define Hyperparameter Search Space"]},{"cell_type":"code","execution_count":10,"id":"06d1ae35","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"06d1ae35","executionInfo":{"status":"ok","timestamp":1764351644696,"user_tz":-180,"elapsed":346,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"75198080-8987-486d-93ca-69f7e969b7d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["âœ“ Hyperparameter search space defined\n","\n","ğŸ“Š Focused Search Space Summary:\n","  Strategy: Tune ONLY critical high-impact parameters\n","  ğŸ¯ Tuned Parameters (11):\n","    - Image Size (imgsz): 640, 800, 1024\n","    - Batch Size: Dynamic (96 for 640, 64 for 800+)\n","    - Optimizer: SGD, Adam, AdamW\n","    - Learning Rate (lr0): 1e-4 to 5e-3\n","    - Momentum: 0.85 to 0.97\n","    - Weight Decay: 1e-5 to 1e-3\n","    - Warmup Epochs: 0 to 3\n","    - Warmup Momentum: 0.5 to 0.95\n","    - Warmup Bias LR: 0.0 to 0.1\n","    - Mosaic: 0.5 to 1.0\n","    - Mixup: 0.0 to 0.2\n","  âš™ï¸  Fixed Parameters:\n","    - Epochs: 8\n","    - Device: cuda\n","  ğŸ“Œ Using YOLO defaults for: HSV augmentation, spatial transforms, loss weights\n"]}],"source":["# ============================================================================\n","# DEFINE FOCUSED HYPERPARAMETER SEARCH SPACE\n","# ============================================================================\n","\n","def define_hyperparameters(trial):\n","    \"\"\"\n","    Focused hyperparameter search for YOLO - only critical high-impact parameters.\n","\n","    Args:\n","        trial: Optuna trial object for sampling hyperparameters\n","\n","    Returns:\n","        dict: Dictionary of hyperparameters for YOLO training\n","\n","    Tuning Strategy:\n","    - Focus ONLY on parameters with proven high impact on performance\n","    - Use YOLO defaults for well-calibrated parameters (HSV, loss weights)\n","    - Reduces search space for faster convergence and better results\n","\n","    Critical Parameters Tuned:\n","    1. Image size (imgsz): 640, 800, 1024\n","    2. Batch size: Dynamically adjusted based on image size (96 for 640, 64 for 800+)\n","    3. Optimizer choice (SGD/Adam/AdamW)\n","    4. Initial learning rate (lr0): 1e-4 to 5e-3\n","    5. Momentum/beta1: 0.85 to 0.97\n","    6. Weight decay (regularization): 1e-5 to 1e-3\n","    7. Warmup epochs: 0 to 3\n","    8. Warmup momentum: 0.5 to 0.95\n","    9. Warmup bias learning rate: 0.0 to 0.1\n","    10. Mosaic augmentation strength: 0.5 to 1.0\n","    11. Mixup augmentation strength: 0.0 to 0.2\n","    \"\"\"\n","\n","    if trial is None:\n","        raise ValueError(\"Trial object cannot be None\")\n","\n","    # ---------------------------\n","    # 1) Image Size\n","    # ---------------------------\n","    # Test different image sizes to find optimal accuracy/speed tradeoff\n","    image_size = trial.suggest_categorical('imgsz', [640, 768])\n","\n","    # ---------------------------\n","    # 2) Batch Size (Dynamic based on image size)\n","    # ---------------------------\n","    # Larger images require more memory, so reduce batch size accordingly\n","    if image_size == 640:\n","        batch_size = 96  # Standard batch size for 640x640\n","    else:  # 768\n","        batch_size = 64  # Reduced batch size for larger images\n","\n","    # ---------------------------\n","    # 3) Optimizer + Learning Rate\n","    # ---------------------------\n","    optimizer_choice = trial.suggest_categorical('optimizer', ['SGD', 'Adam', 'AdamW'])\n","    lr0 = trial.suggest_float('lr0', 1e-4, 5e-3, log=True)\n","\n","    # ---------------------------\n","    # 4) Regularization\n","    # ---------------------------\n","    momentum = trial.suggest_float('momentum', 0.85, 0.97)\n","    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n","\n","    # ---------------------------\n","    # 5) Warmup Configuration\n","    # ---------------------------\n","    warmup_epochs = trial.suggest_int('warmup_epochs', 0, 3)\n","    warmup_momentum = trial.suggest_float('warmup_momentum', 0.5, 0.95)\n","    warmup_bias_lr = trial.suggest_float('warmup_bias_lr', 0.0, 0.1)\n","\n","    # ---------------------------\n","    # 6) Key Augmentation\n","    # ---------------------------\n","    # Mosaic and mixup have the highest impact on performance\n","    mosaic = trial.suggest_float('mosaic', 0.5, 1.0)\n","    mixup = trial.suggest_float('mixup', 0.0, 0.2)\n","\n","    # ---------------------------\n","    # 7) Compile parameters\n","    # ---------------------------\n","    hyperparams = {\n","        # ===== TUNED PARAMETERS (Critical for performance) =====\n","        'imgsz': image_size,\n","        'batch': batch_size,\n","        'optimizer': optimizer_choice,\n","        'lr0': lr0,\n","        'momentum': momentum,\n","        'weight_decay': weight_decay,\n","        'warmup_epochs': warmup_epochs,\n","        'warmup_momentum': warmup_momentum,\n","        'warmup_bias_lr': warmup_bias_lr,\n","        'mosaic': mosaic,\n","        'mixup': mixup,\n","\n","        # ===== DEFAULT PARAMETERS (YOLO defaults work well) =====\n","        # Learning rate decay: default 0.01 is well-calibrated\n","        # HSV augmentation: defaults (0.015, 0.7, 0.4) are optimal for most cases\n","        # Spatial augmentation: defaults for scale/translate work well\n","        # Loss weights: YOLO defaults (7.5, 0.5, 1.5) are well-balanced\n","\n","        # ===== FIXED PARAMETERS =====\n","        'epochs': EPOCHS_PER_TRIAL,\n","        'device': device,\n","        'val': True,\n","        'patience': ModelConfig.DEFAULT_PATIENCE,\n","        'save': True,\n","        'plots': True,\n","        'cache': False,\n","        'workers': ModelConfig.DEFAULT_WORKERS,\n","        'close_mosaic': ModelConfig.CLOSE_MOSAIC_EPOCHS,\n","        'verbose': True,\n","    }\n","\n","    return hyperparams\n","\n","\n","print('âœ“ Hyperparameter search space defined')\n","print('\\nğŸ“Š Focused Search Space Summary:')\n","print('  Strategy: Tune ONLY critical high-impact parameters')\n","print('  ğŸ¯ Tuned Parameters (11):')\n","print('    - Image Size (imgsz): 640, 800, 1024')\n","print('    - Batch Size: Dynamic (96 for 640, 64 for 800+)')\n","print('    - Optimizer: SGD, Adam, AdamW')\n","print('    - Learning Rate (lr0): 1e-4 to 5e-3')\n","print('    - Momentum: 0.85 to 0.97')\n","print('    - Weight Decay: 1e-5 to 1e-3')\n","print('    - Warmup Epochs: 0 to 3')\n","print('    - Warmup Momentum: 0.5 to 0.95')\n","print('    - Warmup Bias LR: 0.0 to 0.1')\n","print('    - Mosaic: 0.5 to 1.0')\n","print('    - Mixup: 0.0 to 0.2')\n","print('  âš™ï¸  Fixed Parameters:')\n","print(f'    - Epochs: {EPOCHS_PER_TRIAL}')\n","print(f'    - Device: {device}')\n","print('  ğŸ“Œ Using YOLO defaults for: HSV augmentation, spatial transforms, loss weights')"]},{"cell_type":"markdown","id":"9a8326b5","metadata":{"id":"9a8326b5"},"source":["## 7. Define Objective Function"]},{"cell_type":"code","execution_count":11,"id":"c5575796","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c5575796","executionInfo":{"status":"ok","timestamp":1764351644796,"user_tz":-180,"elapsed":98,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"842986d2-3cf4-4371-a238-52abc713ae5b"},"outputs":[{"output_type":"stream","name":"stdout","text":["âœ“ Objective function defined\n","  Returns: mAP@0.5 (validation set)\n","  Goal: Maximize validation performance\n"]}],"source":["# DEFINE OBJECTIVE FUNCTION FOR OPTUNA\n","# ============================================================================\n","\n","def objective(trial):\n","    \"\"\"Objective function for Optuna hyperparameter optimization.\n","\n","    Steps:\n","    1. Sample hyperparameters for the current trial\n","    2. Train a YOLO model with those hyperparameters\n","    3. Evaluate the model on the validation set\n","    4. Return validation mAP@0.5 (to maximize)\n","    \"\"\"\n","    # Get hyperparameters for this trial\n","    hyperparameters = define_hyperparameters(trial)\n","\n","    # Create trial-specific directory (absolute path under BASE_DIR)\n","    trial_dir = TUNE_DIR / f\"trial_{trial.number:03d}\"\n","    trial_dir.mkdir(exist_ok=True, parents=True)\n","\n","    # Initialize W&B if enabled\n","    wandb_run = None\n","    if USE_WANDB:\n","        try:\n","            os.environ['WANDB_DIR'] = str(trial_dir)\n","            wandb_run = wandb.init(\n","                project=WANDB_PROJECT_TUNING,\n","                name=f'{MODEL_NAME}_trial_{trial.number:03d}',\n","                config=hyperparameters,\n","                dir=str(trial_dir),\n","                reinit=True\n","            )\n","        except Exception as wandb_error:\n","            print(f'âš ï¸  W&B initialization failed: {wandb_error}')\n","            wandb_run = None\n","\n","    # Print trial information\n","    print(f\"\\n{'=' * 80}\")\n","    print(f\"TRIAL {trial.number}/{N_TRIALS}\")\n","    print(f\"{'=' * 80}\")\n","    print(f\"ğŸ¯ Tuned Parameters:\")\n","    print(f\"  Image Size: {hyperparameters['imgsz']}\")\n","    print(f\"  Batch Size: {hyperparameters['batch']} (auto-adjusted for image size)\")\n","    print(f\"  Optimizer: {hyperparameters['optimizer']}\")\n","    print(f\"  Learning Rate: {hyperparameters['lr0']:.6f}\")\n","    print(f\"  Momentum: {hyperparameters['momentum']:.4f}\")\n","    print(f\"  Weight Decay: {hyperparameters['weight_decay']:.6f}\")\n","    print(f\"  Warmup: epochs={hyperparameters['warmup_epochs']}, momentum={hyperparameters['warmup_momentum']:.2f}, bias_lr={hyperparameters['warmup_bias_lr']:.3f}\")\n","    print(f\"  Mosaic: {hyperparameters['mosaic']:.2f}\")\n","    print(f\"  Mixup: {hyperparameters['mixup']:.2f}\")\n","    print(f\"âœ“ Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\")\n","    print(f\"{'=' * 80}\")\n","\n","    trial_model = None\n","    map50 = 0.001  # Default penalty for failed trials\n","\n","    try:\n","        # Load fresh model for this trial\n","        trial_model = YOLO(str(model_path))\n","\n","        # Train model with hyperparameters (W&B integration via wandb.init)\n","        trial_run_name = f\"{MODEL_NAME}_trial_{trial.number:03d}\"\n","        train_results = trial_model.train(\n","            data=str(DATA_YAML_PATH),\n","            project=str(trial_dir),\n","            name=trial_run_name,\n","            exist_ok=True,\n","            **hyperparameters,\n","        )\n","\n","        # Validate model\n","        validation_results = trial_model.val(\n","            data=str(DATA_YAML_PATH),\n","            split=\"val\",\n","            project=str(trial_dir),\n","            name=\"val\",\n","            verbose=False,\n","        )\n","\n","        # Extract metrics\n","        map50 = float(validation_results.box.map50)\n","        map50_95 = float(validation_results.box.map)\n","        precision = float(validation_results.box.mp)\n","        recall = float(validation_results.box.mr)\n","\n","        # Save training metrics if available\n","        train_metrics = {}\n","        if hasattr(train_results, 'results_dict'):\n","            train_metrics = {key: float(value) if isinstance(value, (int,float,np.floating,np.integer)) else value\n","                             for key,value in train_results.results_dict.items()\n","                             if key not in ['fitness']}\n","\n","        # Save trial results JSON\n","        trial_results = {\n","            \"trial_number\": trial.number,\n","            \"model_name\": MODEL_NAME,\n","            \"dataset\": YOLO_DATASET_ROOT.name,\n","            \"trial_directory\": str(trial_dir),\n","            \"hyperparameters\": {k: float(v) if isinstance(v,(np.floating,np.integer)) else v for k,v in hyperparameters.items()},\n","            \"validation_metrics\": {\"map50\": map50, \"map50_95\": map50_95, \"precision\": precision, \"recall\": recall},\n","            \"training_metrics\": train_metrics,\n","            \"training_config\": {\n","                \"epochs\": EPOCHS_PER_TRIAL,\n","                \"batch_size\": hyperparameters['batch'],\n","                \"image_size\": hyperparameters['imgsz'],\n","                \"device\": device,\n","            },\n","            \"timestamp\": datetime.now().isoformat(),\n","            \"status\": \"completed\"\n","        }\n","\n","        trial_results_path = trial_dir / \"trial_results.json\"\n","        with open(trial_results_path, 'w', encoding='utf-8') as f:\n","            json.dump(trial_results, f, indent=2)\n","\n","        print(f'\\nâœ… Trial {trial.number} Completed')\n","        print(f'  mAP@0.5: {map50:.4f}')\n","        print(f'  mAP@0.5:0.95: {map50_95:.4f}')\n","        print(f'  Precision: {precision:.4f}')\n","        print(f'  Recall: {recall:.4f}')\n","\n","    except Exception as error:\n","        print(f'\\nâŒ Trial {trial.number} Failed: {error}')\n","\n","        # Save error information\n","        trial_results = {\n","            \"trial_number\": trial.number,\n","            \"model_name\": MODEL_NAME,\n","            \"dataset\": YOLO_DATASET_ROOT.name,\n","            \"trial_directory\": str(trial_dir),\n","            \"hyperparameters\": {k: float(v) if isinstance(v,(np.floating,np.integer)) else v for k,v in hyperparameters.items()},\n","            \"error\": str(error),\n","            \"timestamp\": datetime.now().isoformat(),\n","            \"status\": \"failed\"\n","        }\n","\n","        trial_results_path = trial_dir / \"trial_results.json\"\n","        with open(trial_results_path, 'w', encoding='utf-8') as f:\n","            json.dump(trial_results, f, indent=2)\n","\n","        # Return small penalty value instead of raising exception\n","        map50 = 0.001\n","\n","    finally:\n","        # Clean up\n","        if wandb_run is not None:\n","            wandb_run.finish()\n","\n","        # Clean up trial model\n","        if trial_model is not None:\n","            del trial_model\n","\n","        # Force garbage collection\n","        gc.collect()\n","        if device == 'cuda':\n","            torch.cuda.empty_cache()\n","            print(\"ğŸ§¹ CUDA cache cleared\")\n","\n","    return map50\n","\n","\n","print('âœ“ Objective function defined')\n","print('  Returns: mAP@0.5 (validation set)')\n","print('  Goal: Maximize validation performance')"]},{"cell_type":"markdown","id":"b9b2c034","metadata":{"id":"b9b2c034"},"source":["## 8. Run Hyperparameter Optimization"]},{"cell_type":"code","execution_count":12,"id":"e116f130","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["546cae9dc55e4161b198282c48a07e94","b5a4e722b7a741dab5bab027f5e31166","883e135a8964428db8230cc5f0400c84","de7e9fe9b7ee47aa8e69e9b1082f1cba","86b7352837b34b78a6625f7faf2edf84","31244db86381413f8a5fbe3267325f5d","c4592ad6873643d09aa47d074b8df73d","83261c95260849a18d03f5c060723129","8723c3ba4d5b414eb4e951f73653a2b6","6a31c514472747cbbcd28c87f99efaba","39e00fc59a9943dd9bc35c46ed850f6f"]},"id":"e116f130","outputId":"da0f4922-ac0d-4357-fe99-41e388bc8ca8","executionInfo":{"status":"ok","timestamp":1764361093891,"user_tz":-180,"elapsed":9449094,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","STARTING HYPERPARAMETER OPTIMIZATION\n","================================================================================\n","Model: yolov8m_finetuned_1\n","Dataset: bdd100k_yolo_tuning\n","Number of Trials: 40\n","Epochs per Trial: 8\n","Timeout: 24 hours\n","Device: cuda\n","================================================================================\n","\n","================================================================================\n","ğŸ”„ RESUMING PREVIOUS OPTIMIZATION\n","================================================================================\n","\n","ğŸ“Š Previous Run Summary:\n","  Completed Trials: 35\n","  Pruned Trials: 0\n","  Failed Trials: 0\n","  Total Previous Trials: 35\n","\n","ğŸ† Best Result So Far:\n","  Trial: 0\n","  mAP@0.5: 0.5769\n","\n","ğŸ“ˆ Top 3 Trials:\n","  1. Trial 0: mAP@0.5 = 0.5769\n","  2. Trial 22: mAP@0.5 = 0.5767\n","  3. Trial 11: mAP@0.5 = 0.5765\n","\n","ğŸ• Last Checkpoint:\n","  Timestamp: 2025-11-28 17:18:28\n","  Last Trial: 34\n","  Current Best mAP: 0.5769\n","\n","â¡ï¸  Continuing optimization: 5 trials remaining (of 40 total)\n","================================================================================\n","\n","ğŸš€ Optimization started at 2025-11-28 17:40:46\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/40 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"546cae9dc55e4161b198282c48a07e94"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mm3mahdy\u001b[0m (\u001b[33mm3mahdy-king-saud-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_035/wandb/run-20251128_174049-o3m7z13e</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/o3m7z13e' target=\"_blank\">yolov8m_finetuned_1_trial_035</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/o3m7z13e' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/o3m7z13e</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 35/40\n","================================================================================\n","ğŸ¯ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.000161\n","  Momentum: 0.9099\n","  Weight Decay: 0.000428\n","  Warmup: epochs=1, momentum=0.51, bias_lr=0.019\n","  Mosaic: 0.82\n","  Mixup: 0.02\n","âœ“ Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001614596240725037, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.023789168654792303, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.9098500376932075, mosaic=0.8205379408033115, multi_scale=False, name=yolov8m_finetuned_1_trial_035, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_035, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_035/yolov8m_finetuned_1_trial_035, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.018938388657529233, warmup_epochs=1, warmup_momentum=0.5149307497845836, weight_decay=0.00042786651935909105, workers=8, workspace=None\n","\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 77.8MB/s 0.0s\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 363.6MB/s 0.0s\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1728.0Â±645.9 MB/s, size: 53.9 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train... 16391 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16391/16391 1.5Kit/s 11.3s\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 844.1Â±388.5 MB/s, size: 56.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val... 10000 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 10000/10000 940.5it/s 10.6s\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_035/yolov8m_finetuned_1_trial_035/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0001614596240725037, momentum=0.9098500376932075) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.00042786651935909105), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_035/yolov8m_finetuned_1_trial_035\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      34.8G      1.172     0.6138      0.969        306        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.8it/s 43.4s\n","                   all      10000     185578      0.652      0.531      0.574      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      36.5G      1.167     0.6096      0.965        210        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 257/257 1.8it/s 2:23\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.9it/s 42.6s\n","                   all      10000     185578      0.653      0.531      0.577      0.334\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8        38G       1.16     0.6041     0.9619        314        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 257/257 1.8it/s 2:23\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.9it/s 42.7s\n","                   all      10000     185578      0.623      0.551      0.576      0.333\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      36.4G      1.158     0.6042     0.9603        309        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 257/257 1.8it/s 2:23\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.9it/s 42.6s\n","                   all      10000     185578      0.627       0.55      0.576      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      37.2G      1.158     0.6031     0.9594        294        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 257/257 1.8it/s 2:23\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.9it/s 42.6s\n","                   all      10000     185578      0.602      0.546      0.575      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      37.2G      1.157     0.6026     0.9594        325        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 257/257 1.8it/s 2:23\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.9it/s 42.6s\n","                   all      10000     185578      0.624       0.55      0.576      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      35.2G      1.157     0.6006     0.9617        255        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 257/257 1.8it/s 2:23\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.9it/s 42.6s\n","                   all      10000     185578      0.604      0.543      0.574      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8        35G      1.153     0.6007     0.9581        204        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 257/257 1.8it/s 2:23\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.9it/s 42.6s\n","                   all      10000     185578      0.607      0.543      0.576      0.332\n","\n","8 epochs completed in 0.422 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_035/yolov8m_finetuned_1_trial_035/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_035/yolov8m_finetuned_1_trial_035/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_035/yolov8m_finetuned_1_trial_035/weights/best.pt...\n","Ultralytics 8.3.233 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.5it/s 53.6s\n","                   all      10000     185578      0.653      0.531      0.577      0.334\n","                person       3220      13265      0.789      0.584      0.687      0.359\n","                 rider        515        649      0.617      0.501      0.509      0.272\n","                   car       9879     102540      0.851      0.723      0.816      0.513\n","                 truck       2689       4247      0.655       0.62      0.654      0.479\n","                   bus       1242       1597      0.683      0.598      0.653      0.505\n","                 train         14         15       0.19     0.0667     0.0328     0.0212\n","                 motor        334        452      0.627      0.493      0.504      0.259\n","                  bike        578       1007      0.604      0.531      0.545      0.288\n","         traffic light       5653      26891      0.761      0.565      0.654      0.258\n","          traffic sign       8221      34915      0.756      0.632       0.71      0.382\n","Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_035/yolov8m_finetuned_1_trial_035\u001b[0m\n","Ultralytics 8.3.233 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1621.0Â±597.8 MB/s, size: 64.9 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 10000/10000 7.8Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 625/625 9.7it/s 1:04\n","                   all      10000     185578      0.653      0.532      0.577      0.335\n","Speed: 0.5ms preprocess, 2.0ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_035/val\u001b[0m\n","\n","âœ… Trial 35 Completed\n","  mAP@0.5: 0.5771\n","  mAP@0.5:0.95: 0.3346\n","  Precision: 0.6530\n","  Recall: 0.5322\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_035</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/o3m7z13e' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/o3m7z13e</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_035/wandb/run-20251128_174049-o3m7z13e/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["ğŸ§¹ CUDA cache cleared\n","[I 2025-11-28 18:09:12,341] Trial 35 finished with value: 0.5770742349894156 and parameters: {'imgsz': 768, 'optimizer': 'SGD', 'lr0': 0.0001614596240725037, 'momentum': 0.9098500376932075, 'weight_decay': 0.00042786651935909105, 'warmup_epochs': 1, 'warmup_momentum': 0.5149307497845836, 'warmup_bias_lr': 0.018938388657529233, 'mosaic': 0.8205379408033115, 'mixup': 0.023789168654792303}. Best is trial 35 with value: 0.5770742349894156.\n","\n","âœ“ Completed 36/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_036/wandb/run-20251128_180912-ar0y80uc</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/ar0y80uc' target=\"_blank\">yolov8m_finetuned_1_trial_036</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/ar0y80uc' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/ar0y80uc</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 36/40\n","================================================================================\n","ğŸ¯ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: AdamW\n","  Learning Rate: 0.000222\n","  Momentum: 0.8946\n","  Weight Decay: 0.000307\n","  Warmup: epochs=0, momentum=0.54, bias_lr=0.035\n","  Mosaic: 0.76\n","  Mixup: 0.05\n","âœ“ Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00022248867701096445, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.04791713874009272, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.8946024438028313, mosaic=0.7553264786879148, multi_scale=False, name=yolov8m_finetuned_1_trial_036, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_036, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_036/yolov8m_finetuned_1_trial_036, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.03524001773688575, warmup_epochs=0, warmup_momentum=0.5365910374069301, weight_decay=0.0003067897167436233, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1712.4Â±668.4 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16391/16391 14.9Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 545.5Â±155.2 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 10000/10000 6.6Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_036/yolov8m_finetuned_1_trial_036/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00022248867701096445, momentum=0.8946024438028313) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0003067897167436233), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_036/yolov8m_finetuned_1_trial_036\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      36.7G      1.211     0.6744     0.9867        321        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 257/257 1.7it/s 2:28\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.8it/s 42.9s\n","                   all      10000     185578       0.63      0.507      0.545      0.307\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      36.7G      1.203     0.6656      0.983        290        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.8it/s 42.8s\n","                   all      10000     185578      0.728      0.505      0.552      0.313\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      36.6G      1.198     0.6541     0.9803        216        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.9it/s 42.5s\n","                   all      10000     185578      0.632      0.535      0.559      0.318\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8        35G      1.194      0.649     0.9782        179        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.9it/s 42.4s\n","                   all      10000     185578      0.661       0.52      0.567      0.321\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      37.3G      1.184     0.6366     0.9724        401        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.8it/s 42.9s\n","                   all      10000     185578      0.717      0.519      0.559      0.319\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      35.8G      1.177     0.6267     0.9673        303        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.8it/s 42.7s\n","                   all      10000     185578      0.617      0.522      0.561      0.319\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      37.6G      1.168     0.6188     0.9661        205        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.9it/s 42.7s\n","                   all      10000     185578      0.619      0.533      0.564      0.322\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      37.7G       1.16     0.6078     0.9617        166        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.9it/s 42.5s\n","                   all      10000     185578      0.643      0.522      0.566      0.324\n","\n","8 epochs completed in 0.424 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_036/yolov8m_finetuned_1_trial_036/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_036/yolov8m_finetuned_1_trial_036/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_036/yolov8m_finetuned_1_trial_036/weights/best.pt...\n","Ultralytics 8.3.233 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.5it/s 53.3s\n","                   all      10000     185578      0.643      0.522      0.566      0.324\n","                person       3220      13265      0.788       0.58      0.684      0.353\n","                 rider        515        649      0.621      0.499      0.505      0.262\n","                   car       9879     102540      0.844      0.725      0.813       0.51\n","                 truck       2689       4247      0.646      0.596      0.624      0.451\n","                   bus       1242       1597      0.668      0.575      0.629      0.484\n","                 train         14         15      0.143     0.0667      0.039     0.0275\n","                 motor        334        452       0.61      0.489      0.489      0.248\n","                  bike        578       1007      0.596      0.509      0.529      0.272\n","         traffic light       5653      26891      0.765      0.552      0.652      0.256\n","          traffic sign       8221      34915      0.752      0.626        0.7      0.375\n","Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_036/yolov8m_finetuned_1_trial_036\u001b[0m\n","Ultralytics 8.3.233 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1521.3Â±468.4 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 10000/10000 8.3Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 625/625 9.7it/s 1:04\n","                   all      10000     185578      0.643      0.522      0.567      0.324\n","Speed: 0.5ms preprocess, 2.0ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_036/val\u001b[0m\n","\n","âœ… Trial 36 Completed\n","  mAP@0.5: 0.5667\n","  mAP@0.5:0.95: 0.3243\n","  Precision: 0.6431\n","  Recall: 0.5224\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_036</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/ar0y80uc' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/ar0y80uc</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_036/wandb/run-20251128_180912-ar0y80uc/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["ğŸ§¹ CUDA cache cleared\n","[I 2025-11-28 18:37:01,432] Trial 36 finished with value: 0.5667181528282965 and parameters: {'imgsz': 768, 'optimizer': 'AdamW', 'lr0': 0.00022248867701096445, 'momentum': 0.8946024438028313, 'weight_decay': 0.0003067897167436233, 'warmup_epochs': 0, 'warmup_momentum': 0.5365910374069301, 'warmup_bias_lr': 0.03524001773688575, 'mosaic': 0.7553264786879148, 'mixup': 0.04791713874009272}. Best is trial 35 with value: 0.5770742349894156.\n","\n","âœ“ Completed 37/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_037/wandb/run-20251128_183701-fs7bwx12</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/fs7bwx12' target=\"_blank\">yolov8m_finetuned_1_trial_037</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/fs7bwx12' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/fs7bwx12</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 37/40\n","================================================================================\n","ğŸ¯ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: Adam\n","  Learning Rate: 0.000530\n","  Momentum: 0.8910\n","  Weight Decay: 0.000133\n","  Warmup: epochs=1, momentum=0.57, bias_lr=0.004\n","  Mosaic: 0.87\n","  Mixup: 0.01\n","âœ“ Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005299480991997462, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.009323764008681987, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.8910324444575807, mosaic=0.8694090705650911, multi_scale=False, name=yolov8m_finetuned_1_trial_037, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_037, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_037/yolov8m_finetuned_1_trial_037, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.003981033699452843, warmup_epochs=1, warmup_momentum=0.5666023442472398, weight_decay=0.00013259893973744007, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1799.5Â±525.9 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16391/16391 11.0Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 535.0Â±176.8 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 10000/10000 8.0Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_037/yolov8m_finetuned_1_trial_037/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.0005299480991997462, momentum=0.8910324444575807) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.00013259893973744007), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_037/yolov8m_finetuned_1_trial_037\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      35.3G      1.192      0.653     0.9753        314        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 257/257 1.7it/s 2:29\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.8it/s 43.2s\n","                   all      10000     185578      0.569      0.462      0.489      0.273\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      35.7G      1.235     0.7179     0.9978        314        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.9it/s 42.4s\n","                   all      10000     185578      0.702       0.48      0.519      0.289\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      38.9G      1.223      0.701     0.9928        230        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.9it/s 42.4s\n","                   all      10000     185578      0.716      0.493      0.534      0.299\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      38.2G      1.211     0.6842     0.9871        294        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.8it/s 43.3s\n","                   all      10000     185578      0.712      0.491      0.537      0.301\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      36.6G      1.202     0.6688      0.981        271        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.8it/s 43.1s\n","                   all      10000     185578      0.727      0.494      0.547      0.309\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      35.3G       1.19     0.6507     0.9761        166        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.8it/s 42.8s\n","                   all      10000     185578      0.622      0.505       0.55      0.312\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      37.2G      1.176     0.6322     0.9694        213        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.8it/s 42.9s\n","                   all      10000     185578      0.617      0.527      0.557      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      34.4G      1.163      0.617     0.9646        226        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.9it/s 42.6s\n","                   all      10000     185578      0.622      0.528      0.558      0.318\n","\n","8 epochs completed in 0.425 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_037/yolov8m_finetuned_1_trial_037/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_037/yolov8m_finetuned_1_trial_037/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_037/yolov8m_finetuned_1_trial_037/weights/best.pt...\n","Ultralytics 8.3.233 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.5it/s 53.4s\n","                   all      10000     185578      0.622      0.528      0.558      0.318\n","                person       3220      13265      0.774      0.581      0.674      0.348\n","                 rider        515        649      0.551      0.507      0.489      0.257\n","                   car       9879     102540      0.836      0.726       0.81      0.507\n","                 truck       2689       4247      0.625      0.615      0.621      0.448\n","                   bus       1242       1597      0.691      0.565       0.62      0.474\n","                 train         14         15      0.081     0.0667     0.0171    0.00783\n","                 motor        334        452      0.621       0.48       0.47      0.236\n","                  bike        578       1007      0.558      0.538      0.534      0.275\n","         traffic light       5653      26891      0.751      0.567      0.649      0.255\n","          traffic sign       8221      34915      0.736      0.633      0.697      0.373\n","Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_037/yolov8m_finetuned_1_trial_037\u001b[0m\n","Ultralytics 8.3.233 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1366.7Â±482.3 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 10000/10000 7.3Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 625/625 9.7it/s 1:05\n","                   all      10000     185578      0.618      0.532      0.559      0.319\n","Speed: 0.5ms preprocess, 2.0ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_037/val\u001b[0m\n","\n","âœ… Trial 37 Completed\n","  mAP@0.5: 0.5586\n","  mAP@0.5:0.95: 0.3193\n","  Precision: 0.6180\n","  Recall: 0.5319\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_037</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/fs7bwx12' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/fs7bwx12</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_037/wandb/run-20251128_183701-fs7bwx12/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["ğŸ§¹ CUDA cache cleared\n","[I 2025-11-28 19:04:53,898] Trial 37 finished with value: 0.5586432472304765 and parameters: {'imgsz': 768, 'optimizer': 'Adam', 'lr0': 0.0005299480991997462, 'momentum': 0.8910324444575807, 'weight_decay': 0.00013259893973744007, 'warmup_epochs': 1, 'warmup_momentum': 0.5666023442472398, 'warmup_bias_lr': 0.003981033699452843, 'mosaic': 0.8694090705650911, 'mixup': 0.009323764008681987}. Best is trial 35 with value: 0.5770742349894156.\n","\n","âœ“ Completed 38/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_038/wandb/run-20251128_190454-wr59xlhw</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/wr59xlhw' target=\"_blank\">yolov8m_finetuned_1_trial_038</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/wr59xlhw' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/wr59xlhw</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 38/40\n","================================================================================\n","ğŸ¯ Tuned Parameters:\n","  Image Size: 640\n","  Batch Size: 96 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.000556\n","  Momentum: 0.9208\n","  Weight Decay: 0.000711\n","  Warmup: epochs=3, momentum=0.69, bias_lr=0.004\n","  Mosaic: 0.94\n","  Mixup: 0.20\n","âœ“ Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=96, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0005562671827608824, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.19658023796985702, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.9208468793572436, mosaic=0.943400436789498, multi_scale=False, name=yolov8m_finetuned_1_trial_038, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_038, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_038/yolov8m_finetuned_1_trial_038, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0035044865075706784, warmup_epochs=3, warmup_momentum=0.6914645211274437, weight_decay=0.0007112882802612956, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1651.8Â±503.2 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16391/16391 8.1Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 343.7Â±136.6 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 10000/10000 6.0Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_038/yolov8m_finetuned_1_trial_038/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0005562671827608824, momentum=0.9208468793572436) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0010669324203919435), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_038/yolov8m_finetuned_1_trial_038\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      36.6G      1.201     0.6817     0.9777       4445        640: 55% â”â”â”â”â”â”â•¸â”€â”€â”€â”€â”€ 94/171 1.6it/s 1:04<48.8sWARNING âš ï¸ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n","\u001b[K        1/8      36.6G      1.199     0.6759     0.9764       3078        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 1.5it/s 1:55\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 53/53 1.4it/s 38.3s\n","                   all      10000     185578      0.596      0.527      0.555      0.319\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      38.5G      1.191     0.6618     0.9701       2992        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 53/53 1.4it/s 38.3s\n","                   all      10000     185578      0.594      0.525      0.554      0.318\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      37.6G      1.187     0.6556     0.9653       3261        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 53/53 1.4it/s 38.2s\n","                   all      10000     185578      0.596      0.521      0.553      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8        37G      1.183     0.6522     0.9626       3141        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 53/53 1.4it/s 38.3s\n","                   all      10000     185578      0.604      0.524      0.552      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      38.3G       1.18     0.6501     0.9609       3488        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 53/53 1.4it/s 38.1s\n","                   all      10000     185578      0.606      0.528      0.553      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8        37G      1.178     0.6479     0.9605       2923        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 53/53 1.4it/s 38.1s\n","                   all      10000     185578      0.623      0.502      0.551      0.316\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      38.1G      1.175     0.6453     0.9605       3129        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 53/53 1.4it/s 37.9s\n","                   all      10000     185578      0.619      0.501       0.55      0.315\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      38.6G      1.175     0.6437      0.959       3264        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 53/53 1.4it/s 38.1s\n","                   all      10000     185578      0.606      0.525       0.55      0.315\n","\n","8 epochs completed in 0.323 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_038/yolov8m_finetuned_1_trial_038/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_038/yolov8m_finetuned_1_trial_038/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_038/yolov8m_finetuned_1_trial_038/weights/best.pt...\n","Ultralytics 8.3.233 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 53/53 1.1it/s 49.8s\n","                   all      10000     185578      0.596      0.527      0.555      0.319\n","                person       3220      13265      0.731      0.592      0.658      0.339\n","                 rider        515        649      0.577      0.514      0.512       0.26\n","                   car       9879     102540      0.804      0.731      0.794      0.498\n","                 truck       2689       4247      0.625      0.622      0.637      0.465\n","                   bus       1242       1597      0.639      0.611      0.639      0.495\n","                 train         14         15    0.00514     0.0024     0.0225     0.0164\n","                 motor        334        452      0.598      0.506      0.492       0.25\n","                  bike        578       1007      0.541      0.534      0.515      0.266\n","         traffic light       5653      26891      0.728      0.541       0.61      0.238\n","          traffic sign       8221      34915      0.713      0.615      0.667      0.358\n","Speed: 0.1ms preprocess, 0.8ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_038/yolov8m_finetuned_1_trial_038\u001b[0m\n","Ultralytics 8.3.233 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1414.8Â±505.5 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 10000/10000 6.8Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 625/625 10.9it/s 57.5s\n","                   all      10000     185578      0.596      0.527      0.555       0.32\n","Speed: 0.4ms preprocess, 1.4ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_038/val\u001b[0m\n","\n","âœ… Trial 38 Completed\n","  mAP@0.5: 0.5552\n","  mAP@0.5:0.95: 0.3196\n","  Precision: 0.5961\n","  Recall: 0.5271\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_038</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/wr59xlhw' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/wr59xlhw</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_038/wandb/run-20251128_190454-wr59xlhw/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["ğŸ§¹ CUDA cache cleared\n","[I 2025-11-28 19:26:27,869] Trial 38 finished with value: 0.5552333786068102 and parameters: {'imgsz': 640, 'optimizer': 'SGD', 'lr0': 0.0005562671827608824, 'momentum': 0.9208468793572436, 'weight_decay': 0.0007112882802612956, 'warmup_epochs': 3, 'warmup_momentum': 0.6914645211274437, 'warmup_bias_lr': 0.0035044865075706784, 'mosaic': 0.943400436789498, 'mixup': 0.19658023796985702}. Best is trial 35 with value: 0.5770742349894156.\n","\n","âœ“ Completed 39/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_039/wandb/run-20251128_192628-wu0uprb9</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/wu0uprb9' target=\"_blank\">yolov8m_finetuned_1_trial_039</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/wu0uprb9' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/wu0uprb9</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 39/40\n","================================================================================\n","ğŸ¯ Tuned Parameters:\n","  Image Size: 640\n","  Batch Size: 96 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.000260\n","  Momentum: 0.9011\n","  Weight Decay: 0.000154\n","  Warmup: epochs=0, momentum=0.57, bias_lr=0.009\n","  Mosaic: 0.75\n","  Mixup: 0.03\n","âœ“ Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=96, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00025969974443728553, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.02807877625623379, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.9010564532726025, mosaic=0.7499675740997609, multi_scale=False, name=yolov8m_finetuned_1_trial_039, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_039, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_039/yolov8m_finetuned_1_trial_039, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.008529487882382562, warmup_epochs=0, warmup_momentum=0.5678979552619839, weight_decay=0.00015395200555927614, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1641.9Â±509.0 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16391/16391 13.7Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 432.7Â±80.8 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 10000/10000 5.3Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_039/yolov8m_finetuned_1_trial_039/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00025969974443728553, momentum=0.9010564532726025) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0002309280083389142), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_039/yolov8m_finetuned_1_trial_039\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      36.4G       1.13     0.5893     0.9396       2237        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 1.6it/s 1:47\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 53/53 1.4it/s 37.9s\n","                   all      10000     185578      0.643       0.51      0.554      0.318\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      38.2G      1.127     0.5849      0.937       2614        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 1.7it/s 1:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 53/53 1.4it/s 38.1s\n","                   all      10000     185578      0.649      0.507      0.554      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      36.1G      1.128      0.585      0.937       2001        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 1.7it/s 1:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 53/53 1.4it/s 37.9s\n","                   all      10000     185578      0.648      0.508      0.553      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      37.2G      1.127     0.5853     0.9366       2544        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 1.7it/s 1:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 53/53 1.4it/s 38.0s\n","                   all      10000     185578      0.643      0.513      0.553      0.316\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      36.4G      1.125     0.5821     0.9351       2202        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 1.7it/s 1:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 53/53 1.4it/s 38.0s\n","                   all      10000     185578      0.644      0.509      0.553      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      38.7G      1.124     0.5826     0.9357       2486        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 1.7it/s 1:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 53/53 1.4it/s 38.1s\n","                   all      10000     185578      0.637      0.512      0.553      0.316\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      36.6G      1.125     0.5819     0.9361       2512        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 1.7it/s 1:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 53/53 1.4it/s 37.9s\n","                   all      10000     185578      0.643      0.509      0.554      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      36.6G      1.122     0.5817     0.9349       2452        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 1.7it/s 1:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 53/53 1.4it/s 38.0s\n","                   all      10000     185578      0.644      0.507      0.553      0.317\n","\n","8 epochs completed in 0.316 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_039/yolov8m_finetuned_1_trial_039/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_039/yolov8m_finetuned_1_trial_039/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_039/yolov8m_finetuned_1_trial_039/weights/best.pt...\n","Ultralytics 8.3.233 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 53/53 1.1it/s 49.1s\n","                   all      10000     185578      0.643       0.51      0.554      0.318\n","                person       3220      13265      0.766      0.571      0.657      0.338\n","                 rider        515        649       0.62      0.487       0.51      0.261\n","                   car       9879     102540      0.845      0.704      0.794      0.499\n","                 truck       2689       4247      0.638      0.613      0.632      0.461\n","                   bus       1242       1597       0.66      0.597      0.636      0.491\n","                 train         14         15      0.158     0.0667     0.0259      0.018\n","                 motor        334        452      0.635      0.469       0.48      0.245\n","                  bike        578       1007      0.601      0.493      0.521      0.268\n","         traffic light       5653      26891      0.762       0.51      0.614      0.239\n","          traffic sign       8221      34915      0.748      0.587      0.669      0.358\n","Speed: 0.1ms preprocess, 0.8ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_039/yolov8m_finetuned_1_trial_039\u001b[0m\n","Ultralytics 8.3.233 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1488.2Â±451.6 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 10000/10000 8.2Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 625/625 10.9it/s 57.4s\n","                   all      10000     185578      0.643      0.511      0.555      0.319\n","Speed: 0.4ms preprocess, 1.4ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_039/val\u001b[0m\n","\n","âœ… Trial 39 Completed\n","  mAP@0.5: 0.5549\n","  mAP@0.5:0.95: 0.3190\n","  Precision: 0.6427\n","  Recall: 0.5112\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_039</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/wu0uprb9' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/wu0uprb9</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_039/wandb/run-20251128_192628-wu0uprb9/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["ğŸ§¹ CUDA cache cleared\n","[I 2025-11-28 19:47:36,439] Trial 39 finished with value: 0.5548905335656567 and parameters: {'imgsz': 640, 'optimizer': 'SGD', 'lr0': 0.00025969974443728553, 'momentum': 0.9010564532726025, 'weight_decay': 0.00015395200555927614, 'warmup_epochs': 0, 'warmup_momentum': 0.5678979552619839, 'warmup_bias_lr': 0.008529487882382562, 'mosaic': 0.7499675740997609, 'mixup': 0.02807877625623379}. Best is trial 35 with value: 0.5770742349894156.\n","\n","âœ“ Completed 40/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_040/wandb/run-20251128_194736-xyw137vb</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/xyw137vb' target=\"_blank\">yolov8m_finetuned_1_trial_040</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/xyw137vb' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/xyw137vb</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 40/40\n","================================================================================\n","ğŸ¯ Tuned Parameters:\n","  Image Size: 640\n","  Batch Size: 96 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.000349\n","  Momentum: 0.8559\n","  Weight Decay: 0.000991\n","  Warmup: epochs=1, momentum=0.87, bias_lr=0.008\n","  Mosaic: 0.97\n","  Mixup: 0.20\n","âœ“ Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=96, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0003489202891839771, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.19702415968347725, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.8559053049915213, mosaic=0.9650376225502465, multi_scale=False, name=yolov8m_finetuned_1_trial_040, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_040, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_040/yolov8m_finetuned_1_trial_040, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0076481178071809, warmup_epochs=1, warmup_momentum=0.8714204009107174, weight_decay=0.000991194711322742, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1497.2Â±535.0 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16391/16391 12.6Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 539.0Â±121.3 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 10000/10000 5.7Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_040/yolov8m_finetuned_1_trial_040/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0003489202891839771, momentum=0.8559053049915213) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.001486792066984113), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_040/yolov8m_finetuned_1_trial_040\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      38.9G      1.195     0.6693      0.973       3562        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 1.6it/s 1:50\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 53/53 1.4it/s 38.5s\n","                   all      10000     185578      0.595      0.525      0.555      0.318\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      37.5G      1.188     0.6568     0.9654       3012        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 53/53 1.4it/s 38.4s\n","                   all      10000     185578      0.621      0.507      0.554      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      36.8G      1.185     0.6547     0.9634       3082        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 53/53 1.4it/s 38.3s\n","                   all      10000     185578      0.622      0.506      0.552      0.316\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      36.1G      1.177     0.6478     0.9611       3074        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 53/53 1.4it/s 38.3s\n","                   all      10000     185578      0.623      0.504      0.552      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      36.9G      1.178     0.6496     0.9596       3544        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 53/53 1.4it/s 38.4s\n","                   all      10000     185578      0.638      0.515      0.553      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      38.7G      1.177     0.6478     0.9614       3130        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 53/53 1.4it/s 38.3s\n","                   all      10000     185578      0.638      0.515      0.553      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      37.2G      1.183     0.6508     0.9626       3225        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 1.7it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 53/53 1.4it/s 38.2s\n","                   all      10000     185578      0.636      0.515      0.553      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8        36G      1.177     0.6512     0.9586       4598        640: 4% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 6/171 1.5it/s 4.2s<1:52WARNING âš ï¸ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n","\u001b[K        8/8      36.9G      1.177     0.6473     0.9605       3043        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 171/171 1.6it/s 1:49\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 53/53 1.4it/s 38.4s\n","                   all      10000     185578      0.636      0.514      0.553      0.317\n","\n","8 epochs completed in 0.324 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_040/yolov8m_finetuned_1_trial_040/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_040/yolov8m_finetuned_1_trial_040/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_040/yolov8m_finetuned_1_trial_040/weights/best.pt...\n","Ultralytics 8.3.233 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 53/53 1.1it/s 49.9s\n","                   all      10000     185578      0.596      0.526      0.555      0.318\n","                person       3220      13265      0.726      0.593      0.658      0.338\n","                 rider        515        649      0.579      0.508      0.513       0.26\n","                   car       9879     102540      0.801      0.731      0.793      0.497\n","                 truck       2689       4247      0.611      0.632      0.637      0.464\n","                   bus       1242       1597      0.646      0.609       0.64      0.494\n","                 train         14         15     0.0118    0.00395     0.0255     0.0173\n","                 motor        334        452      0.595      0.504      0.493      0.253\n","                  bike        578       1007      0.545      0.522      0.515      0.263\n","         traffic light       5653      26891      0.728      0.542      0.611      0.238\n","          traffic sign       8221      34915      0.714      0.615      0.668      0.357\n","Speed: 0.1ms preprocess, 0.8ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_040/yolov8m_finetuned_1_trial_040\u001b[0m\n","Ultralytics 8.3.233 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1484.9Â±420.4 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 10000/10000 7.5Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 625/625 10.7it/s 58.2s\n","                   all      10000     185578      0.596      0.525      0.556      0.319\n","Speed: 0.4ms preprocess, 1.4ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_040/val\u001b[0m\n","\n","âœ… Trial 40 Completed\n","  mAP@0.5: 0.5561\n","  mAP@0.5:0.95: 0.3192\n","  Precision: 0.5962\n","  Recall: 0.5254\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_040</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/xyw137vb' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/xyw137vb</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_040/wandb/run-20251128_194736-xyw137vb/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["ğŸ§¹ CUDA cache cleared\n","[I 2025-11-28 20:09:14,233] Trial 40 finished with value: 0.5561320329377647 and parameters: {'imgsz': 640, 'optimizer': 'SGD', 'lr0': 0.0003489202891839771, 'momentum': 0.8559053049915213, 'weight_decay': 0.000991194711322742, 'warmup_epochs': 1, 'warmup_momentum': 0.8714204009107174, 'warmup_bias_lr': 0.0076481178071809, 'mosaic': 0.9650376225502465, 'mixup': 0.19702415968347725}. Best is trial 35 with value: 0.5770742349894156.\n","\n","âœ“ Completed 41/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_041/wandb/run-20251128_200914-tmza9m3l</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/tmza9m3l' target=\"_blank\">yolov8m_finetuned_1_trial_041</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/tmza9m3l' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/tmza9m3l</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 41/40\n","================================================================================\n","ğŸ¯ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.000236\n","  Momentum: 0.9335\n","  Weight Decay: 0.000335\n","  Warmup: epochs=1, momentum=0.54, bias_lr=0.023\n","  Mosaic: 0.90\n","  Mixup: 0.01\n","âœ“ Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00023610953279924895, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.005637501635348943, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.9334630232585438, mosaic=0.8966792095706233, multi_scale=False, name=yolov8m_finetuned_1_trial_041, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_041, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_041/yolov8m_finetuned_1_trial_041, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.02284296681450065, warmup_epochs=1, warmup_momentum=0.5409541831782676, weight_decay=0.0003346298991138973, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1657.6Â±507.9 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16391/16391 15.1Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 477.4Â±105.8 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 10000/10000 5.6Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_041/yolov8m_finetuned_1_trial_041/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00023610953279924895, momentum=0.9334630232585438) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0003346298991138973), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_041/yolov8m_finetuned_1_trial_041\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      35.8G      1.158     0.6025     0.9613        395        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 257/257 1.7it/s 2:29\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.8it/s 42.7s\n","                   all      10000     185578      0.655       0.53      0.576      0.333\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      35.2G      1.152     0.5968     0.9575        244        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 257/257 1.8it/s 2:23\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 79/79 1.8it/s 42.8s\n","                   all      10000     185578      0.645      0.532      0.576      0.333\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      35.1G      1.149     0.5945     0.9567        254        768: 100% â”â”â”â”â”â”â”â”â”â”â”â” 257/257 1.8it/s 2:23\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4/79 1.1s/it 2.6s<1:20\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_041</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/tmza9m3l' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/tmza9m3l</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_041/wandb/run-20251128_200914-tmza9m3l/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["ğŸ§¹ CUDA cache cleared\n","[W 2025-11-28 20:18:13,970] Trial 41 failed with parameters: {'imgsz': 768, 'optimizer': 'SGD', 'lr0': 0.00023610953279924895, 'momentum': 0.9334630232585438, 'weight_decay': 0.0003346298991138973, 'warmup_epochs': 1, 'warmup_momentum': 0.5409541831782676, 'warmup_bias_lr': 0.02284296681450065, 'mosaic': 0.8966792095706233, 'mixup': 0.005637501635348943} because of the following error: KeyboardInterrupt().\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n","    value_or_values = func(trial)\n","                      ^^^^^^^^^^^\n","  File \"/tmp/ipython-input-848837866.py\", line 62, in objective\n","    train_results = trial_model.train(\n","                    ^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\", line 773, in train\n","    self.trainer.train()\n","  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\", line 243, in train\n","    self._do_train()\n","  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\", line 478, in _do_train\n","    self.metrics, self.fitness = self.validate()\n","                                 ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\", line 704, in validate\n","    metrics = self.validator(self)\n","              ^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n","    return func(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/engine/validator.py\", line 221, in __call__\n","    preds = self.postprocess(preds)\n","            ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/models/yolo/detect/val.py\", line 115, in postprocess\n","    outputs = nms.non_max_suppression(\n","              ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/utils/nms.py\", line 154, in non_max_suppression\n","    i = torchvision.ops.nms(boxes, scores, iou_thres)\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torchvision/ops/boxes.py\", line 48, in nms\n","    return torch.ops.torchvision.nms(boxes, scores, iou_threshold)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1255, in __call__\n","    return self._op(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^\n","KeyboardInterrupt\n","[W 2025-11-28 20:18:13,974] Trial 41 failed with value None.\n","\n","âš ï¸  Optimization interrupted by user\n","ğŸ’¾ Progress saved to: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340\n","   - Study checkpoint: optuna_study.pkl\n","   - Checkpoint log: checkpoint_log.json\n","\n","ğŸ”„ To resume: Simply re-run this notebook\n","\n","================================================================================\n","OPTIMIZATION COMPLETED\n","================================================================================\n","Started: 2025-11-28 17:40:46\n","Ended: 2025-11-28 20:18:13\n","Duration: 2:37:27.650793\n","Total Trials: 42\n","Completed Trials: 41\n","Pruned Trials: 0\n","Failed Trials: 1\n","\n","Best Trial: 35\n","Best mAP@0.5: 0.5771\n","================================================================================\n"]}],"source":["# RUN HYPERPARAMETER OPTIMIZATION WITH OPTUNA\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('STARTING HYPERPARAMETER OPTIMIZATION')\n","print('=' * 80)\n","print(f'Model: {MODEL_NAME}')\n","print(f'Dataset: {YOLO_DATASET_ROOT.name}')\n","print(f'Number of Trials: {N_TRIALS}')\n","print(f'Epochs per Trial: {EPOCHS_PER_TRIAL}')\n","print(f'Timeout: {TIMEOUT_HOURS} hours' if TIMEOUT_HOURS else 'No timeout')\n","print(f'Device: {device}')\n","print('=' * 80)\n","\n","# Check if resuming from previous run\n","study_pkl_path = TUNE_DIR / 'optuna_study.pkl'\n","checkpoint_log_path = TUNE_DIR / 'checkpoint_log.json'\n","is_resuming = study_pkl_path.exists()\n","\n","if is_resuming:\n","    # Load existing study\n","    print('\\n' + '=' * 80)\n","    print('ğŸ”„ RESUMING PREVIOUS OPTIMIZATION')\n","    print('=' * 80)\n","\n","    with open(study_pkl_path, 'rb') as f:\n","        study = pickle.load(f)\n","\n","    # Load checkpoint log\n","    checkpoint_data = []\n","    if checkpoint_log_path.exists():\n","        with open(checkpoint_log_path, 'r', encoding='utf-8') as f:\n","            checkpoint_data = json.load(f)\n","\n","    # Display resume information\n","    completed_trials = len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])\n","    pruned_trials = len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])\n","    failed_trials = len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL])\n","    total_previous_trials = len(study.trials)\n","\n","    print(f'\\nğŸ“Š Previous Run Summary:')\n","    print(f'  Completed Trials: {completed_trials}')\n","    print(f'  Pruned Trials: {pruned_trials}')\n","    print(f'  Failed Trials: {failed_trials}')\n","    print(f'  Total Previous Trials: {total_previous_trials}')\n","\n","    if completed_trials > 0:\n","        best_trial = study.best_trial\n","        print(f'\\nğŸ† Best Result So Far:')\n","        print(f'  Trial: {best_trial.number}')\n","        print(f'  mAP@0.5: {best_trial.value:.4f}')\n","\n","        # Show top 3 completed trials\n","        completed_trial_list = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n","        sorted_trials = sorted(completed_trial_list, key=lambda t: t.value, reverse=True)\n","        top_3_trials = sorted_trials[:3]\n","\n","        print(f'\\nğŸ“ˆ Top 3 Trials:')\n","        for idx, trial in enumerate(top_3_trials, 1):\n","            print(f'  {idx}. Trial {trial.number}: mAP@0.5 = {trial.value:.4f}')\n","\n","    # Show last checkpoint info\n","    if checkpoint_data:\n","        last_checkpoint = checkpoint_data[-1]\n","        print(f'\\nğŸ• Last Checkpoint:')\n","        print(f'  Timestamp: {last_checkpoint[\"timestamp\"]}')\n","        print(f'  Last Trial: {last_checkpoint[\"trial_number\"]}')\n","        print(f'  Current Best mAP: {last_checkpoint[\"best_map\"]:.4f}')\n","\n","    remaining_trials = N_TRIALS - total_previous_trials\n","    print(f'\\nâ¡ï¸  Continuing optimization: {remaining_trials} trials remaining (of {N_TRIALS} total)')\n","    print('=' * 80)\n","\n","else:\n","    # Create new Optuna study\n","    print('\\nğŸ†• Creating new optimization study')\n","\n","    study = optuna.create_study(\n","        study_name=f'{MODEL_NAME}_optuna_{RUN_TIMESTAMP}',\n","        direction='maximize',  # Maximize mAP@0.5\n","        sampler=optuna.samplers.TPESampler(\n","            seed=42,\n","            n_startup_trials=N_STARTUP_TRIALS,  # Random trials before optimization\n","            multivariate=True,  # Consider parameter interactions\n","            group=True  # Group related parameters\n","        ),\n","        pruner=optuna.pruners.MedianPruner(\n","            n_startup_trials=N_STARTUP_TRIALS,\n","            n_warmup_steps=15,  # Wait before pruning\n","            interval_steps=5  # Check every 5 steps\n","        )\n","    )\n","\n","    # Initialize checkpoint log\n","    checkpoint_data = []\n","\n","# Run optimization\n","start_time = datetime.now()\n","print(f'\\nğŸš€ Optimization started at {start_time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n","\n","# Define checkpoint callback\n","def checkpoint_callback(study, trial):\n","    \"\"\"Save checkpoint after each trial completion\"\"\"\n","    print(f'\\nâœ“ Completed {len(study.trials)}/{N_TRIALS} trials')\n","\n","    # Update checkpoint log\n","    checkpoint_entry = {\n","        'trial_number': trial.number,\n","        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n","        'trial_state': trial.state.name,\n","        'best_map': study.best_value if len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]) > 0 else 0.0,\n","        'completed_trials': len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]),\n","        'total_trials': len(study.trials)\n","    }\n","    checkpoint_data.append(checkpoint_entry)\n","\n","    # Save checkpoint log\n","    with open(checkpoint_log_path, 'w', encoding='utf-8') as f:\n","        json.dump(checkpoint_data, f, indent=2)\n","\n","    # Save study object\n","    with open(study_pkl_path, 'wb') as f:\n","        pickle.dump(study, f)\n","\n","    # Force garbage collection\n","    gc.collect()\n","\n","try:\n","    study.optimize(\n","        objective,\n","        n_trials=N_TRIALS,\n","        timeout=TIMEOUT_HOURS * 3600 if TIMEOUT_HOURS else None,\n","        show_progress_bar=True,\n","        callbacks=[checkpoint_callback]\n","    )\n","except KeyboardInterrupt:\n","    print('\\nâš ï¸  Optimization interrupted by user')\n","    print(f'ğŸ’¾ Progress saved to: {TUNE_DIR}')\n","    print(f'   - Study checkpoint: {study_pkl_path.name}')\n","    print(f'   - Checkpoint log: {checkpoint_log_path.name}')\n","    print(f'\\nğŸ”„ To resume: Simply re-run this notebook')\n","except Exception as e:\n","    print(f'\\nâŒ Optimization failed: {e}')\n","    import traceback\n","    traceback.print_exc()\n","\n","end_time = datetime.now()\n","duration = end_time - start_time\n","\n","print('\\n' + '=' * 80)\n","print('OPTIMIZATION COMPLETED')\n","print('=' * 80)\n","print(f'Started: {start_time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n","print(f'Ended: {end_time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n","print(f'Duration: {duration}')\n","print(f'Total Trials: {len(study.trials)}')\n","print(f'Completed Trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}')\n","print(f'Pruned Trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}')\n","print(f'Failed Trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL])}')\n","print(f'\\nBest Trial: {study.best_trial.number}')\n","print(f'Best mAP@0.5: {study.best_value:.4f}')\n","print('=' * 80)"]},{"cell_type":"markdown","id":"c5ab4d62","metadata":{"id":"c5ab4d62"},"source":["## 9. Save All Trials Summary"]},{"cell_type":"code","execution_count":13,"id":"0a3c5d31","metadata":{"id":"0a3c5d31","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764361120710,"user_tz":-180,"elapsed":26815,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"1c2b9471-5989-4133-c855-64b3afaebdd6"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","SAVING CONSOLIDATED TRIAL SUMMARY\n","================================================================================\n","âš ï¸  No results file found for trial 41\n","âœ“ Consolidated JSON summary saved: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/yolov8m_finetuned_1_all_trials_summary.json\n","  Total trials saved: 41\n","âœ“ CSV summary saved: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/yolov8m_finetuned_1_all_trials_summary.csv\n","  Columns: 29, Rows: 41\n","================================================================================\n","\n","ğŸ“Š Trial Summary Statistics:\n","  Completed Trials: 41\n","  Failed Trials: 0\n","\n","  mAP@0.5 Statistics:\n","    Best: 0.5771 (Trial 35)\n","    Worst: 0.5258\n","    Mean: 0.5647\n","    Std: 0.0126\n","    Median: 0.5673\n","================================================================================\n"]}],"source":["# SAVE CONSOLIDATED SUMMARY OF ALL TRIALS\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('SAVING CONSOLIDATED TRIAL SUMMARY')\n","print('=' * 80)\n","\n","# Collect all trial results dynamically from study\n","all_trials_data = []\n","\n","for trial in study.trials:\n","    trial_dir = TUNE_DIR / f\"trial_{trial.number:03d}\"\n","    results_file = trial_dir / \"trial_results.json\"\n","\n","    if results_file.exists():\n","        try:\n","            with open(results_file, 'r') as f:\n","                trial_data = json.load(f)\n","                all_trials_data.append(trial_data)\n","        except Exception as e:\n","            print(f\"âš ï¸  Could not read trial {trial.number} results: {e}\")\n","    else:\n","        print(f\"âš ï¸  No results file found for trial {trial.number}\")\n","\n","# Create comprehensive summary\n","optimization_summary = {\n","    \"model_name\": MODEL_NAME,\n","    \"dataset\": YOLO_DATASET_ROOT.name,\n","    \"optimization_config\": {\n","        \"n_trials\": N_TRIALS,\n","        \"epochs_per_trial\": EPOCHS_PER_TRIAL,\n","        \"batch_size\": BATCH_SIZE,\n","        \"timeout_hours\": TIMEOUT_HOURS,\n","        \"n_startup_trials\": N_STARTUP_TRIALS,\n","    },\n","    \"optimization_results\": {\n","        \"start_time\": start_time.isoformat(),\n","        \"end_time\": end_time.isoformat(),\n","        \"duration_seconds\": duration.total_seconds(),\n","        \"total_trials\": len(study.trials),\n","        \"completed_trials\": len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]),\n","        \"pruned_trials\": len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]),\n","        \"failed_trials\": len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL]),\n","        \"best_trial_number\": study.best_trial.number,\n","        \"best_map50\": study.best_value,\n","    },\n","    \"best_hyperparameters\": study.best_params,\n","    \"all_trials\": all_trials_data,\n","    \"timestamp\": datetime.now().isoformat(),\n","}\n","\n","# Save consolidated summary as JSON\n","summary_path = TUNE_DIR / f\"{MODEL_NAME}_all_trials_summary.json\"\n","with open(summary_path, 'w') as f:\n","    json.dump(optimization_summary, f, indent=2)\n","\n","print(f'âœ“ Consolidated JSON summary saved: {summary_path}')\n","print(f'  Total trials saved: {len(all_trials_data)}')\n","\n","# Create CSV summary for easy analysis\n","csv_data = []\n","for trial_data in all_trials_data:\n","    row = {\n","        'trial_number': trial_data.get('trial_number'),\n","        'status': trial_data.get('status'),\n","        'map50': trial_data.get('validation_metrics', {}).get('map50'),\n","        'map50_95': trial_data.get('validation_metrics', {}).get('map50_95'),\n","        'precision': trial_data.get('validation_metrics', {}).get('precision'),\n","        'recall': trial_data.get('validation_metrics', {}).get('recall'),\n","        'error_type': trial_data.get('error_type', '')  # Include error type if failed\n","    }\n","    # Add hyperparameters\n","    for key, value in trial_data.get('hyperparameters', {}).items():\n","        row[f'hp_{key}'] = value\n","    # Flag best trial\n","    row['best_trial'] = trial_data.get('trial_number') == study.best_trial.number\n","    csv_data.append(row)\n","\n","df_trials = pd.DataFrame(csv_data)\n","\n","# Sort CSV by mAP@0.5 descending (best first)\n","df_trials.sort_values(by='map50', ascending=False, inplace=True)\n","\n","# Save CSV\n","csv_path = TUNE_DIR / f\"{MODEL_NAME}_all_trials_summary.csv\"\n","df_trials.to_csv(csv_path, index=False)\n","\n","print(f'âœ“ CSV summary saved: {csv_path}')\n","print(f'  Columns: {len(df_trials.columns)}, Rows: {len(df_trials)}')\n","print('=' * 80)\n","\n","# Display summary statistics\n","if len(df_trials) > 0:\n","    print('\\nğŸ“Š Trial Summary Statistics:')\n","    print(f'  Completed Trials: {len(df_trials[df_trials[\"status\"] == \"completed\"])}')\n","    print(f'  Failed Trials: {len(df_trials[df_trials[\"status\"] == \"failed\"])}')\n","\n","    completed_trials = df_trials[df_trials['status'] == 'completed']\n","    if len(completed_trials) > 0:\n","        best_trial_row = completed_trials.loc[completed_trials[\"map50\"].idxmax()]\n","        print(f'\\n  mAP@0.5 Statistics:')\n","        print(f'    Best: {best_trial_row[\"map50\"]:.4f} (Trial {best_trial_row[\"trial_number\"]})')\n","        print(f'    Worst: {completed_trials[\"map50\"].min():.4f}')\n","        print(f'    Mean: {completed_trials[\"map50\"].mean():.4f}')\n","        print(f'    Std: {completed_trials[\"map50\"].std():.4f}')\n","        print(f'    Median: {completed_trials[\"map50\"].median():.4f}')\n","print('=' * 80)"]},{"cell_type":"markdown","id":"923833ab","metadata":{"id":"923833ab"},"source":["## 10. Save Best Hyperparameters"]},{"cell_type":"code","execution_count":14,"id":"58d702ef","metadata":{"id":"58d702ef","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764361120738,"user_tz":-180,"elapsed":7,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"49ee1d32-4b98-469f-a5bb-02ff7b13990b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","SAVING BEST HYPERPARAMETERS\n","================================================================================\n","\n","ğŸ† Best Trial: 35\n","   Best mAP@0.5: 0.5771\n","\n","ğŸ“‹ Best Hyperparameters:\n","   imgsz: 768\n","   optimizer: SGD\n","   lr0: 0.0001614596240725037\n","   momentum: 0.9098500376932075\n","   weight_decay: 0.00042786651935909105\n","   warmup_epochs: 1\n","   warmup_momentum: 0.5149307497845836\n","   warmup_bias_lr: 0.018938388657529233\n","   mosaic: 0.8205379408033115\n","   mixup: 0.023789168654792303\n","\n","âœ“ Best hyperparameters saved to: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/best_hyperparameters.json\n","âœ“ Best hyperparameters saved to: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/best_hyperparameters.yaml\n","\n","ğŸ“‹ Best Hyperparameters Summary:\n","  Optimizer: SGD\n","  Learning Rate: 0.000161\n","  Momentum: 0.9099\n","  Weight Decay: 0.000428\n","================================================================================\n"]}],"source":["# SAVE BEST HYPERPARAMETERS\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('SAVING BEST HYPERPARAMETERS')\n","print('=' * 80)\n","\n","# Extract best parameters from study\n","best_params = study.best_params\n","best_trial = study.best_trial\n","\n","print(f'\\nğŸ† Best Trial: {best_trial.number}')\n","print(f'   Best mAP@0.5: {study.best_value:.4f}')\n","print('\\nğŸ“‹ Best Hyperparameters:')\n","for param_name, param_value in best_params.items():\n","    print(f'   {param_name}: {param_value}')\n","\n","# Save best hyperparameters to JSON\n","best_params_json = TUNE_DIR / 'best_hyperparameters.json'\n","with open(best_params_json, 'w') as f:\n","    json.dump({\n","        'model': MODEL_NAME,\n","        'dataset_root': str(YOLO_DATASET_ROOT),\n","        'data_yaml_path': str(DATA_YAML_PATH),\n","        'optimization_results': {\n","            'best_trial': study.best_trial.number,\n","            'best_map50': study.best_value,\n","            'total_trials': len(study.trials),\n","            'optimization_duration': str(duration),\n","        },\n","        'hyperparameters': best_params,\n","        'timestamp': datetime.now().isoformat(),\n","        'notes': 'Use these hyperparameters for training. Add epochs, batch, imgsz, device, and other training settings.'\n","    }, f, indent=2)\n","\n","print(f'\\nâœ“ Best hyperparameters saved to: {best_params_json}')\n","\n","# Save to YAML format (ready for YOLO training)\n","best_params_yaml = TUNE_DIR / 'best_hyperparameters.yaml'\n","with open(best_params_yaml, 'w') as f:\n","    yaml.dump(best_params, f, default_flow_style=False, sort_keys=False)\n","\n","print(f'âœ“ Best hyperparameters saved to: {best_params_yaml}')\n","\n","print('\\nğŸ“‹ Best Hyperparameters Summary:')\n","print(f'  Optimizer: {best_params.get(\"optimizer\", \"N/A\")}')\n","print(f'  Learning Rate: {best_params.get(\"lr0\", 0):.6f}')\n","print(f'  Momentum: {best_params.get(\"momentum\", 0):.4f}')\n","print(f'  Weight Decay: {best_params.get(\"weight_decay\", 0):.6f}')\n","\n","print('=' * 80)"]},{"cell_type":"code","source":["# ============================================================================\n","# INSTALL AND VERIFY KALEIDO (Required for PNG export of Plotly figures)\n","# ============================================================================\n","# Run this cell to ensure kaleido is installed correctly\n","\n","import subprocess\n","import sys\n","\n","# Force reinstall kaleido with a specific compatible version\n","print('ğŸ“¦ Installing kaleido (this may take a moment)...')\n","result = subprocess.run(\n","    [sys.executable, '-m', 'pip', 'install', '--upgrade', '--force-reinstall', 'kaleido==0.2.1'],\n","    capture_output=True,\n","    text=True\n",")\n","\n","if result.returncode == 0:\n","    print('âœ“ Kaleido 0.2.1 installed successfully')\n","else:\n","    print(f'âš ï¸  Installation warning: {result.stderr}')\n","\n","# Try importing kaleido\n","try:\n","    import kaleido\n","    print('âœ“ Kaleido module imported')\n","except ImportError as e:\n","    print(f'âŒ Failed to import kaleido: {e}')\n","    print('   Please restart the runtime: Runtime > Restart Runtime')\n","\n","# Verify kaleido works with plotly\n","print('\\nğŸ§ª Testing kaleido with Plotly...')\n","try:\n","    import plotly.graph_objects as go\n","    import plotly.io as pio\n","\n","    # Create a simple test figure\n","    test_fig = go.Figure(data=[go.Scatter(x=[1, 2, 3], y=[1, 2, 3])])\n","\n","    # Try to convert to PNG bytes (doesn't write to disk)\n","    img_bytes = test_fig.to_image(format=\"png\", width=100, height=100, engine=\"kaleido\")\n","    print(f'âœ“ Kaleido is working correctly! (Generated {len(img_bytes)} bytes)')\n","    print('âœ… PNG export is ready to use')\n","\n","except Exception as e:\n","    print(f'âŒ Kaleido test failed: {type(e).__name__}')\n","    print(f'   Error: {e}')\n","    print('\\nâš ï¸  ACTION REQUIRED:')\n","    print('   1. Go to: Runtime > Restart Runtime')\n","    print('   2. After restart, run all cells again')\n","    print('   3. Kaleido should work after the runtime restart')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bNZompoiMHYL","executionInfo":{"status":"ok","timestamp":1764362448692,"user_tz":-180,"elapsed":5826,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"c1ec7eb4-ba3b-4996-cb49-74d789a9746d"},"id":"bNZompoiMHYL","execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ“¦ Installing kaleido (this may take a moment)...\n","âœ“ Kaleido 0.2.1 installed successfully\n","âœ“ Kaleido module imported\n","\n","ğŸ§ª Testing kaleido with Plotly...\n","âŒ Kaleido test failed: ValueError\n","   Error: \n","Image export using the \"kaleido\" engine requires the kaleido package,\n","which can be installed using pip:\n","    $ pip install -U kaleido\n","\n","\n","âš ï¸  ACTION REQUIRED:\n","   1. Go to: Runtime > Restart Runtime\n","   2. After restart, run all cells again\n","   3. Kaleido should work after the runtime restart\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# WORKAROUND: Convert Plotly figures to PNG without kaleido\n","# ============================================================================\n","# This cell provides an alternative to save PNG images when kaleido doesn't work\n","\n","def save_plotly_as_png_alternative(fig, output_path, width=1200, height=800):\n","    \"\"\"\n","    Alternative method to save Plotly figure as PNG without kaleido.\n","    Uses matplotlib as a fallback by converting through static image.\n","    \"\"\"\n","    try:\n","        # Method 1: Try orca (older engine, might be available)\n","        try:\n","            fig.write_image(str(output_path), width=width, height=height, scale=2, engine=\"orca\")\n","            return True, \"orca\"\n","        except:\n","            pass\n","\n","        # Method 2: Save as SVG then convert (requires cairosvg)\n","        try:\n","            import cairosvg\n","            svg_path = str(output_path).replace('.png', '_temp.svg')\n","            fig.write_image(svg_path, width=width, height=height, format='svg')\n","            cairosvg.svg2png(url=svg_path, write_to=str(output_path), output_width=width, output_height=height)\n","            os.remove(svg_path)\n","            return True, \"svg+cairosvg\"\n","        except:\n","            pass\n","\n","        # Method 3: Use selenium/chrome (Colab has chrome)\n","        try:\n","            import plotly.io as pio\n","            pio.kaleido.scope.chromium_args = tuple([arg for arg in pio.kaleido.scope.chromium_args if arg != \"--disable-dev-shm-usage\"])\n","            fig.write_image(str(output_path), width=width, height=height, scale=2)\n","            return True, \"kaleido-fixed\"\n","        except:\n","            pass\n","\n","        # Method 4: Just save high-quality HTML (can be converted later)\n","        html_path = str(output_path).replace('.png', '_hq.html')\n","        fig.write_html(\n","            html_path,\n","            config={'toImageButtonOptions': {'format': 'png', 'width': width, 'height': height, 'scale': 2}}\n","        )\n","        print(f'   â„¹ï¸  Saved high-quality HTML instead: {html_path}')\n","        print(f'      You can open it and use the camera icon to download PNG')\n","        return False, \"html-fallback\"\n","\n","    except Exception as e:\n","        print(f'   âŒ All conversion methods failed: {e}')\n","        return False, \"failed\"\n","\n","print('âœ“ PNG conversion workaround functions loaded')\n","print('  Use save_plotly_as_png_alternative(fig, path) to save PNG files')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nx1Kt5Y3M4kQ","executionInfo":{"status":"ok","timestamp":1764362524159,"user_tz":-180,"elapsed":48,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"c62d46f1-0332-4c50-b0d0-563e4e6be044"},"id":"Nx1Kt5Y3M4kQ","execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ“ PNG conversion workaround functions loaded\n","  Use save_plotly_as_png_alternative(fig, path) to save PNG files\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# SIMPLE SOLUTION: Manually download PNGs from the interactive plots above\n","# ============================================================================\n","# Since kaleido isn't working, here's what to do:\n","#\n","# 1. Scroll up to the interactive Plotly visualizations displayed above\n","# 2. Hover over each plot and you'll see a camera icon in the top-right\n","# 3. Click the camera icon to download the PNG file\n","# 4. The files will be saved to your Downloads folder\n","# 5. Upload them to your Colab files or Drive if needed\n","#\n","# Or, use this cell to get download links for the HTML files:\n","\n","print('ğŸ“Š Your visualization files:')\n","print('=' * 80)\n","\n","# Find the latest HTML files\n","import glob\n","from pathlib import Path\n","\n","tune_dir = Path(TUNE_DIR)\n","html_files = {\n","    'Optimization History': sorted(tune_dir.glob('optimization_history_*.html'))[-1:],\n","    'Parameter Importance': sorted(tune_dir.glob('parameter_importance_*.html'))[-1:],\n","    'Parameter Slice': sorted(tune_dir.glob('parameter_slice_*.html'))[-1:]\n","}\n","\n","for title, files in html_files.items():\n","    if files:\n","        file_path = files[0]\n","        print(f'\\n{title}:')\n","        print(f'  ğŸ“ {file_path}')\n","        print(f'  ğŸ’¡ Open this file in Colab and click the camera icon to download PNG')\n","\n","print('\\n' + '=' * 80)\n","print('ğŸ“ To download PNG files:')\n","print('  1. Open each HTML file by double-clicking it in the Files panel')\n","print('  2. The interactive plot will open in a new tab')\n","print('  3. Hover over the plot and click the camera icon (ğŸ“·) in the toolbar')\n","print('  4. The PNG will download automatically')\n","print('\\nğŸ’¡ Alternative: Run the plots again after restarting runtime')\n","print('   (Your study results are saved in the .pkl file, so they won\\'t be lost!)')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ZS2cyB4NCls","executionInfo":{"status":"ok","timestamp":1764362565079,"user_tz":-180,"elapsed":10,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"e0bc9569-00ae-4d1b-cf0f-4fed9ec09cf9"},"id":"2ZS2cyB4NCls","execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ“Š Your visualization files:\n","================================================================================\n","\n","Optimization History:\n","  ğŸ“ /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/optimization_history_20251128_203559.html\n","  ğŸ’¡ Open this file in Colab and click the camera icon to download PNG\n","\n","Parameter Importance:\n","  ğŸ“ /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/parameter_importance_20251128_203559.html\n","  ğŸ’¡ Open this file in Colab and click the camera icon to download PNG\n","\n","Parameter Slice:\n","  ğŸ“ /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/parameter_slice_20251128_203559.html\n","  ğŸ’¡ Open this file in Colab and click the camera icon to download PNG\n","\n","================================================================================\n","ğŸ“ To download PNG files:\n","  1. Open each HTML file by double-clicking it in the Files panel\n","  2. The interactive plot will open in a new tab\n","  3. Hover over the plot and click the camera icon (ğŸ“·) in the toolbar\n","  4. The PNG will download automatically\n","\n","ğŸ’¡ Alternative: Run the plots again after restarting runtime\n","   (Your study results are saved in the .pkl file, so they won't be lost!)\n"]}]},{"cell_type":"markdown","id":"24aed975","metadata":{"id":"24aed975"},"source":["## 11. Visualize Optimization Results"]},{"cell_type":"code","execution_count":29,"id":"26d33d0e","metadata":{"id":"26d33d0e","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1764362666769,"user_tz":-180,"elapsed":755,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"184cfa90-ba41-4e71-c7a7-fc6fe00bba09"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","GENERATING OPTIMIZATION VISUALIZATIONS\n","================================================================================\n","\n","ğŸ“ˆ Creating optimization history plot...\n"]},{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"02d5d150-7342-45df-a0dc-826b6dc26020\" class=\"plotly-graph-div\" style=\"height:600px; width:1200px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"02d5d150-7342-45df-a0dc-826b6dc26020\")) {                    Plotly.newPlot(                        \"02d5d150-7342-45df-a0dc-826b6dc26020\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40],\"y\":[0.5769275868120581,0.5392655211791706,0.572175535486724,0.541650867972252,0.543987769075524,0.5258322084927844,0.5553024646124811,0.5606027818022772,0.5470858450892893,0.5649708908023445,0.5759796832336584,0.5765230783717186,0.5750243795647425,0.555043105045364,0.5720682538193854,0.566847971190009,0.5545956639939752,0.5622170624082131,0.5756351691807339,0.5750657616897434,0.5747262839096262,0.5714628221402573,0.5766610208034043,0.5566937623941979,0.5672992926314723,0.5759153249673427,0.5748535655590452,0.5756012162928592,0.5670742114487848,0.5538962140903665,0.5753678696594505,0.575203871877037,0.568762414083914,0.576135663258636,0.5762132136970319,0.5770742349894156,0.5667181528282965,0.5586432472304765,0.5552333786068102,0.5548905335656567,0.5561320329377647],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41],\"y\":[0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5769275868120581,0.5770742349894156,0.5770742349894156,0.5770742349894156,0.5770742349894156,0.5770742349894156,0.5770742349894156,0.5770742349894156],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"yolov8m_finetuned_1 - Hyperparameter Optimization History\"},\"xaxis\":{\"title\":{\"text\":\"Trial Number\"}},\"yaxis\":{\"title\":{\"text\":\"mAP@0.5\"}},\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"width\":1200,\"height\":600},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('02d5d150-7342-45df-a0dc-826b6dc26020');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["âœ“ HTML saved to: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/optimization_history_20251128_204426.html\n","\n","ğŸ“Š Creating parameter importance plot...\n"]},{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"b9eadfc7-30ce-4453-a447-09fedb02d3f3\" class=\"plotly-graph-div\" style=\"height:800px; width:1200px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b9eadfc7-30ce-4453-a447-09fedb02d3f3\")) {                    Plotly.newPlot(                        \"b9eadfc7-30ce-4453-a447-09fedb02d3f3\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"mosaic (FloatDistribution): 0.0003391359293597821\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"warmup_momentum (FloatDistribution): 0.0014218253050295316\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"momentum (FloatDistribution): 0.0014432967355950943\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"warmup_bias_lr (FloatDistribution): 0.0020157934178665323\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"warmup_epochs (IntDistribution): 0.002455559163511674\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"lr0 (FloatDistribution): 0.005988822720504692\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"mixup (FloatDistribution): 0.010568137242296785\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"weight_decay (FloatDistribution): 0.012782742489209681\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"optimizer (CategoricalDistribution): 0.1978315202063388\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"imgsz (CategoricalDistribution): 0.7651531667902874\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"],\"name\":\"Objective Value\",\"orientation\":\"h\",\"text\":[\"\\u003c0.01\",\"\\u003c0.01\",\"\\u003c0.01\",\"\\u003c0.01\",\"\\u003c0.01\",\"\\u003c0.01\",\"0.01\",\"0.01\",\"0.20\",\"0.77\"],\"textposition\":\"outside\",\"x\":[0.0003391359293597821,0.0014218253050295316,0.0014432967355950943,0.0020157934178665323,0.002455559163511674,0.005988822720504692,0.010568137242296785,0.012782742489209681,0.1978315202063388,0.7651531667902874],\"y\":[\"mosaic\",\"warmup_momentum\",\"momentum\",\"warmup_bias_lr\",\"warmup_epochs\",\"lr0\",\"mixup\",\"weight_decay\",\"optimizer\",\"imgsz\"],\"type\":\"bar\"}],                        {\"title\":{\"text\":\"yolov8m_finetuned_1 - Hyperparameter Importance\"},\"xaxis\":{\"title\":{\"text\":\"Importance\"}},\"yaxis\":{\"title\":{\"text\":\"Parameter\"}},\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"width\":1200,\"height\":800},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('b9eadfc7-30ce-4453-a447-09fedb02d3f3');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["âœ“ HTML saved to: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/parameter_importance_20251128_204426.html\n","âš ï¸  Could not save PNG: \n","Image export using the \"kaleido\" engine requires the kaleido package,\n","which can be installed using pip:\n","    $ pip install -U kaleido\n","\n","   Error type: ValueError\n","   Details: Traceback (most recent call last):\n","  File \"/tmp/ipython-input-706232807.py\", line 63, in <cell line: 0>\n","    fig_importance.write_image(str(param_importance_img_ts), width=1200, height=800, scale=2)\n","  File \"/usr/local/lib/python3.12/dist-packages/plotly/basedatatypes.py\", line 3835, in write_image\n","    return pio.write_image(self, *args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/plotly/io/_kaleido.py\", line 266, in write_image\n","    img_data = to_image(\n","               ^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/plotly/io/_kaleido.py\", line 132, in to_image\n","    raise ValueError(\n","ValueError: \n","Image export using the \"kaleido\" engine requires the kaleido package,\n","which can be installed using pip:\n","    $ pip install -U kaleido\n","\n","\n","\n","ğŸ” Creating parameter slice plots...\n"]},{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"0d78dffd-4310-40f8-bff0-5d3b8bbf0000\" class=\"plotly-graph-div\" style=\"height:1000px; width:1400px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0d78dffd-4310-40f8-bff0-5d3b8bbf0000\")) {                    Plotly.newPlot(                        \"0d78dffd-4310-40f8-bff0-5d3b8bbf0000\",                        [{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":true},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[768,640,768,640,640,640,640,768,640,768,768,768,768,640,768,768,640,768,768,768,768,768,768,640,768,768,768,768,768,640,768,768,768,768,768,768,768,768,640,640,640],\"y\":[0.5769275868120581,0.5392655211791706,0.572175535486724,0.541650867972252,0.543987769075524,0.5258322084927844,0.5553024646124811,0.5606027818022772,0.5470858450892893,0.5649708908023445,0.5759796832336584,0.5765230783717186,0.5750243795647425,0.555043105045364,0.5720682538193854,0.566847971190009,0.5545956639939752,0.5622170624082131,0.5756351691807339,0.5750657616897434,0.5747262839096262,0.5714628221402573,0.5766610208034043,0.5566937623941979,0.5672992926314723,0.5759153249673427,0.5748535655590452,0.5756012162928592,0.5670742114487848,0.5538962140903665,0.5753678696594505,0.575203871877037,0.568762414083914,0.576135663258636,0.5762132136970319,0.5770742349894156,0.5667181528282965,0.5586432472304765,0.5552333786068102,0.5548905335656567,0.5561320329377647],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[0.00018408992080552527,0.0005418282319533242,0.00019485671251272575,0.00027520696850790545,0.000215262809722153,0.0020512599422151364,0.00012822825454807568,0.0007728716861851782,0.00013514082247401428,0.00034695916603302916,0.00010136416726594986,0.00019189188714851022,0.0006707573965261709,0.00015956212481414519,0.0003648765624453425,0.0001500738887151613,0.00011832499546588166,0.0005375733382750209,0.00023763387102495472,0.0012572946482373871,0.00019409774408113843,0.0001170177690808451,0.00014118140573302955,0.00010923720976574512,0.00028982832586057925,0.00010337029702652747,0.000680896077927012,0.00023455204646398111,0.0001816950319371306,0.00025947660221022366,0.00019534509666258856,0.00010527627499202455,0.000136470817178904,0.00011943176232095372,0.00015346984180265746,0.0001614596240725037,0.00022248867701096445,0.0005299480991997462,0.0005562671827608824,0.00025969974443728553,0.0003489202891839771],\"y\":[0.5769275868120581,0.5392655211791706,0.572175535486724,0.541650867972252,0.543987769075524,0.5258322084927844,0.5553024646124811,0.5606027818022772,0.5470858450892893,0.5649708908023445,0.5759796832336584,0.5765230783717186,0.5750243795647425,0.555043105045364,0.5720682538193854,0.566847971190009,0.5545956639939752,0.5622170624082131,0.5756351691807339,0.5750657616897434,0.5747262839096262,0.5714628221402573,0.5766610208034043,0.5566937623941979,0.5672992926314723,0.5759153249673427,0.5748535655590452,0.5756012162928592,0.5670742114487848,0.5538962140903665,0.5753678696594505,0.575203871877037,0.568762414083914,0.576135663258636,0.5762132136970319,0.5770742349894156,0.5667181528282965,0.5586432472304765,0.5552333786068102,0.5548905335656567,0.5561320329377647],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[0.16648852816008436,0.15703519227860274,0.1368466053024314,0.15502656467222292,0.05618690193747616,0.014808930346818072,0.02391884918766034,0.10171413823294057,0.16073441537982291,0.10214946051551316,0.14346732790723005,0.18924351393363523,0.12474316618456899,0.15498974702628246,0.19859216786494333,0.1037890785120699,0.1960881301767174,0.18419081572099077,0.11390959443328483,0.1613009507739077,0.19898880565440097,0.11814716804007039,0.12334438866565361,0.10142130829413395,0.07238307109429609,0.1299937060296653,0.1946641233828872,0.16339193297033638,0.14369498961035593,0.16524907961546959,0.182709152923983,0.15181187495601245,0.19171669528746693,0.0797867932405509,0.038448048254907566,0.023789168654792303,0.04791713874009272,0.009323764008681987,0.19658023796985702,0.02807877625623379,0.19702415968347725],\"y\":[0.5769275868120581,0.5392655211791706,0.572175535486724,0.541650867972252,0.543987769075524,0.5258322084927844,0.5553024646124811,0.5606027818022772,0.5470858450892893,0.5649708908023445,0.5759796832336584,0.5765230783717186,0.5750243795647425,0.555043105045364,0.5720682538193854,0.566847971190009,0.5545956639939752,0.5622170624082131,0.5756351691807339,0.5750657616897434,0.5747262839096262,0.5714628221402573,0.5766610208034043,0.5566937623941979,0.5672992926314723,0.5759153249673427,0.5748535655590452,0.5756012162928592,0.5670742114487848,0.5538962140903665,0.5753678696594505,0.575203871877037,0.568762414083914,0.576135663258636,0.5762132136970319,0.5770742349894156,0.5667181528282965,0.5586432472304765,0.5552333786068102,0.5548905335656567,0.5561320329377647],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[0.856970033460184,0.8849474968237651,0.8578061911582335,0.9295026741224778,0.8554272746692645,0.8738458817841006,0.8873178786058794,0.9013049222030259,0.8847701743496521,0.8632062309433212,0.905713019081271,0.9256140152521548,0.8788032145046235,0.9325638910516862,0.9521414385679057,0.8596635892864232,0.884174215072047,0.9220284993100825,0.9690735222899702,0.9391522790357703,0.8566173352757066,0.9209918879986447,0.9094252069932472,0.9087276077173645,0.9011224088902193,0.8565504231572861,0.8749899221652856,0.912563232474453,0.8618101733544855,0.8549458050763524,0.9241466731188749,0.888593460387621,0.8970109062903935,0.8954532989965969,0.9063315010084676,0.9098500376932075,0.8946024438028313,0.8910324444575807,0.9208468793572436,0.9010564532726025,0.8559053049915213],\"y\":[0.5769275868120581,0.5392655211791706,0.572175535486724,0.541650867972252,0.543987769075524,0.5258322084927844,0.5553024646124811,0.5606027818022772,0.5470858450892893,0.5649708908023445,0.5759796832336584,0.5765230783717186,0.5750243795647425,0.555043105045364,0.5720682538193854,0.566847971190009,0.5545956639939752,0.5622170624082131,0.5756351691807339,0.5750657616897434,0.5747262839096262,0.5714628221402573,0.5766610208034043,0.5566937623941979,0.5672992926314723,0.5759153249673427,0.5748535655590452,0.5756012162928592,0.5670742114487848,0.5538962140903665,0.5753678696594505,0.575203871877037,0.568762414083914,0.576135663258636,0.5762132136970319,0.5770742349894156,0.5667181528282965,0.5586432472304765,0.5552333786068102,0.5548905335656567,0.5561320329377647],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[0.9849549260809971,0.728034992108518,0.5488360570031919,0.9847923138822793,0.6783766633467947,0.8856351733429728,0.7361074625809747,0.6571779905381634,0.9357302950938589,0.5034760652655954,0.8150206227433663,0.9649811229108491,0.9241083394569172,0.8097286598664397,0.8441440983974132,0.9188109532508847,0.9586224212426746,0.9568487765910555,0.9425716260056852,0.924997185059828,0.9748539724246373,0.7454902561777089,0.8913409412138384,0.9502356426031231,0.9078188400390483,0.9923623608226324,0.9086387107056219,0.9767352096136815,0.8527374391318845,0.7780592853354106,0.8278923239363011,0.6997552011797397,0.8940697783805857,0.89405609249683,0.8785089288974699,0.8205379408033115,0.7553264786879148,0.8694090705650911,0.943400436789498,0.7499675740997609,0.9650376225502465],\"y\":[0.5769275868120581,0.5392655211791706,0.572175535486724,0.541650867972252,0.543987769075524,0.5258322084927844,0.5553024646124811,0.5606027818022772,0.5470858450892893,0.5649708908023445,0.5759796832336584,0.5765230783717186,0.5750243795647425,0.555043105045364,0.5720682538193854,0.566847971190009,0.5545956639939752,0.5622170624082131,0.5756351691807339,0.5750657616897434,0.5747262839096262,0.5714628221402573,0.5766610208034043,0.5566937623941979,0.5672992926314723,0.5759153249673427,0.5748535655590452,0.5756012162928592,0.5670742114487848,0.5538962140903665,0.5753678696594505,0.575203871877037,0.568762414083914,0.576135663258636,0.5762132136970319,0.5770742349894156,0.5667181528282965,0.5586432472304765,0.5552333786068102,0.5548905335656567,0.5561320329377647],\"type\":\"scatter\",\"xaxis\":\"x5\",\"yaxis\":\"y5\"},{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[\"SGD\",\"AdamW\",\"AdamW\",\"AdamW\",\"Adam\",\"AdamW\",\"SGD\",\"Adam\",\"Adam\",\"AdamW\",\"SGD\",\"SGD\",\"SGD\",\"SGD\",\"Adam\",\"Adam\",\"SGD\",\"AdamW\",\"SGD\",\"SGD\",\"SGD\",\"Adam\",\"SGD\",\"SGD\",\"AdamW\",\"SGD\",\"SGD\",\"SGD\",\"AdamW\",\"SGD\",\"SGD\",\"SGD\",\"Adam\",\"SGD\",\"SGD\",\"SGD\",\"AdamW\",\"Adam\",\"SGD\",\"SGD\",\"SGD\"],\"y\":[0.5769275868120581,0.5392655211791706,0.572175535486724,0.541650867972252,0.543987769075524,0.5258322084927844,0.5553024646124811,0.5606027818022772,0.5470858450892893,0.5649708908023445,0.5759796832336584,0.5765230783717186,0.5750243795647425,0.555043105045364,0.5720682538193854,0.566847971190009,0.5545956639939752,0.5622170624082131,0.5756351691807339,0.5750657616897434,0.5747262839096262,0.5714628221402573,0.5766610208034043,0.5566937623941979,0.5672992926314723,0.5759153249673427,0.5748535655590452,0.5756012162928592,0.5670742114487848,0.5538962140903665,0.5753678696594505,0.575203871877037,0.568762414083914,0.576135663258636,0.5762132136970319,0.5770742349894156,0.5667181528282965,0.5586432472304765,0.5552333786068102,0.5548905335656567,0.5561320329377647],\"type\":\"scatter\",\"xaxis\":\"x6\",\"yaxis\":\"y6\"},{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[0.0020584494295802446,0.03663618432936917,0.03046137691733707,0.018485445552552705,0.08287375091519295,0.07290071680409874,0.08872127425763265,0.06364104112637804,0.06334037565104235,0.08607305832563435,0.0017830306795590628,0.002410883116536491,0.030481286712759365,0.021881343928649495,0.03694056393169325,0.021051136598623794,0.04145292944378984,0.020549542524289362,0.009569797908782101,0.009581091430440513,0.01672355973911266,0.011034875129972614,0.005798927412947139,0.005708881601387014,0.0022194926894142787,8.375508235552304e-7,0.0020970375937223724,0.0029013894269801677,0.02471331817804086,0.0017337914021303494,0.025731624575078944,0.008846528541806498,0.012875103273384508,0.011564605733975091,0.02471430207500159,0.018938388657529233,0.03524001773688575,0.003981033699452843,0.0035044865075706784,0.008529487882382562,0.0076481178071809],\"y\":[0.5769275868120581,0.5392655211791706,0.572175535486724,0.541650867972252,0.543987769075524,0.5258322084927844,0.5553024646124811,0.5606027818022772,0.5470858450892893,0.5649708908023445,0.5759796832336584,0.5765230783717186,0.5750243795647425,0.555043105045364,0.5720682538193854,0.566847971190009,0.5545956639939752,0.5622170624082131,0.5756351691807339,0.5750657616897434,0.5747262839096262,0.5714628221402573,0.5766610208034043,0.5566937623941979,0.5672992926314723,0.5759153249673427,0.5748535655590452,0.5756012162928592,0.5670742114487848,0.5538962140903665,0.5753678696594505,0.575203871877037,0.568762414083914,0.576135663258636,0.5762132136970319,0.5770742349894156,0.5667181528282965,0.5586432472304765,0.5552333786068102,0.5548905335656567,0.5561320329377647],\"type\":\"scatter\",\"xaxis\":\"x7\",\"yaxis\":\"y7\"},{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[2,0,3,2,1,3,2,0,3,1,3,2,2,1,2,1,2,2,1,3,1,3,3,3,3,3,3,2,2,2,1,3,3,3,1,1,0,1,3,0,1],\"y\":[0.5769275868120581,0.5392655211791706,0.572175535486724,0.541650867972252,0.543987769075524,0.5258322084927844,0.5553024646124811,0.5606027818022772,0.5470858450892893,0.5649708908023445,0.5759796832336584,0.5765230783717186,0.5750243795647425,0.555043105045364,0.5720682538193854,0.566847971190009,0.5545956639939752,0.5622170624082131,0.5756351691807339,0.5750657616897434,0.5747262839096262,0.5714628221402573,0.5766610208034043,0.5566937623941979,0.5672992926314723,0.5759153249673427,0.5748535655590452,0.5756012162928592,0.5670742114487848,0.5538962140903665,0.5753678696594505,0.575203871877037,0.568762414083914,0.576135663258636,0.5762132136970319,0.5770742349894156,0.5667181528282965,0.5586432472304765,0.5552333786068102,0.5548905335656567,0.5561320329377647],\"type\":\"scatter\",\"xaxis\":\"x8\",\"yaxis\":\"y8\"},{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[0.8186326600082204,0.6314650918408482,0.8637788066524075,0.7460196257044758,0.6221070642982531,0.8180858047314277,0.7869008621098459,0.5141431335590304,0.8636541708039875,0.8681066446651219,0.7288507043449868,0.7511661798798476,0.9076339798561361,0.9010023745850442,0.6289642269316154,0.7248156517196116,0.7167381159130815,0.8253358856250237,0.7256297179080418,0.612849991148544,0.7222631373010865,0.6994537517049798,0.668541094684278,0.5914682378765702,0.6375973065667252,0.835109436494624,0.9379847839584119,0.7527886964045045,0.8596224633670249,0.8277014260079567,0.6393878894768946,0.6702643747902545,0.636594500298316,0.6675370754361432,0.5483156020434448,0.5149307497845836,0.5365910374069301,0.5666023442472398,0.6914645211274437,0.5678979552619839,0.8714204009107174],\"y\":[0.5769275868120581,0.5392655211791706,0.572175535486724,0.541650867972252,0.543987769075524,0.5258322084927844,0.5553024646124811,0.5606027818022772,0.5470858450892893,0.5649708908023445,0.5759796832336584,0.5765230783717186,0.5750243795647425,0.555043105045364,0.5720682538193854,0.566847971190009,0.5545956639939752,0.5622170624082131,0.5756351691807339,0.5750657616897434,0.5747262839096262,0.5714628221402573,0.5766610208034043,0.5566937623941979,0.5672992926314723,0.5759153249673427,0.5748535655590452,0.5756012162928592,0.5670742114487848,0.5538962140903665,0.5753678696594505,0.575203871877037,0.568762414083914,0.576135663258636,0.5762132136970319,0.5770742349894156,0.5667181528282965,0.5586432472304765,0.5552333786068102,0.5548905335656567,0.5561320329377647],\"type\":\"scatter\",\"xaxis\":\"x9\",\"yaxis\":\"y9\"},{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[0.0005399484409787432,0.00016738085788752134,0.000790261954970823,0.00004201672054372529,0.00004473636174621264,0.000010257563974185649,0.000044706085467784903,0.000011241862095793047,0.00002101079931010355,0.000028567374298471872,0.0008532637450534103,0.0009223691646885691,0.00018608446967536654,0.0008202218579862699,0.0005733433450715179,0.0004373273933564993,0.0008783853975174846,0.0006245610321427977,0.0004345143055119562,0.0006312790852644021,0.0002337269531669197,0.00015481959953941008,0.0007309395990801345,0.0003818945195905101,0.0008570020016218264,0.000691796111224237,0.0007859094519095029,0.00042559110435000353,0.00018619454328701798,0.00027188537082400006,0.0005430031346760696,0.0008005425935994206,0.0007795392208456435,0.0009320154818982343,0.0009371541289392279,0.00042786651935909105,0.0003067897167436233,0.00013259893973744007,0.0007112882802612956,0.00015395200555927614,0.000991194711322742],\"y\":[0.5769275868120581,0.5392655211791706,0.572175535486724,0.541650867972252,0.543987769075524,0.5258322084927844,0.5553024646124811,0.5606027818022772,0.5470858450892893,0.5649708908023445,0.5759796832336584,0.5765230783717186,0.5750243795647425,0.555043105045364,0.5720682538193854,0.566847971190009,0.5545956639939752,0.5622170624082131,0.5756351691807339,0.5750657616897434,0.5747262839096262,0.5714628221402573,0.5766610208034043,0.5566937623941979,0.5672992926314723,0.5759153249673427,0.5748535655590452,0.5756012162928592,0.5670742114487848,0.5538962140903665,0.5753678696594505,0.575203871877037,0.568762414083914,0.576135663258636,0.5762132136970319,0.5770742349894156,0.5667181528282965,0.5586432472304765,0.5552333786068102,0.5548905335656567,0.5561320329377647],\"type\":\"scatter\",\"xaxis\":\"x10\",\"yaxis\":\"y10\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.082],\"title\":{\"text\":\"imgsz\"},\"type\":\"category\",\"categoryorder\":\"array\",\"categoryarray\":[640,768]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Objective Value\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.10200000000000001,0.184],\"title\":{\"text\":\"lr0\"},\"type\":\"log\"},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.20400000000000001,0.28600000000000003],\"title\":{\"text\":\"mixup\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.306,0.388],\"title\":{\"text\":\"momentum\"}},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis5\":{\"anchor\":\"y5\",\"domain\":[0.40800000000000003,0.49000000000000005],\"title\":{\"text\":\"mosaic\"}},\"yaxis5\":{\"anchor\":\"x5\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis6\":{\"anchor\":\"y6\",\"domain\":[0.51,0.592],\"title\":{\"text\":\"optimizer\"},\"type\":\"category\",\"categoryorder\":\"array\",\"categoryarray\":[\"SGD\",\"Adam\",\"AdamW\"]},\"yaxis6\":{\"anchor\":\"x6\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis7\":{\"anchor\":\"y7\",\"domain\":[0.612,0.694],\"title\":{\"text\":\"warmup_bias_lr\"}},\"yaxis7\":{\"anchor\":\"x7\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis8\":{\"anchor\":\"y8\",\"domain\":[0.7140000000000001,0.796],\"title\":{\"text\":\"warmup_epochs\"}},\"yaxis8\":{\"anchor\":\"x8\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis9\":{\"anchor\":\"y9\",\"domain\":[0.8160000000000001,0.898],\"title\":{\"text\":\"warmup_momentum\"}},\"yaxis9\":{\"anchor\":\"x9\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis10\":{\"anchor\":\"y10\",\"domain\":[0.9179999999999999,0.9999999999999999],\"title\":{\"text\":\"weight_decay\"},\"type\":\"log\"},\"yaxis10\":{\"anchor\":\"x10\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"title\":{\"text\":\"yolov8m_finetuned_1 - Parameter Slice Plot\"},\"width\":1400,\"height\":1000},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('0d78dffd-4310-40f8-bff0-5d3b8bbf0000');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["âœ“ HTML saved to: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/parameter_slice_20251128_204426.html\n","âš ï¸  Could not save PNG: \n","Image export using the \"kaleido\" engine requires the kaleido package,\n","which can be installed using pip:\n","    $ pip install -U kaleido\n","\n","   Error type: ValueError\n","   Details: Traceback (most recent call last):\n","  File \"/tmp/ipython-input-706232807.py\", line 105, in <cell line: 0>\n","    fig_slice.write_image(str(slice_img_path_ts), width=1400, height=1000, scale=2)\n","  File \"/usr/local/lib/python3.12/dist-packages/plotly/basedatatypes.py\", line 3835, in write_image\n","    return pio.write_image(self, *args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/plotly/io/_kaleido.py\", line 266, in write_image\n","    img_data = to_image(\n","               ^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/plotly/io/_kaleido.py\", line 132, in to_image\n","    raise ValueError(\n","ValueError: \n","Image export using the \"kaleido\" engine requires the kaleido package,\n","which can be installed using pip:\n","    $ pip install -U kaleido\n","\n","\n"]}],"source":["# ============================================================================\n","# VISUALIZE OPTIMIZATION RESULTS: HISTORY, PARAMETER IMPORTANCE, SLICE PLOTS\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('GENERATING OPTIMIZATION VISUALIZATIONS')\n","print('=' * 80)\n","\n","if len(study.trials) == 0:\n","    print(\"âš ï¸  No trials found in study, skipping visualization.\")\n","else:\n","    timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')\n","\n","    # -----------------------------\n","    # 1ï¸âƒ£ Optimization History Plot\n","    # -----------------------------\n","    try:\n","        print('\\nğŸ“ˆ Creating optimization history plot...')\n","        fig_history = plot_optimization_history(study)\n","        fig_history.update_layout(\n","            title=f'{MODEL_NAME} - Hyperparameter Optimization History',\n","            xaxis_title='Trial Number',\n","            yaxis_title='mAP@0.5',\n","            template='plotly_white',\n","            width=1200,\n","            height=600\n","        )\n","        fig_history.show()\n","\n","        # Save HTML with timestamp\n","        optimization_history_path = TUNE_DIR / f'optimization_history_{timestamp_str}.html'\n","        fig_history.write_html(str(optimization_history_path))\n","        print(f'âœ“ HTML saved to: {optimization_history_path}')\n","\n","    except Exception as history_error:\n","        print(f'âŒ Failed to create optimization history plot: {history_error}')\n","\n","    # -----------------------------\n","    # 2ï¸âƒ£ Parameter Importance Plot\n","    # -----------------------------\n","    try:\n","        print('\\nğŸ“Š Creating parameter importance plot...')\n","        fig_importance = plot_param_importances(study)\n","        fig_importance.update_layout(\n","            title=f'{MODEL_NAME} - Hyperparameter Importance',\n","            xaxis_title='Importance',\n","            yaxis_title='Parameter',\n","            template='plotly_white',\n","            width=1200,\n","            height=800\n","        )\n","        fig_importance.show()\n","\n","        # Save HTML with timestamp\n","        param_importance_path = TUNE_DIR / f'parameter_importance_{timestamp_str}.html'\n","        fig_importance.write_html(str(param_importance_path))\n","        print(f'âœ“ HTML saved to: {param_importance_path}')\n","\n","        # Save PNG with timestamp AND consistent name\n","        try:\n","            # Try kaleido first\n","            param_importance_img_ts = TUNE_DIR / f'parameter_importance_{timestamp_str}.png'\n","            fig_importance.write_image(str(param_importance_img_ts), width=1200, height=800, scale=2)\n","            print(f'âœ“ PNG saved to: {param_importance_img_ts}')\n","\n","            # Consistent name for PDF report\n","            param_importance_img = TUNE_DIR / 'parameter_importance.png'\n","            fig_importance.write_image(str(param_importance_img), width=1200, height=800, scale=2)\n","            print(f'âœ“ PNG saved to: {param_importance_img} (for PDF report)')\n","        except Exception as png_error:\n","            print(f'âš ï¸  Could not save PNG: {png_error}')\n","            print(f'   Error type: {type(png_error).__name__}')\n","            import traceback\n","            print(f'   Details: {traceback.format_exc()}')\n","            param_importance_img = None\n","\n","    except (RuntimeError, ValueError) as importance_error:\n","        print(f'âš ï¸  Could not generate parameter importance plot: {importance_error}')\n","        print('  (This can happen when trials have insufficient data variation)')\n","        param_importance_img = None\n","\n","    # -----------------------------\n","    # 3ï¸âƒ£ Parameter Slice Plots\n","    # -----------------------------\n","    try:\n","        print('\\nğŸ” Creating parameter slice plots...')\n","        fig_slice = plot_slice(study)\n","        fig_slice.update_layout(\n","            title=f'{MODEL_NAME} - Parameter Slice Plot',\n","            template='plotly_white',\n","            width=1400,\n","            height=1000\n","        )\n","        fig_slice.show()\n","\n","        # Save HTML with timestamp\n","        slice_path = TUNE_DIR / f'parameter_slice_{timestamp_str}.html'\n","        fig_slice.write_html(str(slice_path))\n","        print(f'âœ“ HTML saved to: {slice_path}')\n","\n","        # Save PNG with timestamp AND consistent name\n","        try:\n","            # Try kaleido\n","            slice_img_path_ts = TUNE_DIR / f'parameter_slice_{timestamp_str}.png'\n","            fig_slice.write_image(str(slice_img_path_ts), width=1400, height=1000, scale=2)\n","            print(f'âœ“ PNG saved to: {slice_img_path_ts}')\n","\n","            # Consistent name for PDF report\n","            slice_img_path = TUNE_DIR / 'parameter_slice.png'\n","            fig_slice.write_image(str(slice_img_path), width=1400, height=1000, scale=2)\n","            print(f'âœ“ PNG saved to: {slice_img_path} (for PDF report)')\n","        except Exception as png_error:\n","            print(f'âš ï¸  Could not save PNG: {png_error}')\n","            print(f'   Error type: {type(png_error).__name__}')\n","            import traceback\n","            print(f'   Details: {traceback.format_exc()}')\n","\n","    except Exception as slice_error:\n","        print(f'âš ï¸  Could not generate parameter slice plot: {slice_error}')"]},{"cell_type":"markdown","id":"585a97a5","metadata":{"id":"585a97a5"},"source":["## 12. Generate Tuning PDF Report\n","\n","Create a comprehensive PDF report with optimization results, visualizations, and model performance."]},{"cell_type":"code","source":["# GENERATE Tuning PDF REPORT\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('GENERATING COMPREHENSIVE TUNING PDF REPORT')\n","print('=' * 80)\n","\n","# Use already extracted best parameters and trial data from previous sections\n","best_params = study.best_params\n","best_trial = study.best_trial\n","\n","print(f'\\nğŸ“Š Preparing comprehensive report with {len(study.trials)} trials')\n","print(f'   Best Trial: {best_trial.number}')\n","print(f'   Best mAP@0.5: {study.best_value:.4f}')\n","\n","# Compile all trials data into DataFrame for PDF report\n","print('\\nğŸ“‹ Compiling trials data for report...')\n","trials_data_for_pdf = []\n","\n","for trial in study.trials:\n","    # Create row with trial info and hyperparameters directly from trial.params\n","    row_data = {\n","        'trial': trial.number,\n","        'state': trial.state.name,\n","        'mAP@0.5': trial.value if trial.value is not None else 0.0,\n","    }\n","\n","    # Add all hyperparameters directly from trial.params\n","    row_data.update(trial.params)\n","\n","    trials_data_for_pdf.append(row_data)\n","\n","# Create DataFrame and sort by mAP@0.5\n","df_trials = pd.DataFrame(trials_data_for_pdf)\n","df_trials_sorted = df_trials.sort_values('mAP@0.5', ascending=False)\n","\n","print(f'âœ“ Compiled {len(df_trials)} trials for report')\n","print(f'   Available columns: {list(df_trials.columns)}')\n","\n","# Create tuning PDF report\n","pdf_report_path = TUNE_DIR / f'{MODEL_NAME}_tuning_report.pdf'\n","\n","doc = SimpleDocTemplate(str(pdf_report_path), pagesize=A4,\n","                       rightMargin=30, leftMargin=30,\n","                       topMargin=30, bottomMargin=30)\n","\n","story = []\n","styles = getSampleStyleSheet()\n","\n","# Custom styles\n","title_style = ParagraphStyle(\n","    'CustomTitle',\n","    parent=styles['Heading1'],\n","    fontSize=18,\n","    textColor=rl_colors.HexColor('#2c3e50'),\n","    spaceAfter=30,\n","    alignment=TA_CENTER\n",")\n","\n","heading_style = ParagraphStyle(\n","    'CustomHeading',\n","    parent=styles['Heading2'],\n","    fontSize=16,\n","    textColor=rl_colors.HexColor('#34495e'),\n","    spaceAfter=12,\n","    spaceBefore=20\n",")\n","\n","small_style = ParagraphStyle(\n","    'SmallText',\n","    parent=styles['Normal'],\n","    fontSize=7,\n","    wordWrap='CJK'\n",")\n","\n","# Title\n","story.append(Paragraph(f'{MODEL_NAME} Hyperparameter Tuning Report', title_style))\n","story.append(Paragraph(f'Generated: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}', styles['Normal']))\n","story.append(Spacer(1, 20))\n","\n","# ===== SECTION 1: OVERVIEW =====\n","story.append(Paragraph('1. Optimization Overview', heading_style))\n","\n","info_data = [\n","    ['Property', 'Value'],\n","    ['Model', MODEL_NAME],\n","    ['Dataset', YOLO_DATASET_ROOT.name],\n","    ['Total Trials', str(len(study.trials))],\n","    ['Completed Trials', str(len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]))],\n","    ['Failed Trials', str(len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL]))],\n","    ['Best Trial', str(study.best_trial.number)],\n","    ['Best mAP@0.5', f'{study.best_value:.4f}'],\n","    ['Optimization Duration', str(duration)],\n","]\n","\n","info_table = Table(info_data, colWidths=[2.5*inch, 3.5*inch])\n","info_table.setStyle(TableStyle([\n","    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#2c3e50')),\n","    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","    ('BACKGROUND', (0, 1), (-1, -1), rl_colors.HexColor('#ecf0f1')),\n","    ('TEXTCOLOR', (0, 1), (-1, -1), rl_colors.black),\n","    ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n","    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","    ('FONTNAME', (0, 1), (0, -1), 'Helvetica-Bold'),\n","    ('FONTSIZE', (0, 0), (-1, -1), 10),\n","    ('BOTTOMPADDING', (0, 0), (-1, -1), 8),\n","    ('TOPPADDING', (0, 0), (-1, -1), 8),\n","    ('GRID', (0, 0), (-1, -1), 1, rl_colors.grey)\n","]))\n","story.append(info_table)\n","story.append(Spacer(1, 20))\n","\n","# ===== SECTION 2: CONFIGURATION =====\n","story.append(Paragraph('2. Optimization Configuration', heading_style))\n","\n","opt_config_data = [\n","    ['Parameter', 'Value'],\n","    ['Total Trials', str(N_TRIALS)],\n","    ['Epochs per Trial', str(EPOCHS_PER_TRIAL)],\n","    ['Batch Size', str(BATCH_SIZE)],\n","    ['Startup Trials (TPE)', str(N_STARTUP_TRIALS)],\n","    ['Device', device],\n","    ['Number of Classes', str(NUM_CLASSES)],\n","    ['Train Images', str(dataset_stats.get('train', {}).get('images', 'N/A'))],\n","    ['Val Images', str(dataset_stats.get('val', {}).get('images', 'N/A'))],\n","]\n","\n","opt_config_table = Table(opt_config_data, colWidths=[3*inch, 3*inch])\n","opt_config_table.setStyle(TableStyle([\n","    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#95a5a6')),\n","    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n","    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","    ('FONTSIZE', (0, 0), (-1, 0), 11),\n","    ('FONTSIZE', (0, 1), (-1, -1), 9),\n","    ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n","    ('TOPPADDING', (0, 0), (-1, -1), 6),\n","    ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n","    ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n","]))\n","story.append(opt_config_table)\n","story.append(Spacer(1, 20))\n","\n","# ===== SECTION 3: BEST HYPERPARAMETERS =====\n","story.append(PageBreak())\n","story.append(Paragraph('3. Best Hyperparameters', heading_style))\n","\n","hyperparam_data = [['Parameter', 'Value', 'Description']]\n","param_descriptions = {\n","    'optimizer': 'Optimization algorithm',\n","    'lr0': 'Initial learning rate',\n","    'lrf': 'Final learning rate factor',\n","    'momentum': 'SGD momentum / Adam beta1',\n","    'weight_decay': 'Weight decay (L2 penalty)',\n","    'warmup_epochs': 'Warmup epochs',\n","    'warmup_momentum': 'Warmup momentum',\n","    'box': 'Box loss gain',\n","    'cls': 'Classification loss gain',\n","    'dfl': 'Distribution focal loss gain',\n","    'hsv_h': 'HSV-Hue augmentation',\n","    'hsv_s': 'HSV-Saturation augmentation',\n","    'hsv_v': 'HSV-Value augmentation',\n","    'degrees': 'Rotation augmentation',\n","    'translate': 'Translation augmentation',\n","    'scale': 'Scale augmentation',\n","    'shear': 'Shear augmentation',\n","    'perspective': 'Perspective augmentation',\n","    'flipud': 'Vertical flip probability',\n","    'fliplr': 'Horizontal flip probability',\n","    'mosaic': 'Mosaic augmentation',\n","    'mixup': 'Mixup augmentation',\n","    'copy_paste': 'Copy-paste augmentation',\n","}\n","\n","for param_key, param_value in best_params.items():\n","    desc = param_descriptions.get(param_key, '')\n","    formatted_value = f'{param_value:.6f}' if isinstance(param_value, float) else str(param_value)\n","    hyperparam_data.append([param_key, formatted_value, desc])\n","\n","hyperparam_table = Table(hyperparam_data, colWidths=[1.8*inch, 1.5*inch, 2.7*inch])\n","hyperparam_table.setStyle(TableStyle([\n","    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#3498db')),\n","    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","    ('ALIGN', (0, 0), (1, -1), 'CENTER'),\n","    ('ALIGN', (2, 1), (2, -1), 'LEFT'),\n","    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","    ('FONTSIZE', (0, 0), (-1, 0), 10),\n","    ('FONTSIZE', (0, 1), (-1, -1), 8),\n","    ('BOTTOMPADDING', (0, 0), (-1, -1), 5),\n","    ('TOPPADDING', (0, 0), (-1, -1), 5),\n","    ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n","    ('GRID', (0, 0), (-1, -1), 1, rl_colors.black),\n","    ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n","]))\n","story.append(hyperparam_table)\n","story.append(Spacer(1, 20))\n","\n","# ===== SECTION 4: TOP 20 TRIALS WITH HYPERPARAMETERS =====\n","story.append(PageBreak())\n","story.append(Paragraph('4. Top 20 Trials Performance', heading_style))\n","\n","# Create detailed top trials table with key hyperparameters\n","print(f'   DataFrame columns: {list(df_trials_sorted.columns)}')\n","print(f'   Sample row keys: {list(df_trials_sorted.head(1).iloc[0].keys())}')\n","\n","top_trials_data = [['#', 'mAP@0.5', 'ImgSz', 'Opt', 'lr0', 'mom', 'mixup', 'mosaic']]\n","for idx, (_, row) in enumerate(df_trials_sorted.head(20).iterrows(), 1):\n","    # Use pd.notna() to check if value exists and is not NaN\n","    img_val = str(int(row['imgsz'])) if 'imgsz' in row and pd.notna(row['imgsz']) else 'N/A'\n","    opt_val = row.get('optimizer', 'N/A')\n","    lr0_val = f\"{row['lr0']:.4f}\" if 'lr0' in row and pd.notna(row['lr0']) else 'N/A'\n","    mom_val = f\"{row['momentum']:.3f}\" if 'momentum' in row and pd.notna(row['momentum']) else 'N/A'\n","    mix_val = f\"{row['mixup']:.2f}\" if 'mixup' in row and pd.notna(row['mixup']) else 'N/A'\n","    mos_val = f\"{row['mosaic']:.2f}\" if 'mosaic' in row and pd.notna(row['mosaic']) else 'N/A'\n","\n","    top_trials_data.append([\n","        str(idx),\n","        f\"{row['mAP@0.5']:.4f}\",\n","        img_val,\n","        str(opt_val)[:4] if opt_val != 'N/A' else 'N/A',\n","        lr0_val,\n","        mom_val,\n","        mix_val,\n","        mos_val,\n","    ])\n","\n","top_trials_table = Table(top_trials_data, colWidths=[0.3*inch, 0.8*inch, 0.6*inch, 0.6*inch, 0.7*inch, 0.7*inch, 0.7*inch, 0.7*inch])\n","top_trials_table.setStyle(TableStyle([\n","    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#27ae60')),\n","    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n","    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","    ('FONTSIZE', (0, 0), (-1, 0), 9),\n","    ('FONTSIZE', (0, 1), (-1, -1), 7),\n","    ('BOTTOMPADDING', (0, 0), (-1, -1), 4),\n","    ('TOPPADDING', (0, 0), (-1, -1), 4),\n","    ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n","    ('GRID', (0, 0), (-1, -1), 0.5, rl_colors.black)\n","]))\n","story.append(top_trials_table)\n","story.append(Spacer(1, 15))\n","\n","# Detailed hyperparameters for top 5 trials\n","story.append(PageBreak())\n","story.append(Paragraph('4.1 Detailed Hyperparameters - Top 5 Trials', heading_style))\n","\n","print(f'   Creating detailed params for top 5 trials...')\n","for rank, (_, row) in enumerate(df_trials_sorted.head(5).iterrows(), 1):\n","    story.append(Paragraph(f'<b>Rank {rank}: Trial {int(row[\"trial\"])} (mAP@0.5: {row[\"mAP@0.5\"]:.4f})</b>', styles['Normal']))\n","\n","    trial_params_text = []\n","    # Get all parameter columns (exclude trial, state, mAP@0.5)\n","    param_cols = [col for col in df_trials_sorted.columns if col not in ['trial', 'state', 'mAP@0.5']]\n","\n","    for param_key in sorted(param_cols):\n","        if param_key in row and pd.notna(row[param_key]):\n","            value = row[param_key]\n","            formatted_val = f'{value:.6f}' if isinstance(value, float) else str(value)\n","            trial_params_text.append(f'{param_key}={formatted_val}')\n","\n","    if trial_params_text:\n","        params_str = ', '.join(trial_params_text)\n","        story.append(Paragraph(params_str, small_style))\n","    else:\n","        story.append(Paragraph('No parameter data available', small_style))\n","    story.append(Spacer(1, 10))\n","\n","print(f'   âœ“ Top 5 trials details added')\n","\n","# ===== SECTION 5: OPTIMIZATION VISUALIZATIONS =====\n","story.append(PageBreak())\n","story.append(Paragraph('5. Optimization Visualizations', heading_style))\n","\n","print('\\nğŸ“Š Generating custom visualizations for PDF report...')\n","\n","# Prepare data for completed trials only\n","completed_trials_df = df_trials_sorted[df_trials_sorted['state'] == 'COMPLETE'].copy()\n","\n","print(f'   Completed trials: {len(completed_trials_df)}')\n","print(f'   Columns available: {list(completed_trials_df.columns)}')\n","\n","if len(completed_trials_df) == 0:\n","    story.append(Paragraph('No completed trials available for visualization.', styles['Normal']))\n","    print('   âš ï¸ No completed trials found!')\n","else:\n","    # 5.1 mAP@0.5 Progress Over Trials\n","    story.append(Paragraph('5.1 mAP@0.5 Progress Over Trials', styles['Heading3']))\n","\n","    fig, ax = plt.subplots(figsize=(10, 5))\n","    ax.plot(completed_trials_df['trial'], completed_trials_df['mAP@0.5'],\n","            marker='o', linestyle='-', linewidth=2, markersize=6, color='#3498db', alpha=0.7)\n","    ax.axhline(y=study.best_value, color='#e74c3c', linestyle='--', linewidth=2,\n","               label=f'Best: {study.best_value:.4f}')\n","    ax.set_xlabel('Trial Number', fontsize=12, fontweight='bold')\n","    ax.set_ylabel('mAP@0.5', fontsize=12, fontweight='bold')\n","    ax.set_title(f'{MODEL_NAME} - mAP@0.5 Progress', fontsize=14, fontweight='bold')\n","    ax.grid(True, alpha=0.3)\n","    ax.legend(fontsize=10)\n","    plt.tight_layout()\n","\n","    map_progress_img = TUNE_DIR / 'report_map_progress.png'\n","    plt.savefig(map_progress_img, dpi=150, bbox_inches='tight')\n","    plt.close()\n","\n","    story.append(Image(str(map_progress_img), width=6.5*inch, height=3.25*inch))\n","    story.append(Spacer(1, 15))\n","    print(f'âœ“ mAP progress chart saved: {map_progress_img}')\n","\n","    # 5.2 Learning Rate vs mAP@0.5\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.2 Learning Rate Impact on Performance', styles['Heading3']))\n","\n","    if 'lr0' in completed_trials_df.columns and completed_trials_df['lr0'].notna().any():\n","        print(f'   Creating learning rate impact chart...')\n","        fig, ax = plt.subplots(figsize=(10, 5))\n","        scatter = ax.scatter(completed_trials_df['lr0'], completed_trials_df['mAP@0.5'],\n","                           c=completed_trials_df['mAP@0.5'], cmap='RdYlGn',\n","                           s=100, alpha=0.6, edgecolors='black', linewidth=0.5)\n","        ax.set_xlabel('Learning Rate (lr0)', fontsize=12, fontweight='bold')\n","        ax.set_ylabel('mAP@0.5', fontsize=12, fontweight='bold')\n","        ax.set_title(f'{MODEL_NAME} - Learning Rate vs Performance', fontsize=14, fontweight='bold')\n","        ax.grid(True, alpha=0.3)\n","        cbar = plt.colorbar(scatter, ax=ax)\n","        cbar.set_label('mAP@0.5', fontsize=10)\n","        plt.tight_layout()\n","\n","        lr_impact_img = TUNE_DIR / 'report_lr_impact.png'\n","        plt.savefig(lr_impact_img, dpi=150, bbox_inches='tight')\n","        plt.close()\n","\n","        story.append(Image(str(lr_impact_img), width=6.5*inch, height=3.25*inch))\n","        story.append(Spacer(1, 15))\n","        print(f'âœ“ Learning rate impact chart saved: {lr_impact_img}')\n","    else:\n","        story.append(Paragraph('Learning rate data not available for visualization.', styles['Normal']))\n","        story.append(Spacer(1, 15))\n","        print(f'   âš ï¸ lr0 column not found or empty')\n","\n","    # 5.3 Optimizer Comparison\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.3 Optimizer Performance Comparison', styles['Heading3']))\n","\n","    if 'optimizer' in completed_trials_df.columns and completed_trials_df['optimizer'].notna().any():\n","        print(f'   Creating optimizer comparison chart...')\n","        fig, ax = plt.subplots(figsize=(12, 6))\n","\n","        # Calculate comprehensive statistics\n","        optimizer_stats = completed_trials_df.groupby('optimizer')['mAP@0.5'].agg(['mean', 'max', 'min', 'std', 'count'])\n","        optimizer_stats = optimizer_stats.sort_values('mean', ascending=False)\n","\n","        x_pos = range(len(optimizer_stats))\n","\n","        # Create bars with gradient effect\n","        bars = ax.bar(x_pos, optimizer_stats['mean'], alpha=0.8,\n","                     color=['#2ecc71', '#3498db', '#9b59b6', '#e67e22'][:len(optimizer_stats)],\n","                     edgecolor='black', linewidth=1.5, width=0.6)\n","\n","        # Add max and min markers\n","        ax.scatter(x_pos, optimizer_stats['max'], color='#27ae60', s=150,\n","                  label='Max mAP@0.5', zorder=5, edgecolors='black', linewidth=1.5, marker='^')\n","        ax.scatter(x_pos, optimizer_stats['min'], color='#e74c3c', s=150,\n","                  label='Min mAP@0.5', zorder=5, edgecolors='black', linewidth=1.5, marker='v')\n","\n","        # Add error bars for standard deviation\n","        ax.errorbar(x_pos, optimizer_stats['mean'], yerr=optimizer_stats['std'],\n","                   fmt='none', ecolor='gray', alpha=0.5, capsize=5, capthick=2, linewidth=2)\n","\n","        ax.set_xlabel('Optimizer Type', fontsize=13, fontweight='bold')\n","        ax.set_ylabel('mAP@0.5', fontsize=13, fontweight='bold')\n","        ax.set_title(f'{MODEL_NAME} - Optimizer Performance Comparison (Mean Â± Std Dev)',\n","                    fontsize=14, fontweight='bold')\n","        ax.set_xticks(x_pos)\n","        ax.set_xticklabels([])\n","        ax.legend(fontsize=11, loc='lower left', framealpha=0.9, ncol=2)\n","        ax.grid(True, alpha=0.3, axis='y', linestyle='--')\n","\n","        # Add optimizer names inside bars\n","        for i, (opt, row) in enumerate(optimizer_stats.iterrows()):\n","            # Optimizer name inside bar (centered vertically)\n","            ax.text(i, row['mean'] / 2, opt.upper(),\n","                   ha='center', va='center', fontsize=12, fontweight='bold',\n","                   color='white', rotation=0)\n","\n","            # Mean value below optimizer name in bar\n","            ax.text(i, row['mean'] / 2 - 0.02, f\"{row['mean']:.4f}\",\n","                   ha='center', va='top', fontsize=9, fontweight='bold',\n","                   color='white', alpha=0.9)\n","\n","            # Trial count above max point\n","            ax.text(i, row['max'] - 0.05, f\"n={int(row['count'])}\",\n","                   ha='center', va='bottom', fontsize=10, fontweight='bold',\n","                   bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7, edgecolor='black'))\n","\n","        plt.tight_layout()\n","\n","        optimizer_comp_img = TUNE_DIR / 'report_optimizer_comparison.png'\n","        plt.savefig(optimizer_comp_img, dpi=150, bbox_inches='tight')\n","        plt.close()\n","\n","        story.append(Image(str(optimizer_comp_img), width=6.5*inch, height=3.25*inch))\n","        story.append(Spacer(1, 15))\n","        print(f'âœ“ Optimizer comparison chart saved: {optimizer_comp_img}')\n","\n","        # Add detailed statistics table for optimizers\n","        optimizer_table_data = [['Optimizer', 'Mean', 'Max', 'Min', 'Std Dev', 'Trials']]\n","        for opt, row in optimizer_stats.iterrows():\n","            optimizer_table_data.append([\n","                opt.upper(),\n","                f\"{row['mean']:.4f}\",\n","                f\"{row['max']:.4f}\",\n","                f\"{row['min']:.4f}\",\n","                f\"{row['std']:.4f}\",\n","                str(int(row['count']))\n","            ])\n","\n","        opt_table = Table(optimizer_table_data, colWidths=[1.2*inch, 1.0*inch, 1.0*inch, 1.0*inch, 1.0*inch, 0.8*inch])\n","        opt_table.setStyle(TableStyle([\n","            ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#3498db')),\n","            ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n","            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","            ('FONTSIZE', (0, 0), (-1, 0), 10),\n","            ('FONTSIZE', (0, 1), (-1, -1), 9),\n","            ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n","            ('TOPPADDING', (0, 0), (-1, -1), 6),\n","            ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n","            ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n","        ]))\n","        story.append(opt_table)\n","        story.append(Spacer(1, 15))\n","\n","        # Add interpretation text\n","        best_optimizer = optimizer_stats.index[0]\n","        best_mean = optimizer_stats.iloc[0]['mean']\n","        interpretation = f\"<b>Analysis:</b> {best_optimizer.upper()} achieved the highest mean performance ({best_mean:.4f}) across {int(optimizer_stats.iloc[0]['count'])} trials. The error bars show the standard deviation, indicating performance consistency.\"\n","        story.append(Paragraph(interpretation, styles['Normal']))\n","        story.append(Spacer(1, 15))\n","    else:\n","        story.append(Paragraph('Optimizer data not available for visualization.', styles['Normal']))\n","        story.append(Spacer(1, 15))\n","        print(f'   âš ï¸ optimizer column not found or empty')\n","\n","    # 5.4 Augmentation Parameters vs Performance\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.4 Augmentation Parameters Impact', styles['Heading3']))\n","\n","    # Create 2x2 subplot for key augmentation parameters\n","    aug_params = ['mixup', 'mosaic', 'degrees', 'scale']\n","    available_aug_params = [p for p in aug_params if p in completed_trials_df.columns and completed_trials_df[p].notna().any()]\n","\n","    print(f'   Available augmentation params: {available_aug_params}')\n","\n","    if len(available_aug_params) >= 2:\n","        n_plots = min(len(available_aug_params), 4)\n","        fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n","        axes = axes.flatten()\n","\n","        for idx, param in enumerate(available_aug_params[:4]):\n","            ax = axes[idx]\n","            scatter = ax.scatter(completed_trials_df[param], completed_trials_df['mAP@0.5'],\n","                               c=completed_trials_df['mAP@0.5'], cmap='RdYlGn',\n","                               s=60, alpha=0.6, edgecolors='black', linewidth=0.5)\n","            ax.set_xlabel(param, fontsize=10, fontweight='bold')\n","            ax.set_ylabel('mAP@0.5', fontsize=10, fontweight='bold')\n","            ax.set_title(f'{param.capitalize()} Impact', fontsize=11, fontweight='bold')\n","            ax.grid(True, alpha=0.3)\n","\n","        # Hide unused subplots\n","        for idx in range(len(available_aug_params), 4):\n","            axes[idx].axis('off')\n","\n","        plt.tight_layout()\n","\n","        aug_impact_img = TUNE_DIR / 'report_augmentation_impact.png'\n","        plt.savefig(aug_impact_img, dpi=150, bbox_inches='tight')\n","        plt.close()\n","\n","        story.append(Image(str(aug_impact_img), width=6.5*inch, height=5.2*inch))\n","        story.append(Spacer(1, 15))\n","        print(f'âœ“ Augmentation impact chart saved: {aug_impact_img}')\n","    else:\n","        story.append(Paragraph(f'Insufficient augmentation parameter data for visualization. Found: {available_aug_params}', styles['Normal']))\n","        story.append(Spacer(1, 15))\n","        print(f'   âš ï¸ Not enough augmentation params available')\n","\n","    # 5.5 Weight Decay and Momentum vs Performance\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.5 Regularization Parameters Impact', styles['Heading3']))\n","\n","    has_weight_decay = 'weight_decay' in completed_trials_df.columns and completed_trials_df['weight_decay'].notna().any()\n","    has_momentum = 'momentum' in completed_trials_df.columns and completed_trials_df['momentum'].notna().any()\n","\n","    if has_weight_decay and has_momentum:\n","        print(f'   Creating regularization impact chart...')\n","        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n","\n","        # Weight Decay\n","        scatter1 = ax1.scatter(completed_trials_df['weight_decay'], completed_trials_df['mAP@0.5'],\n","                              c=completed_trials_df['mAP@0.5'], cmap='RdYlGn',\n","                              s=80, alpha=0.6, edgecolors='black', linewidth=0.5)\n","        ax1.set_xlabel('Weight Decay', fontsize=11, fontweight='bold')\n","        ax1.set_ylabel('mAP@0.5', fontsize=11, fontweight='bold')\n","        ax1.set_title('Weight Decay Impact', fontsize=12, fontweight='bold')\n","        ax1.grid(True, alpha=0.3)\n","\n","        # Momentum\n","        scatter2 = ax2.scatter(completed_trials_df['momentum'], completed_trials_df['mAP@0.5'],\n","                              c=completed_trials_df['mAP@0.5'], cmap='RdYlGn',\n","                              s=80, alpha=0.6, edgecolors='black', linewidth=0.5)\n","        ax2.set_xlabel('Momentum', fontsize=11, fontweight='bold')\n","        ax2.set_ylabel('mAP@0.5', fontsize=11, fontweight='bold')\n","        ax2.set_title('Momentum Impact', fontsize=12, fontweight='bold')\n","        ax2.grid(True, alpha=0.3)\n","\n","        plt.tight_layout()\n","\n","        reg_impact_img = TUNE_DIR / 'report_regularization_impact.png'\n","        plt.savefig(reg_impact_img, dpi=150, bbox_inches='tight')\n","        plt.close()\n","\n","        story.append(Image(str(reg_impact_img), width=6.5*inch, height=2.6*inch))\n","        story.append(Spacer(1, 15))\n","        print(f'âœ“ Regularization impact chart saved: {reg_impact_img}')\n","    else:\n","        story.append(Paragraph(f'Regularization parameter data not available. weight_decay: {has_weight_decay}, momentum: {has_momentum}', styles['Normal']))\n","        story.append(Spacer(1, 15))\n","        print(f'   âš ï¸ weight_decay or momentum columns not found or empty')\n","\n","    # 5.6 Image Size Impact on Performance\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.6 Image Size Impact on Performance', styles['Heading3']))\n","\n","    if 'imgsz' in completed_trials_df.columns and completed_trials_df['imgsz'].notna().any():\n","        print(f'   Creating image size impact chart...')\n","        fig, ax = plt.subplots(figsize=(10, 5))\n","\n","        # Group by image size and calculate statistics\n","        imgsz_stats = completed_trials_df.groupby('imgsz')['mAP@0.5'].agg(['mean', 'max', 'min', 'count'])\n","        imgsz_stats = imgsz_stats.sort_index()\n","\n","        x_pos = range(len(imgsz_stats))\n","        bars = ax.bar(x_pos, imgsz_stats['mean'], alpha=0.7, color='#9b59b6',\n","               label='Mean mAP@0.5', edgecolor='black', linewidth=1.5, width=0.6)\n","        ax.scatter(x_pos, imgsz_stats['max'], color='#27ae60', s=120,\n","                  label='Max mAP@0.5', zorder=5, edgecolors='black', linewidth=1, marker='^')\n","        ax.scatter(x_pos, imgsz_stats['min'], color='#e74c3c', s=120,\n","                  label='Min mAP@0.5', zorder=5, edgecolors='black', linewidth=1, marker='v')\n","\n","        ax.set_xlabel('Image Size (pixels)', fontsize=12, fontweight='bold')\n","        ax.set_ylabel('mAP@0.5', fontsize=12, fontweight='bold')\n","        ax.set_title(f'{MODEL_NAME} - Image Size Impact on Performance', fontsize=14, fontweight='bold')\n","        ax.set_xticks(x_pos)\n","        ax.set_xticklabels([int(idx) for idx in imgsz_stats.index], fontsize=11, fontweight='bold')\n","        ax.legend(fontsize=10, loc='best')\n","        ax.grid(True, alpha=0.3, axis='y')\n","\n","        # Add count and mean value annotations\n","        for i, (imgsz, row) in enumerate(imgsz_stats.iterrows()):\n","            # Mean value inside bar\n","            ax.text(i, row['mean'] / 2, f\"{row['mean']:.4f}\",\n","                   ha='center', va='center', fontsize=10, fontweight='bold', color='white')\n","            # Count above bar\n","            ax.text(i, row['max'] + 0.003, f\"n={int(row['count'])}\",\n","                   ha='center', va='bottom', fontsize=9)\n","\n","        plt.tight_layout()\n","\n","        imgsz_impact_img = TUNE_DIR / 'report_imgsz_impact.png'\n","        plt.savefig(imgsz_impact_img, dpi=150, bbox_inches='tight')\n","        plt.close()\n","\n","        story.append(Image(str(imgsz_impact_img), width=6.5*inch, height=3.25*inch))\n","        story.append(Spacer(1, 15))\n","        print(f'âœ“ Image size impact chart saved: {imgsz_impact_img}')\n","\n","        # Add statistics table for image sizes\n","        imgsz_table_data = [['Image Size', 'Mean mAP@0.5', 'Max mAP@0.5', 'Min mAP@0.5', 'Trials']]\n","        for imgsz, row in imgsz_stats.iterrows():\n","            imgsz_table_data.append([\n","                str(int(imgsz)),\n","                f\"{row['mean']:.4f}\",\n","                f\"{row['max']:.4f}\",\n","                f\"{row['min']:.4f}\",\n","                str(int(row['count']))\n","            ])\n","\n","        imgsz_table = Table(imgsz_table_data, colWidths=[1.2*inch, 1.2*inch, 1.2*inch, 1.2*inch, 0.8*inch])\n","        imgsz_table.setStyle(TableStyle([\n","            ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#9b59b6')),\n","            ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n","            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","            ('FONTSIZE', (0, 0), (-1, 0), 10),\n","            ('FONTSIZE', (0, 1), (-1, -1), 9),\n","            ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n","            ('TOPPADDING', (0, 0), (-1, -1), 6),\n","            ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n","            ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n","        ]))\n","        story.append(imgsz_table)\n","        story.append(Spacer(1, 15))\n","    else:\n","        story.append(Paragraph('Image size data not available for visualization.', styles['Normal']))\n","        story.append(Spacer(1, 15))\n","        print(f'   âš ï¸ imgsz column not found or empty')\n","\n","    print('âœ“ All custom visualizations generated for PDF report')\n","\n","# ===== SECTION 6: ALL TRIALS SUMMARY =====\n","story.append(PageBreak())\n","story.append(Paragraph('6. All Trials Summary', heading_style))\n","\n","# Statistics\n","completed_df = df_trials_sorted[df_trials_sorted['state'] == 'COMPLETE']\n","if len(completed_df) > 0:\n","    stats_data = [\n","        ['Metric', 'Value'],\n","        ['Completed Trials', str(len(completed_df))],\n","        ['Best mAP@0.5', f\"{completed_df['mAP@0.5'].max():.4f}\"],\n","        ['Worst mAP@0.5', f\"{completed_df['mAP@0.5'].min():.4f}\"],\n","        ['Mean mAP@0.5', f\"{completed_df['mAP@0.5'].mean():.4f}\"],\n","        ['Std Dev mAP@0.5', f\"{completed_df['mAP@0.5'].std():.4f}\"],\n","        ['Median mAP@0.5', f\"{completed_df['mAP@0.5'].median():.4f}\"],\n","    ]\n","\n","    stats_table = Table(stats_data, colWidths=[2.5*inch, 3.5*inch])\n","    stats_table.setStyle(TableStyle([\n","        ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#e74c3c')),\n","        ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n","        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","        ('FONTSIZE', (0, 0), (-1, -1), 10),\n","        ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n","        ('TOPPADDING', (0, 0), (-1, -1), 6),\n","        ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n","        ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n","    ]))\n","    story.append(stats_table)\n","\n","# Build PDF\n","try:\n","    doc.build(story)\n","    print(f'\\nâœ“ Comprehensive PDF report generated: {pdf_report_path}')\n","    print(f'  Size: {pdf_report_path.stat().st_size / (1024*1024):.1f} MB')\n","    print(f'  Sections: Overview, Configuration, Best Hyperparameters, Top 20 Trials,')\n","    print(f'            Optimization Visualizations (6 charts), All Trials Summary')\n","except Exception as pdf_error:\n","    print(f'\\nâš ï¸  Error generating PDF: {pdf_error}')\n","    import traceback\n","    traceback.print_exc()\n","\n","print('=' * 80)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LPKClM39R62I","executionInfo":{"status":"ok","timestamp":1764365026599,"user_tz":-180,"elapsed":3148,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"3658c858-4e99-4405-ffeb-d1a5b3f7a4bb"},"id":"LPKClM39R62I","execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","GENERATING COMPREHENSIVE TUNING PDF REPORT\n","================================================================================\n","\n","ğŸ“Š Preparing comprehensive report with 42 trials\n","   Best Trial: 35\n","   Best mAP@0.5: 0.5771\n","\n","ğŸ“‹ Compiling trials data for report...\n","âœ“ Compiled 42 trials for report\n","   Available columns: ['trial', 'state', 'mAP@0.5', 'imgsz', 'optimizer', 'lr0', 'momentum', 'weight_decay', 'warmup_epochs', 'warmup_momentum', 'warmup_bias_lr', 'mosaic', 'mixup']\n","   DataFrame columns: ['trial', 'state', 'mAP@0.5', 'imgsz', 'optimizer', 'lr0', 'momentum', 'weight_decay', 'warmup_epochs', 'warmup_momentum', 'warmup_bias_lr', 'mosaic', 'mixup']\n","   Sample row keys: ['trial', 'state', 'mAP@0.5', 'imgsz', 'optimizer', 'lr0', 'momentum', 'weight_decay', 'warmup_epochs', 'warmup_momentum', 'warmup_bias_lr', 'mosaic', 'mixup']\n","   Creating detailed params for top 5 trials...\n","   âœ“ Top 5 trials details added\n","\n","ğŸ“Š Generating custom visualizations for PDF report...\n","   Completed trials: 41\n","   Columns available: ['trial', 'state', 'mAP@0.5', 'imgsz', 'optimizer', 'lr0', 'momentum', 'weight_decay', 'warmup_epochs', 'warmup_momentum', 'warmup_bias_lr', 'mosaic', 'mixup']\n","âœ“ mAP progress chart saved: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/report_map_progress.png\n","   Creating learning rate impact chart...\n","âœ“ Learning rate impact chart saved: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/report_lr_impact.png\n","   Creating optimizer comparison chart...\n","âœ“ Optimizer comparison chart saved: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/report_optimizer_comparison.png\n","   Available augmentation params: ['mixup', 'mosaic']\n","âœ“ Augmentation impact chart saved: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/report_augmentation_impact.png\n","   Creating regularization impact chart...\n","âœ“ Regularization impact chart saved: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/report_regularization_impact.png\n","   Creating image size impact chart...\n","âœ“ Image size impact chart saved: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/report_imgsz_impact.png\n","âœ“ All custom visualizations generated for PDF report\n","\n","âœ“ Comprehensive PDF report generated: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/yolov8m_finetuned_1_tuning_report.pdf\n","  Size: 0.5 MB\n","  Sections: Overview, Configuration, Best Hyperparameters, Top 20 Trials,\n","            Optimization Visualizations (6 charts), All Trials Summary\n","================================================================================\n"]}]},{"cell_type":"code","source":["# GENERATE Tuning PDF REPORT\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('GENERATING COMPREHENSIVE TUNING PDF REPORT')\n","print('=' * 80)\n","\n","# Use already extracted best parameters and trial data from previous sections\n","best_params = study.best_params\n","best_trial = study.best_trial\n","\n","print(f'\\nğŸ“Š Preparing comprehensive report with {len(study.trials)} trials')\n","print(f'   Best Trial: {best_trial.number}')\n","print(f'   Best mAP@0.5: {study.best_value:.4f}')\n","\n","# Compile all trials data into DataFrame for PDF report\n","print('\\nğŸ“‹ Compiling trials data for report...')\n","trials_data_for_pdf = []\n","\n","for trial in study.trials:\n","    # Create row with trial info and hyperparameters directly from trial.params\n","    row_data = {\n","        'trial': trial.number,\n","        'state': trial.state.name,\n","        'mAP@0.5': trial.value if trial.value is not None else 0.0,\n","    }\n","\n","    # Add all hyperparameters directly from trial.params\n","    row_data.update(trial.params)\n","\n","    trials_data_for_pdf.append(row_data)\n","\n","# Create DataFrame and sort by mAP@0.5\n","df_trials = pd.DataFrame(trials_data_for_pdf)\n","df_trials_sorted = df_trials.sort_values('mAP@0.5', ascending=False)\n","\n","print(f'âœ“ Compiled {len(df_trials)} trials for report')\n","print(f'   Available columns: {list(df_trials.columns)}')\n","\n","# Create tuning PDF report\n","pdf_report_path = TUNE_DIR / f'{MODEL_NAME}_tuning_report.pdf'\n","\n","doc = SimpleDocTemplate(str(pdf_report_path), pagesize=A4,\n","                       rightMargin=30, leftMargin=30,\n","                       topMargin=30, bottomMargin=30)\n","\n","story = []\n","styles = getSampleStyleSheet()\n","\n","# Custom styles\n","title_style = ParagraphStyle(\n","    'CustomTitle',\n","    parent=styles['Heading1'],\n","    fontSize=18,\n","    textColor=rl_colors.HexColor('#2c3e50'),\n","    spaceAfter=30,\n","    alignment=TA_CENTER\n",")\n","\n","heading_style = ParagraphStyle(\n","    'CustomHeading',\n","    parent=styles['Heading2'],\n","    fontSize=16,\n","    textColor=rl_colors.HexColor('#34495e'),\n","    spaceAfter=12,\n","    spaceBefore=20\n",")\n","\n","small_style = ParagraphStyle(\n","    'SmallText',\n","    parent=styles['Normal'],\n","    fontSize=7,\n","    wordWrap='CJK'\n",")\n","\n","# Title\n","story.append(Paragraph(f'{MODEL_NAME} Hyperparameter Tuning Report', title_style))\n","story.append(Paragraph(f'Generated: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}', styles['Normal']))\n","story.append(Spacer(1, 20))\n","\n","# ===== SECTION 1: OVERVIEW =====\n","story.append(Paragraph('1. Optimization Overview', heading_style))\n","\n","info_data = [\n","    ['Property', 'Value'],\n","    ['Model', MODEL_NAME],\n","    ['Dataset', YOLO_DATASET_ROOT.name],\n","    ['Total Trials', str(len(study.trials))],\n","    ['Completed Trials', str(len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]))],\n","    ['Failed Trials', str(len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL]))],\n","    ['Best Trial', str(study.best_trial.number)],\n","    ['Best mAP@0.5', f'{study.best_value:.4f}'],\n","    ['Optimization Duration', str(duration)],\n","]\n","\n","info_table = Table(info_data, colWidths=[2.5*inch, 3.5*inch])\n","info_table.setStyle(TableStyle([\n","    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#2c3e50')),\n","    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","    ('BACKGROUND', (0, 1), (-1, -1), rl_colors.HexColor('#ecf0f1')),\n","    ('TEXTCOLOR', (0, 1), (-1, -1), rl_colors.black),\n","    ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n","    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","    ('FONTNAME', (0, 1), (0, -1), 'Helvetica-Bold'),\n","    ('FONTSIZE', (0, 0), (-1, -1), 10),\n","    ('BOTTOMPADDING', (0, 0), (-1, -1), 8),\n","    ('TOPPADDING', (0, 0), (-1, -1), 8),\n","    ('GRID', (0, 0), (-1, -1), 1, rl_colors.grey)\n","]))\n","story.append(info_table)\n","story.append(Spacer(1, 20))\n","\n","# ===== SECTION 2: CONFIGURATION =====\n","story.append(Paragraph('2. Optimization Configuration', heading_style))\n","\n","opt_config_data = [\n","    ['Parameter', 'Value'],\n","    ['Total Trials', str(N_TRIALS)],\n","    ['Epochs per Trial', str(EPOCHS_PER_TRIAL)],\n","    ['Batch Size', str(BATCH_SIZE)],\n","    ['Startup Trials (TPE)', str(N_STARTUP_TRIALS)],\n","    ['Device', device],\n","    ['Number of Classes', str(NUM_CLASSES)],\n","    ['Train Images', str(dataset_stats.get('train', {}).get('images', 'N/A'))],\n","    ['Val Images', str(dataset_stats.get('val', {}).get('images', 'N/A'))],\n","]\n","\n","opt_config_table = Table(opt_config_data, colWidths=[3*inch, 3*inch])\n","opt_config_table.setStyle(TableStyle([\n","    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#95a5a6')),\n","    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n","    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","    ('FONTSIZE', (0, 0), (-1, 0), 11),\n","    ('FONTSIZE', (0, 1), (-1, -1), 9),\n","    ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n","    ('TOPPADDING', (0, 0), (-1, -1), 6),\n","    ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n","    ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n","]))\n","story.append(opt_config_table)\n","story.append(Spacer(1, 20))\n","\n","# ===== SECTION 2.5: EXECUTIVE SUMMARY & KEY FINDINGS =====\n","story.append(PageBreak())\n","story.append(Paragraph('2.5 Executive Summary & Key Findings', heading_style))\n","\n","# Calculate key statistics\n","completed_df_summary = df_trials_sorted[df_trials_sorted['state'] == 'COMPLETE']\n","best_map = completed_df_summary['mAP@0.5'].max()\n","worst_map = completed_df_summary['mAP@0.5'].min()\n","mean_map = completed_df_summary['mAP@0.5'].mean()\n","improvement_pct = ((best_map - worst_map) / worst_map) * 100 if worst_map > 0 else 0\n","\n","# Calculate optimizer statistics\n","if 'optimizer' in completed_df_summary.columns:\n","    opt_stats = completed_df_summary.groupby('optimizer')['mAP@0.5'].agg(['mean', 'count'])\n","    best_opt = opt_stats['mean'].idxmax()\n","    best_opt_mean = opt_stats.loc[best_opt, 'mean']\n","else:\n","    best_opt = 'N/A'\n","    best_opt_mean = 0\n","\n","# Calculate image size impact\n","if 'imgsz' in completed_df_summary.columns:\n","    img_stats = completed_df_summary.groupby('imgsz')['mAP@0.5'].mean()\n","    best_imgsz = img_stats.idxmax()\n","    imgsz_improvement = ((img_stats.max() - img_stats.min()) / img_stats.min()) * 100 if len(img_stats) > 1 else 0\n","else:\n","    best_imgsz = 'N/A'\n","    imgsz_improvement = 0\n","\n","# Create findings summary\n","findings_data = [\n","    ['Metric', 'Value'],\n","    ['ğŸ† Best Performance', f'Trial #{study.best_trial.number}: mAP@0.5 = {best_map:.4f}'],\n","    ['ğŸ“Š Performance Range', f'{worst_map:.4f} to {best_map:.4f} ({improvement_pct:.1f}% improvement)'],\n","    ['ğŸ“ˆ Mean Performance', f'{mean_map:.4f} across {len(completed_df_summary)} trials'],\n","    ['âš¡ Best Optimizer', f'{best_opt} (mean: {best_opt_mean:.4f})'],\n","    ['ğŸ–¼ï¸ Optimal Image Size', f'{int(best_imgsz)}px ({imgsz_improvement:.2f}% better)' if best_imgsz != 'N/A' else 'N/A'],\n","    ['â±ï¸ Optimization Time', str(duration)],\n","    ['âœ… Success Rate', f'{len(completed_df_summary)}/{len(study.trials)} trials ({len(completed_df_summary)/len(study.trials)*100:.1f}%)'],\n","]\n","\n","findings_table = Table(findings_data, colWidths=[2.5*inch, 3.5*inch])\n","findings_table.setStyle(TableStyle([\n","    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#27ae60')),\n","    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","    ('BACKGROUND', (0, 1), (-1, -1), rl_colors.HexColor('#ecf9f2')),\n","    ('ALIGN', (0, 0), (-1, 0), 'CENTER'),\n","    ('ALIGN', (0, 1), (0, -1), 'LEFT'),\n","    ('ALIGN', (1, 1), (1, -1), 'LEFT'),\n","    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","    ('FONTSIZE', (0, 0), (-1, 0), 11),\n","    ('FONTSIZE', (0, 1), (-1, -1), 9),\n","    ('BOTTOMPADDING', (0, 0), (-1, -1), 8),\n","    ('TOPPADDING', (0, 0), (-1, -1), 8),\n","    ('GRID', (0, 0), (-1, -1), 1, rl_colors.black),\n","    ('LINEBELOW', (0, 0), (-1, 0), 2, rl_colors.HexColor('#27ae60'))\n","]))\n","story.append(findings_table)\n","story.append(Spacer(1, 15))\n","\n","# Add key insights text\n","insights_text = f\"\"\"\n","<b>Key Insights:</b><br/>\n","â€¢ The optimization process successfully explored {len(study.trials)} trials, achieving a {improvement_pct:.1f}% performance improvement from worst to best.<br/>\n","â€¢ <b>{best_opt}</b> optimizer demonstrated superior performance with mean mAP@0.5 of {best_opt_mean:.4f}.<br/>\n","â€¢ Image size of <b>{int(best_imgsz)}px</b> provided optimal accuracy-efficiency tradeoff.<br/>\n","â€¢ High consistency achieved: mean performance ({mean_map:.4f}) close to best ({best_map:.4f}), indicating robust hyperparameter space.\n","\"\"\"\n","story.append(Paragraph(insights_text, styles['Normal']))\n","story.append(Spacer(1, 20))\n","\n","print(f'âœ“ Executive summary generated')\n","\n","# ===== SECTION 3: BEST HYPERPARAMETERS =====\n","story.append(PageBreak())\n","story.append(Paragraph('3. Best Hyperparameters', heading_style))\n","\n","hyperparam_data = [['Parameter', 'Value', 'Description']]\n","param_descriptions = {\n","    'optimizer': 'Optimization algorithm',\n","    'lr0': 'Initial learning rate',\n","    'lrf': 'Final learning rate factor',\n","    'momentum': 'SGD momentum / Adam beta1',\n","    'weight_decay': 'Weight decay (L2 penalty)',\n","    'warmup_epochs': 'Warmup epochs',\n","    'warmup_momentum': 'Warmup momentum',\n","    'box': 'Box loss gain',\n","    'cls': 'Classification loss gain',\n","    'dfl': 'Distribution focal loss gain',\n","    'hsv_h': 'HSV-Hue augmentation',\n","    'hsv_s': 'HSV-Saturation augmentation',\n","    'hsv_v': 'HSV-Value augmentation',\n","    'degrees': 'Rotation augmentation',\n","    'translate': 'Translation augmentation',\n","    'scale': 'Scale augmentation',\n","    'shear': 'Shear augmentation',\n","    'perspective': 'Perspective augmentation',\n","    'flipud': 'Vertical flip probability',\n","    'fliplr': 'Horizontal flip probability',\n","    'mosaic': 'Mosaic augmentation',\n","    'mixup': 'Mixup augmentation',\n","    'copy_paste': 'Copy-paste augmentation',\n","}\n","\n","for param_key, param_value in best_params.items():\n","    desc = param_descriptions.get(param_key, '')\n","    formatted_value = f'{param_value:.6f}' if isinstance(param_value, float) else str(param_value)\n","    hyperparam_data.append([param_key, formatted_value, desc])\n","\n","hyperparam_table = Table(hyperparam_data, colWidths=[1.8*inch, 1.5*inch, 2.7*inch])\n","hyperparam_table.setStyle(TableStyle([\n","    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#3498db')),\n","    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","    ('ALIGN', (0, 0), (1, -1), 'CENTER'),\n","    ('ALIGN', (2, 1), (2, -1), 'LEFT'),\n","    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","    ('FONTSIZE', (0, 0), (-1, 0), 10),\n","    ('FONTSIZE', (0, 1), (-1, -1), 8),\n","    ('BOTTOMPADDING', (0, 0), (-1, -1), 5),\n","    ('TOPPADDING', (0, 0), (-1, -1), 5),\n","    ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n","    ('GRID', (0, 0), (-1, -1), 1, rl_colors.black),\n","    ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n","]))\n","story.append(hyperparam_table)\n","story.append(Spacer(1, 20))\n","\n","# ===== SECTION 4: TOP 20 TRIALS WITH HYPERPARAMETERS =====\n","story.append(PageBreak())\n","story.append(Paragraph('4. Top 20 Trials Performance', heading_style))\n","\n","# Create detailed top trials table with key hyperparameters\n","print(f'   DataFrame columns: {list(df_trials_sorted.columns)}')\n","print(f'   Sample row keys: {list(df_trials_sorted.head(1).iloc[0].keys())}')\n","\n","top_trials_data = [['#', 'mAP@0.5', 'ImgSz', 'Opt', 'lr0', 'mom', 'mixup', 'mosaic']]\n","for idx, (_, row) in enumerate(df_trials_sorted.head(20).iterrows(), 1):\n","    # Use pd.notna() to check if value exists and is not NaN\n","    img_val = str(int(row['imgsz'])) if 'imgsz' in row and pd.notna(row['imgsz']) else 'N/A'\n","    opt_val = row.get('optimizer', 'N/A')\n","    lr0_val = f\"{row['lr0']:.4f}\" if 'lr0' in row and pd.notna(row['lr0']) else 'N/A'\n","    mom_val = f\"{row['momentum']:.3f}\" if 'momentum' in row and pd.notna(row['momentum']) else 'N/A'\n","    mix_val = f\"{row['mixup']:.2f}\" if 'mixup' in row and pd.notna(row['mixup']) else 'N/A'\n","    mos_val = f\"{row['mosaic']:.2f}\" if 'mosaic' in row and pd.notna(row['mosaic']) else 'N/A'\n","\n","    top_trials_data.append([\n","        str(idx),\n","        f\"{row['mAP@0.5']:.4f}\",\n","        img_val,\n","        str(opt_val)[:4] if opt_val != 'N/A' else 'N/A',\n","        lr0_val,\n","        mom_val,\n","        mix_val,\n","        mos_val,\n","    ])\n","\n","top_trials_table = Table(top_trials_data, colWidths=[0.3*inch, 0.8*inch, 0.6*inch, 0.6*inch, 0.7*inch, 0.7*inch, 0.7*inch, 0.7*inch])\n","top_trials_table.setStyle(TableStyle([\n","    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#27ae60')),\n","    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n","    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","    ('FONTSIZE', (0, 0), (-1, 0), 9),\n","    ('FONTSIZE', (0, 1), (-1, -1), 7),\n","    ('BOTTOMPADDING', (0, 0), (-1, -1), 4),\n","    ('TOPPADDING', (0, 0), (-1, -1), 4),\n","    ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n","    ('GRID', (0, 0), (-1, -1), 0.5, rl_colors.black)\n","]))\n","story.append(top_trials_table)\n","story.append(Spacer(1, 15))\n","\n","# Detailed hyperparameters for top 5 trials\n","story.append(PageBreak())\n","story.append(Paragraph('4.1 Detailed Hyperparameters - Top 5 Trials', heading_style))\n","\n","print(f'   Creating detailed params for top 5 trials...')\n","for rank, (_, row) in enumerate(df_trials_sorted.head(5).iterrows(), 1):\n","    story.append(Paragraph(f'<b>Rank {rank}: Trial {int(row[\"trial\"])} (mAP@0.5: {row[\"mAP@0.5\"]:.4f})</b>', styles['Normal']))\n","\n","    trial_params_text = []\n","    # Get all parameter columns (exclude trial, state, mAP@0.5)\n","    param_cols = [col for col in df_trials_sorted.columns if col not in ['trial', 'state', 'mAP@0.5']]\n","\n","    for param_key in sorted(param_cols):\n","        if param_key in row and pd.notna(row[param_key]):\n","            value = row[param_key]\n","            formatted_val = f'{value:.6f}' if isinstance(value, float) else str(value)\n","            trial_params_text.append(f'{param_key}={formatted_val}')\n","\n","    if trial_params_text:\n","        params_str = ', '.join(trial_params_text)\n","        story.append(Paragraph(params_str, small_style))\n","    else:\n","        story.append(Paragraph('No parameter data available', small_style))\n","    story.append(Spacer(1, 10))\n","\n","print(f'   âœ“ Top 5 trials details added')\n","\n","# ===== SECTION 5: OPTIMIZATION VISUALIZATIONS =====\n","story.append(PageBreak())\n","story.append(Paragraph('5. Optimization Visualizations & Analysis', heading_style))\n","\n","print('\\nğŸ“Š Generating custom visualizations for PDF report...')\n","\n","# Prepare data for completed trials only\n","completed_trials_df = df_trials_sorted[df_trials_sorted['state'] == 'COMPLETE'].copy()\n","\n","print(f'   Completed trials: {len(completed_trials_df)}')\n","print(f'   Columns available: {list(completed_trials_df.columns)}')\n","\n","if len(completed_trials_df) == 0:\n","    story.append(Paragraph('No completed trials available for visualization.', styles['Normal']))\n","    print('   âš ï¸ No completed trials found!')\n","else:\n","    # 5.0 Performance Distribution Box Plot\n","    story.append(Paragraph('5.0 Performance Distribution Analysis', styles['Heading3']))\n","\n","    print(f'   Creating performance distribution box plot...')\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n","\n","    # Box plot for overall distribution\n","    bp = ax1.boxplot([completed_trials_df['mAP@0.5']], vert=True, patch_artist=True,\n","                     labels=['All Trials'], widths=0.5)\n","    bp['boxes'][0].set_facecolor('#3498db')\n","    bp['boxes'][0].set_alpha(0.7)\n","    bp['medians'][0].set_color('#e74c3c')\n","    bp['medians'][0].set_linewidth(2)\n","\n","    # Add statistics annotations\n","    q1 = completed_trials_df['mAP@0.5'].quantile(0.25)\n","    median = completed_trials_df['mAP@0.5'].median()\n","    q3 = completed_trials_df['mAP@0.5'].quantile(0.75)\n","\n","    ax1.text(1.3, q1, f'Q1: {q1:.4f}', fontsize=9, va='center')\n","    ax1.text(1.3, median, f'Median: {median:.4f}', fontsize=9, va='center', fontweight='bold', color='#e74c3c')\n","    ax1.text(1.3, q3, f'Q3: {q3:.4f}', fontsize=9, va='center')\n","    ax1.text(1.3, completed_trials_df['mAP@0.5'].min(), f'Min: {completed_trials_df[\"mAP@0.5\"].min():.4f}',\n","            fontsize=8, va='center', color='gray')\n","    ax1.text(1.3, completed_trials_df['mAP@0.5'].max(), f'Max: {completed_trials_df[\"mAP@0.5\"].max():.4f}',\n","            fontsize=8, va='center', color='gray')\n","\n","    ax1.set_ylabel('mAP@0.5', fontsize=12, fontweight='bold')\n","    ax1.set_title('Overall Performance Distribution', fontsize=13, fontweight='bold')\n","    ax1.grid(True, alpha=0.3, axis='y')\n","\n","    # Histogram with KDE\n","    ax2.hist(completed_trials_df['mAP@0.5'], bins=15, alpha=0.7, color='#3498db',\n","            edgecolor='black', linewidth=1)\n","    ax2.axvline(median, color='#e74c3c', linestyle='--', linewidth=2, label=f'Median: {median:.4f}')\n","    ax2.axvline(study.best_value, color='#27ae60', linestyle='--', linewidth=2, label=f'Best: {study.best_value:.4f}')\n","    ax2.set_xlabel('mAP@0.5', fontsize=12, fontweight='bold')\n","    ax2.set_ylabel('Frequency', fontsize=12, fontweight='bold')\n","    ax2.set_title('Performance Histogram', fontsize=13, fontweight='bold')\n","    ax2.legend(fontsize=10)\n","    ax2.grid(True, alpha=0.3, axis='y')\n","\n","    plt.tight_layout()\n","\n","    perf_dist_img = TUNE_DIR / 'report_performance_distribution.png'\n","    plt.savefig(perf_dist_img, dpi=150, bbox_inches='tight')\n","    plt.close()\n","\n","    story.append(Image(str(perf_dist_img), width=6.5*inch, height=2.7*inch))\n","    story.append(Spacer(1, 15))\n","    print(f'âœ“ Performance distribution chart saved: {perf_dist_img}')\n","\n","    # Add distribution statistics table\n","    dist_stats_data = [\n","        ['Statistic', 'Value'],\n","        ['Mean', f'{completed_trials_df[\"mAP@0.5\"].mean():.4f}'],\n","        ['Median', f'{median:.4f}'],\n","        ['Std Dev', f'{completed_trials_df[\"mAP@0.5\"].std():.4f}'],\n","        ['IQR (Q3-Q1)', f'{q3-q1:.4f}'],\n","        ['Range', f'{completed_trials_df[\"mAP@0.5\"].max() - completed_trials_df[\"mAP@0.5\"].min():.4f}'],\n","    ]\n","\n","    dist_table = Table(dist_stats_data, colWidths=[2*inch, 2*inch])\n","    dist_table.setStyle(TableStyle([\n","        ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#3498db')),\n","        ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n","        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","        ('FONTSIZE', (0, 0), (-1, 0), 10),\n","        ('FONTSIZE', (0, 1), (-1, -1), 9),\n","        ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n","        ('TOPPADDING', (0, 0), (-1, -1), 6),\n","        ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n","        ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n","    ]))\n","    story.append(dist_table)\n","    story.append(Spacer(1, 15))\n","\n","    # 5.1 Parameter Correlation Heatmap\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.1 Parameter Correlation Analysis', styles['Heading3']))\n","\n","    print(f'   Creating parameter correlation heatmap...')\n","\n","    # Select numeric columns for correlation\n","    numeric_cols = ['mAP@0.5']\n","    param_cols = ['lr0', 'momentum', 'weight_decay', 'mixup', 'mosaic']\n","    available_params = [col for col in param_cols if col in completed_trials_df.columns and completed_trials_df[col].notna().any()]\n","\n","    if len(available_params) >= 2:\n","        corr_cols = numeric_cols + available_params\n","        corr_data = completed_trials_df[corr_cols].corr()\n","\n","        fig, ax = plt.subplots(figsize=(10, 8))\n","        im = ax.imshow(corr_data, cmap='RdYlGn', aspect='auto', vmin=-1, vmax=1)\n","\n","        # Set ticks and labels\n","        ax.set_xticks(range(len(corr_cols)))\n","        ax.set_yticks(range(len(corr_cols)))\n","        ax.set_xticklabels(corr_cols, rotation=45, ha='right', fontsize=10)\n","        ax.set_yticklabels(corr_cols, fontsize=10)\n","\n","        # Add correlation values as text\n","        for i in range(len(corr_cols)):\n","            for j in range(len(corr_cols)):\n","                value = corr_data.iloc[i, j]\n","                color = 'white' if abs(value) > 0.5 else 'black'\n","                ax.text(j, i, f'{value:.2f}', ha='center', va='center',\n","                       color=color, fontsize=9, fontweight='bold')\n","\n","        # Add colorbar\n","        cbar = plt.colorbar(im, ax=ax)\n","        cbar.set_label('Correlation Coefficient', fontsize=11, fontweight='bold')\n","\n","        ax.set_title(f'{MODEL_NAME} - Parameter Correlation with Performance',\n","                    fontsize=13, fontweight='bold', pad=20)\n","        plt.tight_layout()\n","\n","        corr_img = TUNE_DIR / 'report_correlation_heatmap.png'\n","        plt.savefig(corr_img, dpi=150, bbox_inches='tight')\n","        plt.close()\n","\n","        story.append(Image(str(corr_img), width=6*inch, height=4.8*inch))\n","        story.append(Spacer(1, 15))\n","        print(f'âœ“ Correlation heatmap saved: {corr_img}')\n","\n","        # Add interpretation\n","        map_corr = corr_data['mAP@0.5'].drop('mAP@0.5')\n","        strongest_pos = map_corr.idxmax() if map_corr.max() > 0 else None\n","        strongest_neg = map_corr.idxmin() if map_corr.min() < 0 else None\n","\n","        corr_text = f\"<b>Correlation Insights:</b><br/>\"\n","        if strongest_pos:\n","            corr_text += f\"â€¢ Strongest positive correlation: <b>{strongest_pos}</b> ({map_corr[strongest_pos]:.3f}) - Higher values tend to improve performance.<br/>\"\n","        if strongest_neg:\n","            corr_text += f\"â€¢ Strongest negative correlation: <b>{strongest_neg}</b> ({map_corr[strongest_neg]:.3f}) - Higher values tend to decrease performance.<br/>\"\n","        corr_text += f\"â€¢ Green cells indicate positive correlation, red cells indicate negative correlation.\"\n","\n","        story.append(Paragraph(corr_text, styles['Normal']))\n","        story.append(Spacer(1, 15))\n","\n","    # 5.2 Optimization Timeline & Convergence\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.2 Optimization Timeline & Convergence', styles['Heading3']))\n","\n","    print(f'   Creating optimization timeline chart...')\n","    fig, ax = plt.subplots(figsize=(12, 5))\n","\n","    # Sort by trial number for timeline\n","    timeline_df = completed_trials_df.sort_values('trial')\n","\n","    # Plot actual performance\n","    ax.plot(timeline_df['trial'], timeline_df['mAP@0.5'],\n","            marker='o', linestyle='-', linewidth=1.5, markersize=5,\n","            color='#95a5a6', alpha=0.5, label='Trial Performance')\n","\n","    # Calculate and plot moving average (window=5)\n","    window = min(5, len(timeline_df))\n","    if window > 1:\n","        moving_avg = timeline_df['mAP@0.5'].rolling(window=window, min_periods=1).mean()\n","        ax.plot(timeline_df['trial'], moving_avg,\n","               linewidth=3, color='#3498db', label=f'{window}-Trial Moving Average')\n","\n","    # Calculate and plot cumulative best\n","    cumulative_best = timeline_df['mAP@0.5'].cummax()\n","    ax.plot(timeline_df['trial'], cumulative_best,\n","           linewidth=2.5, color='#27ae60', linestyle='--',\n","           label='Cumulative Best', marker='*', markersize=8, markevery=cumulative_best.diff().fillna(1) != 0)\n","\n","    # Mark best trial\n","    best_trial_idx = timeline_df[timeline_df['mAP@0.5'] == study.best_value].iloc[0]\n","    ax.scatter([best_trial_idx['trial']], [study.best_value],\n","              s=300, color='#e74c3c', marker='*', zorder=5,\n","              edgecolors='black', linewidth=2, label=f'Best Trial #{int(best_trial_idx[\"trial\"])}')\n","    ax.annotate(f'Best: {study.best_value:.4f}',\n","               xy=(best_trial_idx['trial'], study.best_value),\n","               xytext=(10, 10), textcoords='offset points',\n","               fontsize=10, fontweight='bold',\n","               bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.7),\n","               arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0', lw=2))\n","\n","    ax.set_xlabel('Trial Number', fontsize=12, fontweight='bold')\n","    ax.set_ylabel('mAP@0.5', fontsize=12, fontweight='bold')\n","    ax.set_title(f'{MODEL_NAME} - Optimization Progress & Convergence', fontsize=14, fontweight='bold')\n","    ax.legend(fontsize=10, loc='lower right')\n","    ax.grid(True, alpha=0.3)\n","\n","    plt.tight_layout()\n","\n","    timeline_img = TUNE_DIR / 'report_optimization_timeline.png'\n","    plt.savefig(timeline_img, dpi=150, bbox_inches='tight')\n","    plt.close()\n","\n","    story.append(Image(str(timeline_img), width=6.5*inch, height=2.7*inch))\n","    story.append(Spacer(1, 15))\n","    print(f'âœ“ Optimization timeline chart saved: {timeline_img}')\n","\n","    # Add convergence analysis\n","    best_found_at = int(best_trial_idx['trial'])\n","    total_trials = len(timeline_df)\n","    convergence_pct = (best_found_at / total_trials) * 100\n","\n","    convergence_text = f\"\"\"<b>Convergence Analysis:</b><br/>\n","â€¢ Best solution found at trial <b>#{best_found_at}</b> ({convergence_pct:.1f}% through optimization).<br/>\n","â€¢ Moving average shows {'rapid early convergence' if convergence_pct < 40 else 'gradual improvement' if convergence_pct < 70 else 'late discovery'} pattern.<br/>\n","â€¢ Cumulative best curve indicates {'efficient' if convergence_pct < 50 else 'moderate'} exploration of hyperparameter space.\n","\"\"\"\n","    story.append(Paragraph(convergence_text, styles['Normal']))\n","    story.append(Spacer(1, 15))\n","\n","    # 5.3 mAP@0.5 Progress Over Trials (original chart)\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.3 mAP@0.5 Progress Over Trials', styles['Heading3']))\n","\n","    fig, ax = plt.subplots(figsize=(10, 5))\n","    ax.plot(completed_trials_df['trial'], completed_trials_df['mAP@0.5'],\n","            marker='o', linestyle='-', linewidth=2, markersize=6, color='#3498db', alpha=0.7)\n","    ax.axhline(y=study.best_value, color='#e74c3c', linestyle='--', linewidth=2,\n","               label=f'Best: {study.best_value:.4f}')\n","    ax.set_xlabel('Trial Number', fontsize=12, fontweight='bold')\n","    ax.set_ylabel('mAP@0.5', fontsize=12, fontweight='bold')\n","    ax.set_title(f'{MODEL_NAME} - mAP@0.5 Progress', fontsize=14, fontweight='bold')\n","    ax.grid(True, alpha=0.3)\n","    ax.legend(fontsize=10)\n","    plt.tight_layout()\n","\n","    map_progress_img = TUNE_DIR / 'report_map_progress.png'\n","    plt.savefig(map_progress_img, dpi=150, bbox_inches='tight')\n","    plt.close()\n","\n","    story.append(Image(str(map_progress_img), width=6.5*inch, height=3.25*inch))\n","    story.append(Spacer(1, 15))\n","    print(f'âœ“ mAP progress chart saved: {map_progress_img}')\n","\n","    # 5.4 Learning Rate vs mAP@0.5\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.4 Learning Rate Impact on Performance', styles['Heading3']))\n","\n","    if 'lr0' in completed_trials_df.columns and completed_trials_df['lr0'].notna().any():\n","        print(f'   Creating learning rate impact chart...')\n","        fig, ax = plt.subplots(figsize=(10, 5))\n","        scatter = ax.scatter(completed_trials_df['lr0'], completed_trials_df['mAP@0.5'],\n","                           c=completed_trials_df['mAP@0.5'], cmap='RdYlGn',\n","                           s=100, alpha=0.6, edgecolors='black', linewidth=0.5)\n","        ax.set_xlabel('Learning Rate (lr0)', fontsize=12, fontweight='bold')\n","        ax.set_ylabel('mAP@0.5', fontsize=12, fontweight='bold')\n","        ax.set_title(f'{MODEL_NAME} - Learning Rate vs Performance', fontsize=14, fontweight='bold')\n","        ax.grid(True, alpha=0.3)\n","        cbar = plt.colorbar(scatter, ax=ax)\n","        cbar.set_label('mAP@0.5', fontsize=10)\n","        plt.tight_layout()\n","\n","        lr_impact_img = TUNE_DIR / 'report_lr_impact.png'\n","        plt.savefig(lr_impact_img, dpi=150, bbox_inches='tight')\n","        plt.close()\n","\n","        story.append(Image(str(lr_impact_img), width=6.5*inch, height=3.25*inch))\n","        story.append(Spacer(1, 15))\n","        print(f'âœ“ Learning rate impact chart saved: {lr_impact_img}')\n","    else:\n","        story.append(Paragraph('Learning rate data not available for visualization.', styles['Normal']))\n","        story.append(Spacer(1, 15))\n","        print(f'   âš ï¸ lr0 column not found or empty')\n","\n","    # 5.5 Optimizer Comparison\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.5 Optimizer Performance Comparison', styles['Heading3']))\n","\n","    if 'optimizer' in completed_trials_df.columns and completed_trials_df['optimizer'].notna().any():\n","        print(f'   Creating optimizer comparison chart...')\n","        fig, ax = plt.subplots(figsize=(12, 6))\n","\n","        # Calculate comprehensive statistics\n","        optimizer_stats = completed_trials_df.groupby('optimizer')['mAP@0.5'].agg(['mean', 'max', 'min', 'std', 'count'])\n","        optimizer_stats = optimizer_stats.sort_values('mean', ascending=False)\n","\n","        x_pos = range(len(optimizer_stats))\n","\n","        # Create bars with gradient effect\n","        bars = ax.bar(x_pos, optimizer_stats['mean'], alpha=0.8,\n","                     color=['#2ecc71', '#3498db', '#9b59b6', '#e67e22'][:len(optimizer_stats)],\n","                     edgecolor='black', linewidth=1.5, width=0.6)\n","\n","        # Add max and min markers\n","        ax.scatter(x_pos, optimizer_stats['max'], color='#27ae60', s=150,\n","                  label='Max mAP@0.5', zorder=5, edgecolors='black', linewidth=1.5, marker='^')\n","        ax.scatter(x_pos, optimizer_stats['min'], color='#e74c3c', s=150,\n","                  label='Min mAP@0.5', zorder=5, edgecolors='black', linewidth=1.5, marker='v')\n","\n","        # Add error bars for standard deviation\n","        ax.errorbar(x_pos, optimizer_stats['mean'], yerr=optimizer_stats['std'],\n","                   fmt='none', ecolor='gray', alpha=0.5, capsize=5, capthick=2, linewidth=2)\n","\n","        ax.set_xlabel('Optimizer Type', fontsize=13, fontweight='bold')\n","        ax.set_ylabel('mAP@0.5', fontsize=13, fontweight='bold')\n","        ax.set_title(f'{MODEL_NAME} - Optimizer Performance Comparison (Mean Â± Std Dev)',\n","                    fontsize=14, fontweight='bold')\n","        ax.set_xticks(x_pos)\n","        ax.set_xticklabels([])\n","        ax.legend(fontsize=11, loc='lower left', framealpha=0.9, ncol=2)\n","        ax.grid(True, alpha=0.3, axis='y', linestyle='--')\n","\n","        # Add optimizer names inside bars\n","        for i, (opt, row) in enumerate(optimizer_stats.iterrows()):\n","            # Optimizer name inside bar (centered vertically)\n","            ax.text(i, row['mean'] / 2, opt.upper(),\n","                   ha='center', va='center', fontsize=12, fontweight='bold',\n","                   color='white', rotation=0)\n","\n","            # Mean value below optimizer name in bar\n","            ax.text(i, row['mean'] / 2 - 0.02, f\"{row['mean']:.4f}\",\n","                   ha='center', va='top', fontsize=9, fontweight='bold',\n","                   color='white', alpha=0.9)\n","\n","            # Trial count above max point\n","            ax.text(i, row['max'] - 0.05, f\"n={int(row['count'])}\",\n","                   ha='center', va='bottom', fontsize=10, fontweight='bold',\n","                   bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7, edgecolor='black'))\n","\n","        plt.tight_layout()\n","\n","        optimizer_comp_img = TUNE_DIR / 'report_optimizer_comparison.png'\n","        plt.savefig(optimizer_comp_img, dpi=150, bbox_inches='tight')\n","        plt.close()\n","\n","        story.append(Image(str(optimizer_comp_img), width=6.5*inch, height=3.25*inch))\n","        story.append(Spacer(1, 15))\n","        print(f'âœ“ Optimizer comparison chart saved: {optimizer_comp_img}')\n","\n","        # Add detailed statistics table for optimizers\n","        optimizer_table_data = [['Optimizer', 'Mean', 'Max', 'Min', 'Std Dev', 'Trials']]\n","        for opt, row in optimizer_stats.iterrows():\n","            optimizer_table_data.append([\n","                opt.upper(),\n","                f\"{row['mean']:.4f}\",\n","                f\"{row['max']:.4f}\",\n","                f\"{row['min']:.4f}\",\n","                f\"{row['std']:.4f}\",\n","                str(int(row['count']))\n","            ])\n","\n","        opt_table = Table(optimizer_table_data, colWidths=[1.2*inch, 1.0*inch, 1.0*inch, 1.0*inch, 1.0*inch, 0.8*inch])\n","        opt_table.setStyle(TableStyle([\n","            ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#3498db')),\n","            ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n","            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","            ('FONTSIZE', (0, 0), (-1, 0), 10),\n","            ('FONTSIZE', (0, 1), (-1, -1), 9),\n","            ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n","            ('TOPPADDING', (0, 0), (-1, -1), 6),\n","            ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n","            ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n","        ]))\n","        story.append(opt_table)\n","        story.append(Spacer(1, 15))\n","\n","        # Add interpretation text\n","        best_optimizer = optimizer_stats.index[0]\n","        best_mean = optimizer_stats.iloc[0]['mean']\n","        interpretation = f\"<b>Analysis:</b> {best_optimizer.upper()} achieved the highest mean performance ({best_mean:.4f}) across {int(optimizer_stats.iloc[0]['count'])} trials. The error bars show the standard deviation, indicating performance consistency.\"\n","        story.append(Paragraph(interpretation, styles['Normal']))\n","        story.append(Spacer(1, 15))\n","    else:\n","        story.append(Paragraph('Optimizer data not available for visualization.', styles['Normal']))\n","        story.append(Spacer(1, 15))\n","        print(f'   âš ï¸ optimizer column not found or empty')\n","\n","    # 5.6 Augmentation Parameters vs Performance\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.6 Augmentation Parameters Impact', styles['Heading3']))\n","\n","    # Create 2x2 subplot for key augmentation parameters\n","    aug_params = ['mixup', 'mosaic', 'degrees', 'scale']\n","    available_aug_params = [p for p in aug_params if p in completed_trials_df.columns and completed_trials_df[p].notna().any()]\n","\n","    print(f'   Available augmentation params: {available_aug_params}')\n","\n","    if len(available_aug_params) >= 2:\n","        n_plots = min(len(available_aug_params), 4)\n","        fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n","        axes = axes.flatten()\n","\n","        for idx, param in enumerate(available_aug_params[:4]):\n","            ax = axes[idx]\n","            scatter = ax.scatter(completed_trials_df[param], completed_trials_df['mAP@0.5'],\n","                               c=completed_trials_df['mAP@0.5'], cmap='RdYlGn',\n","                               s=60, alpha=0.6, edgecolors='black', linewidth=0.5)\n","            ax.set_xlabel(param, fontsize=10, fontweight='bold')\n","            ax.set_ylabel('mAP@0.5', fontsize=10, fontweight='bold')\n","            ax.set_title(f'{param.capitalize()} Impact', fontsize=11, fontweight='bold')\n","            ax.grid(True, alpha=0.3)\n","\n","        # Hide unused subplots\n","        for idx in range(len(available_aug_params), 4):\n","            axes[idx].axis('off')\n","\n","        plt.tight_layout()\n","\n","        aug_impact_img = TUNE_DIR / 'report_augmentation_impact.png'\n","        plt.savefig(aug_impact_img, dpi=150, bbox_inches='tight')\n","        plt.close()\n","\n","        story.append(Image(str(aug_impact_img), width=6.5*inch, height=5.2*inch))\n","        story.append(Spacer(1, 15))\n","        print(f'âœ“ Augmentation impact chart saved: {aug_impact_img}')\n","    else:\n","        story.append(Paragraph(f'Insufficient augmentation parameter data for visualization. Found: {available_aug_params}', styles['Normal']))\n","        story.append(Spacer(1, 15))\n","        print(f'   âš ï¸ Not enough augmentation params available')\n","\n","    # 5.7 Weight Decay and Momentum vs Performance\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.7 Regularization Parameters Impact', styles['Heading3']))\n","\n","    has_weight_decay = 'weight_decay' in completed_trials_df.columns and completed_trials_df['weight_decay'].notna().any()\n","    has_momentum = 'momentum' in completed_trials_df.columns and completed_trials_df['momentum'].notna().any()\n","\n","    if has_weight_decay and has_momentum:\n","        print(f'   Creating regularization impact chart...')\n","        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n","\n","        # Weight Decay\n","        scatter1 = ax1.scatter(completed_trials_df['weight_decay'], completed_trials_df['mAP@0.5'],\n","                              c=completed_trials_df['mAP@0.5'], cmap='RdYlGn',\n","                              s=80, alpha=0.6, edgecolors='black', linewidth=0.5)\n","        ax1.set_xlabel('Weight Decay', fontsize=11, fontweight='bold')\n","        ax1.set_ylabel('mAP@0.5', fontsize=11, fontweight='bold')\n","        ax1.set_title('Weight Decay Impact', fontsize=12, fontweight='bold')\n","        ax1.grid(True, alpha=0.3)\n","\n","        # Momentum\n","        scatter2 = ax2.scatter(completed_trials_df['momentum'], completed_trials_df['mAP@0.5'],\n","                              c=completed_trials_df['mAP@0.5'], cmap='RdYlGn',\n","                              s=80, alpha=0.6, edgecolors='black', linewidth=0.5)\n","        ax2.set_xlabel('Momentum', fontsize=11, fontweight='bold')\n","        ax2.set_ylabel('mAP@0.5', fontsize=11, fontweight='bold')\n","        ax2.set_title('Momentum Impact', fontsize=12, fontweight='bold')\n","        ax2.grid(True, alpha=0.3)\n","\n","        plt.tight_layout()\n","\n","        reg_impact_img = TUNE_DIR / 'report_regularization_impact.png'\n","        plt.savefig(reg_impact_img, dpi=150, bbox_inches='tight')\n","        plt.close()\n","\n","        story.append(Image(str(reg_impact_img), width=6.5*inch, height=2.6*inch))\n","        story.append(Spacer(1, 15))\n","        print(f'âœ“ Regularization impact chart saved: {reg_impact_img}')\n","    else:\n","        story.append(Paragraph(f'Regularization parameter data not available. weight_decay: {has_weight_decay}, momentum: {has_momentum}', styles['Normal']))\n","        story.append(Spacer(1, 15))\n","        print(f'   âš ï¸ weight_decay or momentum columns not found or empty')\n","\n","    # 5.8 Image Size Impact on Performance\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.8 Image Size Impact on Performance', styles['Heading3']))\n","\n","    if 'imgsz' in completed_trials_df.columns and completed_trials_df['imgsz'].notna().any():\n","        print(f'   Creating image size impact chart...')\n","        fig, ax = plt.subplots(figsize=(10, 5))\n","\n","        # Group by image size and calculate statistics\n","        imgsz_stats = completed_trials_df.groupby('imgsz')['mAP@0.5'].agg(['mean', 'max', 'min', 'count'])\n","        imgsz_stats = imgsz_stats.sort_index()\n","\n","        x_pos = range(len(imgsz_stats))\n","        bars = ax.bar(x_pos, imgsz_stats['mean'], alpha=0.7, color='#9b59b6',\n","               label='Mean mAP@0.5', edgecolor='black', linewidth=1.5, width=0.6)\n","        ax.scatter(x_pos, imgsz_stats['max'], color='#27ae60', s=120,\n","                  label='Max mAP@0.5', zorder=5, edgecolors='black', linewidth=1, marker='^')\n","        ax.scatter(x_pos, imgsz_stats['min'], color='#e74c3c', s=120,\n","                  label='Min mAP@0.5', zorder=5, edgecolors='black', linewidth=1, marker='v')\n","\n","        ax.set_xlabel('Image Size (pixels)', fontsize=12, fontweight='bold')\n","        ax.set_ylabel('mAP@0.5', fontsize=12, fontweight='bold')\n","        ax.set_title(f'{MODEL_NAME} - Image Size Impact on Performance', fontsize=14, fontweight='bold')\n","        ax.set_xticks(x_pos)\n","        ax.set_xticklabels([int(idx) for idx in imgsz_stats.index], fontsize=11, fontweight='bold')\n","        ax.legend(fontsize=10, loc='best')\n","        ax.grid(True, alpha=0.3, axis='y')\n","\n","        # Add count and mean value annotations\n","        for i, (imgsz, row) in enumerate(imgsz_stats.iterrows()):\n","            # Mean value inside bar\n","            ax.text(i, row['mean'] / 2, f\"{row['mean']:.4f}\",\n","                   ha='center', va='center', fontsize=10, fontweight='bold', color='white')\n","            # Count above bar\n","            ax.text(i, row['max'] + 0.003, f\"n={int(row['count'])}\",\n","                   ha='center', va='bottom', fontsize=9)\n","\n","        plt.tight_layout()\n","\n","        imgsz_impact_img = TUNE_DIR / 'report_imgsz_impact.png'\n","        plt.savefig(imgsz_impact_img, dpi=150, bbox_inches='tight')\n","        plt.close()\n","\n","        story.append(Image(str(imgsz_impact_img), width=6.5*inch, height=3.25*inch))\n","        story.append(Spacer(1, 15))\n","        print(f'âœ“ Image size impact chart saved: {imgsz_impact_img}')\n","\n","        # Add statistics table for image sizes\n","        imgsz_table_data = [['Image Size', 'Mean mAP@0.5', 'Max mAP@0.5', 'Min mAP@0.5', 'Trials']]\n","        for imgsz, row in imgsz_stats.iterrows():\n","            imgsz_table_data.append([\n","                str(int(imgsz)),\n","                f\"{row['mean']:.4f}\",\n","                f\"{row['max']:.4f}\",\n","                f\"{row['min']:.4f}\",\n","                str(int(row['count']))\n","            ])\n","\n","        imgsz_table = Table(imgsz_table_data, colWidths=[1.2*inch, 1.2*inch, 1.2*inch, 1.2*inch, 0.8*inch])\n","        imgsz_table.setStyle(TableStyle([\n","            ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#9b59b6')),\n","            ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n","            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","            ('FONTSIZE', (0, 0), (-1, 0), 10),\n","            ('FONTSIZE', (0, 1), (-1, -1), 9),\n","            ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n","            ('TOPPADDING', (0, 0), (-1, -1), 6),\n","            ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n","            ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n","        ]))\n","        story.append(imgsz_table)\n","        story.append(Spacer(1, 15))\n","    else:\n","        story.append(Paragraph('Image size data not available for visualization.', styles['Normal']))\n","        story.append(Spacer(1, 15))\n","        print(f'   âš ï¸ imgsz column not found or empty')\n","\n","    print('âœ“ All custom visualizations generated for PDF report')\n","\n","# ===== SECTION 5.9: KEY INSIGHTS & RECOMMENDATIONS =====\n","story.append(PageBreak())\n","story.append(Paragraph('5.9 Key Insights & Production Recommendations', styles['Heading3']))\n","\n","print('   Generating key insights and recommendations...')\n","\n","# Generate comprehensive recommendations based on best trial\n","best_trial_row = completed_trials_df[completed_trials_df['trial'] == study.best_trial.number].iloc[0]\n","\n","recommendations_text = f\"\"\"\n","<b>ğŸ¯ Optimal Configuration for Production Deployment:</b><br/><br/>\n","\n","<b>1. Image Processing:</b><br/>\n","   â€¢ Use <b>{int(best_trial_row.get('imgsz', 'N/A'))}px</b> input resolution for optimal accuracy<br/>\n","   â€¢ Expected performance: <b>mAP@0.5 = {study.best_value:.4f}</b><br/>\n","   â€¢ Tradeoff: Higher resolution improves accuracy but increases inference time<br/><br/>\n","\n","<b>2. Optimizer Configuration:</b><br/>\n","   â€¢ Algorithm: <b>{best_trial_row.get('optimizer', 'N/A')}</b><br/>\n","   â€¢ Learning rate (lr0): <b>{best_trial_row.get('lr0', 0):.6f}</b><br/>\n","   â€¢ Momentum: <b>{best_trial_row.get('momentum', 0):.4f}</b><br/>\n","   â€¢ Weight decay: <b>{best_trial_row.get('weight_decay', 0):.6f}</b><br/><br/>\n","\n","<b>3. Training Warmup:</b><br/>\n","   â€¢ Warmup epochs: <b>{int(best_trial_row.get('warmup_epochs', 0))}</b><br/>\n","   â€¢ Warmup momentum: <b>{best_trial_row.get('warmup_momentum', 0):.4f}</b><br/>\n","   â€¢ Warmup bias lr: <b>{best_trial_row.get('warmup_bias_lr', 0):.6f}</b><br/><br/>\n","\n","<b>4. Data Augmentation:</b><br/>\n","   â€¢ Mosaic augmentation: <b>{best_trial_row.get('mosaic', 0):.4f}</b> (strong augmentation for robustness)<br/>\n","   â€¢ Mixup augmentation: <b>{best_trial_row.get('mixup', 0):.4f}</b> (light augmentation)<br/>\n","   â€¢ Recommendation: Use these exact values for similar datasets<br/><br/>\n","\n","<b>5. Performance Metrics:</b><br/>\n","   â€¢ Best trial found at <b>#{int(best_trial_row['trial'])}</b> out of {len(study.trials)} trials<br/>\n","   â€¢ Performance improvement: <b>{improvement_pct:.1f}%</b> over worst trial<br/>\n","   â€¢ Consistency: Mean mAP@0.5 = {mean_map:.4f} (Std = {completed_df_summary[\"mAP@0.5\"].std():.4f})<br/><br/>\n","\n","<b>6. Deployment Recommendations:</b><br/>\n","\"\"\"\n","\n","# Add optimizer-specific recommendations\n","if 'optimizer' in completed_df_summary.columns:\n","    opt_comparison = completed_df_summary.groupby('optimizer')['mAP@0.5'].agg(['mean', 'std', 'count'])\n","    recommendations_text += f\"   â€¢ <b>{best_opt}</b> optimizer demonstrated best performance (mean: {best_opt_mean:.4f})<br/>\"\n","\n","    if len(opt_comparison) > 1:\n","        other_opts = opt_comparison[opt_comparison.index != best_opt]\n","        if len(other_opts) > 0:\n","            worst_opt = other_opts['mean'].idxmin()\n","            diff_pct = ((best_opt_mean - other_opts.loc[worst_opt, 'mean']) / other_opts.loc[worst_opt, 'mean']) * 100\n","            recommendations_text += f\"   â€¢ <b>{best_opt}</b> outperformed {worst_opt} by {diff_pct:.1f}%<br/>\"\n","\n","# Add image size recommendations\n","if 'imgsz' in completed_df_summary.columns and len(completed_df_summary['imgsz'].unique()) > 1:\n","    imgsz_comparison = completed_df_summary.groupby('imgsz')['mAP@0.5'].mean()\n","    recommendations_text += f\"   â€¢ For maximum accuracy, use {int(best_imgsz)}px images<br/>\"\n","    if len(imgsz_comparison) > 1:\n","        smaller_sizes = imgsz_comparison[imgsz_comparison.index < best_imgsz]\n","        if len(smaller_sizes) > 0:\n","            recommendations_text += f\"   â€¢ For faster inference with slight accuracy trade-off, consider {int(smaller_sizes.index[-1])}px (mAP: {smaller_sizes.iloc[-1]:.4f})<br/>\"\n","\n","recommendations_text += f\"\"\"<br/>\n","<b>7. Next Steps:</b><br/>\n","   â€¢ Train full model with these hyperparameters <br/>\n","   â€¢ Monitor validation metrics for overfitting<br/>\n","   â€¢ Consider ensemble methods for further improvement<br/><br/>\n","\n","<b>ğŸ“Š Confidence Level:</b><br/>\n","   â€¢ Based on {len(completed_df_summary)} successful trials<br/>\n","   â€¢ Optimization converged {'early' if convergence_pct < 40 else 'steadily'} (best at {convergence_pct:.1f}% through search)<br/>\n","   â€¢ Standard deviation ({completed_df_summary['mAP@0.5'].std():.4f}) indicates {'high' if completed_df_summary['mAP@0.5'].std() < 0.02 else 'moderate'} consistency\n","\"\"\"\n","\n","story.append(Paragraph(recommendations_text, styles['Normal']))\n","story.append(Spacer(1, 20))\n","\n","# Add comparison table: Best vs Mean vs Worst\n","comparison_data = [\n","    ['Metric', 'Best Trial', 'Mean Performance', 'Worst Trial'],\n","    ['mAP@0.5', f'{best_map:.4f}', f'{mean_map:.4f}', f'{worst_map:.4f}'],\n","    ['Trial #', f'#{int(best_trial_row[\"trial\"])}', '-', f'#{int(completed_df_summary.loc[completed_df_summary[\"mAP@0.5\"].idxmin(), \"trial\"])}'],\n","]\n","\n","# Add key parameters\n","if 'lr0' in best_trial_row:\n","    worst_trial_row = completed_df_summary.loc[completed_df_summary['mAP@0.5'].idxmin()]\n","    comparison_data.append(['Learning Rate', f'{best_trial_row[\"lr0\"]:.6f}',\n","                           f'{completed_df_summary[\"lr0\"].mean():.6f}', f'{worst_trial_row[\"lr0\"]:.6f}'])\n","if 'momentum' in best_trial_row:\n","    comparison_data.append(['Momentum', f'{best_trial_row[\"momentum\"]:.4f}',\n","                           f'{completed_df_summary[\"momentum\"].mean():.4f}', f'{worst_trial_row[\"momentum\"]:.4f}'])\n","\n","comparison_table = Table(comparison_data, colWidths=[1.5*inch, 1.5*inch, 1.5*inch, 1.5*inch])\n","comparison_table.setStyle(TableStyle([\n","    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#e74c3c')),\n","    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","    ('BACKGROUND', (1, 1), (1, -1), rl_colors.HexColor('#d5f4e6')),  # Highlight best column\n","    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n","    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","    ('FONTSIZE', (0, 0), (-1, 0), 10),\n","    ('FONTSIZE', (0, 1), (-1, -1), 9),\n","    ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n","    ('TOPPADDING', (0, 0), (-1, -1), 6),\n","    ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n","]))\n","story.append(comparison_table)\n","story.append(Spacer(1, 20))\n","\n","print('âœ“ Insights and recommendations section completed')\n","\n","# ===== SECTION 6: ALL TRIALS SUMMARY =====\n","story.append(PageBreak())\n","story.append(Paragraph('6. All Trials Summary', heading_style))\n","\n","# Statistics\n","completed_df = df_trials_sorted[df_trials_sorted['state'] == 'COMPLETE']\n","if len(completed_df) > 0:\n","    stats_data = [\n","        ['Metric', 'Value'],\n","        ['Completed Trials', str(len(completed_df))],\n","        ['Best mAP@0.5', f\"{completed_df['mAP@0.5'].max():.4f}\"],\n","        ['Worst mAP@0.5', f\"{completed_df['mAP@0.5'].min():.4f}\"],\n","        ['Mean mAP@0.5', f\"{completed_df['mAP@0.5'].mean():.4f}\"],\n","        ['Std Dev mAP@0.5', f\"{completed_df['mAP@0.5'].std():.4f}\"],\n","        ['Median mAP@0.5', f\"{completed_df['mAP@0.5'].median():.4f}\"],\n","    ]\n","\n","    stats_table = Table(stats_data, colWidths=[2.5*inch, 3.5*inch])\n","    stats_table.setStyle(TableStyle([\n","        ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#e74c3c')),\n","        ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n","        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","        ('FONTSIZE', (0, 0), (-1, -1), 10),\n","        ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n","        ('TOPPADDING', (0, 0), (-1, -1), 6),\n","        ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n","        ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n","    ]))\n","    story.append(stats_table)\n","\n","# Build PDF\n","try:\n","    doc.build(story)\n","    print(f'\\nâœ“ Comprehensive PDF report generated: {pdf_report_path}')\n","    print(f'  Size: {pdf_report_path.stat().st_size / (1024*1024):.1f} MB')\n","    print(f'  Sections: Overview, Executive Summary, Best Hyperparameters, Top 20 Trials,')\n","    print(f'            Performance Analysis (10 advanced visualizations), Key Insights,')\n","    print(f'            Production Recommendations, All Trials Summary')\n","    print(f'  Charts: Distribution, Correlation, Timeline, mAP Progress, Learning Rate,')\n","    print(f'          Optimizer, Augmentation, Regularization, Image Size')\n","except Exception as pdf_error:\n","    print(f'\\nâš ï¸  Error generating PDF: {pdf_error}')\n","    import traceback\n","    traceback.print_exc()\n","\n","print('=' * 80)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g5wa6dQeXmDq","executionInfo":{"status":"ok","timestamp":1764365827811,"user_tz":-180,"elapsed":4479,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"41d06808-98d5-4ad7-ac5a-45ae626908de"},"id":"g5wa6dQeXmDq","execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","GENERATING COMPREHENSIVE TUNING PDF REPORT\n","================================================================================\n","\n","ğŸ“Š Preparing comprehensive report with 42 trials\n","   Best Trial: 35\n","   Best mAP@0.5: 0.5771\n","\n","ğŸ“‹ Compiling trials data for report...\n","âœ“ Compiled 42 trials for report\n","   Available columns: ['trial', 'state', 'mAP@0.5', 'imgsz', 'optimizer', 'lr0', 'momentum', 'weight_decay', 'warmup_epochs', 'warmup_momentum', 'warmup_bias_lr', 'mosaic', 'mixup']\n","âœ“ Executive summary generated\n","   DataFrame columns: ['trial', 'state', 'mAP@0.5', 'imgsz', 'optimizer', 'lr0', 'momentum', 'weight_decay', 'warmup_epochs', 'warmup_momentum', 'warmup_bias_lr', 'mosaic', 'mixup']\n","   Sample row keys: ['trial', 'state', 'mAP@0.5', 'imgsz', 'optimizer', 'lr0', 'momentum', 'weight_decay', 'warmup_epochs', 'warmup_momentum', 'warmup_bias_lr', 'mosaic', 'mixup']\n","   Creating detailed params for top 5 trials...\n","   âœ“ Top 5 trials details added\n","\n","ğŸ“Š Generating custom visualizations for PDF report...\n","   Completed trials: 41\n","   Columns available: ['trial', 'state', 'mAP@0.5', 'imgsz', 'optimizer', 'lr0', 'momentum', 'weight_decay', 'warmup_epochs', 'warmup_momentum', 'warmup_bias_lr', 'mosaic', 'mixup']\n","   Creating performance distribution box plot...\n","âœ“ Performance distribution chart saved: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/report_performance_distribution.png\n","   Creating parameter correlation heatmap...\n","âœ“ Correlation heatmap saved: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/report_correlation_heatmap.png\n","   Creating optimization timeline chart...\n","âœ“ Optimization timeline chart saved: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/report_optimization_timeline.png\n","âœ“ mAP progress chart saved: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/report_map_progress.png\n","   Creating learning rate impact chart...\n","âœ“ Learning rate impact chart saved: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/report_lr_impact.png\n","   Creating optimizer comparison chart...\n","âœ“ Optimizer comparison chart saved: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/report_optimizer_comparison.png\n","   Available augmentation params: ['mixup', 'mosaic']\n","âœ“ Augmentation impact chart saved: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/report_augmentation_impact.png\n","   Creating regularization impact chart...\n","âœ“ Regularization impact chart saved: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/report_regularization_impact.png\n","   Creating image size impact chart...\n","âœ“ Image size impact chart saved: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/report_imgsz_impact.png\n","âœ“ All custom visualizations generated for PDF report\n","   Generating key insights and recommendations...\n","âœ“ Insights and recommendations section completed\n","\n","âœ“ Comprehensive PDF report generated: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/yolov8m_finetuned_1_tuning_report.pdf\n","  Size: 0.9 MB\n","  Sections: Overview, Executive Summary, Best Hyperparameters, Top 20 Trials,\n","            Performance Analysis (10 advanced visualizations), Key Insights,\n","            Production Recommendations, All Trials Summary\n","  Charts: Distribution, Correlation, Timeline, mAP Progress, Learning Rate,\n","          Optimizer, Augmentation, Regularization, Image Size\n","================================================================================\n"]}]},{"cell_type":"markdown","id":"c5ff99f5","metadata":{"id":"c5ff99f5"},"source":["## 13. Analyze Best Hyperparameters"]},{"cell_type":"code","execution_count":17,"id":"f3823505","metadata":{"id":"f3823505","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764361123422,"user_tz":-180,"elapsed":42,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"3ca461b4-b33d-4f55-bc74-b2448257e41f"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","BEST HYPERPARAMETERS\n","================================================================================\n","\n","Best Trial Number: 35\n","Best mAP@0.5: 0.5771\n","\n","Optimized Hyperparameters:\n","{\n","  \"imgsz\": 768,\n","  \"optimizer\": \"SGD\",\n","  \"lr0\": 0.0001614596240725037,\n","  \"momentum\": 0.9098500376932075,\n","  \"weight_decay\": 0.00042786651935909105,\n","  \"warmup_epochs\": 1,\n","  \"warmup_momentum\": 0.5149307497845836,\n","  \"warmup_bias_lr\": 0.018938388657529233,\n","  \"mosaic\": 0.8205379408033115,\n","  \"mixup\": 0.023789168654792303\n","}\n","================================================================================\n"]}],"source":["# DISPLAY BEST HYPERPARAMETERS\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('BEST HYPERPARAMETERS')\n","print('=' * 80)\n","\n","print(f'\\nBest Trial Number: {study.best_trial.number}')\n","print(f'Best mAP@0.5: {study.best_value:.4f}')\n","print('\\nOptimized Hyperparameters:')\n","print(json.dumps(study.best_params, indent=2))\n","print('=' * 80)"]},{"cell_type":"markdown","id":"1900ad83","metadata":{"id":"1900ad83"},"source":["## 13. Create Trials Summary"]},{"cell_type":"code","execution_count":18,"id":"2c210c33","metadata":{"id":"2c210c33","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764361123448,"user_tz":-180,"elapsed":25,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"f07e0e8b-2d7f-416f-b1a4-a7e30c4ff7f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIALS SUMMARY\n","================================================================================\n","\n","ğŸ“Š TOP 10 TRIALS:\n","================================================================================\n"," trial  mAP@0.5    state optimizer      lr0  momentum  weight_decay    mixup\n","    35 0.577074 COMPLETE       SGD 0.000161  0.909850      0.000428 0.023789\n","     0 0.576928 COMPLETE       SGD 0.000184  0.856970      0.000540 0.166489\n","    22 0.576661 COMPLETE       SGD 0.000141  0.909425      0.000731 0.123344\n","    11 0.576523 COMPLETE       SGD 0.000192  0.925614      0.000922 0.189244\n","    34 0.576213 COMPLETE       SGD 0.000153  0.906332      0.000937 0.038448\n","    33 0.576136 COMPLETE       SGD 0.000119  0.895453      0.000932 0.079787\n","    10 0.575980 COMPLETE       SGD 0.000101  0.905713      0.000853 0.143467\n","    25 0.575915 COMPLETE       SGD 0.000103  0.856550      0.000692 0.129994\n","    18 0.575635 COMPLETE       SGD 0.000238  0.969074      0.000435 0.113910\n","    27 0.575601 COMPLETE       SGD 0.000235  0.912563      0.000426 0.163392\n","================================================================================\n","\n","âœ“ Complete trials summary saved to: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trials_summary.csv\n","âœ“ Optuna study object saved to: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/optuna_study.pkl\n","================================================================================\n"]}],"source":["# CREATE TRIALS SUMMARY AND DATAFRAME (SHARED RESOURCE)\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('TRIALS SUMMARY')\n","print('=' * 80)\n","\n","# Compile all trial data (used by multiple sections)\n","trials_data = []\n","for trial in study.trials:\n","    trial_info = {\n","        'trial': trial.number,\n","        'mAP@0.5': trial.value if trial.value else 0.0,\n","        'state': trial.state.name,\n","        'duration_seconds': (trial.datetime_complete - trial.datetime_start).total_seconds() if trial.datetime_complete else None,\n","    }\n","    # Add all parameters\n","    trial_info.update(trial.params)\n","    trials_data.append(trial_info)\n","\n","# Create DataFrame and sort by performance (used by PDF report and display)\n","df_trials = pd.DataFrame(trials_data)\n","df_trials_sorted = df_trials.sort_values('mAP@0.5', ascending=False)\n","\n","print('\\nğŸ“Š TOP 10 TRIALS:')\n","print('=' * 80)\n","# Display top 10 with selected columns\n","display_cols = ['trial', 'mAP@0.5', 'state', 'optimizer', 'lr0', 'momentum', 'weight_decay', 'mixup']\n","available_cols = [col for col in display_cols if col in df_trials_sorted.columns]\n","print(df_trials_sorted[available_cols].head(10).to_string(index=False))\n","print('=' * 80)\n","\n","# Save complete trials summary\n","trials_csv_path = TUNE_DIR / 'trials_summary.csv'\n","df_trials_sorted.to_csv(trials_csv_path, index=False)\n","print(f'\\nâœ“ Complete trials summary saved to: {trials_csv_path}')\n","\n","# Save study object\n","study_path = TUNE_DIR / 'optuna_study.pkl'\n","with open(study_path, 'wb') as f:\n","    pickle.dump(study, f)\n","print(f'âœ“ Optuna study object saved to: {study_path}')\n","\n","print('=' * 80)"]},{"cell_type":"markdown","id":"7d09278e","metadata":{"id":"7d09278e"},"source":["## 14. Final summary\n"]},{"cell_type":"code","execution_count":19,"id":"9e9576f4","metadata":{"id":"9e9576f4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764361123915,"user_tz":-180,"elapsed":467,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"930363ad-df3c-45a3-ab5f-b10ed23f0134"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\n","================================================================================\n","HYPERPARAMETER OPTIMIZATION COMPLETE!\n","================================================================================\n","\n","ğŸ“Š Project: yolov8m_finetuned_1 on bdd100k_yolo_tuning\n","ğŸ“… Date: 2025-11-28 20:18:43\n","\n","ğŸ”¬ Optimization Summary:\n","  Total Trials: 42\n","  Completed: 41\n","  Best Trial: 35\n","  Best Trial mAP@0.5: 0.5771\n","  Duration: 2:37:27.650793\n","\n","ğŸ“ Generated Files:\n","\n","  ğŸ“Š Tuning Results (in /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340):\n","    - best_hyperparameters.json\n","    - best_hyperparameters.yaml\n","    - trials_summary.csv\n","    - optuna_study.pkl\n","  ğŸ“ˆ Tuning Visualizations:\n","    - optimization_history.html / .png\n","    - parameter_importance.html / .png\n","    - parameter_slice.html / .png\n","  ğŸ“„ Tuning PDF Report:\n","    - yolov8m_finetuned_1_tuning_report.pdf\n","\n","ğŸ“‚ All results saved to:\n","  Tuning: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340\n","\n","ğŸ“ Top 5 Hyperparameters (by importance):\n","  1. imgsz: 0.7685\n","  2. optimizer: 0.1955\n","  3. weight_decay: 0.0108\n","  4. mixup: 0.0087\n","  5. lr0: 0.0070\n","\n","ğŸš€ Next Steps:\n","  1. Review tuning PDF report: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/yolov8m_finetuned_1_tuning_report.pdf\n","  2. Review optimization visualizations in: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340\n","  3. Use best_hyperparameters.yaml for training in a separate notebook\n","\n","================================================================================\n","SUCCESS! âœ“\n","================================================================================\n"]}],"source":["# FINAL SUMMARY\n","# ============================================================================\n","\n","print('\\n\\n')\n","print('=' * 80)\n","print('HYPERPARAMETER OPTIMIZATION COMPLETE!')\n","print('=' * 80)\n","\n","print(f'\\nğŸ“Š Project: {MODEL_NAME} on {YOLO_DATASET_ROOT.name}')\n","print(f'ğŸ“… Date: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n","\n","print(f'\\nğŸ”¬ Optimization Summary:')\n","print(f'  Total Trials: {len(study.trials)}')\n","print(f'  Completed: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}')\n","print(f'  Best Trial: {study.best_trial.number}')\n","print(f'  Best Trial mAP@0.5: {study.best_value:.4f}')\n","print(f'  Duration: {duration}')\n","\n","if 'final_metrics' in globals():\n","    print(f'\\nğŸ¯ Final Model Performance:')\n","    print(f'  mAP@0.5: {final_metrics[\"map50\"]:.4f}')\n","    print(f'  mAP@0.5:0.95: {final_metrics[\"map50_95\"]:.4f}')\n","    print(f'  Precision: {final_metrics[\"precision\"]:.4f}')\n","    print(f'  Recall: {final_metrics[\"recall\"]:.4f}')\n","\n","print(f'\\nğŸ“ Generated Files:')\n","print(f'\\n  ğŸ“Š Tuning Results (in {TUNE_DIR}):')\n","print(f'    - best_hyperparameters.json')\n","print(f'    - best_hyperparameters.yaml')\n","print(f'    - trials_summary.csv')\n","print(f'    - optuna_study.pkl')\n","print(f'  ğŸ“ˆ Tuning Visualizations:')\n","print(f'    - optimization_history.html / .png')\n","print(f'    - parameter_importance.html / .png')\n","print(f'    - parameter_slice.html / .png')\n","print(f'  ğŸ“„ Tuning PDF Report:')\n","print(f'    - {MODEL_NAME}_tuning_report.pdf')\n","\n","print(f'\\nğŸ“‚ All results saved to:')\n","print(f'  Tuning: {TUNE_DIR}')\n","\n","print(f'\\nğŸ“ Top 5 Hyperparameters (by importance):')\n","try:\n","    importances = optuna.importance.get_param_importances(study)\n","    for i, (param, importance) in enumerate(list(importances.items())[:5], 1):\n","        print(f'  {i}. {param}: {importance:.4f}')\n","except:\n","    print('  (Not available - requires completed trials with variation)')\n","\n","print(f'\\nğŸš€ Next Steps:')\n","print(f'  1. Review tuning PDF report: {TUNE_DIR / f\"{MODEL_NAME}_tuning_report.pdf\"}')\n","print(f'  2. Review optimization visualizations in: {TUNE_DIR}')\n","print(f'  3. Use best_hyperparameters.yaml for training in a separate notebook')\n","\n","print('\\n' + '=' * 80)\n","print('SUCCESS! âœ“')\n","print('=' * 80)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"colab":{"provenance":[{"file_id":"1IaNbPRX_fb0zO_CS__OEZJa2IcAEtH24","timestamp":1764351400504},{"file_id":"1IknhmQGJ16M5M_kKwiL_l8vmYKqs5NZK","timestamp":1764322318885}],"gpuType":"A100"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"546cae9dc55e4161b198282c48a07e94":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b5a4e722b7a741dab5bab027f5e31166","IPY_MODEL_883e135a8964428db8230cc5f0400c84","IPY_MODEL_de7e9fe9b7ee47aa8e69e9b1082f1cba"],"layout":"IPY_MODEL_86b7352837b34b78a6625f7faf2edf84"}},"b5a4e722b7a741dab5bab027f5e31166":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_31244db86381413f8a5fbe3267325f5d","placeholder":"â€‹","style":"IPY_MODEL_c4592ad6873643d09aa47d074b8df73d","value":"Bestâ€‡trial:â€‡35.â€‡Bestâ€‡value:â€‡0.577074:â€‡â€‡15%"}},"883e135a8964428db8230cc5f0400c84":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_83261c95260849a18d03f5c060723129","max":40,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8723c3ba4d5b414eb4e951f73653a2b6","value":6}},"de7e9fe9b7ee47aa8e69e9b1082f1cba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a31c514472747cbbcd28c87f99efaba","placeholder":"â€‹","style":"IPY_MODEL_39e00fc59a9943dd9bc35c46ed850f6f","value":"â€‡6/40â€‡[2:37:27&lt;13:06:16,â€‡1387.55s/it,â€‡8908.23/86400â€‡seconds]"}},"86b7352837b34b78a6625f7faf2edf84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31244db86381413f8a5fbe3267325f5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4592ad6873643d09aa47d074b8df73d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83261c95260849a18d03f5c060723129":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8723c3ba4d5b414eb4e951f73653a2b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6a31c514472747cbbcd28c87f99efaba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39e00fc59a9943dd9bc35c46ed850f6f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}