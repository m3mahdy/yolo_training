{"cells":[{"cell_type":"markdown","id":"8b26f5d6","metadata":{"id":"8b26f5d6"},"source":["# YOLO Training\n","- Support for YOLOv8, YOLOv9, YOLOv10, YOLO11, YOLO12\n"]},{"cell_type":"markdown","id":"a7e53f76","metadata":{"id":"a7e53f76"},"source":["# 1. Set Directories"]},{"cell_type":"code","execution_count":1,"id":"c698714c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c698714c","executionInfo":{"status":"ok","timestamp":1764101936227,"user_tz":-180,"elapsed":42884,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"d3fe5174-047e-48ca-f110-1b58be6256e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/Drive\n","âœ“ W&B API key loaded from Colab secrets\n"]}],"source":["# Base directories\n","# Detect environment: Colab or local\n","\n","import os\n","from pathlib import Path\n","\n","\n","IS_COLAB = 'COLAB_GPU' in os.environ or os.path.exists('/content')\n","\n","USE_WANDB = True  # Set to False to disable W&B logging\n","\n","\n","\n","if IS_COLAB:\n","    #Mount Google Drive if not already mounted\n","    from google.colab import drive\n","    drive.mount('/content/Drive', force_remount=True)\n","    # Running in Google Colab\n","    BASE_DIR = Path('/content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo')\n","\n","    # Configure W&B API key\n","    if USE_WANDB:\n","        # In Colab, get API key from secrets\n","        from google.colab import userdata\n","        wandb_api_key = userdata.get('wandb_api_key')\n","        os.environ['WANDB_API_KEY'] = wandb_api_key\n","        print('âœ“ W&B API key loaded from Colab secrets')\n","\n","    DATASET_BASE_DIR = Path('/computer_vision_yolo')\n","\n","else:\n","    # Running locally\n","    BASE_DIR = Path.cwd().parent\n","    if USE_WANDB:\n","        print('âœ“ Running locally - W&B will use existing login or prompt')\n","\n","    DATASET_BASE_DIR = Path.cwd().parent\n"]},{"cell_type":"code","execution_count":3,"id":"c8064a27","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c8064a27","executionInfo":{"status":"ok","timestamp":1764101969095,"user_tz":-180,"elapsed":107,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"3fd4673c-bf76-470a-9186-ed1f2218cfaa"},"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: cd: {/content/Drive/MyDrive/ksu_yolo_2025}: No such file or directory\n"]}],"source":["# ! cd {/content/Drive/MyDrive/ksu_yolo_2025} && git clone https://github.com/m3mahdy/computer_vision_yolo"]},{"cell_type":"code","execution_count":4,"id":"16c67ad5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"16c67ad5","executionInfo":{"status":"ok","timestamp":1764102131496,"user_tz":-180,"elapsed":7922,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"d1127e60-f23d-4f43-c470-bc697634915c"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”\u001b[0m \u001b[32m1.0/1.1 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m329.5/329.5 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["! cd {BASE_DIR} && pip install -r requirements.txt --quiet"]},{"cell_type":"code","execution_count":5,"id":"43f33666","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"43f33666","executionInfo":{"status":"ok","timestamp":1764102231563,"user_tz":-180,"elapsed":98288,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"0c13d714-c23a-46f7-efc7-ba65443e5a1c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Compressed file not found: /computer_vision_yolo/bdd100k_yolo_limited_zipped/bdd100k_yolo_limited.zip\n","\n","Attempting to download from Google Drive...\n","\n","Downloading from Google Drive...\n","File ID: 1DFBUw9ltwvmnyiXuatPuAbrPtOskJ79h\n","Destination: /computer_vision_yolo/bdd100k_yolo_limited_zipped/bdd100k_yolo_limited.zip\n","Downloading...\n","From (original): https://drive.google.com/uc?id=1DFBUw9ltwvmnyiXuatPuAbrPtOskJ79h\n","From (redirected): https://drive.google.com/uc?id=1DFBUw9ltwvmnyiXuatPuAbrPtOskJ79h&confirm=t&uuid=63d33c09-51e1-4269-be9b-970c8a1c7cce\n","To: /computer_vision_yolo/bdd100k_yolo_limited_zipped/bdd100k_yolo_limited.zip\n","100% 3.85G/3.85G [00:47<00:00, 81.3MB/s]\n","âœ“ Download complete: 3672.8 MB\n","âœ“ Download successful!\n","Extracting bdd100k_yolo_limited.zip...\n","Target directory: /computer_vision_yolo/bdd100k_yolo_limited\n","Extracting: 100% 184258/184258 [00:47<00:00, 3903.12files/s] \n","\n","âœ“ Successfully extracted to: /computer_vision_yolo/bdd100k_yolo_limited\n","  Images: 0\n","  Labels: 0\n","\n","You can now use this dataset for quick experiments!\n"]}],"source":["# download limited dataset\n","!mkdir {DATASET_BASE_DIR}\n","!cd {BASE_DIR} && cp download_limited_dataset.py {DATASET_BASE_DIR} && cd {DATASET_BASE_DIR} && python download_limited_dataset.py\n"]},{"cell_type":"markdown","id":"109394c4","metadata":{"id":"109394c4"},"source":["## 2. Import Required Libraries"]},{"cell_type":"code","execution_count":6,"id":"fc6f98f1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fc6f98f1","executionInfo":{"status":"ok","timestamp":1764102286112,"user_tz":-180,"elapsed":7070,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"56821fb4-ce7b-463d-9ca5-5944e21522eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file âœ… \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","âœ“ Libraries imported successfully\n","âœ“ Device: cuda\n","  GPU: NVIDIA A100-SXM4-40GB\n","  CUDA Version: 12.6\n","  Available Memory: 42.47 GB\n"]}],"source":["# Install required libraries (uncomment if running in Colab)\n","# !pip install -q ultralytics wandb pyyaml\n","\n","import os\n","import sys\n","import gc\n","import yaml\n","import json\n","import torch\n","import shutil\n","import warnings\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from pathlib import Path\n","from datetime import datetime\n","from tqdm import tqdm\n","import pickle\n","import platform\n","import psutil\n","\n","import wandb\n","\n","# YOLO imports\n","from ultralytics import YOLO\n","\n","# ReportLab imports for PDF generation\n","from reportlab.lib.pagesizes import A4\n","from reportlab.lib import colors as rl_colors\n","from reportlab.lib.units import inch\n","from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, Image, PageBreak\n","from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n","from reportlab.lib.enums import TA_CENTER, TA_LEFT\n","from PIL import Image as PILImage\n","\n","warnings.filterwarnings('ignore')\n","\n","# Configure matplotlib for notebook display\n","%matplotlib inline\n","sns.set_style('whitegrid')\n","plt.rcParams['figure.figsize'] = (15, 10)\n","\n","# Check GPU availability\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(f'âœ“ Libraries imported successfully')\n","print(f'âœ“ Device: {device}')\n","if device == 'cuda':\n","    print(f'  GPU: {torch.cuda.get_device_name(0)}')\n","    print(f'  CUDA Version: {torch.version.cuda}')\n","    print(f'  Available Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')\n"]},{"cell_type":"markdown","id":"2659c792","metadata":{"id":"2659c792"},"source":["## 3. Configuration"]},{"cell_type":"code","execution_count":7,"id":"d163f0be","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d163f0be","executionInfo":{"status":"ok","timestamp":1764102290881,"user_tz":-180,"elapsed":3972,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"60726946-c26d-434c-bf0b-6c1a86102435"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/Drive\n","âœ“ W&B API key loaded from Colab secrets\n","\n","âš™ï¸  CONFIGURATION MODE: Using Default YOLO Configuration\n","   No hyperparameter tuning will be applied\n","\n","ğŸ†• NEW TRAINING MODE: Creating new run \"yolov8m_train_20251125_202451\"\n","================================================================================\n","CONFIGURATION SUMMARY\n","================================================================================\n","Environment: Google Colab\n","Base Directory: /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo\n","Model: yolov8m\n","Dataset: bdd100k_yolo_limited\n","Data YAML: /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/tmp/yolov8m/data.yaml\n","  Dataset path in YAML: /computer_vision_yolo/bdd100k_yolo_limited\n","Classes: 10\n","Class Names: {0: 'pedestrian', 1: 'rider', 2: 'car', 3: 'truck', 4: 'bus', 5: 'train', 6: 'motorcycle', 7: 'bicycle', 8: 'traffic light', 9: 'traffic sign'}\n","Device: cuda\n","Epochs Final Training: 100\n","Batch Size: 96\n","Image Size: 640\n","Configuration Mode: Default (No Tuning)\n","Training Directory: /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/tune_train/training/yolov8m_train_20251125_202451\n","W&B Logging: Enabled\n","  Training Project: yolo-bdd100k_yolo_limited-training\n","================================================================================\n"]}],"source":["# ============================================================================\n","# CONFIGURATION\n","# ============================================================================\n","\n","# Base directories\n","# Detect environment: Colab or local\n","\n","IS_COLAB = 'COLAB_GPU' in os.environ or os.path.exists('/content')\n","\n","USE_WANDB = True  # Set to False to disable W&B logging\n","\n","if IS_COLAB:\n","    #Mount Google Drive if not already mounted\n","    from google.colab import drive\n","    drive.mount('/content/Drive', force_remount=True)\n","    # Running in Google Colab\n","    BASE_DIR = Path('/content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo')\n","\n","    # Configure W&B API key\n","    if USE_WANDB:\n","        # In Colab, get API key from secrets\n","        from google.colab import userdata\n","        wandb_api_key = userdata.get('wandb_api_key')\n","        os.environ['WANDB_API_KEY'] = wandb_api_key\n","        print('âœ“ W&B API key loaded from Colab secrets')\n","\n","else:\n","    # Running locally\n","    BASE_DIR = Path.cwd().parent\n","    if USE_WANDB:\n","        print('âœ“ Running locally - W&B will use existing login or prompt')\n","class DatasetSplit:\n","    \"\"\"Constants for dataset split names\"\"\"\n","    TRAIN = \"train\"\n","    VAL = \"val\"\n","    TEST = \"test\"\n","\n","class ModelConfig:\n","    \"\"\"Default model training configuration constants\"\"\"\n","    # Image processing\n","    DEFAULT_IMAGE_SIZE = 640  # Standard YOLO input size\n","\n","    # Training workers\n","    DEFAULT_WORKERS = 8  # Number of data loading workers\n","\n","    # Early stopping and checkpointing\n","    DEFAULT_PATIENCE = 10  # Epochs to wait before early stopping\n","    DEFAULT_SAVE_PERIOD = 1  # Save checkpoint every N epochs\n","\n","    # Augmentation timing\n","    CLOSE_MOSAIC_EPOCHS = 10  # Disable mosaic augmentation in last N epochs\n","\n","    # Data loading and caching\n","    DEFAULT_CACHE = False  # Cache images for faster training (use True for small datasets)\n","    DEFAULT_VAL = True  # Run validation during training\n","\n","    # Warmup configuration\n","    # MIN_WARMUP_EPOCHS = 0\n","    # MAX_WARMUP_EPOCHS = 3\n","    # MIN_WARMUP_MOMENTUM = 0.5\n","    # MAX_WARMUP_MOMENTUM = 0.95\n","    # MIN_WARMUP_BIAS_LR = 0.0\n","\n","    # MAX_WARMUP_BIAS_LR = 0.1\n","\n","\n","\n","\n","# Model Selection - Choose one of the following:\n","MODEL_NAME = \"yolov8m\"\n","\n","#yolov10n is for testing purpose only\n","#Mahdy will work yolov8m\n","\n","\n","# Selected models, to choose from, based on the performance and size:\n","# YOLOv8:  'yolov8s', 'yolov8m'\n","\n","# YOLOv10: 'yolov10s', 'yolov10m'\n","\n","# YOLO12: 'yolo12s'\n","\n","# Directory structure\n","MODELS_DIR = BASE_DIR / 'models' / MODEL_NAME\n","TMP_DIR = BASE_DIR / 'tmp' / MODEL_NAME\n","\n","# Dataset Selection\n","# Option 1: Full dataset (~100k images) - for final optimization: \"bdd100k_yolo\"\n","# Option 2: Limited dataset (representative samples) - for quick tuning: \"bdd100k_yolo_limited\"\n","dataset_name = 'bdd100k_yolo_limited'\n","\n","\n","YOLO_DATASET_ROOT = DATASET_BASE_DIR / dataset_name\n","\n","# data.yaml path\n","DATA_YAML_PATH = YOLO_DATASET_ROOT / 'data.yaml'\n","\n","# Verify dataset exists\n","if not DATA_YAML_PATH.exists():\n","    raise FileNotFoundError(\n","        f\"Dataset not found: {DATA_YAML_PATH}\\n\"\n","        f\"Please prepare the dataset first using process_bdd100k_to_yolo_dataset.py\"\n","    )\n","\n","# Update data.yaml path field for Colab compatibility\n","with open(DATA_YAML_PATH, 'r') as yaml_file:\n","    data_config = yaml.safe_load(yaml_file)\n","\n","# Validate required keys in data.yaml\n","required_yaml_keys = ['nc', 'names', 'path']\n","missing_keys = [key for key in required_yaml_keys if key not in data_config]\n","if missing_keys:\n","    raise ValueError(f\"Missing required keys in data.yaml: {missing_keys}\")\n","\n","# Update the 'path' field to use BASE_DIR\n","data_config['path'] = str(YOLO_DATASET_ROOT)\n","\n","# Create a temporary data.yaml with corrected paths\n","temp_data_yaml = TMP_DIR / 'data.yaml'\n","TMP_DIR.mkdir(parents=True, exist_ok=True)\n","with open(temp_data_yaml, 'w') as yaml_output_file:\n","    yaml.dump(data_config, yaml_output_file, default_flow_style=False, sort_keys=False)\n","\n","# Use the temporary data.yaml for training\n","DATA_YAML_PATH = temp_data_yaml\n","\n","# Training Configuration\n","EPOCHS_FINAL_TRAINING = 100  # Training epochs for final model = 150\n","BATCH_SIZE = 96  # Batch size for training\n","# for T4 GPU:\n","# 64 for 10n, 1 epoch 30 min\n","# 32 for 8m, 1 epoch 45 min\n","\n","# for A100 GPU:\n","# 64 for 10m 1 epoch 11 min, 5 epochs completed in 0.797 hours.\n","# 96 for 8m , 1 epoch 10 min, 5 epochs completed in 0.866 hours.\n","\n","IMAGE_SIZE = 640  # Input image size\n","\n","# Weights & Biases (optional)\n","USE_WANDB = True  # Set to True to enable W&B logging\n","WANDB_PROJECT_TRAINING = f\"yolo-{YOLO_DATASET_ROOT.name}-training\"\n","\n","# ============================================================================\n","# CONFIGURATION MODE: DEFAULT vs TUNED HYPERPARAMETERS\n","# ============================================================================\n","# Set to True to use default YOLO configuration (no hyperparameter tuning)\n","# Set to False to load hyperparameters from a tuning run\n","# ============================================================================\n","\n","USE_DEFAULT_CONFIG = True  # Set to True to skip tuning and use default YOLO config\n","\n","# ============================================================================\n","# TUNING RUN CONFIGURATION - SPECIFY WHICH TUNING RUN TO USE\n","# ============================================================================\n","# Specify the tuning run name to load best hyperparameters from\n","# This should match the directory name in tune_train/tune/\n","#\n","# Example: TUNING_RUN_NAME = \"yolov10n_tune_20251125_143022\"\n","# Leave as None to search for the latest tuning run for this model\n","# Note: Only used if USE_DEFAULT_CONFIG = False\n","# ============================================================================\n","\n","TUNING_RUN_NAME = None  # Set to specific tuning run name, or None to auto-detect latest\n","\n","# ============================================================================\n","# TRAINING RUN CONFIGURATION - RESUME OR CREATE NEW\n","# ============================================================================\n","# To RESUME an existing training run: Set RESUME_TRAINING_RUN_NAME to the run directory name\n","# To START NEW training: Leave RESUME_TRAINING_RUN_NAME as None or empty string\n","#\n","# Example to resume: RESUME_TRAINING_RUN_NAME = \"yolov10n_train_20251125_150000\"\n","# ============================================================================\n","\n","RESUME_TRAINING_RUN_NAME = None  # Set to run name to resume, or None to create new run\n","\n","# Find or verify tuning run (only if not using default config)\n","TUNE_TRAIN_BASE = BASE_DIR / 'tune_train'\n","TUNE_BASE_DIR = TUNE_TRAIN_BASE / 'tune'\n","\n","if USE_DEFAULT_CONFIG:\n","    # Using default configuration - skip tuning run search\n","    print('\\nâš™ï¸  CONFIGURATION MODE: Using Default YOLO Configuration')\n","    print('   No hyperparameter tuning will be applied')\n","    TUNE_DIR = None\n","    TUNING_RUN_NAME = None\n","    best_hyperparams_path = None\n","else:\n","    # Using tuned hyperparameters - find or verify tuning run\n","    print('\\nâš™ï¸  CONFIGURATION MODE: Using Tuned Hyperparameters')\n","\n","    if TUNING_RUN_NAME:\n","        # Use specified tuning run\n","        TUNE_DIR = TUNE_BASE_DIR / TUNING_RUN_NAME\n","        if not TUNE_DIR.exists():\n","            raise FileNotFoundError(\n","                f\"Specified tuning run not found: {TUNE_DIR}\\n\"\n","                f\"Available runs in {TUNE_BASE_DIR}:\\n\" +\n","                '\\n'.join(f\"  - {d.name}\" for d in TUNE_BASE_DIR.glob(f'{MODEL_NAME}_tune_*') if d.is_dir())\n","            )\n","        print(f'   ğŸ“‚ Using specified tuning run: {TUNING_RUN_NAME}')\n","    else:\n","        # Auto-detect latest tuning run for this model\n","        tuning_runs = sorted(TUNE_BASE_DIR.glob(f'{MODEL_NAME}_tune_*'), key=lambda p: p.name, reverse=True)\n","        if not tuning_runs:\n","            raise FileNotFoundError(\n","                f\"No tuning runs found for model {MODEL_NAME} in {TUNE_BASE_DIR}\\n\"\n","                f\"Please run the tuning notebook first, specify TUNING_RUN_NAME, or set USE_DEFAULT_CONFIG=True\"\n","            )\n","        TUNE_DIR = tuning_runs[0]\n","        TUNING_RUN_NAME = TUNE_DIR.name\n","        print(f'   ğŸ” Auto-detected latest tuning run: {TUNING_RUN_NAME}')\n","\n","    # Verify best hyperparameters exist\n","    best_hyperparams_path = TUNE_DIR / 'best_hyperparameters.json'\n","    if not best_hyperparams_path.exists():\n","        raise FileNotFoundError(\n","            f\"Best hyperparameters not found in tuning run: {best_hyperparams_path}\\n\"\n","            f\"Please ensure the tuning run completed successfully\"\n","        )\n","\n","    print(f'   âœ“ Found best hyperparameters: {best_hyperparams_path}')\n","\n","# Configure training run name\n","if RESUME_TRAINING_RUN_NAME:\n","    # Resume existing training run\n","    RUN_NAME_TRAINING = RESUME_TRAINING_RUN_NAME\n","    print(f'\\nğŸ”„ RESUME MODE: Will attempt to resume training run \"{RESUME_TRAINING_RUN_NAME}\"')\n","else:\n","    # Create new training run with timestamp\n","    RUN_TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')\n","    RUN_NAME_TRAINING = f'{MODEL_NAME}_train_{RUN_TIMESTAMP}'\n","    print(f'\\nğŸ†• NEW TRAINING MODE: Creating new run \"{RUN_NAME_TRAINING}\"')\n","\n","# Create training directory\n","TRAIN_DIR = TUNE_TRAIN_BASE / 'training' / RUN_NAME_TRAINING\n","TRAIN_DIR.mkdir(parents=True, exist_ok=True)\n","MODELS_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Read dataset configuration\n","NUM_CLASSES = data_config['nc']\n","CLASS_NAMES = {i: name for i, name in enumerate(data_config['names'])}\n","CLASS_NAME_TO_ID = {name: i for i, name in enumerate(data_config['names'])}\n","\n","print('=' * 80)\n","print('CONFIGURATION SUMMARY')\n","print('=' * 80)\n","print(f'Environment: {\"Google Colab\" if \"COLAB_GPU\" in os.environ or os.path.exists(\"/content\") else \"Local\"}')\n","print(f'Base Directory: {BASE_DIR}')\n","print(f'Model: {MODEL_NAME}')\n","print(f'Dataset: {YOLO_DATASET_ROOT.name}')\n","print(f'Data YAML: {DATA_YAML_PATH}')\n","print(f'  Dataset path in YAML: {data_config[\"path\"]}')\n","print(f'Classes: {NUM_CLASSES}')\n","print(f'Class Names: {CLASS_NAMES}')\n","print(f'Device: {device}')\n","print(f'Epochs Final Training: {EPOCHS_FINAL_TRAINING}')\n","print(f'Batch Size: {BATCH_SIZE}')\n","print(f'Image Size: {IMAGE_SIZE}')\n","print(f'Configuration Mode: {\"Default (No Tuning)\" if USE_DEFAULT_CONFIG else \"Tuned Hyperparameters\"}')\n","if not USE_DEFAULT_CONFIG:\n","    print(f'Tuning Run: {TUNING_RUN_NAME}')\n","print(f'Training Directory: {TRAIN_DIR}')\n","if USE_WANDB:\n","    print(f'W&B Logging: Enabled')\n","    print(f'  Training Project: {WANDB_PROJECT_TRAINING}')\n","else:\n","    print(f'W&B Logging: Disabled')\n","print('=' * 80)"]},{"cell_type":"markdown","id":"0af35c3f","metadata":{"id":"0af35c3f"},"source":["## 4. Load Base YOLO Model"]},{"cell_type":"code","execution_count":8,"id":"3deeda88","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3deeda88","executionInfo":{"status":"ok","timestamp":1764102312200,"user_tz":-180,"elapsed":581,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"10198bd0-03a0-438e-b16f-b63a4b8f1353"},"outputs":[{"output_type":"stream","name":"stdout","text":["âœ“ Model loaded from /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/models/yolov8m/yolov8m.pt\n","YOLOv8m summary: 169 layers, 25,902,640 parameters, 0 gradients, 79.3 GFLOPs\n","\n","ğŸ“Š Model Information:\n","  Model: yolov8m\n","  Classes in model: 80\n","  Task: detect\n","  Parameters: 25.9M\n","  Model Size: 0.0 MB\n","  FLOPs (640x640): 79.32 GFLOPs\n"]}],"source":["# Load YOLO model with automatic download\n","model_path = MODELS_DIR / f'{MODEL_NAME}.pt'\n","\n","if not model_path.exists():\n","    print(f'Model not found at {model_path}')\n","    print(f'Downloading {MODEL_NAME} ...')\n","\n","    try:\n","        # Download model - ensure .pt extension for ultralytics\n","        # Ultralytics expects model names with .pt extension for download\n","        if not MODEL_NAME.endswith('.pt'):\n","            model_name_for_download = MODEL_NAME + '.pt'\n","        else:\n","            model_name_for_download = MODEL_NAME\n","\n","        print(f'  Requesting model: {model_name_for_download}')\n","        model = YOLO(model_name_for_download)\n","\n","        # Create models directory\n","        MODELS_DIR.mkdir(parents=True, exist_ok=True)\n","\n","        # Save model to our directory using export/save\n","        try:\n","            # Try to save using the model's save method\n","            if hasattr(model, 'save'):\n","                model.save(str(model_path))\n","                print(f'âœ“ Model downloaded and saved to {model_path}')\n","                print(f'  Size: {model_path.stat().st_size / (1024*1024):.1f} MB')\n","            else:\n","                # Fallback: copy from cache\n","                cache_patterns = [\n","                    str(Path.home() / '.cache' / 'ultralytics' / '**' / f'{MODEL_NAME}.pt'),\n","                    str(Path.home() / '.config' / 'Ultralytics' / '**' / f'{MODEL_NAME}.pt'),\n","                ]\n","\n","                model_found = False\n","                for pattern in cache_patterns:\n","                    cache_paths = glob.glob(pattern, recursive=True)\n","                    if cache_paths:\n","                        shutil.copy(cache_paths[0], model_path)\n","                        print(f'âœ“ Model downloaded and saved to {model_path}')\n","                        print(f'  Size: {model_path.stat().st_size / (1024*1024):.1f} MB')\n","                        model_found = True\n","                        break\n","\n","                if not model_found:\n","                    print(f'âœ“ Model loaded from ultralytics cache')\n","                    print(f'  Note: Model is in cache, not copied to {model_path}')\n","                    print(f'  This is normal and the model will work correctly')\n","        except Exception as save_error:\n","            print(f'âš ï¸  Could not save model to custom location: {save_error}')\n","            print(f'âœ“ Model loaded successfully from ultralytics cache')\n","\n","    except Exception as download_error:\n","        print(f'\\nâŒ Error downloading model: {download_error}')\n","        raise\n","else:\n","    model = YOLO(str(model_path))\n","    print(f'âœ“ Model loaded from {model_path}')\n","\n","# Get model information\n","model_info_dict = {}\n","model_info_result = model.info()\n","model_info_keys = [\"layers\", \"params\", \"size(MB)\", \"FLOPs(G)\"]\n","\n","for info_key, info_value in zip(model_info_keys, model_info_result):\n","    model_info_dict[info_key] = info_value\n","\n","model_params = model_info_dict.get(\"params\", 0)\n","model_size_mb = model_info_dict.get(\"size(MB)\", 0)\n","flops_gflops = model_info_dict.get(\"FLOPs(G)\", 0)\n","\n","\n","print(f'\\nğŸ“Š Model Information:')\n","print(f'  Model: {MODEL_NAME}')\n","print(f'  Classes in model: {len(model.names)}')\n","print(f'  Task: {model.task}')\n","print(f'  Parameters: {model_params / 1e6:.1f}M')\n","print(f'  Model Size: {model_size_mb:.1f} MB')\n","print(f'  FLOPs (640x640): {flops_gflops:.2f} GFLOPs')"]},{"cell_type":"markdown","id":"5fe0b94d","metadata":{"id":"5fe0b94d"},"source":["## 6. Verify Dataset Structure"]},{"cell_type":"code","execution_count":9,"id":"71b15401","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"71b15401","executionInfo":{"status":"ok","timestamp":1764102317077,"user_tz":-180,"elapsed":891,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"7f7a4707-823d-4141-b443-51f174cc60bd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Verifying YOLO dataset structure...\n","\n","ğŸ“ Dataset Root: /computer_vision_yolo/bdd100k_yolo_limited\n","  âœ“ train:  35467 images,  35467 labels\n","  âœ“ val  :   9374 images,   9374 labels\n","  âœ“ test :  16576 images,  16576 labels\n","\n","ğŸ“„ Configuration: /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/tmp/yolov8m/data.yaml\n","  Classes: 10\n","  Names: {0: 'pedestrian', 1: 'rider', 2: 'car', 3: 'truck', 4: 'bus', 5: 'train', 6: 'motorcycle', 7: 'bicycle', 8: 'traffic light', 9: 'traffic sign'}\n","\n","âœ“ Dataset verified: 61,417 total images\n","âœ“ Ready for training\n"]}],"source":["# ============================================================================\n","# VERIFY DATASET STRUCTURE\n","# ============================================================================\n","\n","print('Verifying YOLO dataset structure...')\n","print(f'\\nğŸ“ Dataset Root: {YOLO_DATASET_ROOT}')\n","\n","# Check all splits using constants\n","dataset_stats = {}\n","for split in [DatasetSplit.TRAIN, DatasetSplit.VAL, DatasetSplit.TEST]:\n","    images_dir = YOLO_DATASET_ROOT / 'images' / split\n","    labels_dir = YOLO_DATASET_ROOT / 'labels' / split\n","\n","    if images_dir.exists() and labels_dir.exists():\n","        num_images = len(list(images_dir.glob('*.jpg'))) + len(list(images_dir.glob('*.png')))\n","        num_labels = len(list(labels_dir.glob('*.txt')))\n","        dataset_stats[split] = {'images': num_images, 'labels': num_labels}\n","        print(f'  âœ“ {split:5s}: {num_images:6d} images, {num_labels:6d} labels')\n","    else:\n","        print(f'  âš ï¸  {split:5s}: Directory not found')\n","        dataset_stats[split] = {'images': 0, 'labels': 0}\n","\n","print(f'\\nğŸ“„ Configuration: {DATA_YAML_PATH}')\n","print(f'  Classes: {NUM_CLASSES}')\n","print(f'  Names: {CLASS_NAMES}')\n","\n","total_images = sum(stats['images'] for stats in dataset_stats.values())\n","print(f'\\nâœ“ Dataset verified: {total_images:,} total images')\n","print('âœ“ Ready for training')"]},{"cell_type":"markdown","id":"f03686b4","metadata":{"id":"f03686b4"},"source":["## 5. Load Best Hyperparameters from Tuning"]},{"cell_type":"code","execution_count":10,"id":"f67e089e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f67e089e","executionInfo":{"status":"ok","timestamp":1764102323428,"user_tz":-180,"elapsed":39,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"2c49513e-d7e3-4223-82a0-6a9021e6c023"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","USING DEFAULT YOLO CONFIGURATION\n","================================================================================\n","No hyperparameter tuning applied - using YOLO defaults\n","\n","âœ“ Training will use default YOLO hyperparameters\n","   Default values will be applied by the YOLO model\n","================================================================================\n"]}],"source":["# ============================================================================\n","# LOAD HYPERPARAMETERS (TUNED OR DEFAULT)\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","if USE_DEFAULT_CONFIG:\n","    print('USING DEFAULT YOLO CONFIGURATION')\n","    print('=' * 80)\n","    print('No hyperparameter tuning applied - using YOLO defaults')\n","\n","    # Use empty dict for hyperparameters - YOLO will use its defaults\n","    best_params = {}\n","\n","    print('\\nâœ“ Training will use default YOLO hyperparameters')\n","    print('   Default values will be applied by the YOLO model')\n","\n","else:\n","    print('LOADING BEST HYPERPARAMETERS FROM TUNING')\n","    print('=' * 80)\n","    print(f'Tuning Run: {TUNING_RUN_NAME}')\n","    print(f'Hyperparameters Path: {best_hyperparams_path}')\n","\n","    # Load best hyperparameters from JSON\n","    with open(best_hyperparams_path, 'r', encoding='utf-8') as f:\n","        best_params_file = json.load(f)\n","\n","    # Extract only the actual hyperparameters (not metadata)\n","    # The file structure has metadata fields and a 'hyperparameters' field with the actual params\n","    if 'hyperparameters' in best_params_file:\n","        # New format: metadata + hyperparameters nested\n","        best_params = best_params_file['hyperparameters']\n","        print('\\nâœ“ Loaded hyperparameters from nested structure')\n","    else:\n","        # Old format: hyperparameters directly in root\n","        # Filter out metadata fields that aren't YOLO parameters\n","        metadata_keys = {'model', 'dataset_root', 'data_yaml_path', 'notes',\n","                        'optimization_results', 'timestamp'}\n","        best_params = {k: v for k, v in best_params_file.items() if k not in metadata_keys}\n","        print('\\nâœ“ Loaded hyperparameters from flat structure (filtered metadata)')\n","\n","    print('\\nâœ“ Best Hyperparameters Loaded:')\n","    for key, value in sorted(best_params.items()):\n","        if isinstance(value, (int, float)):\n","            if isinstance(value, float):\n","                print(f'  {key:20s}: {value:.6f}')\n","            else:\n","                print(f'  {key:20s}: {value}')\n","        else:\n","            print(f'  {key:20s}: {value}')\n","\n","    # Load tuning metadata if available\n","    tuning_metadata_path = TUNE_DIR / 'optimization_metadata.json'\n","    if tuning_metadata_path.exists():\n","        with open(tuning_metadata_path, 'r', encoding='utf-8') as f:\n","            tuning_metadata = json.load(f)\n","\n","        print('\\nğŸ“Š Tuning Run Summary:')\n","        print(f\"  Best Trial: {tuning_metadata.get('best_trial', 'N/A')}\")\n","        print(f\"  Best mAP@0.5: {tuning_metadata.get('best_map50', 0):.4f}\")\n","        print(f\"  Total Trials: {tuning_metadata.get('total_trials', 'N/A')}\")\n","        print(f\"  Completed Trials: {tuning_metadata.get('completed_trials', 'N/A')}\")\n","\n","        if 'optimization_duration' in tuning_metadata:\n","            print(f\"  Duration: {tuning_metadata['optimization_duration']}\")\n","\n","print('=' * 80)"]},{"cell_type":"markdown","id":"83385af0","metadata":{"id":"83385af0"},"source":["## 7. Train The Model"]},{"cell_type":"code","execution_count":11,"id":"df0bc9da","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"df0bc9da","executionInfo":{"status":"error","timestamp":1764123280720,"user_tz":-180,"elapsed":20952643,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"c50c685b-a496-4809-d0c3-8c2131232e8e"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRAINING FINAL MODEL WITH DEFAULT CONFIGURATION\n","================================================================================\n","\n","ğŸ“¦ Loading base model: yolov8m\n","\n","ğŸš€ Starting training...\n","  Configuration: Default YOLO\n","  Epochs: 100\n","  Batch Size: 96\n","  Dataset: /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/tmp/yolov8m/data.yaml\n","  Device: cuda\n","  Resume: False\n","\n","ğŸ“Š Using YOLO default hyperparameters (no custom values)\n","\n","This may take a while. Training progress will be displayed below.\n","================================================================================\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mm3mahdy\u001b[0m (\u001b[33mm3mahdy-king-saud-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20251125_202531-ovekgm2m</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_limited-training/runs/ovekgm2m' target=\"_blank\">yolov8m_train_20251125_202451</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_limited-training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_limited-training' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_limited-training</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_limited-training/runs/ovekgm2m' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_limited-training/runs/ovekgm2m</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["âœ“ W&B initialized: yolo-bdd100k_yolo_limited-training/yolov8m_train_20251125_202451\n","Ultralytics 8.3.232 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=96, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/tmp/yolov8m/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/models/yolov8m/yolov8m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_train_20251125_202451, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/tune_train/training, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/tune_train/training/yolov8m_train_20251125_202451, save_frames=False, save_json=False, save_period=1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 15.9MB/s 0.0s\n","Overriding model.yaml nc=80 with nc=10\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 469/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 73.1MB/s 0.1s\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1828.9Â±492.2 MB/s, size: 64.6 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_limited/labels/train... 35467 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 35467/35467 1.5Kit/s 24.2s\n","\u001b[34m\u001b[1mtrain: \u001b[0m/computer_vision_yolo/bdd100k_yolo_limited/images/train/75055858-7d04a650.jpg: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /computer_vision_yolo/bdd100k_yolo_limited/labels/train.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1005.3Â±639.4 MB/s, size: 69.4 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_limited/labels/val... 9374 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9374/9374 894.3it/s 10.5s\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /computer_vision_yolo/bdd100k_yolo_limited/labels/val.cache\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/tune_train/training/yolov8m_train_20251125_202451/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.00075), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/tune_train/training/yolov8m_train_20251125_202451\u001b[0m\n","Starting training for 100 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      1/100        36G      1.286      1.099      1.022       1476        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:37\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.3it/s 36.8s\n","                   all       9374     163770      0.686      0.402      0.442      0.266\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      2/100      35.7G       1.24     0.7989     0.9821       1316        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:36\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.9s\n","                   all       9374     163770      0.692      0.409      0.444      0.264\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      3/100      36.2G       1.27     0.8099     0.9951       1431        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.3it/s 36.9s\n","                   all       9374     163770      0.649      0.373      0.396      0.224\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      4/100      35.8G      1.286      0.819      1.007       1582        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 36.2s\n","                   all       9374     163770      0.676      0.397      0.429      0.244\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      5/100      35.7G      1.259     0.7849     0.9975       1224        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.5s\n","                   all       9374     163770      0.699      0.407      0.443      0.251\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      6/100      36.1G       1.24     0.7593       0.99       1608        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.8s\n","                   all       9374     163770      0.682      0.422       0.45      0.261\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      7/100      38.1G      1.222     0.7407     0.9864       1512        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.9s\n","                   all       9374     163770      0.692      0.437       0.47      0.273\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      8/100      36.1G      1.213     0.7297     0.9818       1196        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.7s\n","                   all       9374     163770      0.699      0.436      0.474      0.277\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      9/100      35.7G      1.206     0.7195     0.9775       1327        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.5s\n","                   all       9374     163770        0.7      0.441      0.478      0.279\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     10/100      36.1G      1.198     0.7097     0.9751       1260        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.4s\n","                   all       9374     163770      0.725       0.44      0.485      0.283\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     11/100      36.1G      1.193     0.7032     0.9744       1291        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.4s\n","                   all       9374     163770      0.719      0.449      0.497      0.293\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     12/100      37.3G      1.186     0.6973      0.972       1412        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.7s\n","                   all       9374     163770      0.725      0.449      0.494      0.292\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     13/100      35.3G      1.183     0.6923     0.9694       1307        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.5s\n","                   all       9374     163770      0.722      0.459      0.503      0.297\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     14/100        36G      1.177     0.6843     0.9669       1233        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.4s\n","                   all       9374     163770      0.734      0.455      0.508      0.301\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     15/100      35.6G      1.172     0.6783     0.9659       1244        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.4s\n","                   all       9374     163770      0.734      0.462      0.514      0.304\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     16/100      37.4G      1.169     0.6766      0.965       1323        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.7s\n","                   all       9374     163770      0.736      0.467      0.513      0.305\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     17/100      35.8G      1.167     0.6725     0.9628       1461        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.5s\n","                   all       9374     163770      0.725      0.471      0.515      0.306\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     18/100      36.6G      1.164      0.668      0.962       1333        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.5s\n","                   all       9374     163770      0.738      0.472       0.52      0.311\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     19/100      36.6G      1.163     0.6663     0.9616       1343        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.4s\n","                   all       9374     163770      0.736      0.476      0.523      0.312\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     20/100      36.3G      1.159     0.6632     0.9612       1420        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.6s\n","                   all       9374     163770      0.591      0.478      0.523      0.314\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     21/100      37.8G      1.156     0.6595     0.9589       1466        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:36\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.4s\n","                   all       9374     163770       0.73      0.478      0.526      0.315\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     22/100      36.2G      1.155     0.6562     0.9582       1564        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.5s\n","                   all       9374     163770      0.742      0.476      0.529      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     23/100      37.6G      1.151      0.655     0.9596       1448        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.5s\n","                   all       9374     163770      0.737      0.484      0.531      0.319\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     24/100      37.8G      1.149     0.6514     0.9559       1456        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.3s\n","                   all       9374     163770      0.595      0.485      0.533       0.32\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     25/100      35.6G      1.148     0.6501     0.9564       1363        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.3s\n","                   all       9374     163770      0.595      0.486      0.535      0.322\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     26/100        35G      1.147     0.6477     0.9552       1209        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:36\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.2s\n","                   all       9374     163770      0.601      0.485      0.537      0.323\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     27/100      35.1G      1.143     0.6433     0.9533       1473        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.2s\n","                   all       9374     163770        0.6      0.489      0.537      0.324\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     28/100        36G      1.142     0.6439     0.9536       1479        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.1s\n","                   all       9374     163770      0.606      0.488       0.54      0.326\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     29/100      37.6G      1.141      0.641     0.9527       1417        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.5s\n","                   all       9374     163770      0.746      0.492      0.542      0.327\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     30/100      35.9G      1.138     0.6364     0.9507       1579        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.2s\n","                   all       9374     163770      0.611      0.489      0.542      0.327\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     31/100      35.9G      1.139     0.6369     0.9509       1360        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.2s\n","                   all       9374     163770      0.595      0.498      0.543      0.328\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     32/100      36.1G      1.137     0.6351     0.9508       1272        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.1s\n","                   all       9374     163770      0.594      0.501      0.545      0.329\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     33/100      35.3G      1.134     0.6321     0.9485       1155        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.1s\n","                   all       9374     163770      0.606      0.496      0.545      0.329\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     34/100      36.1G      1.131     0.6299     0.9495       1457        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:36\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.2s\n","                   all       9374     163770      0.603      0.495      0.546       0.33\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     35/100      35.3G      1.134     0.6297     0.9499       1390        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.3s\n","                   all       9374     163770      0.607      0.495      0.546      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     36/100      35.4G      1.132     0.6278     0.9486       1285        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.2s\n","                   all       9374     163770       0.61      0.495      0.549      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     37/100      35.4G      1.128     0.6255     0.9478       1186        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.1s\n","                   all       9374     163770      0.607      0.497      0.548      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     38/100      35.7G      1.127     0.6235     0.9464       1331        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:36\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.3s\n","                   all       9374     163770      0.603      0.503       0.55      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     39/100      35.7G      1.124     0.6208     0.9464       1327        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.2s\n","                   all       9374     163770      0.601      0.502       0.55      0.333\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     40/100      36.1G      1.123     0.6176     0.9452       1427        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:36\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.3s\n","                   all       9374     163770      0.598      0.506      0.551      0.333\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     41/100      35.9G      1.124     0.6182      0.945       1487        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 34.9s\n","                   all       9374     163770        0.6      0.504      0.552      0.334\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     42/100      37.4G      1.121     0.6157     0.9448       1256        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.1s\n","                   all       9374     163770      0.604      0.503      0.552      0.334\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     43/100      35.8G      1.121     0.6142     0.9446       1334        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.1s\n","                   all       9374     163770      0.601      0.504      0.552      0.335\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     44/100      35.3G      1.116     0.6121     0.9419       1377        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 34.9s\n","                   all       9374     163770      0.603      0.504      0.553      0.335\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     45/100      35.8G      1.117       0.61     0.9408       1474        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.1s\n","                   all       9374     163770      0.605      0.502      0.552      0.335\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     46/100      35.9G      1.113     0.6078     0.9409       1514        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.4s\n","                   all       9374     163770      0.605      0.502      0.553      0.336\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     47/100      35.6G      1.114     0.6073      0.942       1222        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:37\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.1s\n","                   all       9374     163770      0.601      0.504      0.553      0.336\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     48/100      35.7G      1.113     0.6041       0.94       1400        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.0s\n","                   all       9374     163770      0.605      0.502      0.553      0.336\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     49/100      36.2G      1.112      0.604     0.9413       1469        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.1s\n","                   all       9374     163770        0.6      0.506      0.553      0.336\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     50/100      35.8G      1.111     0.6023     0.9396       1349        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:36\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.0s\n","                   all       9374     163770      0.602      0.505      0.553      0.336\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     51/100      37.8G      1.109     0.6004     0.9405       1574        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:36\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.0s\n","                   all       9374     163770      0.599      0.508      0.553      0.336\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     52/100      36.4G      1.106     0.5975     0.9381       1279        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.0s\n","                   all       9374     163770      0.599      0.507      0.553      0.336\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     53/100      37.3G      1.107     0.5969     0.9386       1567        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:36\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.0s\n","                   all       9374     163770      0.599      0.508      0.553      0.336\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     54/100      35.7G      1.102     0.5934     0.9383       1639        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 34.9s\n","                   all       9374     163770      0.603      0.506      0.553      0.336\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     55/100      36.3G      1.101     0.5913     0.9372       1253        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:36\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.0s\n","                   all       9374     163770        0.6      0.507      0.553      0.336\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     56/100        36G      1.099     0.5897     0.9365       1546        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.0s\n","                   all       9374     163770      0.601      0.508      0.553      0.336\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     57/100      37.5G      1.097     0.5872     0.9352       1325        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.1s\n","                   all       9374     163770      0.602      0.506      0.554      0.337\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     58/100      36.2G      1.097     0.5873     0.9352       1551        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.1s\n","                   all       9374     163770      0.584      0.537      0.554      0.337\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     59/100      37.5G      1.097     0.5862     0.9333       1397        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:36\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.1s\n","                   all       9374     163770      0.585      0.538      0.554      0.337\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     60/100        36G      1.095     0.5813     0.9343       1293        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.1s\n","                   all       9374     163770      0.589      0.542      0.554      0.337\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     61/100      37.5G      1.095     0.5812     0.9329       1451        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.0s\n","                   all       9374     163770      0.589      0.543      0.554      0.337\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     62/100      35.9G      1.091     0.5783     0.9336       1185        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.1s\n","                   all       9374     163770      0.591      0.542      0.554      0.337\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     63/100      35.9G       1.09     0.5765     0.9327       1512        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.0s\n","                   all       9374     163770       0.63      0.525      0.555      0.337\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     64/100      36.1G      1.086     0.5732     0.9301       1273        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 34.8s\n","                   all       9374     163770      0.626      0.524      0.555      0.338\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     65/100      35.6G      1.088     0.5736     0.9323       1707        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.1s\n","                   all       9374     163770      0.628      0.524      0.555      0.338\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     66/100      37.5G      1.085     0.5703     0.9297       1831        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 34.8s\n","                   all       9374     163770      0.627      0.524      0.555      0.338\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     67/100      35.9G      1.081     0.5675     0.9288       1403        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.0s\n","                   all       9374     163770      0.629      0.524      0.555      0.338\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     68/100      35.8G      1.081     0.5663     0.9302       1480        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:36\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 34.7s\n","                   all       9374     163770      0.629      0.523      0.555      0.338\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     69/100      37.3G      1.079     0.5646     0.9284       1289        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:36\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.0s\n","                   all       9374     163770      0.628      0.522      0.555      0.338\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     70/100      35.8G      1.077     0.5626     0.9274       1287        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 34.9s\n","                   all       9374     163770      0.628      0.522      0.555      0.338\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     71/100      35.3G      1.073     0.5586     0.9266       1369        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 34.9s\n","                   all       9374     163770       0.63      0.521      0.555      0.338\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     72/100      37.5G      1.072     0.5566     0.9265       1364        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.2s\n","                   all       9374     163770      0.631       0.52      0.555      0.338\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     73/100      35.7G      1.071     0.5551     0.9263       1386        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 34.9s\n","                   all       9374     163770      0.635      0.518      0.555      0.338\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     74/100      35.7G      1.069     0.5529     0.9252       1383        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.2s\n","                   all       9374     163770      0.638      0.517      0.555      0.338\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     75/100        36G      1.067     0.5506     0.9248       1383        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 34.8s\n","                   all       9374     163770      0.639      0.515      0.555      0.337\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     76/100      35.5G      1.061     0.5461     0.9235       1320        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 34.9s\n","                   all       9374     163770      0.641      0.514      0.555      0.338\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     77/100        36G      1.063     0.5466     0.9225       1419        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 34.8s\n","                   all       9374     163770       0.64      0.514      0.555      0.337\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     78/100      37.4G       1.06     0.5427     0.9209       1499        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.1s\n","                   all       9374     163770      0.639      0.513      0.555      0.337\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     79/100      37.5G      1.056     0.5405     0.9196       1253        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 35.0s\n","                   all       9374     163770       0.64      0.512      0.555      0.337\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     80/100      36.1G      1.052     0.5363     0.9174       1315        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 34.6s\n","                   all       9374     163770       0.64      0.513      0.556      0.337\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     81/100      35.9G       1.05     0.5344     0.9179       1312        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 34.8s\n","                   all       9374     163770      0.641      0.513      0.556      0.337\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     82/100      37.2G      1.049     0.5328     0.9168       1268        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 370/370 1.7it/s 3:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.4it/s 34.8s\n","                   all       9374     163770      0.641      0.512      0.556      0.337\n","\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 72, best model saved as best.pt.\n","To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n","\n","82 epochs completed in 5.772 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/tune_train/training/yolov8m_train_20251125_202451/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/tune_train/training/yolov8m_train_20251125_202451/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/tune_train/training/yolov8m_train_20251125_202451/weights/best.pt...\n","Ultralytics 8.3.232 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 49/49 1.1it/s 45.7s\n","                   all       9374     163770      0.633       0.52      0.555      0.338\n","                 rider        515        649      0.587      0.444      0.446      0.234\n","                   car       9275      97167       0.82      0.732      0.803      0.509\n","                 truck       2652       4191      0.644      0.628      0.652      0.479\n","                   bus       1242       1597       0.67      0.608      0.658      0.513\n","                 train         14         15      0.224     0.0667     0.0214     0.0156\n","         traffic light       5436      26229      0.746      0.547      0.623      0.246\n","          traffic sign       7914      33922      0.736      0.613       0.68      0.368\n","Speed: 0.1ms preprocess, 0.8ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/tune_train/training/yolov8m_train_20251125_202451\u001b[0m\n","\n","âœ“ Training completed successfully!\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_train_20251125_202451</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_limited-training/runs/ovekgm2m' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_limited-training/runs/ovekgm2m</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_limited-training' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_limited-training</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20251125_202531-ovekgm2m/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["âœ“ W&B run finished\n","\n","================================================================================\n","TRAINING SUMMARY\n","================================================================================\n","\n","ğŸ“Š Running final validation...\n","Ultralytics 8.3.232 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1253.0Â±375.4 MB/s, size: 36.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_limited/labels/val.cache... 9374 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9374/9374 14.1Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 586/586 11.1it/s 52.8s\n","                   all       9374     163770      0.632      0.521      0.555      0.339\n","                 rider        515        649      0.588      0.445      0.448      0.233\n","                   car       9275      97167       0.82      0.732      0.803       0.51\n","                 truck       2652       4191      0.643      0.628      0.652      0.479\n","                   bus       1242       1597      0.668      0.609      0.658      0.514\n","                 train         14         15      0.223     0.0667     0.0214     0.0155\n","         traffic light       5436      26229      0.747      0.548      0.625      0.248\n","          traffic sign       7914      33922      0.736      0.614      0.681      0.369\n","Speed: 0.4ms preprocess, 1.5ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/tune_train/training/yolov8m_train_20251125_202451/final_val\u001b[0m\n","\n","ğŸ“Š Final Model Performance:\n","  mAP@0.5: 0.5554\n","  mAP@0.5:0.95: 0.3385\n","  Precision: 0.6322\n","  Recall: 0.5205\n","\n","ğŸ’¾ Training log saved: /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/tune_train/training/yolov8m_train_20251125_202451/training_log.json\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'tuning_metadata_path' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-43454033.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;31m# Compare with tuning results if available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mtuning_metadata_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0mtuning_best_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuning_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_map50'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0mimprovement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'map50'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtuning_best_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'tuning_metadata_path' is not defined"]}],"source":["# ============================================================================\n","# TRAIN FINAL MODEL WITH OPTIMIZED HYPERPARAMETERS\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","if USE_DEFAULT_CONFIG:\n","    print('TRAINING FINAL MODEL WITH DEFAULT CONFIGURATION')\n","else:\n","    print('TRAINING FINAL MODEL WITH OPTIMIZED HYPERPARAMETERS')\n","print('=' * 80)\n","\n","# Check if resuming from previous training\n","checkpoint_path = TRAIN_DIR / 'weights' / 'last.pt'\n","training_log_path = TRAIN_DIR / 'training_log.json'\n","is_resuming = checkpoint_path.exists()\n","\n","if is_resuming:\n","    # Resume training\n","    print('\\n' + '=' * 80)\n","    print('ğŸ”„ RESUMING PREVIOUS TRAINING')\n","    print('=' * 80)\n","    print(f'Checkpoint: {checkpoint_path}')\n","\n","    # Load training log if available\n","    if training_log_path.exists():\n","        with open(training_log_path, 'r', encoding='utf-8') as f:\n","            training_log = json.load(f)\n","\n","        print(f'\\nğŸ“Š Previous Training Summary:')\n","        print(f\"  Started: {training_log.get('start_time', 'N/A')}\")\n","        if 'last_epoch' in training_log:\n","            print(f\"  Last Epoch: {training_log['last_epoch']}\")\n","        if 'best_map50' in training_log:\n","            print(f\"  Best mAP@0.5: {training_log['best_map50']:.4f}\")\n","        if 'last_checkpoint' in training_log:\n","            print(f\"  Last Checkpoint: {training_log['last_checkpoint']}\")\n","\n","    print(f'\\nâ¡ï¸  Resuming training from checkpoint')\n","    print('=' * 80)\n","\n","    # Load model from checkpoint\n","    print(f'\\nğŸ“¦ Loading model from checkpoint: {checkpoint_path}')\n","    final_model = YOLO(str(checkpoint_path))\n","    model_to_train = str(checkpoint_path)\n","    resume_training = True\n","\n","else:\n","    # Start new training\n","    print(f'\\nğŸ“¦ Loading base model: {MODEL_NAME}')\n","    final_model = YOLO(str(model_path))\n","    model_to_train = str(model_path)\n","    resume_training = False\n","\n","    # Initialize training log\n","    training_log = {\n","        'start_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n","        'model': MODEL_NAME,\n","        'dataset': YOLO_DATASET_ROOT.name,\n","        'config_mode': 'default' if USE_DEFAULT_CONFIG else 'tuned',\n","        'tuning_run': TUNING_RUN_NAME if not USE_DEFAULT_CONFIG else None,\n","        'best_hyperparameters': best_params,\n","        'epochs': EPOCHS_FINAL_TRAINING,\n","        'batch_size': BATCH_SIZE,\n","        'image_size': IMAGE_SIZE\n","    }\n","\n","# Prepare training parameters\n","# Note: Fixed parameters (not part of optimization) are always included\n","# Optimization parameters are added via **best_params (empty if using defaults)\n","final_training_params = {\n","    # ============================================================================\n","    # FIXED PARAMETERS - Always passed, not part of hyperparameter optimization\n","    # ============================================================================\n","    'data': str(DATA_YAML_PATH),              # Dataset configuration file\n","    'epochs': EPOCHS_FINAL_TRAINING,          # Number of training epochs\n","    'batch': BATCH_SIZE,                       # Batch size\n","    'imgsz': IMAGE_SIZE,                       # Input image size\n","    'device': device,                          # Training device (cuda/cpu)\n","    'project': str(TRAIN_DIR.parent),         # Project directory\n","    'name': TRAIN_DIR.name,                    # Run name\n","    'exist_ok': True,                          # Overwrite existing project\n","    'patience': ModelConfig.DEFAULT_PATIENCE,  # Early stopping patience\n","    'save_period': ModelConfig.DEFAULT_SAVE_PERIOD,  # Save checkpoint frequency\n","    'workers': ModelConfig.DEFAULT_WORKERS,    # Number of data loading workers\n","    'verbose': True,                           # Verbose output\n","    'seed': 42,                                # Random seed for reproducibility\n","    'close_mosaic': ModelConfig.CLOSE_MOSAIC_EPOCHS,  # Disable mosaic in final epochs\n","    'resume': resume_training,                 # Resume from checkpoint if exists\n","    'cache': ModelConfig.DEFAULT_CACHE,        # Cache images for faster training\n","    'val': ModelConfig.DEFAULT_VAL,            # Run validation during training\n","\n","    # ============================================================================\n","    # OPTIMIZATION PARAMETERS - From tuning (if USE_DEFAULT_CONFIG=False)\n","    # ============================================================================\n","    # Parameters like: lr0, lrf, momentum, weight_decay, warmup_epochs, etc.\n","    **best_params  # Empty dict if USE_DEFAULT_CONFIG=True, tuned params otherwise\n","}\n","\n","print(f'\\nğŸš€ {\"Resuming\" if resume_training else \"Starting\"} training...')\n","print(f'  Configuration: {\"Default YOLO\" if USE_DEFAULT_CONFIG else \"Tuned Hyperparameters\"}')\n","print(f'  Epochs: {final_training_params[\"epochs\"]}')\n","print(f'  Batch Size: {final_training_params[\"batch\"]}')\n","print(f'  Dataset: {DATA_YAML_PATH}')\n","print(f'  Device: {device}')\n","print(f'  Resume: {resume_training}')\n","\n","if best_params:\n","    print('\\nğŸ“Š Applied Hyperparameters:')\n","    for key, value in sorted(best_params.items()):\n","        if isinstance(value, float):\n","            print(f'  {key:20s}: {value:.6f}')\n","        else:\n","            print(f'  {key:20s}: {value}')\n","else:\n","    print('\\nğŸ“Š Using YOLO default hyperparameters (no custom values)')\n","\n","print('\\nThis may take a while. Training progress will be displayed below.')\n","print('=' * 80)\n","\n","# Initialize W&B for final training\n","if USE_WANDB:\n","    try:\n","        wandb_config = {\n","            'model': MODEL_NAME,\n","            'dataset': YOLO_DATASET_ROOT.name,\n","            'phase': 'final_training',\n","            'config_mode': 'default' if USE_DEFAULT_CONFIG else 'tuned',\n","            'tuning_run': TUNING_RUN_NAME if not USE_DEFAULT_CONFIG else None,\n","            'epochs': final_training_params['epochs'],\n","            'batch_size': final_training_params['batch'],\n","            'resume': resume_training,\n","            **best_params\n","        }\n","\n","        wandb_training_run = wandb.init(\n","            project=WANDB_PROJECT_TRAINING,\n","            name=RUN_NAME_TRAINING,\n","            id=training_log.get('wandb_run_id') if is_resuming else None,\n","            resume='allow' if is_resuming else None,\n","            config=wandb_config,\n","            group='final-training',\n","            tags=['final', 'optimized' if not USE_DEFAULT_CONFIG else 'default', MODEL_NAME, YOLO_DATASET_ROOT.name]\n","        )\n","\n","        # Save W&B run ID for future resume\n","        if not is_resuming:\n","            training_log['wandb_run_id'] = wandb_training_run.id\n","            with open(training_log_path, 'w', encoding='utf-8') as f:\n","                json.dump(training_log, f, indent=2)\n","\n","        print(f'âœ“ W&B initialized: {WANDB_PROJECT_TRAINING}/{RUN_NAME_TRAINING}')\n","    except Exception as wandb_error:\n","        print(f'âš ï¸  Could not initialize W&B: {wandb_error}')\n","        wandb_training_run = None\n","else:\n","    wandb_training_run = None\n","\n","# Train model\n","start_time = datetime.now()\n","try:\n","    final_results = final_model.train(**final_training_params)\n","\n","    # Update training log with completion\n","    training_log['end_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n","    training_log['status'] = 'completed'\n","    training_log['duration'] = str(datetime.now() - start_time)\n","\n","    # Save final metrics\n","    if hasattr(final_results, 'results_dict'):\n","        training_log['final_metrics'] = final_results.results_dict\n","\n","    # Save updated training log\n","    with open(training_log_path, 'w', encoding='utf-8') as f:\n","        json.dump(training_log, f, indent=2)\n","\n","    print('\\nâœ“ Training completed successfully!')\n","\n","except KeyboardInterrupt:\n","    print('\\nâš ï¸  Training interrupted by user')\n","    print(f'ğŸ’¾ Progress saved to: {TRAIN_DIR}')\n","    print(f'   - Last checkpoint: {checkpoint_path}')\n","    print(f'   - Training log: {training_log_path}')\n","    print(f'\\nğŸ”„ To resume: Simply re-run this notebook')\n","\n","    # Update training log\n","    training_log['last_interrupt'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n","    training_log['status'] = 'interrupted'\n","    training_log['end_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n","    with open(training_log_path, 'w', encoding='utf-8') as f:\n","        json.dump(training_log, f, indent=2)\n","    raise\n","\n","except Exception as e:\n","    print(f'\\nâŒ Training failed with error: {e}')\n","    training_log['status'] = 'failed'\n","    training_log['error'] = str(e)\n","    training_log['end_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n","    with open(training_log_path, 'w', encoding='utf-8') as f:\n","        json.dump(training_log, f, indent=2)\n","    raise\n","\n","finally:\n","    if USE_WANDB and wandb_training_run is not None:\n","        wandb_training_run.finish()\n","        print('âœ“ W&B run finished')\n","\n","end_time = datetime.now()\n","duration = end_time - start_time\n","\n","print('\\n' + '=' * 80)\n","print('TRAINING SUMMARY')\n","print('=' * 80)\n","\n","# Get final validation metrics\n","print('\\nğŸ“Š Running final validation...')\n","final_val_results = final_model.val(\n","    data=str(DATA_YAML_PATH),\n","    project=str(TRAIN_DIR),\n","    name='final_val',\n",")\n","\n","final_metrics = {\n","    'map50': float(final_val_results.box.map50),\n","    'map50_95': float(final_val_results.box.map),\n","    'precision': float(final_val_results.box.mp),\n","    'recall': float(final_val_results.box.mr),\n","}\n","\n","print('\\nğŸ“Š Final Model Performance:')\n","print(f\"  mAP@0.5: {final_metrics['map50']:.4f}\")\n","print(f\"  mAP@0.5:0.95: {final_metrics['map50_95']:.4f}\")\n","print(f\"  Precision: {final_metrics['precision']:.4f}\")\n","print(f\"  Recall: {final_metrics['recall']:.4f}\")\n","\n","# Update training log with final metrics\n","training_log['final_metrics'] = final_metrics\n","training_log['best_model_path'] = str(TRAIN_DIR / 'weights' / 'best.pt')\n","training_log['last_model_path'] = str(TRAIN_DIR / 'weights' / 'last.pt')\n","\n","# Save final training log\n","with open(training_log_path, 'w', encoding='utf-8') as f:\n","    json.dump(training_log, f, indent=2)\n","\n","print(f'\\nğŸ’¾ Training log saved: {training_log_path}')\n","\n","# Compare with tuning results if available\n","if tuning_metadata_path.exists():\n","    tuning_best_map = tuning_metadata.get('best_map50', 0)\n","    improvement = final_metrics['map50'] - tuning_best_map\n","    print('\\nğŸ“ˆ Improvement vs Best Tuning Trial:')\n","    print(f\"  Best Tuning mAP@0.5: {tuning_best_map:.4f}\")\n","    print(f\"  Final Model mAP@0.5: {final_metrics['map50']:.4f}\")\n","\n","    print(f\"  Improvement: {improvement:+.4f} ({improvement/tuning_best_map*100:+.2f}%)\")\n","    print('=' * 80)\n","\n","print(f'Last Weights: {TRAIN_DIR / \"weights\" / \"last.pt\"}')\n","\n","print('=' * 80)\n","print(f'Best Weights: {TRAIN_DIR / \"weights\" / \"best.pt\"}')\n","\n","print(f'Training Directory: {TRAIN_DIR}')\n","\n","print(f'Start Time: {start_time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n","print(f'Configuration: {\"Default YOLO\" if USE_DEFAULT_CONFIG else f\"Tuned ({TUNING_RUN_NAME})\"}')\n","\n","print(f'End Time: {end_time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n","print(f'Duration: {duration}')"]},{"cell_type":"markdown","id":"b4b00a39","metadata":{"id":"b4b00a39"},"source":["## 8. Save Final Model and Metadata"]},{"cell_type":"code","execution_count":15,"id":"9d959bb4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9d959bb4","executionInfo":{"status":"ok","timestamp":1764123897273,"user_tz":-180,"elapsed":228,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"615d8175-9f6f-438c-838c-6bd0eb3fb2ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","SAVING FINAL OPTIMIZED MODEL\n","================================================================================\n","\n","âœ“ Final model saved to: /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/models/yolov8m_finetuned_20251126/yolov8m_finetuned_20251126.pt\n","  Size: 49.6 MB\n","âœ“ Model metadata saved to: /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/models/yolov8m_finetuned_20251126/yolov8m_finetuned_20251126_metadata.json\n","\n","ğŸ“¦ Final Model Package:\n","  Model: /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/models/yolov8m_finetuned_20251126/yolov8m_finetuned_20251126.pt\n","  Metadata: /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/models/yolov8m_finetuned_20251126/yolov8m_finetuned_20251126_metadata.json\n","  Training Log: /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/tune_train/training/yolov8m_train_20251125_202451/training_log.json\n","================================================================================\n"]}],"source":["# ============================================================================\n","# SAVE FINAL OPTIMIZED MODEL\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('SAVING FINAL OPTIMIZED MODEL')\n","print('=' * 80)\n","\n","date_stamp = datetime.now().strftime('%Y%m%d')\n","finetuned_model_name = f'{MODEL_NAME}_finetuned_{date_stamp}'\n","\n","# Create model directory if it doesn't exist\n","model_save_dir = BASE_DIR / 'models' / finetuned_model_name\n","model_save_dir.mkdir(parents=True, exist_ok=True)\n","\n","# Define paths for saving\n","final_model_path = model_save_dir / f'{finetuned_model_name}.pt'\n","metadata_path = model_save_dir / f'{finetuned_model_name}_metadata.json'\n","\n","# Copy best weights from training directory\n","# Note: TRAIN_DIR already includes RUN_NAME_TRAINING\n","weights_path = TRAIN_DIR / 'weights' / 'best.pt'\n","\n","if weights_path.exists():\n","    shutil.copy(weights_path, final_model_path)\n","    print(f'\\nâœ“ Final model saved to: {final_model_path}')\n","    print(f'  Size: {final_model_path.stat().st_size / (1024*1024):.1f} MB')\n","else:\n","    print(f'\\nâš ï¸  Best weights not found at: {weights_path}')\n","    print('  Attempting to save current model state...')\n","    try:\n","        # Save current model state if weights not found\n","        final_model.save(str(final_model_path))\n","        print(f'âœ“ Model saved to: {final_model_path}')\n","    except Exception as save_error:\n","        print(f'âš ï¸  Error saving model: {save_error}')\n","\n","# Prepare optimization metadata\n","optimization_meta = {\n","    'tuning_run': TUNING_RUN_NAME,\n","    'tuning_run_path': str(TUNE_DIR),\n","}\n","\n","# Add tuning details if available\n","if not USE_DEFAULT_CONFIG and tuning_metadata_path.exists():\n","    optimization_meta.update({\n","        'n_trials': tuning_metadata.get('total_trials', 'N/A'),\n","        'completed_trials': tuning_metadata.get('completed_trials', 'N/A'),\n","        'best_trial': tuning_metadata.get('best_trial', 'N/A'),\n","        'best_trial_map50': tuning_metadata.get('best_map50', 0),\n","        'optimization_duration': tuning_metadata.get('optimization_duration', 'N/A'),\n","    })\n","\n","# Calculate improvement if tuning metadata available\n","improvement_value = 0\n","if not USE_DEFAULT_CONFIG and tuning_metadata_path.exists():\n","    tuning_best_map = tuning_metadata.get('best_map50', 0)\n","    if tuning_best_map > 0:\n","        improvement_value = float(final_metrics['map50'] - tuning_best_map)\n","\n","# Save model metadata\n","metadata = {\n","    'model_name': MODEL_NAME,\n","    'finetuned_name': finetuned_model_name,\n","    'model_path': str(final_model_path),\n","    'dataset': str(YOLO_DATASET_ROOT),\n","    'training_date': datetime.now().isoformat(),\n","    'training_run': RUN_NAME_TRAINING,\n","    'training_run_path': str(TRAIN_DIR),\n","    'optimization': optimization_meta,\n","    'best_hyperparameters': best_params,\n","    'training_params': {\n","        'epochs': EPOCHS_FINAL_TRAINING,\n","        'batch_size': BATCH_SIZE,\n","        'image_size': IMAGE_SIZE,\n","        'patience': ModelConfig.DEFAULT_PATIENCE,\n","        'save_period': ModelConfig.DEFAULT_SAVE_PERIOD,\n","    },\n","    'final_metrics': final_metrics,\n","    'improvement_vs_tuning': improvement_value,\n","}\n","\n","with open(metadata_path, 'w', encoding='utf-8') as f:\n","    json.dump(metadata, f, indent=2)\n","\n","print(f'âœ“ Model metadata saved to: {metadata_path}')\n","print('\\nğŸ“¦ Final Model Package:')\n","print(f'  Model: {final_model_path}')\n","print(f'  Metadata: {metadata_path}')\n","print(f'  Training Log: {training_log_path}')\n","print('=' * 80)"]},{"cell_type":"markdown","id":"338ab57b","metadata":{"id":"338ab57b"},"source":["## 9. Test Final Model"]},{"cell_type":"code","execution_count":16,"id":"6cfc6346","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"6cfc6346","executionInfo":{"status":"ok","timestamp":1764124179120,"user_tz":-180,"elapsed":163279,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"49010225-64a7-4770-bc9e-cd1e889d9162"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","RUNNING FINAL VALIDATION ON TEST SET\n","================================================================================\n","\n","ğŸ” Validation Configuration:\n","   Base Dir: /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo\n","   Dataset: bdd100k_yolo_limited\n","   Model: yolov8m_finetuned_20251126\n","   Expected dataset path: /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/bdd100k_yolo_limited/data.yaml\n","   Expected model path: /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/models/yolov8m_finetuned_20251126/yolov8m_finetuned_20251126.pt\n","   Actual model path: /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/models/yolov8m_finetuned_20251126/yolov8m_finetuned_20251126.pt\n","âœ“ Device: cuda\n","  GPU: NVIDIA A100-SXM4-40GB\n","âœ“ W&B logging enabled\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Finishing previous runs because reinit is set to 'default'."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_20251126_bdd100k_yolo_limited_test_20251126_022311</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_limited-testing/runs/0qhmzqc2' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_limited-testing/runs/0qhmzqc2</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_limited-testing' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_limited-testing</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20251126_022311-0qhmzqc2/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20251126_022656-mdzjrzin</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_limited-testing/runs/mdzjrzin' target=\"_blank\">yolov8m_finetuned_20251126_bdd100k_yolo_limited_test_20251126_022656</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_limited-testing' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_limited-testing' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_limited-testing</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_limited-testing/runs/mdzjrzin' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_limited-testing/runs/mdzjrzin</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","âœ“ Weights & Biases initialized: yolov8m_finetuned_20251126_bdd100k_yolo_limited_test_20251126_022656\n","âœ“ Dataset loaded\n","  Total images: 16576\n","  Images with labels: 16576\n","  Label files: 16576\n","\n","âœ“ Performance metadata loaded: test_performance_analysis.json\n","  Images with attributes: 16576\n","âœ“ Model loaded from /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/models/yolov8m_finetuned_20251126/yolov8m_finetuned_20251126.pt\n","Model summary: 169 layers, 25,862,110 parameters, 0 gradients, 79.1 GFLOPs\n","\n","ğŸ“Š Model Information:\n","  Model: yolov8m_finetuned_20251126\n","  Classes in model: 10\n","  Task: detect\n","  Parameters: 25.9M\n","  Model Size: 49.6 MB\n","  FLOPs (640x640): 79.09 GFLOPs\n","  Model Size: 49.6 MB\n","\n","Running YOLO validation...\n","Ultralytics 8.3.232 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1199.0Â±671.2 MB/s, size: 64.3 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_limited/labels/test.cache... 16576 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16576/16576 13.1Mit/s 0.0s\n","\u001b[34m\u001b[1mval: \u001b[0m/computer_vision_yolo/bdd100k_yolo_limited/images/test/e6f10c58-c46de527.jpg: 1 duplicate labels removed\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 173/173 2.0it/s 1:26\n","                   all      16576     296515      0.644      0.546       0.57      0.342\n","                 rider       1004       1293      0.601      0.474       0.48      0.246\n","                   car      16457     176913      0.811      0.747      0.803      0.512\n","                 truck       5265       8339      0.637      0.651       0.66      0.482\n","                   bus       2380       3119      0.621      0.594      0.614      0.473\n","                 train         26         28      0.378      0.143      0.118     0.0578\n","         traffic light       9165      45554      0.737      0.577      0.629      0.251\n","          traffic sign      14072      61269       0.72      0.634      0.684      0.371\n","Speed: 0.4ms preprocess, 1.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/yolo_test/runs/yolov8m_finetuned_20251126_testing_20251126_022656/yolo_validation\u001b[0m\n","\n","âœ“ YOLO validation completed in 92.99 seconds\n","\n","================================================================================\n","OFFICIAL YOLO VALIDATION RESULTS\n","================================================================================\n","Precision (mean): 0.6438\n","Recall (mean):    0.5457\n","mAP@0.5:          0.5696\n","mAP@0.5:0.95:     0.3416\n","Fitness:          0.3416\n","\n","âš¡ Performance Metrics:\n","  Total Time: 92.99s\n","  Average Inference Time: 2348.61 ms per image\n","  FPS (Frames Per Second): 425.78\n","================================================================================\n","(Green = Correct Predictions, Red = Incorrect Predictions, White = No Predictions)\n","\n","================================================================================\n","GENERATING SAMPLE COMPARISONS\n","================================================================================\n","\n","Generating 6 high-resolution comparison figures with attributes...\n"]},{"output_type":"stream","name":"stderr","text":["Generating comparisons: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:13<00:00,  2.23s/it]\n"]},{"output_type":"stream","name":"stdout","text":["âœ“ Generated 6 comparison images\n","  Saved to: /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/yolo_test/runs/yolov8m_finetuned_20251126_testing_20251126_022656/sample_comparisons\n","================================================================================\n","âœ“ COMPREHENSIVE REPORT GENERATED (script)\n","================================================================================\n","PDF Report: /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/yolo_test/runs/yolov8m_finetuned_20251126_testing_20251126_022656/report.pdf\n","JSON Metrics: /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/yolo_test/runs/yolov8m_finetuned_20251126_testing_20251126_022656/metrics_data.json\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_20251126_bdd100k_yolo_limited_test_20251126_022656</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_limited-testing/runs/mdzjrzin' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_limited-testing/runs/mdzjrzin</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_limited-testing' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_limited-testing</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20251126_022656-mdzjrzin/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","âœ“ Weights & Biases run completed successfully\n","\n","ğŸ§¹ Cleaning up model from memory...\n","âœ“ Model removed from memory\n","\n","ğŸ“Š Final Validation Results:\n"]},{"output_type":"display_data","data":{"text/plain":["                   model_name               dataset split  iou  \\\n","0  yolov8m_finetuned_20251126  bdd100k_yolo_limited  test  0.5   \n","\n","   precision_confusion  recall_confusion  f1_confusion  precision_yolo  \\\n","0             0.699732          0.808943      0.750385        0.643804   \n","\n","   recall_yolo     map50  map50_95  params_m    size_mb         fps status  \\\n","0     0.545749  0.569589  0.341597  25.86211  49.610735  425.783928     ok   \n","\n","                                             run_dir  \\\n","0  /content/Drive/MyDrive/ksu_yolo_2025/computer_...   \n","\n","                                     hyperparameters  \n","0  {'data': '/content/Drive/MyDrive/ksu_yolo_2025...  "],"text/html":["\n","  <div id=\"df-d5f3698b-2564-4765-be16-d32dba8427cb\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model_name</th>\n","      <th>dataset</th>\n","      <th>split</th>\n","      <th>iou</th>\n","      <th>precision_confusion</th>\n","      <th>recall_confusion</th>\n","      <th>f1_confusion</th>\n","      <th>precision_yolo</th>\n","      <th>recall_yolo</th>\n","      <th>map50</th>\n","      <th>map50_95</th>\n","      <th>params_m</th>\n","      <th>size_mb</th>\n","      <th>fps</th>\n","      <th>status</th>\n","      <th>run_dir</th>\n","      <th>hyperparameters</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>yolov8m_finetuned_20251126</td>\n","      <td>bdd100k_yolo_limited</td>\n","      <td>test</td>\n","      <td>0.5</td>\n","      <td>0.699732</td>\n","      <td>0.808943</td>\n","      <td>0.750385</td>\n","      <td>0.643804</td>\n","      <td>0.545749</td>\n","      <td>0.569589</td>\n","      <td>0.341597</td>\n","      <td>25.86211</td>\n","      <td>49.610735</td>\n","      <td>425.783928</td>\n","      <td>ok</td>\n","      <td>/content/Drive/MyDrive/ksu_yolo_2025/computer_...</td>\n","      <td>{'data': '/content/Drive/MyDrive/ksu_yolo_2025...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5f3698b-2564-4765-be16-d32dba8427cb')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d5f3698b-2564-4765-be16-d32dba8427cb button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d5f3698b-2564-4765-be16-d32dba8427cb');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","  <div id=\"id_aff5ea47-80c4-4f16-8249-56c08e80a475\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_aff5ea47-80c4-4f16-8249-56c08e80a475 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('results_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"results_df","summary":"{\n  \"name\": \"results_df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"model_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"yolov8m_finetuned_20251126\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dataset\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"bdd100k_yolo_limited\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"test\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"iou\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.5,\n        \"max\": 0.5,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision_confusion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6997318854020876,\n        \"max\": 0.6997318854020876,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6997318854020876\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall_confusion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8089432479218976,\n        \"max\": 0.8089432479218976,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8089432479218976\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_confusion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.7503847204063661,\n        \"max\": 0.7503847204063661,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7503847204063661\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision_yolo\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6438038161675464,\n        \"max\": 0.6438038161675464,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6438038161675464\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall_yolo\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.5457492897282813,\n        \"max\": 0.5457492897282813,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5457492897282813\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"map50\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.5695893320902446,\n        \"max\": 0.5695893320902446,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5695893320902446\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"map50_95\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.34159702054339824,\n        \"max\": 0.34159702054339824,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.34159702054339824\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"params_m\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 25.86211,\n        \"max\": 25.86211,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          25.86211\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"size_mb\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 49.610734939575195,\n        \"max\": 49.610734939575195,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          49.610734939575195\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 425.78392845620266,\n        \"max\": 425.78392845620266,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          425.78392845620266\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"status\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"ok\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"run_dir\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"/content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/yolo_test/runs/yolov8m_finetuned_20251126_testing_20251126_022656\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hyperparameters\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}],"source":["# RUN FINAL VALIDATION ON TEST SET (ENHANCED)\n","# ============================================================================\n","print('\\n' + '=' * 80)\n","print('RUNNING FINAL VALIDATION ON TEST SET')\n","print('=' * 80)\n","\n","results_summary = []\n","IOU_THRESHOLDS = 0.5  # Could expand to [0.5, 0.55, 0.6] if needed\n","\n","# Verify that the final model exists before validation\n","if not final_model_path.exists():\n","    print(f\"âš ï¸  Warning: Final model not found at {final_model_path}\")\n","    print(f\"   Skipping test validation. Please complete training first.\")\n","else:\n","    # Add YOLO test scripts path safely\n","    scrpt_dir = BASE_DIR / \"yolo_test\"\n","    if str(scrpt_dir) not in sys.path:\n","        sys.path.append(str(scrpt_dir))\n","\n","    try:\n","        from run_yolo_validation_report import run_validation_pipeline\n","\n","        # Important:\n","        # - Datasets are in DATASET_BASE_DIR (can be different in Colab)\n","        # - Models are ALWAYS in BASE_DIR/models/\n","        #\n","        # Validation script uses base_dir for both:\n","        #   - Dataset path: base_dir / dataset_name / data.yaml\n","        #   - Model path: base_dir / models / model_name / model_name.pt\n","        #\n","        # Solution: Copy dataset to BASE_DIR temporarily, or use symlink\n","\n","        # For Colab: Need to ensure model is accessible\n","        if IS_COLAB:\n","            # Check if dataset exists in BASE_DIR\n","            base_dir_dataset = BASE_DIR / dataset_name\n","            if not (base_dir_dataset / 'data.yaml').exists() and YOLO_DATASET_ROOT.exists():\n","                print(f\"\\nğŸ“‚ Dataset location mismatch detected\")\n","                print(f\"   Dataset is in: {YOLO_DATASET_ROOT}\")\n","                print(f\"   Validation expects: {base_dir_dataset}\")\n","                print(f\"   Creating symbolic link...\")\n","                try:\n","                    import os\n","                    if not base_dir_dataset.exists():\n","                        os.symlink(str(YOLO_DATASET_ROOT), str(base_dir_dataset))\n","                        print(f\"   âœ“ Symbolic link created\")\n","                except Exception as symlink_error:\n","                    print(f\"   âš ï¸  Could not create symlink: {symlink_error}\")\n","                    print(f\"   Validation may fail if dataset path is incorrect\")\n","\n","            validation_base_dir = BASE_DIR\n","        else:\n","            validation_base_dir = BASE_DIR\n","\n","        print(f\"\\nğŸ” Validation Configuration:\")\n","        print(f\"   Base Dir: {validation_base_dir}\")\n","        print(f\"   Dataset: {dataset_name}\")\n","        print(f\"   Model: {finetuned_model_name}\")\n","        print(f\"   Expected dataset path: {validation_base_dir / dataset_name / 'data.yaml'}\")\n","        print(f\"   Expected model path: {validation_base_dir / 'models' / finetuned_model_name / f'{finetuned_model_name}.pt'}\")\n","        print(f\"   Actual model path: {final_model_path}\")\n","\n","        # Verify paths\n","        expected_model_path = validation_base_dir / 'models' / finetuned_model_name / f'{finetuned_model_name}.pt'\n","        if final_model_path != expected_model_path and not expected_model_path.exists():\n","            print(f\"\\nğŸ“¦ Copying model to expected location...\")\n","            expected_model_path.parent.mkdir(parents=True, exist_ok=True)\n","            shutil.copy(final_model_path, expected_model_path)\n","            print(f\"   âœ“ Model copied to {expected_model_path}\")\n","\n","        result = run_validation_pipeline(\n","            model_name=finetuned_model_name,\n","            dataset_name=dataset_name,\n","            split=\"test\",\n","            iou_threshold=IOU_THRESHOLDS,\n","            base_dir=validation_base_dir,\n","            use_wandb=True,\n","            save_reports=True,\n","            batch_size=BATCH_SIZE,\n","        )\n","\n","        overall = result[\"metrics\"][\"overall\"]\n","        yolo_overall = result[\"metrics\"][\"yolo_metrics\"]\n","\n","        results_summary.append({\n","            \"model_name\": finetuned_model_name,\n","            \"dataset\": dataset_name,\n","            \"split\": \"test\",\n","            \"iou\": IOU_THRESHOLDS,\n","            \"precision_confusion\": overall[\"precision\"],\n","            \"recall_confusion\": overall[\"recall\"],\n","            \"f1_confusion\": overall[\"f1\"],\n","            \"precision_yolo\": yolo_overall[\"precision\"],\n","            \"recall_yolo\": yolo_overall[\"recall\"],\n","            \"map50\": yolo_overall[\"map50\"],\n","            \"map50_95\": yolo_overall[\"map50_95\"],\n","            \"params_m\": result[\"model_info\"][\"params\"] / 1e6,\n","            \"size_mb\": result[\"model_info\"][\"size(MB)\"],\n","            \"fps\": result[\"metrics\"][\"fps\"],\n","            \"status\": \"ok\",\n","            \"run_dir\": str(result[\"run_dir\"]),\n","            \"hyperparameters\": final_training_params,  # traceable\n","        })\n","\n","    except Exception as e:\n","        print(f\"âš ï¸ Model {finetuned_model_name} failed during validation: {e}\")\n","        import traceback\n","        traceback.print_exc()\n","        results_summary.append({\n","            \"model_name\": finetuned_model_name,\n","            \"dataset\": dataset_name,\n","            \"split\": \"test\",\n","            \"iou\": IOU_THRESHOLDS,\n","            \"status\": \"error\",\n","            \"error_message\": str(e)\n","        })\n","\n","# Convert to DataFrame\n","if results_summary:\n","    results_df = pd.DataFrame(results_summary)\n","    print('\\nğŸ“Š Final Validation Results:')\n","    display(results_df)\n","else:\n","    print('\\nâš ï¸  No validation results - model training not completed yet')\n"]},{"cell_type":"markdown","id":"35471d99","metadata":{"id":"35471d99"},"source":["## 10. Generate Training Report (PDF)"]},{"cell_type":"code","execution_count":17,"id":"b66f810c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b66f810c","executionInfo":{"status":"ok","timestamp":1764124308590,"user_tz":-180,"elapsed":14106,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"e2d69b5c-b767-4ad1-b7ff-5947e6da4beb"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","GENERATING COMPREHENSIVE TRAINING PDF REPORT\n","================================================================================\n","\n","âœ“ Comprehensive Training PDF generated: /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/tune_train/training/yolov8m_train_20251125_202451/yolov8m_training_report.pdf\n"]}],"source":["# GENERATE COMPREHENSIVE TRAINING PDF REPORT\n","# ============================================================================\n","from reportlab.lib.pagesizes import A4\n","from reportlab.lib import colors as rl_colors\n","from reportlab.lib.units import inch\n","from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, Image, PageBreak\n","from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n","from reportlab.lib.enums import TA_CENTER, TA_LEFT\n","import platform\n","import psutil\n","\n","print('\\n' + '=' * 80)\n","print('GENERATING COMPREHENSIVE TRAINING PDF REPORT')\n","print('=' * 80)\n","\n","pdf_training_report_path = TRAIN_DIR / f'{MODEL_NAME}_training_report.pdf'\n","doc = SimpleDocTemplate(str(pdf_training_report_path), pagesize=A4,\n","                       rightMargin=30, leftMargin=30,\n","                       topMargin=30, bottomMargin=30)\n","story = []\n","styles = getSampleStyleSheet()\n","\n","# Custom styles\n","title_style = ParagraphStyle('Title', parent=styles['Heading1'], fontSize=24,\n","                             textColor=rl_colors.HexColor('#2c3e50'), alignment=TA_CENTER, spaceAfter=20)\n","heading_style = ParagraphStyle('Heading', parent=styles['Heading2'], fontSize=16,\n","                               textColor=rl_colors.HexColor('#34495e'), spaceAfter=12, spaceBefore=20)\n","normal_style = ParagraphStyle('Normal', parent=styles['Normal'], fontSize=10)\n","\n","# --- Title ---\n","story.append(Paragraph(f'{MODEL_NAME} Final Training Report', title_style))\n","story.append(Spacer(1, 12))\n","\n","# --- System Info ---\n","story.append(Paragraph('System Information', heading_style))\n","sys_info_data = [\n","    ['OS', platform.system() + ' ' + platform.release()],\n","    ['Python Version', platform.python_version()],\n","    ['PyTorch Version', torch.__version__],\n","    ['CUDA Available', str(torch.cuda.is_available())],\n","    ['Device', device],\n","    ['RAM (GB)', f\"{psutil.virtual_memory().total/1e9:.2f}\"],\n","]\n","sys_table = Table(sys_info_data, colWidths=[2.5*inch, 3.5*inch])\n","sys_table.setStyle(TableStyle([\n","    ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#95a5a6')),\n","    ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n","    ('GRID', (0,0), (-1,-1), 1, rl_colors.black),\n","    ('FONTNAME', (0,0), (-1,0), 'Helvetica-Bold'),\n","]))\n","story.append(sys_table)\n","story.append(Spacer(1, 12))\n","\n","# --- Dataset Info ---\n","story.append(Paragraph('Dataset Information', heading_style))\n","# Wrap class names text for better readability\n","class_names_text = ', '.join(str(name) for name in CLASS_NAMES.values())\n","class_names_wrapped = Paragraph(class_names_text, normal_style)\n","\n","dataset_info_data = [\n","    ['Property', 'Value'],\n","    ['Dataset', YOLO_DATASET_ROOT.name],\n","    ['Number of Classes', str(NUM_CLASSES)],\n","    ['Train Images', str(dataset_stats.get('train', {}).get('images', 'N/A'))],\n","    ['Val Images', str(dataset_stats.get('val', {}).get('images', 'N/A'))],\n","    ['Test Images', str(dataset_stats.get('test', {}).get('images', 'N/A'))],\n","    ['Data YAML', str(DATA_YAML_PATH.name)],\n","]\n","dataset_table = Table(dataset_info_data, colWidths=[2*inch, 4*inch])\n","dataset_table.setStyle(TableStyle([\n","    ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#16a085')),\n","    ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n","    ('GRID', (0,0), (-1,-1), 1, rl_colors.black),\n","]))\n","story.append(dataset_table)\n","story.append(Spacer(1, 6))\n","# Add class names separately with wrapping\n","story.append(Paragraph('<b>Classes:</b>', normal_style))\n","story.append(class_names_wrapped)\n","story.append(Spacer(1, 12))\n","\n","# --- Optimization Summary ---\n","story.append(Paragraph('Optimization Summary', heading_style))\n","opt_summary_data = [\n","    ['Metric', 'Value'],\n","    ['Tuning Run', TUNING_RUN_NAME],\n","    ['Total Trials', str(tuning_metadata.get('total_trials', 'N/A')) if not USE_DEFAULT_CONFIG and  tuning_metadata_path.exists() else 'N/A'],\n","    ['Completed Trials', str(tuning_metadata.get('completed_trials', 'N/A')) if not USE_DEFAULT_CONFIG and  tuning_metadata_path.exists() else 'N/A'],\n","    ['Best Trial Number', str(tuning_metadata.get('best_trial', 'N/A')) if not USE_DEFAULT_CONFIG and  tuning_metadata_path.exists() else 'N/A'],\n","    ['Best Trial mAP@0.5', f\"{tuning_metadata.get('best_map50', 0):.4f}\" if not USE_DEFAULT_CONFIG and tuning_metadata_path.exists() else 'N/A'],\n","    ['Final Training Epochs', str(EPOCHS_FINAL_TRAINING)],\n","]\n","opt_table = Table(opt_summary_data, colWidths=[3*inch, 3*inch])\n","opt_table.setStyle(TableStyle([\n","    ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#f39c12')),\n","    ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n","    ('GRID', (0,0), (-1,-1), 1, rl_colors.black),\n","]))\n","story.append(opt_table)\n","story.append(Spacer(1, 12))\n","\n","# --- Optimized Hyperparameters ---\n","story.append(PageBreak())\n","story.append(Paragraph('Optimized Hyperparameters Used', heading_style))\n","hyperparam_data = [['Parameter', 'Value']]\n","for key, value in best_params.items():\n","    hyperparam_data.append([key, f\"{value:.6f}\" if isinstance(value, float) else str(value)])\n","hyperparam_table = Table(hyperparam_data, colWidths=[3*inch, 3*inch])\n","hyperparam_table.setStyle(TableStyle([\n","    ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#3498db')),\n","    ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n","    ('GRID', (0,0), (-1,-1), 1, rl_colors.black),\n","]))\n","story.append(hyperparam_table)\n","story.append(Spacer(1, 12))\n","\n","# --- Training Process Details ---\n","story.append(PageBreak())\n","story.append(Paragraph('Training Process Analysis', heading_style))\n","\n","# Try to load training results CSV for detailed epoch-by-epoch analysis\n","# YOLO saves results.csv directly in the training run directory\n","results_csv = TRAIN_DIR / 'results.csv'\n","if results_csv.exists():\n","    try:\n","        import pandas as pd\n","        import matplotlib.pyplot as plt\n","        import matplotlib\n","        matplotlib.use('Agg')\n","\n","        # Load results\n","        training_results = pd.read_csv(results_csv)\n","        training_results.columns = training_results.columns.str.strip()\n","\n","        story.append(Paragraph('Epoch-by-Epoch Training Metrics', styles['Heading3']))\n","        story.append(Spacer(1, 6))\n","\n","        # Create comprehensive training curves\n","        fig, axes = plt.subplots(3, 2, figsize=(12, 14))\n","        fig.suptitle('Training Progress Over Epochs', fontsize=16, fontweight='bold')\n","\n","        # 1. Loss Curves (Train/Box/Cls/DFL)\n","        ax = axes[0, 0]\n","        if 'train/box_loss' in training_results.columns:\n","            ax.plot(training_results['epoch'], training_results['train/box_loss'],\n","                   label='Box Loss', color='#e74c3c', linewidth=2)\n","        if 'train/cls_loss' in training_results.columns:\n","            ax.plot(training_results['epoch'], training_results['train/cls_loss'],\n","                   label='Class Loss', color='#3498db', linewidth=2)\n","        if 'train/dfl_loss' in training_results.columns:\n","            ax.plot(training_results['epoch'], training_results['train/dfl_loss'],\n","                   label='DFL Loss', color='#f39c12', linewidth=2)\n","        ax.set_xlabel('Epoch', fontsize=10)\n","        ax.set_ylabel('Loss', fontsize=10)\n","        ax.set_title('Training Loss Components', fontsize=12, fontweight='bold')\n","        ax.legend(loc='best', fontsize=9)\n","        ax.grid(True, alpha=0.3)\n","\n","        # 2. Validation Loss Curves\n","        ax = axes[0, 1]\n","        if 'val/box_loss' in training_results.columns:\n","            ax.plot(training_results['epoch'], training_results['val/box_loss'],\n","                   label='Box Loss', color='#e74c3c', linewidth=2, linestyle='--')\n","        if 'val/cls_loss' in training_results.columns:\n","            ax.plot(training_results['epoch'], training_results['val/cls_loss'],\n","                   label='Class Loss', color='#3498db', linewidth=2, linestyle='--')\n","        if 'val/dfl_loss' in training_results.columns:\n","            ax.plot(training_results['epoch'], training_results['val/dfl_loss'],\n","                   label='DFL Loss', color='#f39c12', linewidth=2, linestyle='--')\n","        ax.set_xlabel('Epoch', fontsize=10)\n","        ax.set_ylabel('Loss', fontsize=10)\n","        ax.set_title('Validation Loss Components', fontsize=12, fontweight='bold')\n","        ax.legend(loc='best', fontsize=9)\n","        ax.grid(True, alpha=0.3)\n","\n","        # 3. mAP Metrics Over Epochs\n","        ax = axes[1, 0]\n","        if 'metrics/mAP50(B)' in training_results.columns:\n","            ax.plot(training_results['epoch'], training_results['metrics/mAP50(B)'],\n","                   label='mAP@0.5', color='#27ae60', linewidth=2.5, marker='o', markersize=4)\n","        if 'metrics/mAP50-95(B)' in training_results.columns:\n","            ax.plot(training_results['epoch'], training_results['metrics/mAP50-95(B)'],\n","                   label='mAP@0.5:0.95', color='#16a085', linewidth=2.5, marker='s', markersize=4)\n","        ax.set_xlabel('Epoch', fontsize=10)\n","        ax.set_ylabel('mAP', fontsize=10)\n","        ax.set_title('mAP Progression', fontsize=12, fontweight='bold')\n","        ax.legend(loc='best', fontsize=9)\n","        ax.grid(True, alpha=0.3)\n","        ax.set_ylim(0, 1)\n","\n","        # 4. Precision and Recall\n","        ax = axes[1, 1]\n","        if 'metrics/precision(B)' in training_results.columns:\n","            ax.plot(training_results['epoch'], training_results['metrics/precision(B)'],\n","                   label='Precision', color='#9b59b6', linewidth=2.5, marker='^', markersize=4)\n","        if 'metrics/recall(B)' in training_results.columns:\n","            ax.plot(training_results['epoch'], training_results['metrics/recall(B)'],\n","                   label='Recall', color='#e67e22', linewidth=2.5, marker='v', markersize=4)\n","        ax.set_xlabel('Epoch', fontsize=10)\n","        ax.set_ylabel('Score', fontsize=10)\n","        ax.set_title('Precision & Recall Progression', fontsize=12, fontweight='bold')\n","        ax.legend(loc='best', fontsize=9)\n","        ax.grid(True, alpha=0.3)\n","        ax.set_ylim(0, 1)\n","\n","        # 5. Learning Rate Schedule\n","        ax = axes[2, 0]\n","        if 'lr/pg0' in training_results.columns:\n","            ax.plot(training_results['epoch'], training_results['lr/pg0'],\n","                   label='LR Group 0', color='#34495e', linewidth=2)\n","        if 'lr/pg1' in training_results.columns:\n","            ax.plot(training_results['epoch'], training_results['lr/pg1'],\n","                   label='LR Group 1', color='#7f8c8d', linewidth=2)\n","        if 'lr/pg2' in training_results.columns:\n","            ax.plot(training_results['epoch'], training_results['lr/pg2'],\n","                   label='LR Group 2', color='#95a5a6', linewidth=2)\n","        ax.set_xlabel('Epoch', fontsize=10)\n","        ax.set_ylabel('Learning Rate', fontsize=10)\n","        ax.set_title('Learning Rate Schedule', fontsize=12, fontweight='bold')\n","        ax.legend(loc='best', fontsize=9)\n","        ax.grid(True, alpha=0.3)\n","\n","        # 6. Combined Loss (Train vs Val)\n","        ax = axes[2, 1]\n","        # Calculate total train loss if components available\n","        train_loss_cols = [col for col in training_results.columns if 'train/' in col and 'loss' in col]\n","        val_loss_cols = [col for col in training_results.columns if 'val/' in col and 'loss' in col]\n","\n","        if train_loss_cols:\n","            train_total = training_results[train_loss_cols].sum(axis=1)\n","            ax.plot(training_results['epoch'], train_total,\n","                   label='Total Train Loss', color='#c0392b', linewidth=2.5)\n","        if val_loss_cols:\n","            val_total = training_results[val_loss_cols].sum(axis=1)\n","            ax.plot(training_results['epoch'], val_total,\n","                   label='Total Val Loss', color='#2980b9', linewidth=2.5, linestyle='--')\n","        ax.set_xlabel('Epoch', fontsize=10)\n","        ax.set_ylabel('Total Loss', fontsize=10)\n","        ax.set_title('Total Loss: Train vs Validation', fontsize=12, fontweight='bold')\n","        ax.legend(loc='best', fontsize=9)\n","        ax.grid(True, alpha=0.3)\n","\n","        plt.tight_layout()\n","\n","        # Save training curves\n","        training_curves_img = TRAIN_DIR / 'report_training_curves.png'\n","        plt.savefig(training_curves_img, dpi=150, bbox_inches='tight')\n","        plt.close()\n","\n","        # Add to PDF\n","        story.append(Image(str(training_curves_img), width=6.5*inch, height=7.5*inch))\n","        story.append(Spacer(1, 12))\n","\n","        # Epoch-by-Epoch Summary Table (First 10, Middle 5, Last 10)\n","        story.append(PageBreak())\n","        story.append(Paragraph('Detailed Epoch Metrics', styles['Heading3']))\n","        story.append(Spacer(1, 6))\n","\n","        # Select representative epochs\n","        total_epochs = len(training_results)\n","        if total_epochs <= 25:\n","            selected_epochs = training_results\n","        else:\n","            # First 10, middle 5, last 10\n","            first_10 = training_results.head(10)\n","            middle_start = total_epochs // 2 - 2\n","            middle_5 = training_results.iloc[middle_start:middle_start+5]\n","            last_10 = training_results.tail(10)\n","            selected_epochs = pd.concat([first_10, middle_5, last_10])\n","\n","        # Build table with key metrics\n","        epoch_table_data = [['Epoch', 'Train Loss', 'Val Loss', 'mAP@0.5', 'mAP@0.5:0.95', 'Precision', 'Recall']]\n","\n","        for _, row in selected_epochs.iterrows():\n","            epoch_num = int(row['epoch']) if 'epoch' in row else '?'\n","\n","            # Calculate total losses\n","            train_loss = sum([row.get(col, 0) for col in train_loss_cols]) if train_loss_cols else 'N/A'\n","            val_loss = sum([row.get(col, 0) for col in val_loss_cols]) if val_loss_cols else 'N/A'\n","\n","            map50 = f\"{row.get('metrics/mAP50(B)', 0):.4f}\" if 'metrics/mAP50(B)' in row else 'N/A'\n","            map50_95 = f\"{row.get('metrics/mAP50-95(B)', 0):.4f}\" if 'metrics/mAP50-95(B)' in row else 'N/A'\n","            precision = f\"{row.get('metrics/precision(B)', 0):.4f}\" if 'metrics/precision(B)' in row else 'N/A'\n","            recall = f\"{row.get('metrics/recall(B)', 0):.4f}\" if 'metrics/recall(B)' in row else 'N/A'\n","\n","            epoch_table_data.append([\n","                str(epoch_num),\n","                f\"{train_loss:.4f}\" if isinstance(train_loss, (int, float)) else train_loss,\n","                f\"{val_loss:.4f}\" if isinstance(val_loss, (int, float)) else val_loss,\n","                map50,\n","                map50_95,\n","                precision,\n","                recall\n","            ])\n","\n","        epoch_table = Table(epoch_table_data, colWidths=[0.6*inch, 1*inch, 1*inch, 0.9*inch, 1.1*inch, 0.9*inch, 0.9*inch])\n","        epoch_table.setStyle(TableStyle([\n","            ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#8e44ad')),\n","            ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n","            ('FONTSIZE', (0,0), (-1,-1), 8),\n","            ('GRID', (0,0), (-1,-1), 0.5, rl_colors.black),\n","            ('FONTNAME', (0,0), (-1,0), 'Helvetica-Bold'),\n","            ('ALIGN', (0,0), (-1,-1), 'CENTER'),\n","        ]))\n","        story.append(epoch_table)\n","        story.append(Spacer(1, 12))\n","\n","        # Training Summary Statistics\n","        story.append(Paragraph('Training Statistics Summary', styles['Heading3']))\n","        story.append(Spacer(1, 6))\n","\n","        stats_data = [['Metric', 'Initial', 'Final', 'Best', 'Change']]\n","\n","        # mAP@0.5\n","        if 'metrics/mAP50(B)' in training_results.columns:\n","            map50_col = training_results['metrics/mAP50(B)']\n","            stats_data.append([\n","                'mAP@0.5',\n","                f\"{map50_col.iloc[0]:.4f}\",\n","                f\"{map50_col.iloc[-1]:.4f}\",\n","                f\"{map50_col.max():.4f}\",\n","                f\"+{map50_col.iloc[-1] - map50_col.iloc[0]:.4f}\"\n","            ])\n","\n","        # mAP@0.5:0.95\n","        if 'metrics/mAP50-95(B)' in training_results.columns:\n","            map50_95_col = training_results['metrics/mAP50-95(B)']\n","            stats_data.append([\n","                'mAP@0.5:0.95',\n","                f\"{map50_95_col.iloc[0]:.4f}\",\n","                f\"{map50_95_col.iloc[-1]:.4f}\",\n","                f\"{map50_95_col.max():.4f}\",\n","                f\"+{map50_95_col.iloc[-1] - map50_95_col.iloc[0]:.4f}\"\n","            ])\n","\n","        # Precision\n","        if 'metrics/precision(B)' in training_results.columns:\n","            prec_col = training_results['metrics/precision(B)']\n","            stats_data.append([\n","                'Precision',\n","                f\"{prec_col.iloc[0]:.4f}\",\n","                f\"{prec_col.iloc[-1]:.4f}\",\n","                f\"{prec_col.max():.4f}\",\n","                f\"+{prec_col.iloc[-1] - prec_col.iloc[0]:.4f}\"\n","            ])\n","\n","        # Recall\n","        if 'metrics/recall(B)' in training_results.columns:\n","            recall_col = training_results['metrics/recall(B)']\n","            stats_data.append([\n","                'Recall',\n","                f\"{recall_col.iloc[0]:.4f}\",\n","                f\"{recall_col.iloc[-1]:.4f}\",\n","                f\"{recall_col.max():.4f}\",\n","                f\"+{recall_col.iloc[-1] - recall_col.iloc[0]:.4f}\"\n","            ])\n","\n","        stats_table = Table(stats_data, colWidths=[1.5*inch, 1*inch, 1*inch, 1*inch, 1*inch])\n","        stats_table.setStyle(TableStyle([\n","            ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#2ecc71')),\n","            ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n","            ('GRID', (0,0), (-1,-1), 1, rl_colors.black),\n","            ('FONTNAME', (0,0), (-1,0), 'Helvetica-Bold'),\n","            ('ALIGN', (1,1), (-1,-1), 'CENTER'),\n","        ]))\n","        story.append(stats_table)\n","        story.append(Spacer(1, 12))\n","\n","    except Exception as e:\n","        story.append(Paragraph(f'Could not load detailed training results: {str(e)}', normal_style))\n","        story.append(Spacer(1, 12))\n","else:\n","    story.append(Paragraph('Training results file (results.csv) not found. Train the model to generate detailed metrics.', normal_style))\n","    story.append(Spacer(1, 12))\n","\n","# --- Final Model Performance ---\n","if 'final_metrics' in globals():\n","    story.append(PageBreak())\n","    story.append(Paragraph('Final Model Performance', heading_style))\n","\n","    perf_data = [\n","        ['Metric', 'Value'],\n","        ['mAP@0.5', f\"{final_metrics['map50']:.4f}\"],\n","        ['mAP@0.5:0.95', f\"{final_metrics['map50_95']:.4f}\"],\n","        ['Precision', f\"{final_metrics['precision']:.4f}\"],\n","        ['Recall', f\"{final_metrics['recall']:.4f}\"],\n","    ]\n","    perf_table = Table(perf_data, colWidths=[3*inch, 3*inch])\n","    perf_table.setStyle(TableStyle([\n","        ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#27ae60')),\n","        ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n","        ('GRID', (0,0), (-1,-1), 1, rl_colors.black),\n","    ]))\n","    story.append(perf_table)\n","    story.append(Spacer(1, 12))\n","\n","# --- Test Set Validation Results ---\n","if 'result' in globals() and 'metrics' in result:\n","    story.append(PageBreak())\n","    story.append(Paragraph('Test Set Validation Results', heading_style))\n","    story.append(Spacer(1, 6))\n","\n","    # Test metrics summary\n","    test_metrics = result['metrics']\n","    test_overall = test_metrics['overall']\n","    test_yolo = test_metrics['yolo_metrics']\n","    test_model_info = result['model_info']\n","\n","    # Model Architecture and Performance Summary\n","    story.append(Paragraph('Model Architecture & Performance', styles['Heading3']))\n","    model_arch_data = [\n","        ['Metric', 'Value'],\n","        ['Model Name', finetuned_model_name],\n","        ['Parameters (M)', f\"{test_model_info.get('params', 0) / 1e6:.2f}\"],\n","        ['Model Size (MB)', f\"{test_model_info.get('size(MB)', 0):.2f}\"],\n","        ['FLOPs (G)', f\"{test_model_info.get('FLOPs(G)', 0):.2f}\"],\n","        ['Layers', str(test_model_info.get('layers', 'N/A'))],\n","        ['Inference Speed (FPS)', f\"{test_metrics['fps']:.2f}\"],\n","        ['IoU Threshold', f\"{IOU_THRESHOLDS:.2f}\"],\n","    ]\n","    model_arch_table = Table(model_arch_data, colWidths=[2.5*inch, 3.5*inch])\n","    model_arch_table.setStyle(TableStyle([\n","        ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#34495e')),\n","        ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n","        ('GRID', (0,0), (-1,-1), 1, rl_colors.black),\n","        ('FONTNAME', (0,0), (-1,0), 'Helvetica-Bold'),\n","        ('ALIGN', (1,1), (-1,-1), 'CENTER'),\n","    ]))\n","    story.append(model_arch_table)\n","    story.append(Spacer(1, 12))\n","\n","    # Overall Performance Metrics\n","    story.append(Paragraph('Overall Performance Metrics on Test Set', styles['Heading3']))\n","    test_perf_data = [\n","        ['Metric', 'Confusion Matrix', 'YOLO Validation'],\n","        ['Precision', f\"{test_overall['precision']:.4f}\", f\"{test_yolo['precision']:.4f}\"],\n","        ['Recall', f\"{test_overall['recall']:.4f}\", f\"{test_yolo['recall']:.4f}\"],\n","        ['F1-Score', f\"{test_overall['f1']:.4f}\", 'N/A'],\n","        ['mAP@0.5 (Overall)', 'N/A', f\"{test_yolo['map50']:.4f}\"],\n","        ['mAP@0.5:0.95 (Overall)', 'N/A', f\"{test_yolo['map50_95']:.4f}\"],\n","    ]\n","    test_perf_table = Table(test_perf_data, colWidths=[2*inch, 2*inch, 2*inch])\n","    test_perf_table.setStyle(TableStyle([\n","        ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#e74c3c')),\n","        ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n","        ('GRID', (0,0), (-1,-1), 1, rl_colors.black),\n","        ('FONTNAME', (0,0), (-1,0), 'Helvetica-Bold'),\n","        ('ALIGN', (1,0), (-1,-1), 'CENTER'),\n","    ]))\n","    story.append(test_perf_table)\n","    story.append(Spacer(1, 12))\n","\n","    # Per-Class mAP@0.5 and Performance\n","    if 'df_metrics' in result and not result['df_metrics'].empty:\n","        story.append(PageBreak())\n","        story.append(Paragraph('Per-Class Performance Metrics', styles['Heading3']))\n","        story.append(Spacer(1, 6))\n","\n","        df_metrics = result['df_metrics']\n","\n","        # Per-class table with all metrics\n","        per_class_data = [['Class', 'Precision', 'Recall', 'F1-Score', 'mAP@0.5', 'TP', 'FP', 'FN']]\n","        for _, row in df_metrics.iterrows():\n","            per_class_data.append([\n","                str(row['Class']),\n","                f\"{row['Precision']:.4f}\",\n","                f\"{row['Recall']:.4f}\",\n","                f\"{row['F1-Score']:.4f}\",\n","                f\"{row['mAP@0.5']:.4f}\",\n","                str(int(row['TP'])),\n","                str(int(row['FP'])),\n","                str(int(row['FN']))\n","            ])\n","\n","        per_class_table = Table(per_class_data, colWidths=[1.2*inch, 0.8*inch, 0.7*inch, 0.8*inch, 0.8*inch, 0.5*inch, 0.5*inch, 0.5*inch])\n","        per_class_table.setStyle(TableStyle([\n","            ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#9b59b6')),\n","            ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n","            ('FONTSIZE', (0,0), (-1,-1), 8),\n","            ('GRID', (0,0), (-1,-1), 0.5, rl_colors.black),\n","            ('FONTNAME', (0,0), (-1,0), 'Helvetica-Bold'),\n","            ('ALIGN', (1,0), (-1,-1), 'CENTER'),\n","        ]))\n","        story.append(per_class_table)\n","        story.append(Spacer(1, 12))\n","\n","        # mAP@0.5 by Class visualization\n","        map50_by_class_img = result['figures'].get('map50_by_class')\n","        if map50_by_class_img and Path(map50_by_class_img).exists():\n","            try:\n","                story.append(Paragraph('mAP@0.5 Distribution by Class', styles['Heading4']))\n","                story.append(Spacer(1, 4))\n","                story.append(Image(str(map50_by_class_img), width=6.5*inch, height=4.5*inch))\n","                story.append(Spacer(1, 12))\n","            except Exception as img_error:\n","                story.append(Paragraph(f'Could not load mAP by class chart: {str(img_error)}', normal_style))\n","\n","    # IoU Information\n","    story.append(PageBreak())\n","    story.append(Paragraph('Intersection over Union (IoU) Analysis', styles['Heading3']))\n","    story.append(Spacer(1, 6))\n","\n","    iou_info_text = f\"\"\"\n","    <b>IoU Threshold Used:</b> {IOU_THRESHOLDS:.2f}<br/>\n","    <br/>\n","    IoU (Intersection over Union) measures the overlap between predicted and ground truth bounding boxes.\n","    A prediction is considered correct (True Positive) when IoU â‰¥ {IOU_THRESHOLDS:.2f}.<br/>\n","    <br/>\n","    <b>Per-Class IoU Performance:</b><br/>\n","    The confusion matrix and per-class metrics above show detection accuracy at IoU={IOU_THRESHOLDS:.2f} threshold.\n","    Each class's True Positives (TP) represent detections with IoU â‰¥ {IOU_THRESHOLDS:.2f}.\n","    \"\"\"\n","    story.append(Paragraph(iou_info_text, normal_style))\n","    story.append(Spacer(1, 12))\n","\n","    # Confusion Matrix\n","    story.append(PageBreak())\n","    story.append(Paragraph('Confusion Matrix (Test Set)', styles['Heading3']))\n","    story.append(Spacer(1, 6))\n","\n","    confusion_matrix_img = result['figures'].get('confusion_matrix')\n","    if confusion_matrix_img and Path(confusion_matrix_img).exists():\n","        try:\n","            with PILImage.open(confusion_matrix_img) as img:\n","                img_width, img_height = img.size\n","                aspect_ratio = img_height / img_width\n","                pdf_width = 6*inch\n","                pdf_height = pdf_width * aspect_ratio\n","                if pdf_height > 6*inch:\n","                    pdf_height = 6*inch\n","                    pdf_width = pdf_height / aspect_ratio\n","                story.append(Image(str(confusion_matrix_img), width=pdf_width, height=pdf_height))\n","                story.append(Spacer(1, 12))\n","        except Exception as img_error:\n","            story.append(Paragraph(f'Could not load confusion matrix: {str(img_error)}', normal_style))\n","    else:\n","        story.append(Paragraph('Confusion matrix image not available.', normal_style))\n","    story.append(Spacer(1, 12))\n","\n","    # Test Performance Curves - Only add section if curves exist\n","    pr_curve_img = result['figures'].get('pr_curve')\n","    f1_curve_img = result['figures'].get('f1_curve')\n","    overall_metrics_img = result['figures'].get('overall_metrics')\n","\n","    has_curves = (\n","        (pr_curve_img and Path(pr_curve_img).exists()) or\n","        (f1_curve_img and Path(f1_curve_img).exists()) or\n","        (overall_metrics_img and Path(overall_metrics_img).exists())\n","    )\n","\n","    if has_curves:\n","        story.append(PageBreak())\n","        story.append(Paragraph('Test Set Performance Curves', styles['Heading3']))\n","        story.append(Spacer(1, 6))\n","\n","        # PR Curve\n","        if pr_curve_img and Path(pr_curve_img).exists():\n","            try:\n","                story.append(Paragraph('Precision-Recall Curve', styles['Heading4']))\n","                story.append(Image(str(pr_curve_img), width=6*inch, height=4*inch))\n","                story.append(Spacer(1, 12))\n","            except Exception as img_error:\n","                story.append(Paragraph(f'Could not load PR curve: {str(img_error)}', normal_style))\n","\n","        # F1 Curve\n","        if f1_curve_img and Path(f1_curve_img).exists():\n","            try:\n","                story.append(Paragraph('F1-Score Curve', styles['Heading4']))\n","                story.append(Image(str(f1_curve_img), width=6*inch, height=4*inch))\n","                story.append(Spacer(1, 12))\n","            except Exception as img_error:\n","                story.append(Paragraph(f'Could not load F1 curve: {str(img_error)}', normal_style))\n","\n","        # Overall Metrics\n","        if overall_metrics_img and Path(overall_metrics_img).exists():\n","            try:\n","                story.append(Paragraph('Overall Metrics Visualization', styles['Heading4']))\n","                story.append(Image(str(overall_metrics_img), width=6.5*inch, height=5*inch))\n","                story.append(Spacer(1, 12))\n","            except Exception as img_error:\n","                story.append(Paragraph(f'Could not load overall metrics: {str(img_error)}', normal_style))\n","\n","    # Sample Comparison Images\n","    if 'comparison_data' in result and result['comparison_data']:\n","        story.append(PageBreak())\n","        story.append(Paragraph('Sample Predictions: Ground Truth vs Model Output', heading_style))\n","        story.append(Spacer(1, 6))\n","\n","        # Add up to 6 comparison images\n","        for idx, comp in enumerate(result['comparison_data'][:6], 1):\n","            comp_img_path = comp.get('comparison_image_path')\n","            if comp_img_path and Path(comp_img_path).exists():\n","                try:\n","                    # Add attributes info\n","                    attributes = comp.get('attributes', {})\n","                    attr_text = f\"Sample {idx} - Weather: {attributes.get('weather', 'unknown')}, Scene: {attributes.get('scene', 'unknown')}, Time: {attributes.get('timeofday', 'unknown')}\"\n","                    story.append(Paragraph(attr_text, normal_style))\n","                    story.append(Spacer(1, 4))\n","\n","                    # Add comparison image\n","                    with PILImage.open(comp_img_path) as img:\n","                        img_width, img_height = img.size\n","                        aspect_ratio = img_height / img_width\n","                        pdf_width = 6.5*inch\n","                        pdf_height = pdf_width * aspect_ratio\n","                        if pdf_height > 4*inch:\n","                            pdf_height = 4*inch\n","                            pdf_width = pdf_height / aspect_ratio\n","                        story.append(Image(str(comp_img_path), width=pdf_width, height=pdf_height))\n","\n","                    # Add object count info\n","                    gt_count = comp.get('gt_count', 0)\n","                    pred_count = comp.get('pred_count', 0)\n","                    count_text = f\"Ground Truth: {gt_count} objects | Predictions: {pred_count} objects\"\n","                    story.append(Paragraph(count_text, ParagraphStyle('Small', parent=normal_style, fontSize=8, textColor=rl_colors.grey)))\n","                    story.append(Spacer(1, 15))\n","\n","                    # Page break after every 2 comparisons\n","                    if idx % 2 == 0 and idx < len(result['comparison_data'][:6]):\n","                        story.append(PageBreak())\n","\n","                except Exception as img_error:\n","                    story.append(Paragraph(f'Could not load comparison {idx}: {str(img_error)}', normal_style))\n","                    story.append(Spacer(1, 12))\n","\n","elif 'results_summary' in globals() and len(results_summary) > 0 and results_summary[0].get('status') == 'ok':\n","    # Fallback: Show basic info from results_summary\n","    story.append(PageBreak())\n","    story.append(Paragraph('Test Set Validation Results', heading_style))\n","\n","    res = results_summary[0]\n","    fallback_data = [\n","        ['Metric', 'Value'],\n","        ['Model', res.get('model_name', 'N/A')],\n","        ['Precision (YOLO)', f\"{res.get('precision_yolo', 0):.4f}\"],\n","        ['Recall (YOLO)', f\"{res.get('recall_yolo', 0):.4f}\"],\n","        ['mAP@0.5', f\"{res.get('map50', 0):.4f}\"],\n","        ['mAP@0.5:0.95', f\"{res.get('map50_95', 0):.4f}\"],\n","        ['Parameters (M)', f\"{res.get('params_m', 0):.2f}\"],\n","        ['Size (MB)', f\"{res.get('size_mb', 0):.2f}\"],\n","        ['FPS', f\"{res.get('fps', 0):.2f}\"],\n","    ]\n","    fallback_table = Table(fallback_data, colWidths=[3*inch, 3*inch])\n","    fallback_table.setStyle(TableStyle([\n","        ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#95a5a6')),\n","        ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n","        ('GRID', (0,0), (-1,-1), 1, rl_colors.black),\n","    ]))\n","    story.append(fallback_table)\n","    story.append(Spacer(1, 12))\n","\n","    # Try to load images from run_dir if available\n","    if 'run_dir' in res:\n","        run_dir = Path(res['run_dir'])\n","\n","        # Try confusion matrix\n","        confusion_img = run_dir / 'confusion_matrix.png'\n","        if confusion_img.exists():\n","            try:\n","                story.append(PageBreak())\n","                story.append(Paragraph('Confusion Matrix', styles['Heading3']))\n","                story.append(Image(str(confusion_img), width=6*inch, height=5*inch))\n","                story.append(Spacer(1, 12))\n","            except:\n","                pass\n","\n","        # Try comparison images\n","        comparisons_dir = run_dir / 'sample_comparisons'\n","        if comparisons_dir.exists():\n","            comparison_imgs = sorted(comparisons_dir.glob('comparison_*.png'))[:4]\n","            if comparison_imgs:\n","                story.append(PageBreak())\n","                story.append(Paragraph('Sample Predictions', styles['Heading3']))\n","                for comp_img in comparison_imgs:\n","                    try:\n","                        story.append(Image(str(comp_img), width=6.5*inch, height=3.5*inch))\n","                        story.append(Spacer(1, 10))\n","                    except:\n","                        pass\n","\n","# --- Footer ---\n","story.append(Spacer(1, 20))\n","story.append(Paragraph('Generated by YOLO Training Notebook', ParagraphStyle('Footer', parent=styles['Normal'], alignment=TA_CENTER, textColor=rl_colors.grey)))\n","story.append(Paragraph('BDD100K Dataset - Computer Vision Project', ParagraphStyle('Footer2', parent=styles['Normal'], alignment=TA_CENTER, textColor=rl_colors.grey)))\n","\n","# Build PDF\n","try:\n","    doc.build(story)\n","    print(f'\\nâœ“ Comprehensive Training PDF generated: {pdf_training_report_path}')\n","except Exception as e:\n","    print(f'\\nâŒ Error generating PDF: {e}')\n","    import traceback\n","    traceback.print_exc()\n"]},{"cell_type":"markdown","id":"7d09278e","metadata":{"id":"7d09278e"},"source":["## 11. Final Summary"]},{"cell_type":"code","execution_count":21,"id":"9e9576f4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9e9576f4","executionInfo":{"status":"ok","timestamp":1764124447635,"user_tz":-180,"elapsed":48,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"249c6118-642d-453f-eb21-32aa2518977a"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\n","================================================================================\n","FINAL TRAINING COMPLETE!\n","================================================================================\n","\n","ğŸ“Š Project: yolov8m on bdd100k_yolo_limited\n","ğŸ“… Date: 2025-11-26 02:34:07\n","\n","ğŸ”¬ Tuning Run Used:\n","  Run Name: None\n","  Run Path: None\n","\n","ğŸ¯ Training Run:\n","  Run Name: yolov8m_train_20251125_202451\n","  Run Path: /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/tune_train/training/yolov8m_train_20251125_202451\n","  Epochs: 100\n","  Batch Size: 96\n","\n","ğŸ¯ Final Model Performance:\n","  mAP@0.5: 0.5554\n","  mAP@0.5:0.95: 0.3385\n","  Precision: 0.6322\n","  Recall: 0.5205\n","\n","ğŸ“ Generated Files:\n","\n","  ğŸ¯ Training Results (in yolov8m_train_20251125_202451):\n","    - training_log.json\n","    - weights/best.pt\n","    - weights/last.pt\n","    - results.csv\n","  ğŸ“„ Training PDF Report:\n","    - yolov8m_training_report.pdf\n","\n","  ğŸ¯ Final Model Package:\n","    - yolov8m_finetuned_20251126.pt\n","    - yolov8m_finetuned_20251126_metadata.json\n","    Location: /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/models/yolov8m_finetuned_20251126\n","\n","ğŸ“‚ All results saved to:\n","  Tuning: None\n","  Training: /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/tune_train/training/yolov8m_train_20251125_202451\n","  Final Model: /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/models/yolov8m_finetuned_20251126\n","\n","ğŸš€ Next Steps:\n","  1. Review training PDF report: /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/tune_train/training/yolov8m_train_20251125_202451/yolov8m_training_report.pdf\n","  2. Review training plots and metrics in: /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/tune_train/training/yolov8m_train_20251125_202451\n","  3. Use final model for inference: /content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo/models/yolov8m_finetuned_20251126/yolov8m_finetuned_20251126.pt\n","  4. Evaluate on test set using yolo_test scripts\n","  5. Consider fine-tuning with different datasets or model sizes\n","\n","ğŸ“ To Resume Training:\n","  Set RESUME_TRAINING_RUN_NAME = \"yolov8m_train_20251125_202451\"\n","  Then re-run this notebook\n","\n","================================================================================\n","SUCCESS! âœ“\n","================================================================================\n"]}],"source":["# FINAL SUMMARY\n","# ============================================================================\n","\n","print('\\n\\n')\n","print('=' * 80)\n","print('FINAL TRAINING COMPLETE!')\n","print('=' * 80)\n","\n","print(f'\\nğŸ“Š Project: {MODEL_NAME} on {YOLO_DATASET_ROOT.name}')\n","print(f'ğŸ“… Date: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n","\n","# Tuning Summary\n","print(f'\\nğŸ”¬ Tuning Run Used:')\n","print(f'  Run Name: {TUNING_RUN_NAME}')\n","print(f'  Run Path: {TUNE_DIR}')\n","\n","if not USE_DEFAULT_CONFIG and tuning_metadata_path.exists():\n","    print(f'  Total Trials: {tuning_metadata.get(\"total_trials\", \"N/A\")}')\n","    print(f'  Completed Trials: {tuning_metadata.get(\"completed_trials\", \"N/A\")}')\n","    print(f'  Best Trial: {tuning_metadata.get(\"best_trial\", \"N/A\")}')\n","    print(f'  Best Trial mAP@0.5: {tuning_metadata.get(\"best_map50\", 0):.4f}')\n","    if 'optimization_duration' in tuning_metadata:\n","        print(f'  Tuning Duration: {tuning_metadata[\"optimization_duration\"]}')\n","\n","# Training Summary\n","print(f'\\nğŸ¯ Training Run:')\n","print(f'  Run Name: {RUN_NAME_TRAINING}')\n","print(f'  Run Path: {TRAIN_DIR}')\n","print(f'  Epochs: {EPOCHS_FINAL_TRAINING}')\n","print(f'  Batch Size: {BATCH_SIZE}')\n","\n","if 'final_metrics' in globals():\n","    print(f'\\nğŸ¯ Final Model Performance:')\n","    print(f'  mAP@0.5: {final_metrics[\"map50\"]:.4f}')\n","    print(f'  mAP@0.5:0.95: {final_metrics[\"map50_95\"]:.4f}')\n","    print(f'  Precision: {final_metrics[\"precision\"]:.4f}')\n","    print(f'  Recall: {final_metrics[\"recall\"]:.4f}')\n","\n","    # Show improvement if available\n","    if not USE_DEFAULT_CONFIG and tuning_metadata_path.exists():\n","        tuning_best_map = tuning_metadata.get('best_map50', 0)\n","        if tuning_best_map > 0:\n","            improvement = final_metrics['map50'] - tuning_best_map\n","            print(f'\\nğŸ“ˆ Improvement vs Tuning:')\n","            print(f'  Tuning Best: {tuning_best_map:.4f}')\n","            print(f'  Training Final: {final_metrics[\"map50\"]:.4f}')\n","            print(f'  Improvement: {improvement:+.4f} ({improvement/tuning_best_map*100:+.2f}%)')\n","\n","print(f'\\nğŸ“ Generated Files:')\n","if not USE_DEFAULT_CONFIG:\n","    print(f'\\n  ğŸ“Š Tuning Results (in {TUNE_DIR.name}):')\n","    print(f'    - best_hyperparameters.json')\n","    print(f'    - best_hparams.yaml')\n","    print(f'    - checkpoint_log.json')\n","    print(f'    - optuna_study.pkl')\n","\n","print(f'\\n  ğŸ¯ Training Results (in {TRAIN_DIR.name}):')\n","print(f'    - training_log.json')\n","print(f'    - weights/best.pt')\n","print(f'    - weights/last.pt')\n","print(f'    - results.csv')\n","print(f'  ğŸ“„ Training PDF Report:')\n","print(f'    - {MODEL_NAME}_training_report.pdf')\n","\n","if 'final_model_path' in globals():\n","    print(f'\\n  ğŸ¯ Final Model Package:')\n","    print(f'    - {final_model_path.name}')\n","    print(f'    - {metadata_path.name}')\n","    print(f'    Location: {model_save_dir}')\n","\n","print(f'\\nğŸ“‚ All results saved to:')\n","print(f'  Tuning: {TUNE_DIR}')\n","print(f'  Training: {TRAIN_DIR}')\n","if 'model_save_dir' in globals():\n","    print(f'  Final Model: {model_save_dir}')\n","\n","print(f'\\nğŸš€ Next Steps:')\n","print(f'  1. Review training PDF report: {TRAIN_DIR / f\"{MODEL_NAME}_training_report.pdf\"}')\n","print(f'  2. Review training plots and metrics in: {TRAIN_DIR}')\n","if 'final_model_path' in globals():\n","    print(f'  3. Use final model for inference: {final_model_path}')\n","    print(f'  4. Evaluate on test set using yolo_test scripts')\n","else:\n","    print(f'  3. Complete training to generate final model')\n","print(f'  5. Consider fine-tuning with different datasets or model sizes')\n","\n","print('\\nğŸ“ To Resume Training:')\n","print(f'  Set RESUME_TRAINING_RUN_NAME = \"{RUN_NAME_TRAINING}\"')\n","print(f'  Then re-run this notebook')\n","\n","print('\\n' + '=' * 80)\n","print('SUCCESS! âœ“')\n","print('=' * 80)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"colab":{"provenance":[],"gpuType":"A100"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}