{"cells":[{"cell_type":"markdown","id":"8b26f5d6","metadata":{"id":"8b26f5d6"},"source":["# YOLO Hyperparameter Tuning\n","\n","- Support for YOLOv8, YOLOv9, YOLOv10, YOLO11, YOLO12"]},{"cell_type":"code","execution_count":6,"id":"f68c7bbf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f68c7bbf","executionInfo":{"status":"ok","timestamp":1764322617367,"user_tz":-180,"elapsed":7317,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"3a2d4f01-b48c-48e6-bdf5-f77f47d413ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/Drive\n","‚úì W&B API key loaded from Colab secrets\n"]}],"source":["# Base directories\n","# Detect environment: Colab or local\n","\n","import os\n","from pathlib import Path\n","\n","\n","IS_COLAB = 'COLAB_GPU' in os.environ or os.path.exists('/content')\n","\n","USE_WANDB = True  # Set to False to disable W&B logging\n","\n","\n","\n","if IS_COLAB:\n","    #Mount Google Drive if not already mounted\n","    from google.colab import drive\n","    drive.mount('/content/Drive', force_remount=True)\n","    # Running in Google Colab\n","    BASE_DIR = Path('/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo')\n","\n","    # Configure W&B API key\n","    if USE_WANDB:\n","        # In Colab, get API key from secrets\n","        from google.colab import userdata\n","        wandb_api_key = userdata.get('wandb_api_key')\n","        os.environ['WANDB_API_KEY'] = wandb_api_key\n","        print('‚úì W&B API key loaded from Colab secrets')\n","\n","    DATASET_BASE_DIR = Path('/computer_vision_yolo')\n","\n","else:\n","    # Running locally\n","    BASE_DIR = Path.cwd().parent\n","    if USE_WANDB:\n","        print('‚úì Running locally - W&B will use existing login or prompt')\n","\n","    DATASET_BASE_DIR = Path.cwd().parent\n"]},{"cell_type":"code","execution_count":7,"id":"7c504221","metadata":{"id":"7c504221","executionInfo":{"status":"ok","timestamp":1764322617370,"user_tz":-180,"elapsed":1,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}}},"outputs":[],"source":["# !cd /content/Drive/MyDrive/ksu_yolo_tuning_2025 && git clone https://github.com/m3mahdy/computer_vision_yolo"]},{"cell_type":"code","execution_count":8,"id":"fde7425c","metadata":{"id":"fde7425c","executionInfo":{"status":"ok","timestamp":1764322617372,"user_tz":-180,"elapsed":1,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}}},"outputs":[],"source":["# ! cd {BASE_DIR} && pip install -r requirements.txt --quiet"]},{"cell_type":"code","execution_count":9,"id":"92da27e0","metadata":{"id":"92da27e0","executionInfo":{"status":"ok","timestamp":1764322617386,"user_tz":-180,"elapsed":12,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}}},"outputs":[],"source":["# limited dataset\n","# !mkdir {DATASET_BASE_DIR}\n","# !cd {BASE_DIR}/dataset && cp 8_download_extract_other_datasets.py {DATASET_BASE_DIR} && cd {DATASET_BASE_DIR} && python 8_download_extract_other_datasets.py\n"]},{"cell_type":"markdown","id":"109394c4","metadata":{"id":"109394c4"},"source":["## 1. Import Required Libraries"]},{"cell_type":"code","execution_count":10,"id":"fc6f98f1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fc6f98f1","executionInfo":{"status":"ok","timestamp":1764322624985,"user_tz":-180,"elapsed":7593,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"ca43ef0f-cab7-49ff-b1a2-207e0e76aea3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","‚úì Libraries imported successfully\n","‚úì Device: cuda\n","  GPU: NVIDIA A100-SXM4-40GB\n","  CUDA Version: 12.6\n","  Available Memory: 42.47 GB\n"]}],"source":["# Install required libraries (uncomment if running in Colab)\n","# !pip install -q ultralytics optuna plotly kaleido wandb pyyaml\n","\n","import os\n","import sys\n","import gc\n","import yaml\n","import json\n","import torch\n","import shutil\n","import warnings\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from pathlib import Path\n","from datetime import datetime\n","from tqdm import tqdm\n","import pickle\n","import platform\n","import psutil\n","\n","import wandb\n","\n","# YOLO and Optuna imports\n","from ultralytics import YOLO\n","import optuna\n","from optuna.visualization import plot_optimization_history, plot_param_importances, plot_slice\n","\n","# ReportLab imports for PDF generation\n","from reportlab.lib.pagesizes import A4\n","from reportlab.lib import colors as rl_colors\n","from reportlab.lib.units import inch\n","from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, Image, PageBreak\n","from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n","from reportlab.lib.enums import TA_CENTER, TA_LEFT\n","from PIL import Image as PILImage\n","\n","warnings.filterwarnings('ignore')\n","\n","# Configure matplotlib for notebook display\n","%matplotlib inline\n","sns.set_style('whitegrid')\n","plt.rcParams['figure.figsize'] = (15, 10)\n","\n","# Check GPU availability\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(f'‚úì Libraries imported successfully')\n","print(f'‚úì Device: {device}')\n","if device == 'cuda':\n","    print(f'  GPU: {torch.cuda.get_device_name(0)}')\n","    print(f'  CUDA Version: {torch.version.cuda}')\n","    print(f'  Available Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')"]},{"cell_type":"markdown","id":"2eda31f6","metadata":{"id":"2eda31f6"},"source":["## 2. Constants and Enums"]},{"cell_type":"code","execution_count":11,"id":"2031059f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2031059f","executionInfo":{"status":"ok","timestamp":1764322625000,"user_tz":-180,"elapsed":7,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"b03fa214-afe9-49f1-cd59-6af9b73545b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Constants and enums defined\n"]}],"source":["# ============================================================================\n","# CONSTANTS AND ENUMS\n","# ============================================================================\n","\n","class TrialStatus:\n","    \"\"\"Constants for trial execution status\"\"\"\n","    COMPLETED = \"completed\"\n","    FAILED = \"failed\"\n","    PRUNED = \"pruned\"\n","    RUNNING = \"running\"\n","\n","class DatasetSplit:\n","    \"\"\"Constants for dataset split names\"\"\"\n","    TRAIN = \"train\"\n","    VAL = \"val\"\n","    TEST = \"test\"\n","\n","class ModelConfig:\n","    \"\"\"Default model training configuration constants\"\"\"\n","    # Training workers\n","    DEFAULT_WORKERS = 8  # Number of data loading workers\n","\n","    # Early stopping and checkpointing\n","    DEFAULT_PATIENCE = 20  # Epochs to wait before early stopping\n","\n","    # Augmentation timing\n","    CLOSE_MOSAIC_EPOCHS = 10  # Disable mosaic augmentation in last N epochs\n","\n","print('‚úì Constants and enums defined')"]},{"cell_type":"markdown","id":"2659c792","metadata":{"id":"2659c792"},"source":["## 3. Configuration"]},{"cell_type":"code","execution_count":12,"id":"d163f0be","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d163f0be","executionInfo":{"status":"ok","timestamp":1764322626274,"user_tz":-180,"elapsed":1264,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"55cd8503-4529-443b-c324-1ad0b8524263"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üîÑ RESUME MODE: Will attempt to resume run \"yolov8m_finetuned_1_tune_20251127_230340\"\n","================================================================================\n","CONFIGURATION SUMMARY\n","================================================================================\n","Environment: Google Colab\n","Base Directory: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo\n","Model: yolov8m_finetuned_1\n","Dataset: bdd100k_yolo_tuning\n","Data YAML: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml\n","  Dataset path in YAML: /computer_vision_yolo/bdd100k_yolo_tuning\n","Classes: 10\n","Class Names: {0: 'person', 1: 'rider', 2: 'car', 3: 'truck', 4: 'bus', 5: 'train', 6: 'motor', 7: 'bike', 8: 'traffic light', 9: 'traffic sign'}\n","Device: cuda\n","Optimization Trials: 40\n","Epochs per Trial: 8\n","Batch Size: 96\n","Timeout: 24 hours\n","Tuning Directory: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340\n","W&B Logging: Enabled\n","  Tuning Project: yolo-bdd100k_yolo_tuning-tuning\n","================================================================================\n"]}],"source":["# CONFIGURATION\n","# ============================================================================\n","\n","\n","# Model Selection - Choose one of the following:\n","MODEL_NAME = \"yolov8m_finetuned_1\"\n","\n","#yolov10n is for testing purpose only\n","#Mahdy will work yolov8m\n","\n","\n","# Selected models, to choose from, based on the performance and size:\n","# YOLOv8:  'yolov8s', 'yolov8m'\n","\n","# YOLOv10: 'yolov10s', 'yolov10m'\n","\n","# YOLO12: 'yolo12s'\n","\n","# Directory structure\n","MODELS_DIR = BASE_DIR / 'models' / MODEL_NAME\n","TMP_DIR = BASE_DIR / 'tmp' / MODEL_NAME\n","\n","# Dataset Selection\n","# Option 1: Full dataset (~100k images) - for final optimization: \"bdd100k_yolo\"\n","# Option 2: Limited dataset (representative samples) - for quick tuning: \"bdd100k_yolo_limited\"\n","dataset_name = 'bdd100k_yolo_tuning'\n","\n","\n","YOLO_DATASET_ROOT = DATASET_BASE_DIR / dataset_name\n","\n","# data.yaml path\n","DATA_YAML_PATH = YOLO_DATASET_ROOT / 'data.yaml'\n","\n","# Verify dataset exists\n","if not DATA_YAML_PATH.exists():\n","    raise FileNotFoundError(\n","        f\"Dataset not found: {DATA_YAML_PATH}\\n\"\n","        f\"Please prepare the dataset first using process_bdd100k_to_yolo_dataset.py\"\n","    )\n","\n","# Update data.yaml path field for Colab compatibility\n","with open(DATA_YAML_PATH, 'r') as yaml_file:\n","    data_config = yaml.safe_load(yaml_file)\n","\n","# Validate required keys in data.yaml\n","required_yaml_keys = ['nc', 'names', 'path']\n","missing_keys = [key for key in required_yaml_keys if key not in data_config]\n","if missing_keys:\n","    raise ValueError(f\"Missing required keys in data.yaml: {missing_keys}\")\n","\n","# Update the 'path' field to use BASE_DIR\n","data_config['path'] = str(YOLO_DATASET_ROOT)\n","\n","# Create a temporary data.yaml with corrected paths\n","temp_data_yaml = TMP_DIR / 'data.yaml'\n","TMP_DIR.mkdir(parents=True, exist_ok=True)\n","with open(temp_data_yaml, 'w') as yaml_output_file:\n","    yaml.dump(data_config, yaml_output_file, default_flow_style=False, sort_keys=False)\n","\n","# Use the temporary data.yaml for training\n","DATA_YAML_PATH = temp_data_yaml\n","\n","# Optimization Configuration\n","N_TRIALS = 40  # Number of optimization trials = 50‚Äì70 trials\n","TIMEOUT_HOURS = 24  # Maximum time for optimization (None for no limit)\n","N_STARTUP_TRIALS = 10  # Random exploration trials before optimization =10\n","EPOCHS_PER_TRIAL = 8  # Training epochs per trial = 50\n","BATCH_SIZE = 96  # Batch size for training\n","# for T4 GPU:\n","# 64 for 10n, 1 epoch 30 min\n","# 32 for 8m, 1 epoch 45 min\n","\n","# for A100 GPU:\n","# 64 for 10m 1 epoch 11 min, 5 epochs completed in 0.797 hours.\n","# 96 for 8m , 1 epoch 10 min, 5 epochs completed in 0.866 hours.\n","\n","\n","\n","# Weights & Biases (optional)\n","USE_WANDB = True  # Set to True to enable W&B logging\n","WANDB_PROJECT_TUNING = f\"yolo-{YOLO_DATASET_ROOT.name}-tuning\"\n","\n","# ============================================================================\n","# RUN NAME CONFIGURATION - RESUME OR CREATE NEW\n","# ============================================================================\n","# To RESUME an existing run: Set RESUME_RUN_NAME to the run directory name\n","# To START NEW run: Leave RESUME_RUN_NAME as None or empty string\n","#\n","# Example to resume: RESUME_RUN_NAME = \"yolov10n_tune_20251125_143022\"\n","# ============================================================================\n","\n","RESUME_RUN_NAME = \"yolov8m_finetuned_1_tune_20251127_230340\"  # Set to run name to resume, or None to create new run\n","\n","if RESUME_RUN_NAME:\n","    # Resume existing run\n","    RUN_NAME_TUNING = RESUME_RUN_NAME\n","    print(f'\\nüîÑ RESUME MODE: Will attempt to resume run \"{RESUME_RUN_NAME}\"')\n","else:\n","    # Create new run with timestamp\n","    RUN_TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')\n","    RUN_NAME_TUNING = f'{MODEL_NAME}_tune_{RUN_TIMESTAMP}'\n","    print(f'\\nüÜï NEW RUN MODE: Creating new run \"{RUN_NAME_TUNING}\"')\n","\n","RUN_NAME_TRAINING = f'{MODEL_NAME}_train_{RUN_TIMESTAMP if not RESUME_RUN_NAME else RESUME_RUN_NAME}'\n","\n","# Create directories for tuning within tune_train folder\n","# All paths are absolute to ensure consistency across environments (local/Colab)\n","TUNE_TRAIN_BASE = BASE_DIR / 'tune_train'\n","TUNE_DIR = TUNE_TRAIN_BASE / 'tune' / RUN_NAME_TUNING\n","TUNE_DIR.mkdir(parents=True, exist_ok=True)\n","MODELS_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Keep RUN_DIR for backward compatibility (points to tuning)\n","RUN_DIR = TUNE_DIR\n","# Keep RUN_DIR for backward compatibility (points to tuning)\n","# Read dataset configuration\n","NUM_CLASSES = data_config['nc']\n","CLASS_NAMES = {i: name for i, name in enumerate(data_config['names'])}\n","CLASS_NAME_TO_ID = {name: i for i, name in enumerate(data_config['names'])}\n","\n","print('=' * 80)\n","print('CONFIGURATION SUMMARY')\n","print('=' * 80)\n","print(f'Environment: {\"Google Colab\" if \"COLAB_GPU\" in os.environ or os.path.exists(\"/content\") else \"Local\"}')\n","print(f'Base Directory: {BASE_DIR}')\n","print(f'Model: {MODEL_NAME}')\n","print(f'Dataset: {YOLO_DATASET_ROOT.name}')\n","print(f'Data YAML: {DATA_YAML_PATH}')\n","print(f'  Dataset path in YAML: {data_config[\"path\"]}')\n","print(f'Classes: {NUM_CLASSES}')\n","print(f'Class Names: {CLASS_NAMES}')\n","print(f'Device: {device}')\n","print(f'Optimization Trials: {N_TRIALS}')\n","print(f'Epochs per Trial: {EPOCHS_PER_TRIAL}')\n","print(f'Batch Size: {BATCH_SIZE}')\n","print(f'Timeout: {TIMEOUT_HOURS} hours' if TIMEOUT_HOURS else 'No timeout')\n","print(f'Tuning Directory: {TUNE_DIR}')\n","if USE_WANDB:\n","    print(f'W&B Logging: Enabled')\n","    print(f'  Tuning Project: {WANDB_PROJECT_TUNING}')\n","else:\n","    print(f'W&B Logging: Disabled')\n","print('=' * 80)"]},{"cell_type":"markdown","id":"0af35c3f","metadata":{"id":"0af35c3f"},"source":["## 4. Load Base YOLO Model"]},{"cell_type":"code","execution_count":13,"id":"3deeda88","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3deeda88","executionInfo":{"status":"ok","timestamp":1764322632116,"user_tz":-180,"elapsed":5840,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"8dc80443-ae60-4a44-81ba-3037f2c67088"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Model loaded from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt\n","Model summary: 169 layers, 25,862,110 parameters, 0 gradients, 79.1 GFLOPs\n","\n","üìä Model Information:\n","  Model: yolov8m_finetuned_1\n","  Classes in model: 10\n","  Task: detect\n","  Parameters: 25.9M\n","  Model Size: 0.0 MB\n","  FLOPs (640x640): 79.09 GFLOPs\n"]}],"source":["# Load YOLO model with automatic download\n","model_path = MODELS_DIR / f'{MODEL_NAME}.pt'\n","\n","if not model_path.exists():\n","    print(f'Model not found at {model_path}')\n","    print(f'Downloading {MODEL_NAME} ...')\n","\n","    try:\n","        # Download model - ensure .pt extension for ultralytics\n","        # Ultralytics expects model names with .pt extension for download\n","        if not MODEL_NAME.endswith('.pt'):\n","            model_name_for_download = MODEL_NAME + '.pt'\n","        else:\n","            model_name_for_download = MODEL_NAME\n","\n","        print(f'  Requesting model: {model_name_for_download}')\n","        model = YOLO(model_name_for_download)\n","\n","        # Create models directory\n","        MODELS_DIR.mkdir(parents=True, exist_ok=True)\n","\n","        # Save model to our directory using export/save\n","        try:\n","            # Try to save using the model's save method\n","            if hasattr(model, 'save'):\n","                model.save(str(model_path))\n","                print(f'‚úì Model downloaded and saved to {model_path}')\n","                print(f'  Size: {model_path.stat().st_size / (1024*1024):.1f} MB')\n","            else:\n","                # Fallback: copy from cache\n","                cache_patterns = [\n","                    str(Path.home() / '.cache' / 'ultralytics' / '**' / f'{MODEL_NAME}.pt'),\n","                    str(Path.home() / '.config' / 'Ultralytics' / '**' / f'{MODEL_NAME}.pt'),\n","                ]\n","\n","                model_found = False\n","                for pattern in cache_patterns:\n","                    cache_paths = glob.glob(pattern, recursive=True)\n","                    if cache_paths:\n","                        shutil.copy(cache_paths[0], model_path)\n","                        print(f'‚úì Model downloaded and saved to {model_path}')\n","                        print(f'  Size: {model_path.stat().st_size / (1024*1024):.1f} MB')\n","                        model_found = True\n","                        break\n","\n","                if not model_found:\n","                    print(f'‚úì Model loaded from ultralytics cache')\n","                    print(f'  Note: Model is in cache, not copied to {model_path}')\n","                    print(f'  This is normal and the model will work correctly')\n","        except Exception as save_error:\n","            print(f'‚ö†Ô∏è  Could not save model to custom location: {save_error}')\n","            print(f'‚úì Model loaded successfully from ultralytics cache')\n","\n","    except Exception as download_error:\n","        print(f'\\n‚ùå Error downloading model: {download_error}')\n","        raise\n","else:\n","    model = YOLO(str(model_path))\n","    print(f'‚úì Model loaded from {model_path}')\n","\n","# Get model information\n","model_info_dict = {}\n","model_info_result = model.info()\n","model_info_keys = [\"layers\", \"params\", \"size(MB)\", \"FLOPs(G)\"]\n","\n","for info_key, info_value in zip(model_info_keys, model_info_result):\n","    model_info_dict[info_key] = info_value\n","\n","model_params = model_info_dict.get(\"params\", 0)\n","model_size_mb = model_info_dict.get(\"size(MB)\", 0)\n","flops_gflops = model_info_dict.get(\"FLOPs(G)\", 0)\n","\n","\n","print(f'\\nüìä Model Information:')\n","print(f'  Model: {MODEL_NAME}')\n","print(f'  Classes in model: {len(model.names)}')\n","print(f'  Task: {model.task}')\n","print(f'  Parameters: {model_params / 1e6:.1f}M')\n","print(f'  Model Size: {model_size_mb:.1f} MB')\n","print(f'  FLOPs (640x640): {flops_gflops:.2f} GFLOPs')"]},{"cell_type":"markdown","id":"5fe0b94d","metadata":{"id":"5fe0b94d"},"source":["## 5. Verify Dataset Structure"]},{"cell_type":"code","execution_count":14,"id":"71b15401","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"71b15401","executionInfo":{"status":"ok","timestamp":1764322632424,"user_tz":-180,"elapsed":305,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"143aa8c3-a7e6-4727-9e6f-89371d00be7b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Verifying YOLO dataset structure...\n","\n","üìÅ Dataset Root: /computer_vision_yolo/bdd100k_yolo_tuning\n","  ‚úì train:  16391 images,  16391 labels\n","  ‚úì val  :  10000 images,  10000 labels\n","  ‚ö†Ô∏è  test : Directory not found\n","\n","üìÑ Configuration: /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml\n","  Classes: 10\n","  Names: {0: 'person', 1: 'rider', 2: 'car', 3: 'truck', 4: 'bus', 5: 'train', 6: 'motor', 7: 'bike', 8: 'traffic light', 9: 'traffic sign'}\n","\n","‚úì Dataset verified: 26,391 total images\n","‚úì Ready for hyperparameter optimization\n"]}],"source":["# ============================================================================\n","# VERIFY DATASET STRUCTURE\n","# ============================================================================\n","\n","print('Verifying YOLO dataset structure...')\n","print(f'\\nüìÅ Dataset Root: {YOLO_DATASET_ROOT}')\n","\n","# Check all splits using constants\n","dataset_stats = {}\n","for split in [DatasetSplit.TRAIN, DatasetSplit.VAL, DatasetSplit.TEST]:\n","    images_dir = YOLO_DATASET_ROOT / 'images' / split\n","    labels_dir = YOLO_DATASET_ROOT / 'labels' / split\n","\n","    if images_dir.exists() and labels_dir.exists():\n","        num_images = len(list(images_dir.glob('*.jpg'))) + len(list(images_dir.glob('*.png')))\n","        num_labels = len(list(labels_dir.glob('*.txt')))\n","        dataset_stats[split] = {'images': num_images, 'labels': num_labels}\n","        print(f'  ‚úì {split:5s}: {num_images:6d} images, {num_labels:6d} labels')\n","    else:\n","        print(f'  ‚ö†Ô∏è  {split:5s}: Directory not found')\n","        dataset_stats[split] = {'images': 0, 'labels': 0}\n","\n","print(f'\\nüìÑ Configuration: {DATA_YAML_PATH}')\n","print(f'  Classes: {NUM_CLASSES}')\n","print(f'  Names: {CLASS_NAMES}')\n","\n","total_images = sum(stats['images'] for stats in dataset_stats.values())\n","print(f'\\n‚úì Dataset verified: {total_images:,} total images')\n","print('‚úì Ready for hyperparameter optimization')"]},{"cell_type":"markdown","id":"3cf76930","metadata":{"id":"3cf76930"},"source":["## 6. Define Hyperparameter Search Space"]},{"cell_type":"code","execution_count":15,"id":"06d1ae35","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"06d1ae35","executionInfo":{"status":"ok","timestamp":1764322632733,"user_tz":-180,"elapsed":306,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"421f73ae-8331-4761-997f-adb90ba2a4e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Hyperparameter search space defined\n","\n","üìä Focused Search Space Summary:\n","  Strategy: Tune ONLY critical high-impact parameters\n","  üéØ Tuned Parameters (11):\n","    - Image Size (imgsz): 640, 800, 1024\n","    - Batch Size: Dynamic (96 for 640, 64 for 800+)\n","    - Optimizer: SGD, Adam, AdamW\n","    - Learning Rate (lr0): 1e-4 to 5e-3\n","    - Momentum: 0.85 to 0.97\n","    - Weight Decay: 1e-5 to 1e-3\n","    - Warmup Epochs: 0 to 3\n","    - Warmup Momentum: 0.5 to 0.95\n","    - Warmup Bias LR: 0.0 to 0.1\n","    - Mosaic: 0.5 to 1.0\n","    - Mixup: 0.0 to 0.2\n","  ‚öôÔ∏è  Fixed Parameters:\n","    - Epochs: 8\n","    - Device: cuda\n","  üìå Using YOLO defaults for: HSV augmentation, spatial transforms, loss weights\n"]}],"source":["# ============================================================================\n","# DEFINE FOCUSED HYPERPARAMETER SEARCH SPACE\n","# ============================================================================\n","\n","def define_hyperparameters(trial):\n","    \"\"\"\n","    Focused hyperparameter search for YOLO - only critical high-impact parameters.\n","\n","    Args:\n","        trial: Optuna trial object for sampling hyperparameters\n","\n","    Returns:\n","        dict: Dictionary of hyperparameters for YOLO training\n","\n","    Tuning Strategy:\n","    - Focus ONLY on parameters with proven high impact on performance\n","    - Use YOLO defaults for well-calibrated parameters (HSV, loss weights)\n","    - Reduces search space for faster convergence and better results\n","\n","    Critical Parameters Tuned:\n","    1. Image size (imgsz): 640, 800, 1024\n","    2. Batch size: Dynamically adjusted based on image size (96 for 640, 64 for 800+)\n","    3. Optimizer choice (SGD/Adam/AdamW)\n","    4. Initial learning rate (lr0): 1e-4 to 5e-3\n","    5. Momentum/beta1: 0.85 to 0.97\n","    6. Weight decay (regularization): 1e-5 to 1e-3\n","    7. Warmup epochs: 0 to 3\n","    8. Warmup momentum: 0.5 to 0.95\n","    9. Warmup bias learning rate: 0.0 to 0.1\n","    10. Mosaic augmentation strength: 0.5 to 1.0\n","    11. Mixup augmentation strength: 0.0 to 0.2\n","    \"\"\"\n","\n","    if trial is None:\n","        raise ValueError(\"Trial object cannot be None\")\n","\n","    # ---------------------------\n","    # 1) Image Size\n","    # ---------------------------\n","    # Test different image sizes to find optimal accuracy/speed tradeoff\n","    image_size = trial.suggest_categorical('imgsz', [640, 768])\n","\n","    # ---------------------------\n","    # 2) Batch Size (Dynamic based on image size)\n","    # ---------------------------\n","    # Larger images require more memory, so reduce batch size accordingly\n","    if image_size == 640:\n","        batch_size = 96  # Standard batch size for 640x640\n","    else:  # 768\n","        batch_size = 64  # Reduced batch size for larger images\n","\n","    # ---------------------------\n","    # 3) Optimizer + Learning Rate\n","    # ---------------------------\n","    optimizer_choice = trial.suggest_categorical('optimizer', ['SGD', 'Adam', 'AdamW'])\n","    lr0 = trial.suggest_float('lr0', 1e-4, 5e-3, log=True)\n","\n","    # ---------------------------\n","    # 4) Regularization\n","    # ---------------------------\n","    momentum = trial.suggest_float('momentum', 0.85, 0.97)\n","    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n","\n","    # ---------------------------\n","    # 5) Warmup Configuration\n","    # ---------------------------\n","    warmup_epochs = trial.suggest_int('warmup_epochs', 0, 3)\n","    warmup_momentum = trial.suggest_float('warmup_momentum', 0.5, 0.95)\n","    warmup_bias_lr = trial.suggest_float('warmup_bias_lr', 0.0, 0.1)\n","\n","    # ---------------------------\n","    # 6) Key Augmentation\n","    # ---------------------------\n","    # Mosaic and mixup have the highest impact on performance\n","    mosaic = trial.suggest_float('mosaic', 0.5, 1.0)\n","    mixup = trial.suggest_float('mixup', 0.0, 0.2)\n","\n","    # ---------------------------\n","    # 7) Compile parameters\n","    # ---------------------------\n","    hyperparams = {\n","        # ===== TUNED PARAMETERS (Critical for performance) =====\n","        'imgsz': image_size,\n","        'batch': batch_size,\n","        'optimizer': optimizer_choice,\n","        'lr0': lr0,\n","        'momentum': momentum,\n","        'weight_decay': weight_decay,\n","        'warmup_epochs': warmup_epochs,\n","        'warmup_momentum': warmup_momentum,\n","        'warmup_bias_lr': warmup_bias_lr,\n","        'mosaic': mosaic,\n","        'mixup': mixup,\n","\n","        # ===== DEFAULT PARAMETERS (YOLO defaults work well) =====\n","        # Learning rate decay: default 0.01 is well-calibrated\n","        # HSV augmentation: defaults (0.015, 0.7, 0.4) are optimal for most cases\n","        # Spatial augmentation: defaults for scale/translate work well\n","        # Loss weights: YOLO defaults (7.5, 0.5, 1.5) are well-balanced\n","\n","        # ===== FIXED PARAMETERS =====\n","        'epochs': EPOCHS_PER_TRIAL,\n","        'device': device,\n","        'val': True,\n","        'patience': ModelConfig.DEFAULT_PATIENCE,\n","        'save': True,\n","        'plots': True,\n","        'cache': False,\n","        'workers': ModelConfig.DEFAULT_WORKERS,\n","        'close_mosaic': ModelConfig.CLOSE_MOSAIC_EPOCHS,\n","        'verbose': True,\n","    }\n","\n","    return hyperparams\n","\n","\n","print('‚úì Hyperparameter search space defined')\n","print('\\nüìä Focused Search Space Summary:')\n","print('  Strategy: Tune ONLY critical high-impact parameters')\n","print('  üéØ Tuned Parameters (11):')\n","print('    - Image Size (imgsz): 640, 800, 1024')\n","print('    - Batch Size: Dynamic (96 for 640, 64 for 800+)')\n","print('    - Optimizer: SGD, Adam, AdamW')\n","print('    - Learning Rate (lr0): 1e-4 to 5e-3')\n","print('    - Momentum: 0.85 to 0.97')\n","print('    - Weight Decay: 1e-5 to 1e-3')\n","print('    - Warmup Epochs: 0 to 3')\n","print('    - Warmup Momentum: 0.5 to 0.95')\n","print('    - Warmup Bias LR: 0.0 to 0.1')\n","print('    - Mosaic: 0.5 to 1.0')\n","print('    - Mixup: 0.0 to 0.2')\n","print('  ‚öôÔ∏è  Fixed Parameters:')\n","print(f'    - Epochs: {EPOCHS_PER_TRIAL}')\n","print(f'    - Device: {device}')\n","print('  üìå Using YOLO defaults for: HSV augmentation, spatial transforms, loss weights')"]},{"cell_type":"markdown","id":"9a8326b5","metadata":{"id":"9a8326b5"},"source":["## 7. Define Objective Function"]},{"cell_type":"code","execution_count":16,"id":"c5575796","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c5575796","executionInfo":{"status":"ok","timestamp":1764322632856,"user_tz":-180,"elapsed":121,"user":{"displayName":"Mohammed Mahdy","userId":"14753646347419625264"}},"outputId":"c173cc8b-4f89-4161-9f6f-7b4acb41f4c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Objective function defined\n","  Returns: mAP@0.5 (validation set)\n","  Goal: Maximize validation performance\n"]}],"source":["# DEFINE OBJECTIVE FUNCTION FOR OPTUNA\n","# ============================================================================\n","\n","def objective(trial):\n","    \"\"\"Objective function for Optuna hyperparameter optimization.\n","\n","    Steps:\n","    1. Sample hyperparameters for the current trial\n","    2. Train a YOLO model with those hyperparameters\n","    3. Evaluate the model on the validation set\n","    4. Return validation mAP@0.5 (to maximize)\n","    \"\"\"\n","    # Get hyperparameters for this trial\n","    hyperparameters = define_hyperparameters(trial)\n","\n","    # Create trial-specific directory (absolute path under BASE_DIR)\n","    trial_dir = TUNE_DIR / f\"trial_{trial.number:03d}\"\n","    trial_dir.mkdir(exist_ok=True, parents=True)\n","\n","    # Initialize W&B if enabled\n","    wandb_run = None\n","    if USE_WANDB:\n","        try:\n","            os.environ['WANDB_DIR'] = str(trial_dir)\n","            wandb_run = wandb.init(\n","                project=WANDB_PROJECT_TUNING,\n","                name=f'{MODEL_NAME}_trial_{trial.number:03d}',\n","                config=hyperparameters,\n","                dir=str(trial_dir),\n","                reinit=True\n","            )\n","        except Exception as wandb_error:\n","            print(f'‚ö†Ô∏è  W&B initialization failed: {wandb_error}')\n","            wandb_run = None\n","\n","    # Print trial information\n","    print(f\"\\n{'=' * 80}\")\n","    print(f\"TRIAL {trial.number}/{N_TRIALS}\")\n","    print(f\"{'=' * 80}\")\n","    print(f\"üéØ Tuned Parameters:\")\n","    print(f\"  Image Size: {hyperparameters['imgsz']}\")\n","    print(f\"  Batch Size: {hyperparameters['batch']} (auto-adjusted for image size)\")\n","    print(f\"  Optimizer: {hyperparameters['optimizer']}\")\n","    print(f\"  Learning Rate: {hyperparameters['lr0']:.6f}\")\n","    print(f\"  Momentum: {hyperparameters['momentum']:.4f}\")\n","    print(f\"  Weight Decay: {hyperparameters['weight_decay']:.6f}\")\n","    print(f\"  Warmup: epochs={hyperparameters['warmup_epochs']}, momentum={hyperparameters['warmup_momentum']:.2f}, bias_lr={hyperparameters['warmup_bias_lr']:.3f}\")\n","    print(f\"  Mosaic: {hyperparameters['mosaic']:.2f}\")\n","    print(f\"  Mixup: {hyperparameters['mixup']:.2f}\")\n","    print(f\"‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\")\n","    print(f\"{'=' * 80}\")\n","\n","    trial_model = None\n","    map50 = 0.001  # Default penalty for failed trials\n","\n","    try:\n","        # Load fresh model for this trial\n","        trial_model = YOLO(str(model_path))\n","\n","        # Train model with hyperparameters (W&B integration via wandb.init)\n","        trial_run_name = f\"{MODEL_NAME}_trial_{trial.number:03d}\"\n","        train_results = trial_model.train(\n","            data=str(DATA_YAML_PATH),\n","            project=str(trial_dir),\n","            name=trial_run_name,\n","            exist_ok=True,\n","            **hyperparameters,\n","        )\n","\n","        # Validate model\n","        validation_results = trial_model.val(\n","            data=str(DATA_YAML_PATH),\n","            split=\"val\",\n","            project=str(trial_dir),\n","            name=\"val\",\n","            verbose=False,\n","        )\n","\n","        # Extract metrics\n","        map50 = float(validation_results.box.map50)\n","        map50_95 = float(validation_results.box.map)\n","        precision = float(validation_results.box.mp)\n","        recall = float(validation_results.box.mr)\n","\n","        # Save training metrics if available\n","        train_metrics = {}\n","        if hasattr(train_results, 'results_dict'):\n","            train_metrics = {key: float(value) if isinstance(value, (int,float,np.floating,np.integer)) else value\n","                             for key,value in train_results.results_dict.items()\n","                             if key not in ['fitness']}\n","\n","        # Save trial results JSON\n","        trial_results = {\n","            \"trial_number\": trial.number,\n","            \"model_name\": MODEL_NAME,\n","            \"dataset\": YOLO_DATASET_ROOT.name,\n","            \"trial_directory\": str(trial_dir),\n","            \"hyperparameters\": {k: float(v) if isinstance(v,(np.floating,np.integer)) else v for k,v in hyperparameters.items()},\n","            \"validation_metrics\": {\"map50\": map50, \"map50_95\": map50_95, \"precision\": precision, \"recall\": recall},\n","            \"training_metrics\": train_metrics,\n","            \"training_config\": {\n","                \"epochs\": EPOCHS_PER_TRIAL,\n","                \"batch_size\": hyperparameters['batch'],\n","                \"image_size\": hyperparameters['imgsz'],\n","                \"device\": device,\n","            },\n","            \"timestamp\": datetime.now().isoformat(),\n","            \"status\": \"completed\"\n","        }\n","\n","        trial_results_path = trial_dir / \"trial_results.json\"\n","        with open(trial_results_path, 'w', encoding='utf-8') as f:\n","            json.dump(trial_results, f, indent=2)\n","\n","        print(f'\\n‚úÖ Trial {trial.number} Completed')\n","        print(f'  mAP@0.5: {map50:.4f}')\n","        print(f'  mAP@0.5:0.95: {map50_95:.4f}')\n","        print(f'  Precision: {precision:.4f}')\n","        print(f'  Recall: {recall:.4f}')\n","\n","    except Exception as error:\n","        print(f'\\n‚ùå Trial {trial.number} Failed: {error}')\n","\n","        # Save error information\n","        trial_results = {\n","            \"trial_number\": trial.number,\n","            \"model_name\": MODEL_NAME,\n","            \"dataset\": YOLO_DATASET_ROOT.name,\n","            \"trial_directory\": str(trial_dir),\n","            \"hyperparameters\": {k: float(v) if isinstance(v,(np.floating,np.integer)) else v for k,v in hyperparameters.items()},\n","            \"error\": str(error),\n","            \"timestamp\": datetime.now().isoformat(),\n","            \"status\": \"failed\"\n","        }\n","\n","        trial_results_path = trial_dir / \"trial_results.json\"\n","        with open(trial_results_path, 'w', encoding='utf-8') as f:\n","            json.dump(trial_results, f, indent=2)\n","\n","        # Return small penalty value instead of raising exception\n","        map50 = 0.001\n","\n","    finally:\n","        # Clean up\n","        if wandb_run is not None:\n","            wandb_run.finish()\n","\n","        # Clean up trial model\n","        if trial_model is not None:\n","            del trial_model\n","\n","        # Force garbage collection\n","        gc.collect()\n","        if device == 'cuda':\n","            torch.cuda.empty_cache()\n","            print(\"üßπ CUDA cache cleared\")\n","\n","    return map50\n","\n","\n","print('‚úì Objective function defined')\n","print('  Returns: mAP@0.5 (validation set)')\n","print('  Goal: Maximize validation performance')"]},{"cell_type":"markdown","id":"b9b2c034","metadata":{"id":"b9b2c034"},"source":["## 8. Run Hyperparameter Optimization"]},{"cell_type":"code","execution_count":null,"id":"e116f130","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["aca59875617646e68d8efc9b0e4c92a2","fba3b951317f43ce80e9d7fce06d5b98","792dc260c93545598b0f4f8687222b6a","44dfdc8ae50d49f29bb3b27fdb36dcd7","fdd8a7f1f09a4e7bb78838dd76694e02","7a3c3832f4124785a09d38c8360977a9","1b79535acf014f099677439a29363375","fdf1cfcc9c9e4f65ac7ee284fc17d45a","b47d796eec3245ec8265a72d621583a7","0f3f2202eb1c4aa69f359a4957ac73a6","64d21409dabf43718cc561425a686ce7"]},"id":"e116f130","outputId":"72b7133d-cc40-4577-e258-421ad0460e2c"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","STARTING HYPERPARAMETER OPTIMIZATION\n","================================================================================\n","Model: yolov8m_finetuned_1\n","Dataset: bdd100k_yolo_tuning\n","Number of Trials: 40\n","Epochs per Trial: 8\n","Timeout: 24 hours\n","Device: cuda\n","================================================================================\n","\n","================================================================================\n","üîÑ RESUMING PREVIOUS OPTIMIZATION\n","================================================================================\n","\n","üìä Previous Run Summary:\n","  Completed Trials: 18\n","  Pruned Trials: 0\n","  Failed Trials: 0\n","  Total Previous Trials: 18\n","\n","üèÜ Best Result So Far:\n","  Trial: 0\n","  mAP@0.5: 0.5769\n","\n","üìà Top 3 Trials:\n","  1. Trial 0: mAP@0.5 = 0.5769\n","  2. Trial 11: mAP@0.5 = 0.5765\n","  3. Trial 10: mAP@0.5 = 0.5760\n","\n","üïê Last Checkpoint:\n","  Timestamp: 2025-11-28 06:36:52\n","  Last Trial: 17\n","  Current Best mAP: 0.5769\n","\n","‚û°Ô∏è  Continuing optimization: 22 trials remaining (of 40 total)\n","================================================================================\n","\n","üöÄ Optimization started at 2025-11-28 09:37:14\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/40 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aca59875617646e68d8efc9b0e4c92a2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mm3mahdy\u001b[0m (\u001b[33mm3mahdy-king-saud-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_018/wandb/run-20251128_093718-oc9615d7</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/oc9615d7' target=\"_blank\">yolov8m_finetuned_1_trial_018</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/oc9615d7' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/oc9615d7</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 18/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.000238\n","  Momentum: 0.9691\n","  Weight Decay: 0.000435\n","  Warmup: epochs=1, momentum=0.73, bias_lr=0.010\n","  Mosaic: 0.94\n","  Mixup: 0.11\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00023763387102495472, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.11390959443328483, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.9690735222899702, mosaic=0.9425716260056852, multi_scale=False, name=yolov8m_finetuned_1_trial_018, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_018, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_018/yolov8m_finetuned_1_trial_018, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.009569797908782101, warmup_epochs=1, warmup_momentum=0.7256297179080418, weight_decay=0.0004345143055119562, workers=8, workspace=None\n","\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 112.9MB/s 0.0s\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.4MB 286.2MB/s 0.0s\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1725.7¬±618.7 MB/s, size: 53.9 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 1.4Kit/s 11.4s\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1000.2¬±548.4 MB/s, size: 56.1 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 920.1it/s 10.9s\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_018/yolov8m_finetuned_1_trial_018/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00023763387102495472, momentum=0.9690735222899702) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0004345143055119562), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_018/yolov8m_finetuned_1_trial_018\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      36.8G      1.202     0.6528     0.9871        287        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.4s\n","                   all      10000     185578      0.625      0.531      0.575      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      37.2G      1.197     0.6525     0.9801        423        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.4s\n","                   all      10000     185578      0.635      0.523      0.574       0.33\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      37.1G      1.178     0.6359     0.9711        191        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.4s\n","                   all      10000     185578      0.647      0.529      0.574      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      36.4G      1.185     0.6401     0.9729        411        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.2s\n","                   all      10000     185578      0.634      0.526      0.574       0.33\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      38.2G      1.183     0.6379      0.972        270        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.7s\n","                   all      10000     185578      0.644      0.533      0.574      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8        38G      1.179     0.6345     0.9711        398        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 42.9s\n","                   all      10000     185578      0.636      0.523      0.574      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      36.8G      1.176     0.6321     0.9697        298        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.2s\n","                   all      10000     185578      0.639      0.524      0.574      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      35.2G      1.176     0.6311     0.9703        367        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.2s\n","                   all      10000     185578      0.638      0.522      0.573       0.33\n","\n","8 epochs completed in 0.427 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_018/yolov8m_finetuned_1_trial_018/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_018/yolov8m_finetuned_1_trial_018/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_018/yolov8m_finetuned_1_trial_018/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.5it/s 53.1s\n","                   all      10000     185578      0.625      0.531      0.574      0.331\n","                person       3220      13265      0.777      0.591      0.687      0.357\n","                 rider        515        649      0.609      0.512      0.516      0.274\n","                   car       9879     102540      0.841      0.728      0.816      0.511\n","                 truck       2689       4247      0.641      0.631      0.657       0.48\n","                   bus       1242       1597      0.666      0.602      0.652      0.504\n","                 train         14         15          0          0     0.0118      0.005\n","                 motor        334        452      0.602      0.502      0.498      0.258\n","                  bike        578       1007      0.617      0.526      0.543      0.285\n","         traffic light       5653      26891      0.753      0.572      0.654      0.258\n","          traffic sign       8221      34915      0.745      0.641       0.71      0.381\n","Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_018/yolov8m_finetuned_1_trial_018\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1568.6¬±553.7 MB/s, size: 64.9 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 9.8Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 9.7it/s 1:04\n","                   all      10000     185578      0.627      0.531      0.576      0.333\n","Speed: 0.5ms preprocess, 2.0ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_018/val\u001b[0m\n","\n","‚úÖ Trial 18 Completed\n","  mAP@0.5: 0.5756\n","  mAP@0.5:0.95: 0.3328\n","  Precision: 0.6266\n","  Recall: 0.5309\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_018</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/oc9615d7' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/oc9615d7</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_018/wandb/run-20251128_093718-oc9615d7/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 10:05:56,184] Trial 18 finished with value: 0.5756351691807339 and parameters: {'imgsz': 768, 'optimizer': 'SGD', 'lr0': 0.00023763387102495472, 'momentum': 0.9690735222899702, 'weight_decay': 0.0004345143055119562, 'warmup_epochs': 1, 'warmup_momentum': 0.7256297179080418, 'warmup_bias_lr': 0.009569797908782101, 'mosaic': 0.9425716260056852, 'mixup': 0.11390959443328483}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 19/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_019/wandb/run-20251128_100556-p5wbe0rp</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/p5wbe0rp' target=\"_blank\">yolov8m_finetuned_1_trial_019</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/p5wbe0rp' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/p5wbe0rp</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 19/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.001257\n","  Momentum: 0.9392\n","  Weight Decay: 0.000631\n","  Warmup: epochs=3, momentum=0.61, bias_lr=0.010\n","  Mosaic: 0.92\n","  Mixup: 0.16\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0012572946482373871, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.1613009507739077, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.9391522790357703, mosaic=0.924997185059828, multi_scale=False, name=yolov8m_finetuned_1_trial_019, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_019, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_019/yolov8m_finetuned_1_trial_019, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.009581091430440513, warmup_epochs=3, warmup_momentum=0.612849991148544, weight_decay=0.0006312790852644021, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1635.0¬±542.0 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 12.3Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 370.0¬±109.2 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 5.1Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_019/yolov8m_finetuned_1_trial_019/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0012572946482373871, momentum=0.9391522790357703) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0006312790852644021), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_019/yolov8m_finetuned_1_trial_019\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      36.1G      1.223     0.6752     0.9976        251        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.7it/s 2:29\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.6s\n","                   all      10000     185578      0.635      0.525      0.574      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      35.8G      1.209     0.6658     0.9866        253        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 42.8s\n","                   all      10000     185578      0.638      0.521      0.574      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      35.7G      1.201     0.6574     0.9817        325        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.5s\n","                   all      10000     185578      0.658      0.526      0.574      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      35.9G      1.205     0.6602     0.9808        352        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.3s\n","                   all      10000     185578      0.635      0.518      0.572      0.329\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      37.5G        1.2     0.6561      0.978        282        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.4s\n","                   all      10000     185578       0.63      0.543      0.573      0.329\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      35.6G      1.195     0.6523     0.9785        381        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.4s\n","                   all      10000     185578       0.64      0.537      0.573      0.329\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      35.3G      1.194      0.651     0.9783        226        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.4s\n","                   all      10000     185578      0.628      0.541      0.571      0.328\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      36.4G      1.192     0.6476     0.9775        328        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.6s\n","                   all      10000     185578      0.629      0.542      0.572      0.329\n","\n","8 epochs completed in 0.424 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_019/yolov8m_finetuned_1_trial_019/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_019/yolov8m_finetuned_1_trial_019/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_019/yolov8m_finetuned_1_trial_019/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.5it/s 53.2s\n","                   all      10000     185578      0.638      0.521      0.575      0.332\n","                person       3220      13265      0.786      0.579      0.686      0.357\n","                 rider        515        649      0.643      0.499      0.516      0.274\n","                   car       9879     102540      0.849      0.723      0.815      0.511\n","                 truck       2689       4247      0.659      0.613      0.654      0.478\n","                   bus       1242       1597      0.681       0.59      0.653      0.505\n","                 train         14         15          0          0     0.0102    0.00476\n","                 motor        334        452      0.627       0.48      0.501      0.262\n","                  bike        578       1007      0.636      0.522      0.551      0.288\n","         traffic light       5653      26891      0.752      0.569      0.651      0.257\n","          traffic sign       8221      34915      0.751      0.634      0.709      0.381\n","Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_019/yolov8m_finetuned_1_trial_019\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1306.8¬±437.3 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 8.8Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 9.7it/s 1:05\n","                   all      10000     185578      0.638      0.521      0.575      0.333\n","Speed: 0.5ms preprocess, 2.0ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_019/val\u001b[0m\n","\n","‚úÖ Trial 19 Completed\n","  mAP@0.5: 0.5751\n","  mAP@0.5:0.95: 0.3329\n","  Precision: 0.6384\n","  Recall: 0.5214\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_019</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/p5wbe0rp' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/p5wbe0rp</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_019/wandb/run-20251128_100556-p5wbe0rp/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 10:33:46,273] Trial 19 finished with value: 0.5750657616897434 and parameters: {'imgsz': 768, 'optimizer': 'SGD', 'lr0': 0.0012572946482373871, 'momentum': 0.9391522790357703, 'weight_decay': 0.0006312790852644021, 'warmup_epochs': 3, 'warmup_momentum': 0.612849991148544, 'warmup_bias_lr': 0.009581091430440513, 'mosaic': 0.924997185059828, 'mixup': 0.1613009507739077}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 20/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_020/wandb/run-20251128_103346-5am4wpav</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/5am4wpav' target=\"_blank\">yolov8m_finetuned_1_trial_020</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/5am4wpav' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/5am4wpav</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 20/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.000194\n","  Momentum: 0.8566\n","  Weight Decay: 0.000234\n","  Warmup: epochs=1, momentum=0.72, bias_lr=0.017\n","  Mosaic: 0.97\n","  Mixup: 0.20\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00019409774408113843, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.19898880565440097, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.8566173352757066, mosaic=0.9748539724246373, multi_scale=False, name=yolov8m_finetuned_1_trial_020, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_020, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_020/yolov8m_finetuned_1_trial_020, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.01672355973911266, warmup_epochs=1, warmup_momentum=0.7222631373010865, weight_decay=0.0002337269531669197, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1719.9¬±488.9 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 13.3Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 492.6¬±112.4 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 6.3Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_020/yolov8m_finetuned_1_trial_020/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00019409774408113843, momentum=0.8566173352757066) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0002337269531669197), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_020/yolov8m_finetuned_1_trial_020\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      35.9G       1.23     0.6872      1.004        336        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.7it/s 2:31\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.6s\n","                   all      10000     185578      0.633      0.525      0.573      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      37.6G      1.219     0.6775      0.992        362        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.6s\n","                   all      10000     185578      0.626       0.53      0.574      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      35.8G      1.216     0.6722     0.9886        283        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.5s\n","                   all      10000     185578      0.632      0.528      0.575      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      35.6G      1.216     0.6741     0.9895        473        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.6s\n","                   all      10000     185578      0.634      0.527      0.575      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      37.5G      1.212     0.6715     0.9865        423        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 42.9s\n","                   all      10000     185578      0.633      0.529      0.576      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      37.6G      1.208     0.6665     0.9852        214        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.6s\n","                   all      10000     185578      0.634      0.527      0.575      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      38.3G      1.214     0.6709     0.9887        299        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.6s\n","                   all      10000     185578      0.633      0.527      0.574      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      38.1G      1.208      0.667     0.9854        250        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 42.9s\n","                   all      10000     185578      0.634      0.528      0.575      0.332\n","\n","8 epochs completed in 0.426 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_020/yolov8m_finetuned_1_trial_020/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_020/yolov8m_finetuned_1_trial_020/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_020/yolov8m_finetuned_1_trial_020/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.5it/s 53.1s\n","                   all      10000     185578      0.633      0.525      0.573      0.332\n","                person       3220      13265      0.784      0.587      0.686      0.357\n","                 rider        515        649      0.627      0.502      0.515      0.277\n","                   car       9879     102540      0.845      0.726      0.816      0.511\n","                 truck       2689       4247      0.662      0.616      0.656       0.48\n","                   bus       1242       1597      0.672      0.599      0.652      0.504\n","                 train         14         15          0          0     0.0113     0.0071\n","                 motor        334        452      0.619      0.496      0.496      0.257\n","                  bike        578       1007      0.616      0.521      0.543      0.286\n","         traffic light       5653      26891      0.754      0.568      0.651      0.257\n","          traffic sign       8221      34915      0.748      0.637      0.708      0.381\n","Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_020/yolov8m_finetuned_1_trial_020\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1334.2¬±493.9 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 8.8Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 9.7it/s 1:05\n","                   all      10000     185578      0.633      0.526      0.575      0.332\n","Speed: 0.5ms preprocess, 2.0ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_020/val\u001b[0m\n","\n","‚úÖ Trial 20 Completed\n","  mAP@0.5: 0.5747\n","  mAP@0.5:0.95: 0.3324\n","  Precision: 0.6334\n","  Recall: 0.5262\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_020</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/5am4wpav' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/5am4wpav</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_020/wandb/run-20251128_103346-5am4wpav/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 11:01:40,365] Trial 20 finished with value: 0.5747262839096262 and parameters: {'imgsz': 768, 'optimizer': 'SGD', 'lr0': 0.00019409774408113843, 'momentum': 0.8566173352757066, 'weight_decay': 0.0002337269531669197, 'warmup_epochs': 1, 'warmup_momentum': 0.7222631373010865, 'warmup_bias_lr': 0.01672355973911266, 'mosaic': 0.9748539724246373, 'mixup': 0.19898880565440097}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 21/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_021/wandb/run-20251128_110140-x0y0bzp8</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/x0y0bzp8' target=\"_blank\">yolov8m_finetuned_1_trial_021</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/x0y0bzp8' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/x0y0bzp8</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 21/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: Adam\n","  Learning Rate: 0.000117\n","  Momentum: 0.9210\n","  Weight Decay: 0.000155\n","  Warmup: epochs=3, momentum=0.70, bias_lr=0.011\n","  Mosaic: 0.75\n","  Mixup: 0.12\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001170177690808451, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.11814716804007039, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.9209918879986447, mosaic=0.7454902561777089, multi_scale=False, name=yolov8m_finetuned_1_trial_021, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_021, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_021/yolov8m_finetuned_1_trial_021, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.011034875129972614, warmup_epochs=3, warmup_momentum=0.6994537517049798, weight_decay=0.00015481959953941008, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 969.8¬±422.1 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 12.7Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 495.9¬±143.4 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 5.9Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_021/yolov8m_finetuned_1_trial_021/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.0001170177690808451, momentum=0.9209918879986447) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.00015481959953941008), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_021/yolov8m_finetuned_1_trial_021\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      37.4G      1.201      0.656     0.9806        396        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.7it/s 2:32\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.6s\n","                   all      10000     185578      0.637      0.522      0.571      0.328\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8        38G      1.201      0.651     0.9774        356        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.3s\n","                   all      10000     185578      0.636      0.528      0.567      0.326\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      35.4G      1.201      0.652     0.9785        324        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.1s\n","                   all      10000     185578      0.643      0.512      0.567      0.325\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      38.3G      1.196     0.6494     0.9766        234        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.3s\n","                   all      10000     185578      0.638      0.525      0.569      0.325\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      36.9G      1.191     0.6439      0.974        123        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.2s\n","                   all      10000     185578      0.628       0.56       0.57      0.325\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      36.7G      1.183     0.6361     0.9702        327        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.3s\n","                   all      10000     185578      0.629      0.521      0.567      0.324\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      35.3G      1.183     0.6343     0.9708        296        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.3s\n","                   all      10000     185578       0.62      0.538      0.568      0.326\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      35.2G      1.178     0.6265     0.9694        357        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.5s\n","                   all      10000     185578      0.618      0.552       0.57      0.327\n","\n","8 epochs completed in 0.425 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_021/yolov8m_finetuned_1_trial_021/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_021/yolov8m_finetuned_1_trial_021/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_021/yolov8m_finetuned_1_trial_021/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.5it/s 53.4s\n","                   all      10000     185578      0.637      0.521       0.57      0.328\n","                person       3220      13265      0.772      0.589      0.683      0.355\n","                 rider        515        649      0.668      0.495      0.514      0.276\n","                   car       9879     102540      0.838       0.73      0.814       0.51\n","                 truck       2689       4247      0.657      0.607      0.642      0.467\n","                   bus       1242       1597      0.672      0.592      0.645      0.498\n","                 train         14         15          0          0     0.0118    0.00633\n","                 motor        334        452      0.635      0.487      0.502      0.256\n","                  bike        578       1007      0.621       0.52      0.534      0.279\n","         traffic light       5653      26891      0.752      0.569      0.654      0.258\n","          traffic sign       8221      34915      0.755      0.626      0.704      0.377\n","Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_021/yolov8m_finetuned_1_trial_021\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1437.1¬±457.3 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 8.1Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 9.7it/s 1:04\n","                   all      10000     185578      0.638      0.522      0.571      0.329\n","Speed: 0.5ms preprocess, 1.9ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_021/val\u001b[0m\n","\n","‚úÖ Trial 21 Completed\n","  mAP@0.5: 0.5715\n","  mAP@0.5:0.95: 0.3290\n","  Precision: 0.6377\n","  Recall: 0.5224\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_021</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/x0y0bzp8' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/x0y0bzp8</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_021/wandb/run-20251128_110140-x0y0bzp8/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 11:29:31,787] Trial 21 finished with value: 0.5714628221402573 and parameters: {'imgsz': 768, 'optimizer': 'Adam', 'lr0': 0.0001170177690808451, 'momentum': 0.9209918879986447, 'weight_decay': 0.00015481959953941008, 'warmup_epochs': 3, 'warmup_momentum': 0.6994537517049798, 'warmup_bias_lr': 0.011034875129972614, 'mosaic': 0.7454902561777089, 'mixup': 0.11814716804007039}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 22/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_022/wandb/run-20251128_112932-xzr6swft</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/xzr6swft' target=\"_blank\">yolov8m_finetuned_1_trial_022</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/xzr6swft' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/xzr6swft</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 22/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.000141\n","  Momentum: 0.9094\n","  Weight Decay: 0.000731\n","  Warmup: epochs=3, momentum=0.67, bias_lr=0.006\n","  Mosaic: 0.89\n","  Mixup: 0.12\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00014118140573302955, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.12334438866565361, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.9094252069932472, mosaic=0.8913409412138384, multi_scale=False, name=yolov8m_finetuned_1_trial_022, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_022, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_022/yolov8m_finetuned_1_trial_022, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.005798927412947139, warmup_epochs=3, warmup_momentum=0.668541094684278, weight_decay=0.0007309395990801345, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1909.0¬±706.8 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 14.6Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 423.9¬±85.5 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 4.5Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_022/yolov8m_finetuned_1_trial_022/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00014118140573302955, momentum=0.9094252069932472) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0007309395990801345), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_022/yolov8m_finetuned_1_trial_022\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      36.9G       1.21     0.6625     0.9941        269        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.7it/s 2:30\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.5s\n","                   all      10000     185578      0.649      0.528      0.571       0.33\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8        38G      1.206      0.656     0.9889        225        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.5s\n","                   all      10000     185578       0.64      0.536      0.573      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      38.3G      1.198     0.6507     0.9834        316        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 42.7s\n","                   all      10000     185578       0.63      0.527      0.574      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      37.4G      1.195     0.6502     0.9796        215        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.5s\n","                   all      10000     185578      0.631      0.529      0.576      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      35.9G      1.192     0.6477     0.9783        405        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.3s\n","                   all      10000     185578       0.63      0.528      0.576      0.333\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      38.6G      1.197     0.6493      0.979        287        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.6s\n","                   all      10000     185578      0.629      0.528      0.575      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      35.8G      1.194     0.6457     0.9775        200        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 42.9s\n","                   all      10000     185578      0.625      0.531      0.576      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      38.6G      1.193     0.6457     0.9769        388        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.7s\n","                   all      10000     185578      0.627       0.53      0.576      0.332\n","\n","8 epochs completed in 0.424 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_022/yolov8m_finetuned_1_trial_022/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_022/yolov8m_finetuned_1_trial_022/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_022/yolov8m_finetuned_1_trial_022/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.5it/s 53.1s\n","                   all      10000     185578      0.629      0.529      0.576      0.333\n","                person       3220      13265      0.776      0.592      0.687      0.359\n","                 rider        515        649      0.625      0.501      0.518      0.277\n","                   car       9879     102540      0.842      0.728      0.816      0.512\n","                 truck       2689       4247      0.646      0.622      0.654      0.479\n","                   bus       1242       1597      0.672      0.602      0.653      0.506\n","                 train         14         15          0          0     0.0156    0.00726\n","                 motor        334        452      0.624      0.502      0.502      0.259\n","                  bike        578       1007      0.608      0.529      0.547      0.288\n","         traffic light       5653      26891      0.752      0.575      0.654      0.258\n","          traffic sign       8221      34915      0.748      0.637       0.71      0.382\n","Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_022/yolov8m_finetuned_1_trial_022\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1181.0¬±407.0 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 8.7Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 9.7it/s 1:05\n","                   all      10000     185578      0.631      0.529      0.577      0.334\n","Speed: 0.5ms preprocess, 2.0ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_022/val\u001b[0m\n","\n","‚úÖ Trial 22 Completed\n","  mAP@0.5: 0.5767\n","  mAP@0.5:0.95: 0.3336\n","  Precision: 0.6312\n","  Recall: 0.5286\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_022</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/xzr6swft' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/xzr6swft</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_022/wandb/run-20251128_112932-xzr6swft/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 11:57:22,248] Trial 22 finished with value: 0.5766610208034043 and parameters: {'imgsz': 768, 'optimizer': 'SGD', 'lr0': 0.00014118140573302955, 'momentum': 0.9094252069932472, 'weight_decay': 0.0007309395990801345, 'warmup_epochs': 3, 'warmup_momentum': 0.668541094684278, 'warmup_bias_lr': 0.005798927412947139, 'mosaic': 0.8913409412138384, 'mixup': 0.12334438866565361}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 23/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_023/wandb/run-20251128_115722-q58ttu3t</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/q58ttu3t' target=\"_blank\">yolov8m_finetuned_1_trial_023</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/q58ttu3t' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/q58ttu3t</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 23/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 640\n","  Batch Size: 96 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.000109\n","  Momentum: 0.9087\n","  Weight Decay: 0.000382\n","  Warmup: epochs=3, momentum=0.59, bias_lr=0.006\n","  Mosaic: 0.95\n","  Mixup: 0.10\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=96, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00010923720976574512, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.10142130829413395, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.9087276077173645, mosaic=0.9502356426031231, multi_scale=False, name=yolov8m_finetuned_1_trial_023, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_023, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_023/yolov8m_finetuned_1_trial_023, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.005708881601387014, warmup_epochs=3, warmup_momentum=0.5914682378765702, weight_decay=0.0003818945195905101, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1819.2¬±417.1 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 12.4Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 430.4¬±102.9 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 5.3Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_023/yolov8m_finetuned_1_trial_023/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00010923720976574512, momentum=0.9087276077173645) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005728417793857651), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_023/yolov8m_finetuned_1_trial_023\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      36.9G      1.159     0.6308     0.9584       2790        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.6it/s 1:49\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 37.7s\n","                   all      10000     185578      0.624      0.525      0.555      0.319\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      36.9G      1.159     0.6303     0.9575       3104        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 37.6s\n","                   all      10000     185578      0.625      0.524      0.555      0.319\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      36.9G      1.153     0.6201     0.9526       2835        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 37.6s\n","                   all      10000     185578      0.618      0.527      0.556      0.319\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      38.2G      1.156     0.6224     0.9518       2802        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 37.7s\n","                   all      10000     185578      0.623      0.525      0.555      0.319\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      37.6G      1.154     0.6208     0.9512       3284        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 37.8s\n","                   all      10000     185578      0.624      0.525      0.555      0.318\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      38.2G      1.153     0.6191     0.9509       2968        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 37.7s\n","                   all      10000     185578      0.624      0.525      0.555      0.318\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      38.6G      1.153     0.6178     0.9506       2921        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 37.8s\n","                   all      10000     185578      0.619      0.529      0.555      0.318\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      36.9G      1.153     0.6184     0.9497       3042        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 37.5s\n","                   all      10000     185578      0.615      0.531      0.555      0.318\n","\n","8 epochs completed in 0.318 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_023/yolov8m_finetuned_1_trial_023/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_023/yolov8m_finetuned_1_trial_023/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_023/yolov8m_finetuned_1_trial_023/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.1it/s 48.9s\n","                   all      10000     185578      0.617      0.527      0.556      0.319\n","                person       3220      13265      0.736      0.588      0.658      0.339\n","                 rider        515        649      0.584      0.508      0.514      0.262\n","                   car       9879     102540      0.815      0.725      0.794      0.499\n","                 truck       2689       4247      0.628      0.621      0.636      0.465\n","                   bus       1242       1597      0.648      0.602       0.64      0.495\n","                 train         14         15      0.154     0.0667     0.0267     0.0194\n","                 motor        334        452      0.598      0.496      0.489      0.251\n","                  bike        578       1007      0.549      0.526      0.516      0.267\n","         traffic light       5653      26891      0.738      0.531      0.612      0.239\n","          traffic sign       8221      34915      0.724      0.609      0.669      0.359\n","Speed: 0.1ms preprocess, 0.8ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_023/yolov8m_finetuned_1_trial_023\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1406.7¬±473.9 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 7.7Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 11.0it/s 57.1s\n","                   all      10000     185578      0.619      0.528      0.557       0.32\n","Speed: 0.4ms preprocess, 1.4ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_023/val\u001b[0m\n","\n","‚úÖ Trial 23 Completed\n","  mAP@0.5: 0.5567\n","  mAP@0.5:0.95: 0.3205\n","  Precision: 0.6191\n","  Recall: 0.5278\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_023</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/q58ttu3t' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/q58ttu3t</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_023/wandb/run-20251128_115722-q58ttu3t/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 12:18:36,710] Trial 23 finished with value: 0.5566937623941979 and parameters: {'imgsz': 640, 'optimizer': 'SGD', 'lr0': 0.00010923720976574512, 'momentum': 0.9087276077173645, 'weight_decay': 0.0003818945195905101, 'warmup_epochs': 3, 'warmup_momentum': 0.5914682378765702, 'warmup_bias_lr': 0.005708881601387014, 'mosaic': 0.9502356426031231, 'mixup': 0.10142130829413395}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 24/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_024/wandb/run-20251128_121837-vox3tuti</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/vox3tuti' target=\"_blank\">yolov8m_finetuned_1_trial_024</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/vox3tuti' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/vox3tuti</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 24/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: AdamW\n","  Learning Rate: 0.000290\n","  Momentum: 0.9011\n","  Weight Decay: 0.000857\n","  Warmup: epochs=3, momentum=0.64, bias_lr=0.002\n","  Mosaic: 0.91\n","  Mixup: 0.07\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00028982832586057925, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.07238307109429609, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.9011224088902193, mosaic=0.9078188400390483, multi_scale=False, name=yolov8m_finetuned_1_trial_024, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_024, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_024/yolov8m_finetuned_1_trial_024, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0022194926894142787, warmup_epochs=3, warmup_momentum=0.6375973065667252, weight_decay=0.0008570020016218264, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1802.9¬±479.8 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 12.9Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 512.3¬±112.3 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 6.0Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_024/yolov8m_finetuned_1_trial_024/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00028982832586057925, momentum=0.9011224088902193) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0008570020016218264), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_024/yolov8m_finetuned_1_trial_024\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      34.9G      1.181     0.6342     0.9723        260        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.7it/s 2:30\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.1s\n","                   all      10000     185578       0.63      0.521      0.567      0.325\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      35.2G      1.188     0.6468     0.9756        312        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 41.9s\n","                   all      10000     185578      0.633      0.513      0.561      0.319\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      36.2G      1.196     0.6584     0.9782        319        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.5s\n","                   all      10000     185578      0.624      0.499       0.55      0.312\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      38.1G      1.197     0.6633     0.9801        156        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.5s\n","                   all      10000     185578      0.631      0.514       0.56      0.318\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      38.5G      1.194     0.6561     0.9796        244        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.4s\n","                   all      10000     185578      0.627      0.511      0.556      0.316\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      34.8G       1.18     0.6415     0.9717        350        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.0s\n","                   all      10000     185578      0.618      0.515      0.559      0.319\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      38.5G      1.174     0.6307     0.9692        244        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.3s\n","                   all      10000     185578      0.621      0.538      0.563      0.321\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8        36G      1.165     0.6191     0.9638        337        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.2s\n","                   all      10000     185578      0.636      0.524      0.568      0.325\n","\n","8 epochs completed in 0.423 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_024/yolov8m_finetuned_1_trial_024/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_024/yolov8m_finetuned_1_trial_024/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_024/yolov8m_finetuned_1_trial_024/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.5it/s 53.1s\n","                   all      10000     185578      0.631      0.521      0.567      0.325\n","                person       3220      13265       0.78      0.584      0.681      0.353\n","                 rider        515        649      0.625      0.516       0.51      0.271\n","                   car       9879     102540       0.83      0.733      0.814       0.51\n","                 truck       2689       4247      0.643      0.593      0.626      0.456\n","                   bus       1242       1597      0.696       0.57      0.644      0.494\n","                 train         14         15          0          0    0.00517    0.00364\n","                 motor        334        452      0.606      0.496      0.501      0.256\n","                  bike        578       1007      0.636      0.508      0.535      0.277\n","         traffic light       5653      26891      0.751      0.573      0.653      0.255\n","          traffic sign       8221      34915      0.739      0.639      0.703      0.378\n","Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_024/yolov8m_finetuned_1_trial_024\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1440.5¬±443.5 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 8.4Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 9.7it/s 1:04\n","                   all      10000     185578       0.63      0.522      0.567      0.326\n","Speed: 0.5ms preprocess, 1.9ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_024/val\u001b[0m\n","\n","‚úÖ Trial 24 Completed\n","  mAP@0.5: 0.5673\n","  mAP@0.5:0.95: 0.3261\n","  Precision: 0.6297\n","  Recall: 0.5219\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_024</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/vox3tuti' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/vox3tuti</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_024/wandb/run-20251128_121837-vox3tuti/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 12:46:22,796] Trial 24 finished with value: 0.5672992926314723 and parameters: {'imgsz': 768, 'optimizer': 'AdamW', 'lr0': 0.00028982832586057925, 'momentum': 0.9011224088902193, 'weight_decay': 0.0008570020016218264, 'warmup_epochs': 3, 'warmup_momentum': 0.6375973065667252, 'warmup_bias_lr': 0.0022194926894142787, 'mosaic': 0.9078188400390483, 'mixup': 0.07238307109429609}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 25/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_025/wandb/run-20251128_124623-0cmx2kbi</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/0cmx2kbi' target=\"_blank\">yolov8m_finetuned_1_trial_025</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/0cmx2kbi' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/0cmx2kbi</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 25/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.000103\n","  Momentum: 0.8566\n","  Weight Decay: 0.000692\n","  Warmup: epochs=3, momentum=0.84, bias_lr=0.000\n","  Mosaic: 0.99\n","  Mixup: 0.13\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00010337029702652747, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.1299937060296653, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.8565504231572861, mosaic=0.9923623608226324, multi_scale=False, name=yolov8m_finetuned_1_trial_025, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_025, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_025/yolov8m_finetuned_1_trial_025, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=8.375508235552304e-07, warmup_epochs=3, warmup_momentum=0.835109436494624, weight_decay=0.000691796111224237, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1704.0¬±591.6 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 15.4Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 511.2¬±144.1 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 5.9Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_025/yolov8m_finetuned_1_trial_025/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00010337029702652747, momentum=0.8565504231572861) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.000691796111224237), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_025/yolov8m_finetuned_1_trial_025\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      35.5G      1.209      0.663     0.9931        336        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.7it/s 2:31\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.6s\n","                   all      10000     185578      0.647      0.531      0.572       0.33\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      35.5G      1.208     0.6614     0.9911        314        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.1s\n","                   all      10000     185578      0.621      0.548      0.573      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      36.6G      1.196     0.6513     0.9835        215        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.4s\n","                   all      10000     185578      0.613       0.54      0.575      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      38.1G      1.199     0.6552     0.9822        354        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.6s\n","                   all      10000     185578      0.629      0.531      0.575      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      37.2G      1.198     0.6509     0.9812        293        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 42.8s\n","                   all      10000     185578      0.638      0.525      0.574      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      37.8G      1.192     0.6483     0.9783        339        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.5s\n","                   all      10000     185578      0.636      0.526      0.576      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      37.1G      1.199     0.6529      0.982        186        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 42.7s\n","                   all      10000     185578      0.633      0.527      0.574      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      35.4G      1.196     0.6511     0.9805        375        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.5s\n","                   all      10000     185578      0.635      0.527      0.575      0.332\n","\n","8 epochs completed in 0.425 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_025/yolov8m_finetuned_1_trial_025/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_025/yolov8m_finetuned_1_trial_025/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_025/yolov8m_finetuned_1_trial_025/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.5it/s 53.2s\n","                   all      10000     185578      0.612       0.54      0.575      0.332\n","                person       3220      13265      0.751       0.61      0.688      0.357\n","                 rider        515        649      0.607      0.512      0.516      0.274\n","                   car       9879     102540      0.823      0.742      0.816      0.512\n","                 truck       2689       4247      0.641      0.633      0.657       0.48\n","                   bus       1242       1597      0.658      0.609      0.653      0.506\n","                 train         14         15          0          0     0.0144     0.0095\n","                 motor        334        452      0.596      0.509      0.496      0.256\n","                  bike        578       1007      0.586      0.543      0.545      0.287\n","         traffic light       5653      26891      0.734      0.592      0.653      0.258\n","          traffic sign       8221      34915       0.73      0.653       0.71      0.382\n","Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_025/yolov8m_finetuned_1_trial_025\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1394.4¬±517.8 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 7.6Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 9.7it/s 1:05\n","                   all      10000     185578      0.614      0.541      0.576      0.333\n","Speed: 0.5ms preprocess, 1.9ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_025/val\u001b[0m\n","\n","‚úÖ Trial 25 Completed\n","  mAP@0.5: 0.5759\n","  mAP@0.5:0.95: 0.3334\n","  Precision: 0.6142\n","  Recall: 0.5407\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_025</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/0cmx2kbi' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/0cmx2kbi</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_025/wandb/run-20251128_124623-0cmx2kbi/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 13:14:13,814] Trial 25 finished with value: 0.5759153249673427 and parameters: {'imgsz': 768, 'optimizer': 'SGD', 'lr0': 0.00010337029702652747, 'momentum': 0.8565504231572861, 'weight_decay': 0.000691796111224237, 'warmup_epochs': 3, 'warmup_momentum': 0.835109436494624, 'warmup_bias_lr': 8.375508235552304e-07, 'mosaic': 0.9923623608226324, 'mixup': 0.1299937060296653}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 26/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_026/wandb/run-20251128_131414-eehru6w7</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/eehru6w7' target=\"_blank\">yolov8m_finetuned_1_trial_026</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/eehru6w7' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/eehru6w7</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 26/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.000681\n","  Momentum: 0.8750\n","  Weight Decay: 0.000786\n","  Warmup: epochs=3, momentum=0.94, bias_lr=0.002\n","  Mosaic: 0.91\n","  Mixup: 0.19\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.000680896077927012, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.1946641233828872, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.8749899221652856, mosaic=0.9086387107056219, multi_scale=False, name=yolov8m_finetuned_1_trial_026, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_026, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_026/yolov8m_finetuned_1_trial_026, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0020970375937223724, warmup_epochs=3, warmup_momentum=0.9379847839584119, weight_decay=0.0007859094519095029, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1776.6¬±486.7 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 14.0Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 453.6¬±102.2 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 6.4Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_026/yolov8m_finetuned_1_trial_026/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.000680896077927012, momentum=0.8749899221652856) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0007859094519095029), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_026/yolov8m_finetuned_1_trial_026\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      38.8G      1.229     0.6848      1.001        331        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.7it/s 2:31\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.0s\n","                   all      10000     185578      0.632      0.527      0.575      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      38.3G      1.216     0.6749      0.989        529        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 42.7s\n","                   all      10000     185578      0.629      0.525      0.574      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      36.3G      1.209      0.667     0.9856        343        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.6s\n","                   all      10000     185578      0.634      0.524      0.574       0.33\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8        38G      1.214      0.669     0.9865        292        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.6s\n","                   all      10000     185578      0.629      0.545      0.575      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      38.7G      1.208     0.6643     0.9837        260        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 42.7s\n","                   all      10000     185578      0.641       0.52      0.573       0.33\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      35.4G      1.209     0.6634     0.9827        349        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.6s\n","                   all      10000     185578      0.639      0.524      0.574      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      38.5G      1.209     0.6649     0.9843        396        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.4s\n","                   all      10000     185578      0.639      0.523      0.574       0.33\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      38.3G      1.201     0.6598     0.9823        229        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 42.8s\n","                   all      10000     185578      0.612      0.537      0.574      0.331\n","\n","8 epochs completed in 0.425 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_026/yolov8m_finetuned_1_trial_026/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_026/yolov8m_finetuned_1_trial_026/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_026/yolov8m_finetuned_1_trial_026/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.5it/s 53.5s\n","                   all      10000     185578      0.633      0.526      0.575      0.332\n","                person       3220      13265      0.772      0.594      0.687      0.357\n","                 rider        515        649      0.632      0.503      0.517      0.277\n","                   car       9879     102540       0.84      0.729      0.815       0.51\n","                 truck       2689       4247      0.653      0.617      0.655      0.478\n","                   bus       1242       1597      0.663      0.604      0.653      0.506\n","                 train         14         15          0          0    0.00852    0.00446\n","                 motor        334        452      0.634      0.496      0.503       0.26\n","                  bike        578       1007      0.635      0.516      0.547      0.288\n","         traffic light       5653      26891      0.755       0.57      0.652      0.258\n","          traffic sign       8221      34915      0.749      0.636      0.709      0.381\n","Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_026/yolov8m_finetuned_1_trial_026\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1267.6¬±357.8 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 9.3Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 9.6it/s 1:05\n","                   all      10000     185578      0.633      0.527      0.575      0.333\n","Speed: 0.5ms preprocess, 2.0ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_026/val\u001b[0m\n","\n","‚úÖ Trial 26 Completed\n","  mAP@0.5: 0.5749\n","  mAP@0.5:0.95: 0.3325\n","  Precision: 0.6332\n","  Recall: 0.5271\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_026</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/eehru6w7' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/eehru6w7</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_026/wandb/run-20251128_131414-eehru6w7/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 13:42:13,311] Trial 26 finished with value: 0.5748535655590452 and parameters: {'imgsz': 768, 'optimizer': 'SGD', 'lr0': 0.000680896077927012, 'momentum': 0.8749899221652856, 'weight_decay': 0.0007859094519095029, 'warmup_epochs': 3, 'warmup_momentum': 0.9379847839584119, 'warmup_bias_lr': 0.0020970375937223724, 'mosaic': 0.9086387107056219, 'mixup': 0.1946641233828872}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 27/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_027/wandb/run-20251128_134213-7c72dy5m</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/7c72dy5m' target=\"_blank\">yolov8m_finetuned_1_trial_027</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/7c72dy5m' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/7c72dy5m</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 27/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.000235\n","  Momentum: 0.9126\n","  Weight Decay: 0.000426\n","  Warmup: epochs=2, momentum=0.75, bias_lr=0.003\n","  Mosaic: 0.98\n","  Mixup: 0.16\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00023455204646398111, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.16339193297033638, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.912563232474453, mosaic=0.9767352096136815, multi_scale=False, name=yolov8m_finetuned_1_trial_027, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_027, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_027/yolov8m_finetuned_1_trial_027, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0029013894269801677, warmup_epochs=2, warmup_momentum=0.7527886964045045, weight_decay=0.00042559110435000353, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1730.1¬±481.0 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 13.6Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 413.3¬±116.1 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 6.4Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_027/yolov8m_finetuned_1_trial_027/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00023455204646398111, momentum=0.912563232474453) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.00042559110435000353), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_027/yolov8m_finetuned_1_trial_027\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      35.2G      1.218     0.6747     0.9987        386        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.7it/s 2:31\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.5s\n","                   all      10000     185578      0.607      0.541      0.573      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8        36G      1.209     0.6659     0.9879        299        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 42.7s\n","                   all      10000     185578      0.629      0.529      0.574      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      37.8G      1.201     0.6579     0.9826        264        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 42.7s\n","                   all      10000     185578      0.638      0.525      0.575      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      38.3G      1.204     0.6605     0.9823        320        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 42.7s\n","                   all      10000     185578      0.636      0.526      0.575      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8        37G      1.201     0.6588     0.9813        365        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.7s\n","                   all      10000     185578      0.637      0.524      0.575      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      38.8G      1.201     0.6573     0.9816        356        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.7s\n","                   all      10000     185578      0.637      0.524      0.574      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      36.9G        1.2     0.6588     0.9819        267        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.7s\n","                   all      10000     185578      0.639      0.524      0.576      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      38.7G      1.195      0.652     0.9794        450        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 42.8s\n","                   all      10000     185578      0.639      0.524      0.575      0.332\n","\n","8 epochs completed in 0.426 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_027/yolov8m_finetuned_1_trial_027/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_027/yolov8m_finetuned_1_trial_027/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_027/yolov8m_finetuned_1_trial_027/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.5it/s 53.4s\n","                   all      10000     185578      0.637      0.526      0.575      0.332\n","                person       3220      13265      0.779      0.588      0.687      0.358\n","                 rider        515        649      0.647      0.505      0.517      0.276\n","                   car       9879     102540      0.847      0.723      0.816      0.511\n","                 truck       2689       4247      0.649       0.62      0.653      0.478\n","                   bus       1242       1597      0.676      0.602      0.652      0.504\n","                 train         14         15          0          0     0.0114    0.00503\n","                 motor        334        452      0.623      0.509        0.5       0.26\n","                  bike        578       1007      0.631      0.521      0.548       0.29\n","         traffic light       5653      26891      0.758      0.564      0.653      0.258\n","          traffic sign       8221      34915      0.758      0.628       0.71      0.381\n","Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_027/yolov8m_finetuned_1_trial_027\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1291.2¬±461.2 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 8.3Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 9.6it/s 1:05\n","                   all      10000     185578      0.638      0.526      0.576      0.333\n","Speed: 0.5ms preprocess, 2.0ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_027/val\u001b[0m\n","\n","‚úÖ Trial 27 Completed\n","  mAP@0.5: 0.5756\n","  mAP@0.5:0.95: 0.3328\n","  Precision: 0.6383\n","  Recall: 0.5261\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_027</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/7c72dy5m' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/7c72dy5m</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_027/wandb/run-20251128_134213-7c72dy5m/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 14:10:07,856] Trial 27 finished with value: 0.5756012162928592 and parameters: {'imgsz': 768, 'optimizer': 'SGD', 'lr0': 0.00023455204646398111, 'momentum': 0.912563232474453, 'weight_decay': 0.00042559110435000353, 'warmup_epochs': 2, 'warmup_momentum': 0.7527886964045045, 'warmup_bias_lr': 0.0029013894269801677, 'mosaic': 0.9767352096136815, 'mixup': 0.16339193297033638}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 28/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_028/wandb/run-20251128_141008-2jw4jez5</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/2jw4jez5' target=\"_blank\">yolov8m_finetuned_1_trial_028</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/2jw4jez5' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/2jw4jez5</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 28/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: AdamW\n","  Learning Rate: 0.000182\n","  Momentum: 0.8618\n","  Weight Decay: 0.000186\n","  Warmup: epochs=2, momentum=0.86, bias_lr=0.025\n","  Mosaic: 0.85\n","  Mixup: 0.14\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001816950319371306, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.14369498961035593, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.8618101733544855, mosaic=0.8527374391318845, multi_scale=False, name=yolov8m_finetuned_1_trial_028, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_028, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_028/yolov8m_finetuned_1_trial_028, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.02471331817804086, warmup_epochs=2, warmup_momentum=0.8596224633670249, weight_decay=0.00018619454328701798, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1335.3¬±498.7 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 14.6Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 566.9¬±269.3 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 8.0Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_028/yolov8m_finetuned_1_trial_028/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0001816950319371306, momentum=0.8618101733544855) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.00018619454328701798), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_028/yolov8m_finetuned_1_trial_028\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      35.6G      1.211     0.6703     0.9851        327        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.7it/s 2:31\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.4s\n","                   all      10000     185578      0.637      0.514      0.565      0.324\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      38.5G      1.212     0.6724     0.9861        282        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.4s\n","                   all      10000     185578      0.622      0.511      0.556      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      37.4G      1.211     0.6726     0.9861        272        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.5s\n","                   all      10000     185578      0.626      0.513      0.564      0.321\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      36.3G      1.208     0.6693     0.9815        267        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.3s\n","                   all      10000     185578       0.65      0.509      0.562       0.32\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      37.3G      1.204     0.6608     0.9817        406        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.4s\n","                   all      10000     185578      0.633      0.541      0.564      0.322\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      37.5G      1.196     0.6521     0.9783        531        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.2s\n","                   all      10000     185578      0.637      0.524      0.563      0.322\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      38.2G      1.188     0.6446     0.9771        187        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.3s\n","                   all      10000     185578      0.622      0.537      0.566      0.324\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      37.1G      1.185     0.6399     0.9738        187        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.2s\n","                   all      10000     185578      0.618      0.545      0.565      0.324\n","\n","8 epochs completed in 0.426 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_028/yolov8m_finetuned_1_trial_028/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_028/yolov8m_finetuned_1_trial_028/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_028/yolov8m_finetuned_1_trial_028/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.5it/s 52.9s\n","                   all      10000     185578      0.621      0.538      0.566      0.324\n","                person       3220      13265      0.758      0.603      0.682      0.352\n","                 rider        515        649      0.648      0.513       0.52      0.274\n","                   car       9879     102540      0.827      0.733      0.811      0.508\n","                 truck       2689       4247      0.627      0.607      0.623      0.451\n","                   bus       1242       1597      0.601      0.614       0.63      0.488\n","                 train         14         15      0.115     0.0667     0.0226    0.00995\n","                 motor        334        452      0.563        0.5      0.488      0.248\n","                  bike        578       1007      0.588      0.524       0.53      0.277\n","         traffic light       5653      26891      0.745      0.578      0.651      0.256\n","          traffic sign       8221      34915       0.74      0.637      0.703      0.376\n","Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_028/yolov8m_finetuned_1_trial_028\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1362.1¬±475.2 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 8.6Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 9.7it/s 1:04\n","                   all      10000     185578      0.622      0.538      0.567      0.325\n","Speed: 0.5ms preprocess, 1.9ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_028/val\u001b[0m\n","\n","‚úÖ Trial 28 Completed\n","  mAP@0.5: 0.5671\n","  mAP@0.5:0.95: 0.3247\n","  Precision: 0.6220\n","  Recall: 0.5378\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_028</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/2jw4jez5' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/2jw4jez5</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_028/wandb/run-20251128_141008-2jw4jez5/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 14:38:06,867] Trial 28 finished with value: 0.5670742114487848 and parameters: {'imgsz': 768, 'optimizer': 'AdamW', 'lr0': 0.0001816950319371306, 'momentum': 0.8618101733544855, 'weight_decay': 0.00018619454328701798, 'warmup_epochs': 2, 'warmup_momentum': 0.8596224633670249, 'warmup_bias_lr': 0.02471331817804086, 'mosaic': 0.8527374391318845, 'mixup': 0.14369498961035593}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 29/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_029/wandb/run-20251128_143807-dpcasrx3</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/dpcasrx3' target=\"_blank\">yolov8m_finetuned_1_trial_029</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/dpcasrx3' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/dpcasrx3</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 29/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 640\n","  Batch Size: 96 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.000259\n","  Momentum: 0.8549\n","  Weight Decay: 0.000272\n","  Warmup: epochs=2, momentum=0.83, bias_lr=0.002\n","  Mosaic: 0.78\n","  Mixup: 0.17\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=96, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00025947660221022366, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.16524907961546959, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.8549458050763524, mosaic=0.7780592853354106, multi_scale=False, name=yolov8m_finetuned_1_trial_029, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_029, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_029/yolov8m_finetuned_1_trial_029, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0017337914021303494, warmup_epochs=2, warmup_momentum=0.8277014260079567, weight_decay=0.00027188537082400006, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1589.5¬±457.7 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 13.5Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 327.5¬±92.4 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 5.1Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_029/yolov8m_finetuned_1_trial_029/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00025947660221022366, momentum=0.8549458050763524) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.00040782805623600007), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_029/yolov8m_finetuned_1_trial_029\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      38.5G      1.188     0.6558     0.9706       2798        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.6it/s 1:47\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 37.8s\n","                   all      10000     185578      0.611      0.531      0.553      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      38.9G      1.184     0.6494     0.9662       2581        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 37.7s\n","                   all      10000     185578      0.593      0.525      0.553      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      36.8G      1.177     0.6397     0.9597       2939        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 37.9s\n","                   all      10000     185578      0.622      0.505      0.554      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      37.8G      1.176     0.6401     0.9588       2498        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.0s\n","                   all      10000     185578      0.619       0.52      0.552      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      38.1G      1.172     0.6367     0.9578       2892        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.0s\n","                   all      10000     185578      0.618       0.52      0.552      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      38.9G      1.171     0.6332     0.9566       2719        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 37.9s\n","                   all      10000     185578      0.615      0.526      0.553      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      37.4G      1.179     0.6402     0.9595       3138        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 37.7s\n","                   all      10000     185578      0.611      0.524      0.553      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      36.2G      1.175     0.6385     0.9593       2961        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 171/171 1.7it/s 1:42\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.4it/s 38.0s\n","                   all      10000     185578      0.607      0.523      0.553      0.317\n","\n","8 epochs completed in 0.318 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_029/yolov8m_finetuned_1_trial_029/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_029/yolov8m_finetuned_1_trial_029/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_029/yolov8m_finetuned_1_trial_029/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53/53 1.1it/s 49.1s\n","                   all      10000     185578      0.611      0.531      0.553      0.317\n","                person       3220      13265      0.731      0.591      0.657      0.338\n","                 rider        515        649       0.58      0.512      0.512      0.261\n","                   car       9879     102540      0.807      0.729      0.793      0.498\n","                 truck       2689       4247      0.628       0.62      0.636      0.463\n","                   bus       1242       1597      0.633      0.611      0.639      0.493\n","                 train         14         15      0.136     0.0667     0.0201     0.0139\n","                 motor        334        452      0.607      0.496      0.487      0.249\n","                  bike        578       1007      0.542      0.534      0.513      0.264\n","         traffic light       5653      26891      0.731      0.536      0.608      0.237\n","          traffic sign       8221      34915      0.712      0.614      0.667      0.357\n","Speed: 0.1ms preprocess, 0.8ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_029/yolov8m_finetuned_1_trial_029\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1458.1¬±435.7 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 8.2Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 10.9it/s 57.1s\n","                   all      10000     185578      0.614       0.53      0.554      0.319\n","Speed: 0.4ms preprocess, 1.4ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_029/val\u001b[0m\n","\n","‚úÖ Trial 29 Completed\n","  mAP@0.5: 0.5539\n","  mAP@0.5:0.95: 0.3186\n","  Precision: 0.6137\n","  Recall: 0.5299\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_029</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/dpcasrx3' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/dpcasrx3</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_029/wandb/run-20251128_143807-dpcasrx3/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 14:59:21,949] Trial 29 finished with value: 0.5538962140903665 and parameters: {'imgsz': 640, 'optimizer': 'SGD', 'lr0': 0.00025947660221022366, 'momentum': 0.8549458050763524, 'weight_decay': 0.00027188537082400006, 'warmup_epochs': 2, 'warmup_momentum': 0.8277014260079567, 'warmup_bias_lr': 0.0017337914021303494, 'mosaic': 0.7780592853354106, 'mixup': 0.16524907961546959}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 30/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_030/wandb/run-20251128_145922-gh1sdn1a</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/gh1sdn1a' target=\"_blank\">yolov8m_finetuned_1_trial_030</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/gh1sdn1a' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/gh1sdn1a</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 30/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.000195\n","  Momentum: 0.9241\n","  Weight Decay: 0.000543\n","  Warmup: epochs=1, momentum=0.64, bias_lr=0.026\n","  Mosaic: 0.83\n","  Mixup: 0.18\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00019534509666258856, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.182709152923983, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.9241466731188749, mosaic=0.8278923239363011, multi_scale=False, name=yolov8m_finetuned_1_trial_030, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_030, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_030/yolov8m_finetuned_1_trial_030, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.025731624575078944, warmup_epochs=1, warmup_momentum=0.6393878894768946, weight_decay=0.0005430031346760696, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1690.0¬±564.1 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 12.7Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 467.1¬±162.1 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 5.2Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_030/yolov8m_finetuned_1_trial_030/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00019534509666258856, momentum=0.9241466731188749) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005430031346760696), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_030/yolov8m_finetuned_1_trial_030\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      35.2G      1.225     0.6787          1        327        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.7it/s 2:30\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.7s\n","                   all      10000     185578      0.606      0.541      0.573      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      34.9G      1.213      0.668     0.9884        437        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.5s\n","                   all      10000     185578      0.623      0.531      0.574      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8        35G      1.208     0.6626     0.9849        259        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.0s\n","                   all      10000     185578       0.63      0.528      0.574      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8        37G      1.211     0.6661      0.986        413        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.0s\n","                   all      10000     185578      0.636      0.524      0.574      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      37.8G      1.209     0.6633     0.9842        308        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.0s\n","                   all      10000     185578      0.632      0.525      0.574      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      35.3G      1.209     0.6625     0.9845        279        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 42.8s\n","                   all      10000     185578      0.637      0.522      0.574      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      36.7G      1.208     0.6619     0.9859        153        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.5s\n","                   all      10000     185578      0.636      0.522      0.574      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      37.2G      1.206     0.6599     0.9823        341        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 42.9s\n","                   all      10000     185578      0.637      0.523      0.574      0.332\n","\n","8 epochs completed in 0.425 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_030/yolov8m_finetuned_1_trial_030/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_030/yolov8m_finetuned_1_trial_030/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_030/yolov8m_finetuned_1_trial_030/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.5it/s 53.4s\n","                   all      10000     185578      0.637      0.523      0.574      0.332\n","                person       3220      13265      0.786      0.582      0.686      0.358\n","                 rider        515        649      0.644       0.51      0.521      0.276\n","                   car       9879     102540      0.847      0.725      0.815      0.512\n","                 truck       2689       4247      0.648      0.613      0.647      0.474\n","                   bus       1242       1597      0.679      0.594       0.65      0.502\n","                 train         14         15          0          0     0.0132    0.00586\n","                 motor        334        452      0.631      0.493      0.503      0.261\n","                  bike        578       1007      0.623       0.52      0.547      0.289\n","         traffic light       5653      26891       0.76      0.563      0.654      0.259\n","          traffic sign       8221      34915      0.754      0.629      0.709      0.381\n","Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_030/yolov8m_finetuned_1_trial_030\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1430.9¬±442.3 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 9.6Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 9.6it/s 1:05\n","                   all      10000     185578      0.637      0.524      0.575      0.333\n","Speed: 0.5ms preprocess, 1.9ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_030/val\u001b[0m\n","\n","‚úÖ Trial 30 Completed\n","  mAP@0.5: 0.5754\n","  mAP@0.5:0.95: 0.3325\n","  Precision: 0.6374\n","  Recall: 0.5242\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_030</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/gh1sdn1a' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/gh1sdn1a</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_030/wandb/run-20251128_145922-gh1sdn1a/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 15:27:15,477] Trial 30 finished with value: 0.5753678696594505 and parameters: {'imgsz': 768, 'optimizer': 'SGD', 'lr0': 0.00019534509666258856, 'momentum': 0.9241466731188749, 'weight_decay': 0.0005430031346760696, 'warmup_epochs': 1, 'warmup_momentum': 0.6393878894768946, 'warmup_bias_lr': 0.025731624575078944, 'mosaic': 0.8278923239363011, 'mixup': 0.182709152923983}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 31/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_031/wandb/run-20251128_152715-2mytcmjt</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/2mytcmjt' target=\"_blank\">yolov8m_finetuned_1_trial_031</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/2mytcmjt' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/2mytcmjt</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 31/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.000105\n","  Momentum: 0.8886\n","  Weight Decay: 0.000801\n","  Warmup: epochs=3, momentum=0.67, bias_lr=0.009\n","  Mosaic: 0.70\n","  Mixup: 0.15\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00010527627499202455, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.15181187495601245, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.888593460387621, mosaic=0.6997552011797397, multi_scale=False, name=yolov8m_finetuned_1_trial_031, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_031, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_031/yolov8m_finetuned_1_trial_031, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.008846528541806498, warmup_epochs=3, warmup_momentum=0.6702643747902545, weight_decay=0.0008005425935994206, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1738.5¬±487.2 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 13.4Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 720.9¬±461.2 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 4.7Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_031/yolov8m_finetuned_1_trial_031/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00010527627499202455, momentum=0.888593460387621) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0008005425935994206), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_031/yolov8m_finetuned_1_trial_031\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      36.1G      1.232     0.6764      1.002        272        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.7it/s 2:30\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.2s\n","                   all      10000     185578      0.646      0.527      0.569      0.329\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      35.7G      1.225     0.6719     0.9993        204        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:25\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.7s\n","                   all      10000     185578      0.644      0.529      0.571       0.33\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      37.5G       1.22     0.6659     0.9929        350        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.6s\n","                   all      10000     185578      0.622      0.531      0.573      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      38.9G      1.212     0.6612     0.9873        223        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.7s\n","                   all      10000     185578      0.626      0.529      0.573      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      38.9G      1.214     0.6613     0.9853        200        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.6s\n","                   all      10000     185578      0.628      0.526      0.574      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      36.9G      1.207     0.6584     0.9842        284        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 43.2s\n","                   all      10000     185578      0.629      0.525      0.574      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      37.1G      1.212     0.6598     0.9861        377        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 42.8s\n","                   all      10000     185578      0.628      0.527      0.574      0.331\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      37.5G      1.209     0.6561     0.9829        244        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 42.8s\n","                   all      10000     185578      0.629      0.526      0.574      0.331\n","\n","8 epochs completed in 0.424 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_031/yolov8m_finetuned_1_trial_031/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_031/yolov8m_finetuned_1_trial_031/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_031/yolov8m_finetuned_1_trial_031/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.5it/s 53.5s\n","                   all      10000     185578      0.628      0.526      0.574      0.332\n","                person       3220      13265      0.782      0.586      0.686      0.358\n","                 rider        515        649      0.613      0.499      0.517      0.276\n","                   car       9879     102540      0.844      0.725      0.815      0.511\n","                 truck       2689       4247      0.648      0.619      0.654      0.479\n","                   bus       1242       1597      0.674      0.605      0.653      0.505\n","                 train         14         15          0          0     0.0144    0.00753\n","                 motor        334        452      0.609      0.498        0.5      0.259\n","                  bike        578       1007      0.608       0.52      0.543      0.286\n","         traffic light       5653      26891      0.749      0.576      0.653      0.257\n","          traffic sign       8221      34915      0.751      0.633      0.708      0.381\n","Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_031/yolov8m_finetuned_1_trial_031\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1423.2¬±453.3 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 8.4Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 9.6it/s 1:05\n","                   all      10000     185578      0.628      0.528      0.575      0.333\n","Speed: 0.5ms preprocess, 2.0ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_031/val\u001b[0m\n","\n","‚úÖ Trial 31 Completed\n","  mAP@0.5: 0.5752\n","  mAP@0.5:0.95: 0.3329\n","  Precision: 0.6280\n","  Recall: 0.5280\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_031</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/2mytcmjt' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/2mytcmjt</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_031/wandb/run-20251128_152715-2mytcmjt/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 15:55:06,334] Trial 31 finished with value: 0.575203871877037 and parameters: {'imgsz': 768, 'optimizer': 'SGD', 'lr0': 0.00010527627499202455, 'momentum': 0.888593460387621, 'weight_decay': 0.0008005425935994206, 'warmup_epochs': 3, 'warmup_momentum': 0.6702643747902545, 'warmup_bias_lr': 0.008846528541806498, 'mosaic': 0.6997552011797397, 'mixup': 0.15181187495601245}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 32/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_032/wandb/run-20251128_155506-he291c0c</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/he291c0c' target=\"_blank\">yolov8m_finetuned_1_trial_032</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/he291c0c' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/he291c0c</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 32/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: Adam\n","  Learning Rate: 0.000136\n","  Momentum: 0.8970\n","  Weight Decay: 0.000780\n","  Warmup: epochs=3, momentum=0.64, bias_lr=0.013\n","  Mosaic: 0.89\n","  Mixup: 0.19\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.000136470817178904, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.19171669528746693, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.8970109062903935, mosaic=0.8940697783805857, multi_scale=False, name=yolov8m_finetuned_1_trial_032, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_032, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_032/yolov8m_finetuned_1_trial_032, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.012875103273384508, warmup_epochs=3, warmup_momentum=0.636594500298316, weight_decay=0.0007795392208456435, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1210.2¬±592.8 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 13.4Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 416.9¬±89.6 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 4.6Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_032/yolov8m_finetuned_1_trial_032/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.000136470817178904, momentum=0.8970109062903935) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0007795392208456435), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_032/yolov8m_finetuned_1_trial_032\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8        37G      1.219     0.6818     0.9914        363        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.7it/s 2:31\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.8it/s 42.8s\n","                   all      10000     185578      0.627       0.52      0.568      0.327\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      36.6G      1.218     0.6759     0.9875        285        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.7s\n","                   all      10000     185578      0.626      0.519      0.563      0.322\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      37.6G      1.212     0.6747     0.9866        366        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:27\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.5s\n","                   all      10000     185578      0.626      0.518      0.566      0.325\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      37.5G      1.215     0.6752      0.988        305        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.4s\n","                   all      10000     185578      0.627       0.52      0.564      0.322\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      35.4G      1.205     0.6655     0.9817        272        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.3s\n","                   all      10000     185578      0.639      0.542      0.568      0.324\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      35.7G      1.204     0.6616     0.9833        400        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.4s\n","                   all      10000     185578      0.634      0.534      0.567      0.324\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      37.8G      1.199     0.6564     0.9814        281        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.6s\n","                   all      10000     185578      0.647      0.527      0.569      0.326\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      37.9G      1.193     0.6483     0.9791        323        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:26\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.6s\n","                   all      10000     185578      0.639      0.528       0.57      0.326\n","\n","8 epochs completed in 0.427 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_032/yolov8m_finetuned_1_trial_032/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_032/yolov8m_finetuned_1_trial_032/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_032/yolov8m_finetuned_1_trial_032/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.5it/s 53.4s\n","                   all      10000     185578      0.626       0.52      0.568      0.327\n","                person       3220      13265      0.774      0.585      0.683      0.354\n","                 rider        515        649      0.577      0.505      0.512      0.275\n","                   car       9879     102540      0.839      0.727      0.814      0.509\n","                 truck       2689       4247      0.608      0.626      0.632      0.463\n","                   bus       1242       1597      0.703      0.561      0.637      0.493\n","                 train         14         15          0          0    0.00482    0.00198\n","                 motor        334        452      0.649      0.476      0.506      0.259\n","                  bike        578       1007      0.607      0.526       0.54      0.283\n","         traffic light       5653      26891      0.749      0.568       0.65      0.255\n","          traffic sign       8221      34915      0.757      0.623      0.705      0.378\n","Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_032/yolov8m_finetuned_1_trial_032\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1407.6¬±425.3 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 7.1Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 9.6it/s 1:05\n","                   all      10000     185578      0.627       0.52      0.569      0.328\n","Speed: 0.5ms preprocess, 2.0ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_032/val\u001b[0m\n","\n","‚úÖ Trial 32 Completed\n","  mAP@0.5: 0.5688\n","  mAP@0.5:0.95: 0.3280\n","  Precision: 0.6272\n","  Recall: 0.5199\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_032</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/he291c0c' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/he291c0c</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_032/wandb/run-20251128_155506-he291c0c/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 16:23:09,498] Trial 32 finished with value: 0.568762414083914 and parameters: {'imgsz': 768, 'optimizer': 'Adam', 'lr0': 0.000136470817178904, 'momentum': 0.8970109062903935, 'weight_decay': 0.0007795392208456435, 'warmup_epochs': 3, 'warmup_momentum': 0.636594500298316, 'warmup_bias_lr': 0.012875103273384508, 'mosaic': 0.8940697783805857, 'mixup': 0.19171669528746693}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 33/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_033/wandb/run-20251128_162309-cuubzj6b</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/cuubzj6b' target=\"_blank\">yolov8m_finetuned_1_trial_033</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/cuubzj6b' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/cuubzj6b</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 33/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.000119\n","  Momentum: 0.8955\n","  Weight Decay: 0.000932\n","  Warmup: epochs=3, momentum=0.67, bias_lr=0.012\n","  Mosaic: 0.89\n","  Mixup: 0.08\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00011943176232095372, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0797867932405509, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.8954532989965969, mosaic=0.89405609249683, multi_scale=False, name=yolov8m_finetuned_1_trial_033, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_033, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_033/yolov8m_finetuned_1_trial_033, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.011564605733975091, warmup_epochs=3, warmup_momentum=0.6675370754361432, weight_decay=0.0009320154818982343, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1714.5¬±453.2 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 13.0Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 436.7¬±135.9 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 7.5Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_033/yolov8m_finetuned_1_trial_033/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00011943176232095372, momentum=0.8954532989965969) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0009320154818982343), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_033/yolov8m_finetuned_1_trial_033\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      36.7G      1.193     0.6409     0.9812        136        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.7it/s 2:30\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.4s\n","                   all      10000     185578      0.648      0.528      0.572       0.33\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8        36G      1.187     0.6357     0.9786        356        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.3s\n","                   all      10000     185578      0.648      0.532      0.573      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      37.9G      1.184     0.6352     0.9773        209        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.4s\n","                   all      10000     185578       0.62      0.548      0.575      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      38.8G      1.181     0.6313     0.9718        339        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.6s\n","                   all      10000     185578      0.605      0.545      0.575      0.333\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      37.1G      1.181     0.6341      0.974        294        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.4s\n","                   all      10000     185578      0.631       0.53      0.576      0.333\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8      37.1G      1.177     0.6274     0.9705        196        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.5s\n","                   all      10000     185578      0.632      0.529      0.575      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      37.9G      1.178     0.6287     0.9721        196        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.5s\n","                   all      10000     185578      0.631      0.528      0.575      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      36.2G      1.175     0.6267     0.9684        260        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:24\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.3s\n","                   all      10000     185578      0.631      0.528      0.575      0.332\n","\n","8 epochs completed in 0.422 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_033/yolov8m_finetuned_1_trial_033/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_033/yolov8m_finetuned_1_trial_033/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_033/yolov8m_finetuned_1_trial_033/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.5it/s 53.1s\n","                   all      10000     185578      0.604      0.546      0.575      0.333\n","                person       3220      13265      0.742      0.615      0.687      0.358\n","                 rider        515        649      0.604      0.519      0.517      0.276\n","                   car       9879     102540      0.815      0.747      0.817      0.513\n","                 truck       2689       4247      0.622      0.644      0.654       0.48\n","                   bus       1242       1597      0.651      0.613      0.654      0.506\n","                 train         14         15          0          0      0.016     0.0105\n","                 motor        334        452      0.587      0.511      0.498      0.256\n","                  bike        578       1007      0.568      0.555      0.546      0.288\n","         traffic light       5653      26891      0.728      0.597      0.654      0.258\n","          traffic sign       8221      34915      0.727      0.656       0.71      0.382\n","Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_033/yolov8m_finetuned_1_trial_033\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1172.7¬±547.2 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 8.7Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 9.7it/s 1:04\n","                   all      10000     185578      0.607      0.546      0.576      0.334\n","Speed: 0.5ms preprocess, 2.0ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_033/val\u001b[0m\n","\n","‚úÖ Trial 33 Completed\n","  mAP@0.5: 0.5761\n","  mAP@0.5:0.95: 0.3339\n","  Precision: 0.6067\n","  Recall: 0.5458\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_033</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/cuubzj6b' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/cuubzj6b</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_033/wandb/run-20251128_162309-cuubzj6b/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 16:50:53,644] Trial 33 finished with value: 0.576135663258636 and parameters: {'imgsz': 768, 'optimizer': 'SGD', 'lr0': 0.00011943176232095372, 'momentum': 0.8954532989965969, 'weight_decay': 0.0009320154818982343, 'warmup_epochs': 3, 'warmup_momentum': 0.6675370754361432, 'warmup_bias_lr': 0.011564605733975091, 'mosaic': 0.89405609249683, 'mixup': 0.0797867932405509}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 34/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_034/wandb/run-20251128_165053-gmemfz7o</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/gmemfz7o' target=\"_blank\">yolov8m_finetuned_1_trial_034</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/gmemfz7o' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/gmemfz7o</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 34/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.000153\n","  Momentum: 0.9063\n","  Weight Decay: 0.000937\n","  Warmup: epochs=1, momentum=0.55, bias_lr=0.025\n","  Mosaic: 0.88\n","  Mixup: 0.04\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00015346984180265746, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.038448048254907566, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.9063315010084676, mosaic=0.8785089288974699, multi_scale=False, name=yolov8m_finetuned_1_trial_034, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_034, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_034/yolov8m_finetuned_1_trial_034, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.02471430207500159, warmup_epochs=1, warmup_momentum=0.5483156020434448, weight_decay=0.0009371541289392279, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1572.9¬±541.8 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 14.8Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 529.9¬±119.4 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 8.6Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_034/yolov8m_finetuned_1_trial_034/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00015346984180265746, momentum=0.9063315010084676) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0009371541289392279), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_034/yolov8m_finetuned_1_trial_034\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      35.8G      1.175     0.6198     0.9713        316        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.7it/s 2:29\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.2s\n","                   all      10000     185578      0.649      0.533      0.574      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      36.4G      1.171     0.6146     0.9672        251        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:23\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.3s\n","                   all      10000     185578      0.632      0.541      0.576      0.333\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8      35.3G      1.162      0.611     0.9639        279        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:23\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.4s\n","                   all      10000     185578      0.609      0.543      0.576      0.333\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      35.7G      1.168      0.614     0.9657        197        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:23\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.3s\n","                   all      10000     185578      0.607      0.545      0.576      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      37.5G      1.159     0.6093     0.9622        169        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:23\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.2s\n","                   all      10000     185578       0.62      0.548      0.575      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        6/8        38G      1.163      0.609     0.9615        235        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:23\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.5s\n","                   all      10000     185578      0.622      0.552      0.575      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        7/8      37.1G      1.161     0.6091     0.9623        312        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:23\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.4s\n","                   all      10000     185578      0.624      0.551      0.575      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        8/8      38.4G       1.16     0.6085      0.962        307        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:23\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.4s\n","                   all      10000     185578      0.625       0.55      0.575      0.332\n","\n","8 epochs completed in 0.420 hours.\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_034/yolov8m_finetuned_1_trial_034/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_034/yolov8m_finetuned_1_trial_034/weights/best.pt, 52.0MB\n","\n","Validating /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_034/yolov8m_finetuned_1_trial_034/weights/best.pt...\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.5it/s 52.9s\n","                   all      10000     185578      0.633      0.541      0.576      0.333\n","                person       3220      13265      0.759      0.606      0.687      0.358\n","                 rider        515        649      0.604      0.506      0.514      0.274\n","                   car       9879     102540      0.835      0.734      0.817      0.513\n","                 truck       2689       4247      0.641      0.628      0.656       0.48\n","                   bus       1242       1597      0.668      0.604      0.652      0.505\n","                 train         14         15      0.123     0.0667     0.0252      0.013\n","                 motor        334        452      0.618        0.5      0.496      0.255\n","                  bike        578       1007      0.596      0.538      0.545      0.286\n","         traffic light       5653      26891      0.744      0.583      0.654      0.259\n","          traffic sign       8221      34915      0.741      0.645       0.71      0.382\n","Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_034/yolov8m_finetuned_1_trial_034\u001b[0m\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,845,550 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1279.3¬±441.9 MB/s, size: 54.7 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 8.2Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 9.6it/s 1:05\n","                   all      10000     185578      0.633      0.542      0.576      0.334\n","Speed: 0.5ms preprocess, 1.9ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_034/val\u001b[0m\n","\n","‚úÖ Trial 34 Completed\n","  mAP@0.5: 0.5762\n","  mAP@0.5:0.95: 0.3338\n","  Precision: 0.6329\n","  Recall: 0.5420\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">yolov8m_finetuned_1_trial_034</strong> at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/gmemfz7o' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/gmemfz7o</a><br> View project at: <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_034/wandb/run-20251128_165053-gmemfz7o/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ CUDA cache cleared\n","[I 2025-11-28 17:18:28,283] Trial 34 finished with value: 0.5762132136970319 and parameters: {'imgsz': 768, 'optimizer': 'SGD', 'lr0': 0.00015346984180265746, 'momentum': 0.9063315010084676, 'weight_decay': 0.0009371541289392279, 'warmup_epochs': 1, 'warmup_momentum': 0.5483156020434448, 'warmup_bias_lr': 0.02471430207500159, 'mosaic': 0.8785089288974699, 'mixup': 0.038448048254907566}. Best is trial 0 with value: 0.5769275868120581.\n","\n","‚úì Completed 35/40 trials\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_035/wandb/run-20251128_171828-wa9emddk</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/wa9emddk' target=\"_blank\">yolov8m_finetuned_1_trial_035</a></strong> to <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/wa9emddk' target=\"_blank\">https://wandb.ai/m3mahdy-king-saud-university/yolo-bdd100k_yolo_tuning-tuning/runs/wa9emddk</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRIAL 35/40\n","================================================================================\n","üéØ Tuned Parameters:\n","  Image Size: 768\n","  Batch Size: 64 (auto-adjusted for image size)\n","  Optimizer: SGD\n","  Learning Rate: 0.000161\n","  Momentum: 0.9099\n","  Weight Decay: 0.000428\n","  Warmup: epochs=1, momentum=0.51, bias_lr=0.019\n","  Mosaic: 0.82\n","  Mixup: 0.02\n","‚úì Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\n","================================================================================\n","Ultralytics 8.3.233 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tmp/yolov8m_finetuned_1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=8, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001614596240725037, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.023789168654792303, mode=train, model=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/models/yolov8m_finetuned_1/yolov8m_finetuned_1.pt, momentum=0.9098500376932075, mosaic=0.8205379408033115, multi_scale=False, name=yolov8m_finetuned_1_trial_035, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_035, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_035/yolov8m_finetuned_1_trial_035, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.018938388657529233, warmup_epochs=1, warmup_momentum=0.5149307497845836, weight_decay=0.00042786651935909105, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, [192, 384, 576]]         \n","Model summary: 169 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1619.5¬±528.6 MB/s, size: 58.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/train.cache... 16391 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16391/16391 13.7Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 399.4¬±99.8 MB/s, size: 58.2 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /computer_vision_yolo/bdd100k_yolo_tuning/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 7.1Mit/s 0.0s\n","Plotting labels to /content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_035/yolov8m_finetuned_1_trial_035/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0001614596240725037, momentum=0.9098500376932075) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.00042786651935909105), 83 bias(decay=0.0)\n","Image sizes 768 train, 768 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo/tune_train/tune/yolov8m_finetuned_1_tune_20251127_230340/trial_035/yolov8m_finetuned_1_trial_035\u001b[0m\n","Starting training for 8 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        1/8      34.8G      1.172     0.6138      0.969        306        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.7it/s 2:28\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.1s\n","                   all      10000     185578      0.652      0.531      0.574      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        2/8      36.4G      1.167     0.6096      0.965        210        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:23\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.3s\n","                   all      10000     185578      0.653      0.531      0.577      0.334\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        3/8        38G       1.16     0.6041     0.9619        314        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:23\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.2s\n","                   all      10000     185578      0.623      0.551      0.576      0.333\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        4/8      36.4G      1.158     0.6042     0.9603        309        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 257/257 1.8it/s 2:23\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.9it/s 42.4s\n","                   all      10000     185578      0.627       0.55      0.576      0.332\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K        5/8      37.2G      1.156     0.6022     0.9588       2417        768: 93% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ 239/257 1.8it/s 2:14<10.0s"]}],"source":["# RUN HYPERPARAMETER OPTIMIZATION WITH OPTUNA\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('STARTING HYPERPARAMETER OPTIMIZATION')\n","print('=' * 80)\n","print(f'Model: {MODEL_NAME}')\n","print(f'Dataset: {YOLO_DATASET_ROOT.name}')\n","print(f'Number of Trials: {N_TRIALS}')\n","print(f'Epochs per Trial: {EPOCHS_PER_TRIAL}')\n","print(f'Timeout: {TIMEOUT_HOURS} hours' if TIMEOUT_HOURS else 'No timeout')\n","print(f'Device: {device}')\n","print('=' * 80)\n","\n","# Check if resuming from previous run\n","study_pkl_path = TUNE_DIR / 'optuna_study.pkl'\n","checkpoint_log_path = TUNE_DIR / 'checkpoint_log.json'\n","is_resuming = study_pkl_path.exists()\n","\n","if is_resuming:\n","    # Load existing study\n","    print('\\n' + '=' * 80)\n","    print('üîÑ RESUMING PREVIOUS OPTIMIZATION')\n","    print('=' * 80)\n","\n","    with open(study_pkl_path, 'rb') as f:\n","        study = pickle.load(f)\n","\n","    # Load checkpoint log\n","    checkpoint_data = []\n","    if checkpoint_log_path.exists():\n","        with open(checkpoint_log_path, 'r', encoding='utf-8') as f:\n","            checkpoint_data = json.load(f)\n","\n","    # Display resume information\n","    completed_trials = len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])\n","    pruned_trials = len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])\n","    failed_trials = len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL])\n","    total_previous_trials = len(study.trials)\n","\n","    print(f'\\nüìä Previous Run Summary:')\n","    print(f'  Completed Trials: {completed_trials}')\n","    print(f'  Pruned Trials: {pruned_trials}')\n","    print(f'  Failed Trials: {failed_trials}')\n","    print(f'  Total Previous Trials: {total_previous_trials}')\n","\n","    if completed_trials > 0:\n","        best_trial = study.best_trial\n","        print(f'\\nüèÜ Best Result So Far:')\n","        print(f'  Trial: {best_trial.number}')\n","        print(f'  mAP@0.5: {best_trial.value:.4f}')\n","\n","        # Show top 3 completed trials\n","        completed_trial_list = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n","        sorted_trials = sorted(completed_trial_list, key=lambda t: t.value, reverse=True)\n","        top_3_trials = sorted_trials[:3]\n","\n","        print(f'\\nüìà Top 3 Trials:')\n","        for idx, trial in enumerate(top_3_trials, 1):\n","            print(f'  {idx}. Trial {trial.number}: mAP@0.5 = {trial.value:.4f}')\n","\n","    # Show last checkpoint info\n","    if checkpoint_data:\n","        last_checkpoint = checkpoint_data[-1]\n","        print(f'\\nüïê Last Checkpoint:')\n","        print(f'  Timestamp: {last_checkpoint[\"timestamp\"]}')\n","        print(f'  Last Trial: {last_checkpoint[\"trial_number\"]}')\n","        print(f'  Current Best mAP: {last_checkpoint[\"best_map\"]:.4f}')\n","\n","    remaining_trials = N_TRIALS - total_previous_trials\n","    print(f'\\n‚û°Ô∏è  Continuing optimization: {remaining_trials} trials remaining (of {N_TRIALS} total)')\n","    print('=' * 80)\n","\n","else:\n","    # Create new Optuna study\n","    print('\\nüÜï Creating new optimization study')\n","\n","    study = optuna.create_study(\n","        study_name=f'{MODEL_NAME}_optuna_{RUN_TIMESTAMP}',\n","        direction='maximize',  # Maximize mAP@0.5\n","        sampler=optuna.samplers.TPESampler(\n","            seed=42,\n","            n_startup_trials=N_STARTUP_TRIALS,  # Random trials before optimization\n","            multivariate=True,  # Consider parameter interactions\n","            group=True  # Group related parameters\n","        ),\n","        pruner=optuna.pruners.MedianPruner(\n","            n_startup_trials=N_STARTUP_TRIALS,\n","            n_warmup_steps=15,  # Wait before pruning\n","            interval_steps=5  # Check every 5 steps\n","        )\n","    )\n","\n","    # Initialize checkpoint log\n","    checkpoint_data = []\n","\n","# Run optimization\n","start_time = datetime.now()\n","print(f'\\nüöÄ Optimization started at {start_time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n","\n","# Define checkpoint callback\n","def checkpoint_callback(study, trial):\n","    \"\"\"Save checkpoint after each trial completion\"\"\"\n","    print(f'\\n‚úì Completed {len(study.trials)}/{N_TRIALS} trials')\n","\n","    # Update checkpoint log\n","    checkpoint_entry = {\n","        'trial_number': trial.number,\n","        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n","        'trial_state': trial.state.name,\n","        'best_map': study.best_value if len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]) > 0 else 0.0,\n","        'completed_trials': len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]),\n","        'total_trials': len(study.trials)\n","    }\n","    checkpoint_data.append(checkpoint_entry)\n","\n","    # Save checkpoint log\n","    with open(checkpoint_log_path, 'w', encoding='utf-8') as f:\n","        json.dump(checkpoint_data, f, indent=2)\n","\n","    # Save study object\n","    with open(study_pkl_path, 'wb') as f:\n","        pickle.dump(study, f)\n","\n","    # Force garbage collection\n","    gc.collect()\n","\n","try:\n","    study.optimize(\n","        objective,\n","        n_trials=N_TRIALS,\n","        timeout=TIMEOUT_HOURS * 3600 if TIMEOUT_HOURS else None,\n","        show_progress_bar=True,\n","        callbacks=[checkpoint_callback]\n","    )\n","except KeyboardInterrupt:\n","    print('\\n‚ö†Ô∏è  Optimization interrupted by user')\n","    print(f'üíæ Progress saved to: {TUNE_DIR}')\n","    print(f'   - Study checkpoint: {study_pkl_path.name}')\n","    print(f'   - Checkpoint log: {checkpoint_log_path.name}')\n","    print(f'\\nüîÑ To resume: Simply re-run this notebook')\n","except Exception as e:\n","    print(f'\\n‚ùå Optimization failed: {e}')\n","    import traceback\n","    traceback.print_exc()\n","\n","end_time = datetime.now()\n","duration = end_time - start_time\n","\n","print('\\n' + '=' * 80)\n","print('OPTIMIZATION COMPLETED')\n","print('=' * 80)\n","print(f'Started: {start_time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n","print(f'Ended: {end_time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n","print(f'Duration: {duration}')\n","print(f'Total Trials: {len(study.trials)}')\n","print(f'Completed Trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}')\n","print(f'Pruned Trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}')\n","print(f'Failed Trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL])}')\n","print(f'\\nBest Trial: {study.best_trial.number}')\n","print(f'Best mAP@0.5: {study.best_value:.4f}')\n","print('=' * 80)"]},{"cell_type":"markdown","id":"c5ab4d62","metadata":{"id":"c5ab4d62"},"source":["## 9. Save All Trials Summary"]},{"cell_type":"code","execution_count":null,"id":"0a3c5d31","metadata":{"id":"0a3c5d31"},"outputs":[],"source":["# SAVE CONSOLIDATED SUMMARY OF ALL TRIALS\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('SAVING CONSOLIDATED TRIAL SUMMARY')\n","print('=' * 80)\n","\n","# Collect all trial results dynamically from study\n","all_trials_data = []\n","\n","for trial in study.trials:\n","    trial_dir = TUNE_DIR / f\"trial_{trial.number:03d}\"\n","    results_file = trial_dir / \"trial_results.json\"\n","\n","    if results_file.exists():\n","        try:\n","            with open(results_file, 'r') as f:\n","                trial_data = json.load(f)\n","                all_trials_data.append(trial_data)\n","        except Exception as e:\n","            print(f\"‚ö†Ô∏è  Could not read trial {trial.number} results: {e}\")\n","    else:\n","        print(f\"‚ö†Ô∏è  No results file found for trial {trial.number}\")\n","\n","# Create comprehensive summary\n","optimization_summary = {\n","    \"model_name\": MODEL_NAME,\n","    \"dataset\": YOLO_DATASET_ROOT.name,\n","    \"optimization_config\": {\n","        \"n_trials\": N_TRIALS,\n","        \"epochs_per_trial\": EPOCHS_PER_TRIAL,\n","        \"batch_size\": BATCH_SIZE,\n","        \"timeout_hours\": TIMEOUT_HOURS,\n","        \"n_startup_trials\": N_STARTUP_TRIALS,\n","    },\n","    \"optimization_results\": {\n","        \"start_time\": start_time.isoformat(),\n","        \"end_time\": end_time.isoformat(),\n","        \"duration_seconds\": duration.total_seconds(),\n","        \"total_trials\": len(study.trials),\n","        \"completed_trials\": len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]),\n","        \"pruned_trials\": len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]),\n","        \"failed_trials\": len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL]),\n","        \"best_trial_number\": study.best_trial.number,\n","        \"best_map50\": study.best_value,\n","    },\n","    \"best_hyperparameters\": study.best_params,\n","    \"all_trials\": all_trials_data,\n","    \"timestamp\": datetime.now().isoformat(),\n","}\n","\n","# Save consolidated summary as JSON\n","summary_path = TUNE_DIR / f\"{MODEL_NAME}_all_trials_summary.json\"\n","with open(summary_path, 'w') as f:\n","    json.dump(optimization_summary, f, indent=2)\n","\n","print(f'‚úì Consolidated JSON summary saved: {summary_path}')\n","print(f'  Total trials saved: {len(all_trials_data)}')\n","\n","# Create CSV summary for easy analysis\n","csv_data = []\n","for trial_data in all_trials_data:\n","    row = {\n","        'trial_number': trial_data.get('trial_number'),\n","        'status': trial_data.get('status'),\n","        'map50': trial_data.get('validation_metrics', {}).get('map50'),\n","        'map50_95': trial_data.get('validation_metrics', {}).get('map50_95'),\n","        'precision': trial_data.get('validation_metrics', {}).get('precision'),\n","        'recall': trial_data.get('validation_metrics', {}).get('recall'),\n","        'error_type': trial_data.get('error_type', '')  # Include error type if failed\n","    }\n","    # Add hyperparameters\n","    for key, value in trial_data.get('hyperparameters', {}).items():\n","        row[f'hp_{key}'] = value\n","    # Flag best trial\n","    row['best_trial'] = trial_data.get('trial_number') == study.best_trial.number\n","    csv_data.append(row)\n","\n","df_trials = pd.DataFrame(csv_data)\n","\n","# Sort CSV by mAP@0.5 descending (best first)\n","df_trials.sort_values(by='map50', ascending=False, inplace=True)\n","\n","# Save CSV\n","csv_path = TUNE_DIR / f\"{MODEL_NAME}_all_trials_summary.csv\"\n","df_trials.to_csv(csv_path, index=False)\n","\n","print(f'‚úì CSV summary saved: {csv_path}')\n","print(f'  Columns: {len(df_trials.columns)}, Rows: {len(df_trials)}')\n","print('=' * 80)\n","\n","# Display summary statistics\n","if len(df_trials) > 0:\n","    print('\\nüìä Trial Summary Statistics:')\n","    print(f'  Completed Trials: {len(df_trials[df_trials[\"status\"] == \"completed\"])}')\n","    print(f'  Failed Trials: {len(df_trials[df_trials[\"status\"] == \"failed\"])}')\n","\n","    completed_trials = df_trials[df_trials['status'] == 'completed']\n","    if len(completed_trials) > 0:\n","        best_trial_row = completed_trials.loc[completed_trials[\"map50\"].idxmax()]\n","        print(f'\\n  mAP@0.5 Statistics:')\n","        print(f'    Best: {best_trial_row[\"map50\"]:.4f} (Trial {best_trial_row[\"trial_number\"]})')\n","        print(f'    Worst: {completed_trials[\"map50\"].min():.4f}')\n","        print(f'    Mean: {completed_trials[\"map50\"].mean():.4f}')\n","        print(f'    Std: {completed_trials[\"map50\"].std():.4f}')\n","        print(f'    Median: {completed_trials[\"map50\"].median():.4f}')\n","print('=' * 80)"]},{"cell_type":"markdown","id":"923833ab","metadata":{"id":"923833ab"},"source":["## 10. Save Best Hyperparameters"]},{"cell_type":"code","execution_count":null,"id":"58d702ef","metadata":{"id":"58d702ef"},"outputs":[],"source":["# SAVE BEST HYPERPARAMETERS\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('SAVING BEST HYPERPARAMETERS')\n","print('=' * 80)\n","\n","# Extract best parameters from study\n","best_params = study.best_params\n","best_trial = study.best_trial\n","\n","print(f'\\nüèÜ Best Trial: {best_trial.number}')\n","print(f'   Best mAP@0.5: {study.best_value:.4f}')\n","print('\\nüìã Best Hyperparameters:')\n","for param_name, param_value in best_params.items():\n","    print(f'   {param_name}: {param_value}')\n","\n","# Save best hyperparameters to JSON\n","best_params_json = TUNE_DIR / 'best_hyperparameters.json'\n","with open(best_params_json, 'w') as f:\n","    json.dump({\n","        'model': MODEL_NAME,\n","        'dataset_root': str(YOLO_DATASET_ROOT),\n","        'data_yaml_path': str(DATA_YAML_PATH),\n","        'optimization_results': {\n","            'best_trial': study.best_trial.number,\n","            'best_map50': study.best_value,\n","            'total_trials': len(study.trials),\n","            'optimization_duration': str(duration),\n","        },\n","        'hyperparameters': best_params,\n","        'timestamp': datetime.now().isoformat(),\n","        'notes': 'Use these hyperparameters for training. Add epochs, batch, imgsz, device, and other training settings.'\n","    }, f, indent=2)\n","\n","print(f'\\n‚úì Best hyperparameters saved to: {best_params_json}')\n","\n","# Save to YAML format (ready for YOLO training)\n","best_params_yaml = TUNE_DIR / 'best_hyperparameters.yaml'\n","with open(best_params_yaml, 'w') as f:\n","    yaml.dump(best_params, f, default_flow_style=False, sort_keys=False)\n","\n","print(f'‚úì Best hyperparameters saved to: {best_params_yaml}')\n","\n","print('\\nüìã Best Hyperparameters Summary:')\n","print(f'  Optimizer: {best_params.get(\"optimizer\", \"N/A\")}')\n","print(f'  Learning Rate: {best_params.get(\"lr0\", 0):.6f}')\n","print(f'  Momentum: {best_params.get(\"momentum\", 0):.4f}')\n","print(f'  Weight Decay: {best_params.get(\"weight_decay\", 0):.6f}')\n","\n","print('=' * 80)"]},{"cell_type":"markdown","id":"24aed975","metadata":{"id":"24aed975"},"source":["## 11. Visualize Optimization Results"]},{"cell_type":"code","execution_count":null,"id":"26d33d0e","metadata":{"id":"26d33d0e"},"outputs":[],"source":["# ============================================================================\n","# VISUALIZE OPTIMIZATION RESULTS: HISTORY, PARAMETER IMPORTANCE, SLICE PLOTS\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('GENERATING OPTIMIZATION VISUALIZATIONS')\n","print('=' * 80)\n","\n","if len(study.trials) == 0:\n","    print(\"‚ö†Ô∏è  No trials found in study, skipping visualization.\")\n","else:\n","    timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')\n","\n","    # -----------------------------\n","    # 1Ô∏è‚É£ Optimization History Plot\n","    # -----------------------------\n","    try:\n","        print('\\nüìà Creating optimization history plot...')\n","        fig_history = plot_optimization_history(study)\n","        fig_history.update_layout(\n","            title=f'{MODEL_NAME} - Hyperparameter Optimization History',\n","            xaxis_title='Trial Number',\n","            yaxis_title='mAP@0.5',\n","            template='plotly_white',\n","            width=1200,\n","            height=600\n","        )\n","        fig_history.show()\n","\n","        # Save HTML with timestamp\n","        optimization_history_path = TUNE_DIR / f'optimization_history_{timestamp_str}.html'\n","        fig_history.write_html(str(optimization_history_path))\n","        print(f'‚úì HTML saved to: {optimization_history_path}')\n","\n","    except Exception as history_error:\n","        print(f'‚ùå Failed to create optimization history plot: {history_error}')\n","\n","    # -----------------------------\n","    # 2Ô∏è‚É£ Parameter Importance Plot\n","    # -----------------------------\n","    try:\n","        print('\\nüìä Creating parameter importance plot...')\n","        fig_importance = plot_param_importances(study)\n","        fig_importance.update_layout(\n","            title=f'{MODEL_NAME} - Hyperparameter Importance',\n","            xaxis_title='Importance',\n","            yaxis_title='Parameter',\n","            template='plotly_white',\n","            width=1200,\n","            height=800\n","        )\n","        fig_importance.show()\n","\n","        # Save HTML with timestamp\n","        param_importance_path = TUNE_DIR / f'parameter_importance_{timestamp_str}.html'\n","        fig_importance.write_html(str(param_importance_path))\n","        print(f'‚úì HTML saved to: {param_importance_path}')\n","\n","        # Save PNG with timestamp AND consistent name\n","        try:\n","            # Try kaleido\n","            param_importance_img_ts = TUNE_DIR / f'parameter_importance_{timestamp_str}.png'\n","            fig_importance.write_image(str(param_importance_img_ts), width=1200, height=800, scale=2)\n","            print(f'‚úì PNG saved to: {param_importance_img_ts}')\n","\n","            # Consistent name for PDF report\n","            param_importance_img = TUNE_DIR / 'parameter_importance.png'\n","            fig_importance.write_image(str(param_importance_img), width=1200, height=800, scale=2)\n","            print(f'‚úì PNG saved to: {param_importance_img} (for PDF report)')\n","        except Exception as png_error:\n","            try:\n","                # Fallback to orca\n","                param_importance_img_ts = TUNE_DIR / f'parameter_importance_{timestamp_str}.png'\n","                fig_importance.write_image(str(param_importance_img_ts), format='png', width=1200, height=800, engine='orca')\n","                print(f'‚úì PNG saved to: {param_importance_img_ts}')\n","\n","                param_importance_img = TUNE_DIR / 'parameter_importance.png'\n","                fig_importance.write_image(str(param_importance_img), format='png', width=1200, height=800, engine='orca')\n","                print(f'‚úì PNG saved to: {param_importance_img} (for PDF report)')\n","            except:\n","                print(f'‚ö†Ô∏è  Could not save PNG: {png_error}')\n","                param_importance_img = None\n","\n","    except (RuntimeError, ValueError) as importance_error:\n","        print(f'‚ö†Ô∏è  Could not generate parameter importance plot: {importance_error}')\n","        print('  (This can happen when trials have insufficient data variation)')\n","        param_importance_img = None\n","\n","    # -----------------------------\n","    # 3Ô∏è‚É£ Parameter Slice Plots\n","    # -----------------------------\n","    except (RuntimeError, ValueError) as importance_error:\n","        print(f'‚ö†Ô∏è  Could not generate parameter importance plot: {importance_error}')\n","        print('  (This can happen when trials have insufficient data variation)')\n","\n","    # -----------------------------\n","    # 3Ô∏è‚É£ Parameter Slice Plots\n","    # -----------------------------\n","    try:\n","        print('\\nüîç Creating parameter slice plots...')\n","        fig_slice = plot_slice(study)\n","        fig_slice.update_layout(\n","            title=f'{MODEL_NAME} - Parameter Slice Plot',\n","            template='plotly_white',\n","            width=1400,\n","            height=1000\n","        )\n","        fig_slice.show()\n","\n","        # Save HTML with timestamp\n","        slice_path = TUNE_DIR / f'parameter_slice_{timestamp_str}.html'\n","        fig_slice.write_html(str(slice_path))\n","        print(f'‚úì HTML saved to: {slice_path}')\n","\n","        # Save PNG with timestamp AND consistent name\n","        try:\n","            # Try kaleido\n","            slice_img_path_ts = TUNE_DIR / f'parameter_slice_{timestamp_str}.png'\n","            fig_slice.write_image(str(slice_img_path_ts), width=1400, height=1000, scale=2)\n","            print(f'‚úì PNG saved to: {slice_img_path_ts}')\n","\n","            # Consistent name for PDF report\n","            slice_img_path = TUNE_DIR / 'parameter_slice.png'\n","            fig_slice.write_image(str(slice_img_path), width=1400, height=1000, scale=2)\n","            print(f'‚úì PNG saved to: {slice_img_path} (for PDF report)')\n","        except Exception as png_error:\n","            try:\n","                # Fallback to orca\n","                slice_img_path_ts = TUNE_DIR / f'parameter_slice_{timestamp_str}.png'\n","                fig_slice.write_image(str(slice_img_path_ts), format='png', width=1400, height=1000, engine='orca')\n","                print(f'‚úì PNG saved to: {slice_img_path_ts}')\n","\n","                slice_img_path = TUNE_DIR / 'parameter_slice.png'\n","                fig_slice.write_image(str(slice_img_path), format='png', width=1400, height=1000, engine='orca')\n","                print(f'‚úì PNG saved to: {slice_img_path} (for PDF report)')\n","            except:\n","                print(f'‚ö†Ô∏è  Could not save PNG: {png_error}')\n","\n","    except Exception as slice_error:\n","        print(f'‚ö†Ô∏è  Could not generate parameter slice plot: {slice_error}')"]},{"cell_type":"markdown","id":"585a97a5","metadata":{"id":"585a97a5"},"source":["## 12. Generate Tuning PDF Report\n","\n","Create a comprehensive PDF report with optimization results, visualizations, and model performance."]},{"cell_type":"code","execution_count":null,"id":"6e3c3580","metadata":{"id":"6e3c3580"},"outputs":[],"source":["# GENERATE Tuning PDF REPORT\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('GENERATING COMPREHENSIVE TUNING PDF REPORT')\n","print('=' * 80)\n","\n","# Use already extracted best parameters and trial data from previous sections\n","best_params = study.best_params\n","best_trial = study.best_trial\n","\n","print(f'\\nüìä Preparing comprehensive report with {len(study.trials)} trials')\n","print(f'   Best Trial: {best_trial.number}')\n","print(f'   Best mAP@0.5: {study.best_value:.4f}')\n","\n","# Compile all trials data into DataFrame for PDF report\n","print('\\nüìã Compiling trials data for report...')\n","trials_data_for_pdf = []\n","\n","for trial in study.trials:\n","    trial_dir = TUNE_DIR / f'trial_{trial.number}'\n","    trial_json_path = trial_dir / 'trial_results.json'\n","\n","    if trial_json_path.exists():\n","        with open(trial_json_path, 'r', encoding='utf-8') as f:\n","            trial_data = json.load(f)\n","\n","        # Extract hyperparameters\n","        hyperparams = trial_data.get('hyperparameters', {})\n","\n","        # Create row with trial info\n","        row_data = {\n","            'trial': trial.number,\n","            'state': trial.state.name,\n","            'mAP@0.5': trial.value if trial.value is not None else 0.0,\n","        }\n","\n","        # Add all hyperparameters\n","        row_data.update(hyperparams)\n","\n","        trials_data_for_pdf.append(row_data)\n","    else:\n","        # Trial without saved data (failed/pruned)\n","        row_data = {\n","            'trial': trial.number,\n","            'state': trial.state.name,\n","            'mAP@0.5': trial.value if trial.value is not None else 0.0,\n","        }\n","        trials_data_for_pdf.append(row_data)\n","\n","# Create DataFrame and sort by mAP@0.5\n","df_trials = pd.DataFrame(trials_data_for_pdf)\n","df_trials_sorted = df_trials.sort_values('mAP@0.5', ascending=False)\n","\n","print(f'‚úì Compiled {len(df_trials)} trials for report')\n","\n","# Create tuning PDF report\n","pdf_report_path = TUNE_DIR / f'{MODEL_NAME}_tuning_report.pdf'\n","\n","doc = SimpleDocTemplate(str(pdf_report_path), pagesize=A4,\n","                       rightMargin=30, leftMargin=30,\n","                       topMargin=30, bottomMargin=30)\n","\n","story = []\n","styles = getSampleStyleSheet()\n","\n","# Custom styles\n","title_style = ParagraphStyle(\n","    'CustomTitle',\n","    parent=styles['Heading1'],\n","    fontSize=24,\n","    textColor=rl_colors.HexColor('#2c3e50'),\n","    spaceAfter=30,\n","    alignment=TA_CENTER\n",")\n","\n","heading_style = ParagraphStyle(\n","    'CustomHeading',\n","    parent=styles['Heading2'],\n","    fontSize=16,\n","    textColor=rl_colors.HexColor('#34495e'),\n","    spaceAfter=12,\n","    spaceBefore=20\n",")\n","\n","small_style = ParagraphStyle(\n","    'SmallText',\n","    parent=styles['Normal'],\n","    fontSize=7,\n","    wordWrap='CJK'\n",")\n","\n","# Title\n","story.append(Paragraph(f'{MODEL_NAME} Hyperparameter Tuning Report', title_style))\n","story.append(Paragraph(f'Generated: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}', styles['Normal']))\n","story.append(Spacer(1, 20))\n","\n","# ===== SECTION 1: OVERVIEW =====\n","story.append(Paragraph('1. Optimization Overview', heading_style))\n","\n","info_data = [\n","    ['Property', 'Value'],\n","    ['Model', MODEL_NAME],\n","    ['Dataset', YOLO_DATASET_ROOT.name],\n","    ['Total Trials', str(len(study.trials))],\n","    ['Completed Trials', str(len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]))],\n","    ['Failed Trials', str(len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL]))],\n","    ['Best Trial', str(study.best_trial.number)],\n","    ['Best mAP@0.5', f'{study.best_value:.4f}'],\n","    ['Optimization Duration', str(duration)],\n","]\n","\n","info_table = Table(info_data, colWidths=[2.5*inch, 3.5*inch])\n","info_table.setStyle(TableStyle([\n","    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#2c3e50')),\n","    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","    ('BACKGROUND', (0, 1), (-1, -1), rl_colors.HexColor('#ecf0f1')),\n","    ('TEXTCOLOR', (0, 1), (-1, -1), rl_colors.black),\n","    ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n","    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","    ('FONTNAME', (0, 1), (0, -1), 'Helvetica-Bold'),\n","    ('FONTSIZE', (0, 0), (-1, -1), 10),\n","    ('BOTTOMPADDING', (0, 0), (-1, -1), 8),\n","    ('TOPPADDING', (0, 0), (-1, -1), 8),\n","    ('GRID', (0, 0), (-1, -1), 1, rl_colors.grey)\n","]))\n","story.append(info_table)\n","story.append(Spacer(1, 20))\n","\n","# ===== SECTION 2: CONFIGURATION =====\n","story.append(Paragraph('2. Optimization Configuration', heading_style))\n","\n","opt_config_data = [\n","    ['Parameter', 'Value'],\n","    ['Total Trials', str(N_TRIALS)],\n","    ['Epochs per Trial', str(EPOCHS_PER_TRIAL)],\n","    ['Batch Size', str(BATCH_SIZE)],\n","    ['Startup Trials (TPE)', str(N_STARTUP_TRIALS)],\n","    ['Device', device],\n","    ['Number of Classes', str(NUM_CLASSES)],\n","    ['Train Images', str(dataset_stats.get('train', {}).get('images', 'N/A'))],\n","    ['Val Images', str(dataset_stats.get('val', {}).get('images', 'N/A'))],\n","]\n","\n","opt_config_table = Table(opt_config_data, colWidths=[3*inch, 3*inch])\n","opt_config_table.setStyle(TableStyle([\n","    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#95a5a6')),\n","    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n","    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","    ('FONTSIZE', (0, 0), (-1, 0), 11),\n","    ('FONTSIZE', (0, 1), (-1, -1), 9),\n","    ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n","    ('TOPPADDING', (0, 0), (-1, -1), 6),\n","    ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n","    ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n","]))\n","story.append(opt_config_table)\n","story.append(Spacer(1, 20))\n","\n","# ===== SECTION 3: BEST HYPERPARAMETERS =====\n","story.append(PageBreak())\n","story.append(Paragraph('3. Best Hyperparameters', heading_style))\n","\n","hyperparam_data = [['Parameter', 'Value', 'Description']]\n","param_descriptions = {\n","    'optimizer': 'Optimization algorithm',\n","    'lr0': 'Initial learning rate',\n","    'lrf': 'Final learning rate factor',\n","    'momentum': 'SGD momentum / Adam beta1',\n","    'weight_decay': 'Weight decay (L2 penalty)',\n","    'warmup_epochs': 'Warmup epochs',\n","    'warmup_momentum': 'Warmup momentum',\n","    'box': 'Box loss gain',\n","    'cls': 'Classification loss gain',\n","    'dfl': 'Distribution focal loss gain',\n","    'hsv_h': 'HSV-Hue augmentation',\n","    'hsv_s': 'HSV-Saturation augmentation',\n","    'hsv_v': 'HSV-Value augmentation',\n","    'degrees': 'Rotation augmentation',\n","    'translate': 'Translation augmentation',\n","    'scale': 'Scale augmentation',\n","    'shear': 'Shear augmentation',\n","    'perspective': 'Perspective augmentation',\n","    'flipud': 'Vertical flip probability',\n","    'fliplr': 'Horizontal flip probability',\n","    'mosaic': 'Mosaic augmentation',\n","    'mixup': 'Mixup augmentation',\n","    'copy_paste': 'Copy-paste augmentation',\n","}\n","\n","for param_key, param_value in best_params.items():\n","    desc = param_descriptions.get(param_key, '')\n","    formatted_value = f'{param_value:.6f}' if isinstance(param_value, float) else str(param_value)\n","    hyperparam_data.append([param_key, formatted_value, desc])\n","\n","hyperparam_table = Table(hyperparam_data, colWidths=[1.8*inch, 1.5*inch, 2.7*inch])\n","hyperparam_table.setStyle(TableStyle([\n","    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#3498db')),\n","    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","    ('ALIGN', (0, 0), (1, -1), 'CENTER'),\n","    ('ALIGN', (2, 1), (2, -1), 'LEFT'),\n","    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","    ('FONTSIZE', (0, 0), (-1, 0), 10),\n","    ('FONTSIZE', (0, 1), (-1, -1), 8),\n","    ('BOTTOMPADDING', (0, 0), (-1, -1), 5),\n","    ('TOPPADDING', (0, 0), (-1, -1), 5),\n","    ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n","    ('GRID', (0, 0), (-1, -1), 1, rl_colors.black),\n","    ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n","]))\n","story.append(hyperparam_table)\n","story.append(Spacer(1, 20))\n","\n","# ===== SECTION 4: TOP 20 TRIALS WITH HYPERPARAMETERS =====\n","story.append(PageBreak())\n","story.append(Paragraph('4. Top 20 Trials Performance', heading_style))\n","\n","# Create detailed top trials table with key hyperparameters\n","top_trials_data = [['#', 'mAP@0.5', 'Optimizer', 'lr0', 'momentum', 'mixup', 'mosaic']]\n","for idx, (_, row) in enumerate(df_trials_sorted.head(20).iterrows(), 1):\n","    top_trials_data.append([\n","        str(idx),\n","        f\"{row['mAP@0.5']:.4f}\",\n","        str(row.get('optimizer', 'N/A'))[:6],\n","        f\"{row.get('lr0', 0):.4f}\" if 'lr0' in row else 'N/A',\n","        f\"{row.get('momentum', 0):.3f}\" if 'momentum' in row else 'N/A',\n","        f\"{row.get('mixup', 0):.2f}\" if 'mixup' in row else 'N/A',\n","        f\"{row.get('mosaic', 0):.2f}\" if 'mosaic' in row else 'N/A',\n","    ])\n","\n","top_trials_table = Table(top_trials_data, colWidths=[0.4*inch, 0.9*inch, 0.9*inch, 0.8*inch, 0.9*inch, 0.8*inch, 0.8*inch])\n","top_trials_table.setStyle(TableStyle([\n","    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#27ae60')),\n","    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n","    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","    ('FONTSIZE', (0, 0), (-1, 0), 9),\n","    ('FONTSIZE', (0, 1), (-1, -1), 7),\n","    ('BOTTOMPADDING', (0, 0), (-1, -1), 4),\n","    ('TOPPADDING', (0, 0), (-1, -1), 4),\n","    ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n","    ('GRID', (0, 0), (-1, -1), 0.5, rl_colors.black)\n","]))\n","story.append(top_trials_table)\n","story.append(Spacer(1, 15))\n","\n","# Detailed hyperparameters for top 5 trials\n","story.append(PageBreak())\n","story.append(Paragraph('4.1 Detailed Hyperparameters - Top 5 Trials', heading_style))\n","for rank, (_, row) in enumerate(df_trials_sorted.head(5).iterrows(), 1):\n","    story.append(Paragraph(f'<b>Rank {rank}: Trial {int(row[\"trial\"])} (mAP@0.5: {row[\"mAP@0.5\"]:.4f})</b>', styles['Normal']))\n","\n","    trial_params_text = []\n","    for param_key in sorted(best_params.keys()):\n","        if param_key in row:\n","            value = row[param_key]\n","            formatted_val = f'{value:.6f}' if isinstance(value, float) else str(value)\n","            trial_params_text.append(f'{param_key}={formatted_val}')\n","\n","    params_str = ', '.join(trial_params_text)\n","    story.append(Paragraph(params_str, small_style))\n","    story.append(Spacer(1, 10))\n","\n","# ===== SECTION 5: OPTIMIZATION VISUALIZATIONS =====\n","story.append(PageBreak())\n","story.append(Paragraph('5. Optimization Visualizations', heading_style))\n","\n","print('\\nüìä Generating custom visualizations for PDF report...')\n","\n","# Prepare data for completed trials only\n","completed_trials_df = df_trials_sorted[df_trials_sorted['state'] == 'COMPLETE'].copy()\n","\n","if len(completed_trials_df) > 0:\n","    # 5.1 mAP@0.5 Progress Over Trials\n","    story.append(Paragraph('5.1 mAP@0.5 Progress Over Trials', styles['Heading3']))\n","\n","    fig, ax = plt.subplots(figsize=(10, 5))\n","    ax.plot(completed_trials_df['trial'], completed_trials_df['mAP@0.5'],\n","            marker='o', linestyle='-', linewidth=2, markersize=6, color='#3498db', alpha=0.7)\n","    ax.axhline(y=study.best_value, color='#e74c3c', linestyle='--', linewidth=2,\n","               label=f'Best: {study.best_value:.4f}')\n","    ax.set_xlabel('Trial Number', fontsize=12, fontweight='bold')\n","    ax.set_ylabel('mAP@0.5', fontsize=12, fontweight='bold')\n","    ax.set_title(f'{MODEL_NAME} - mAP@0.5 Progress', fontsize=14, fontweight='bold')\n","    ax.grid(True, alpha=0.3)\n","    ax.legend(fontsize=10)\n","    plt.tight_layout()\n","\n","    map_progress_img = TUNE_DIR / 'report_map_progress.png'\n","    plt.savefig(map_progress_img, dpi=150, bbox_inches='tight')\n","    plt.close()\n","\n","    story.append(Image(str(map_progress_img), width=6.5*inch, height=3.25*inch))\n","    story.append(Spacer(1, 15))\n","    print(f'‚úì mAP progress chart saved: {map_progress_img}')\n","\n","    # 5.2 Learning Rate vs mAP@0.5\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.2 Learning Rate Impact on Performance', styles['Heading3']))\n","\n","    if 'lr0' in completed_trials_df.columns:\n","        fig, ax = plt.subplots(figsize=(10, 5))\n","        scatter = ax.scatter(completed_trials_df['lr0'], completed_trials_df['mAP@0.5'],\n","                           c=completed_trials_df['mAP@0.5'], cmap='RdYlGn',\n","                           s=100, alpha=0.6, edgecolors='black', linewidth=0.5)\n","        ax.set_xlabel('Learning Rate (lr0)', fontsize=12, fontweight='bold')\n","        ax.set_ylabel('mAP@0.5', fontsize=12, fontweight='bold')\n","        ax.set_title(f'{MODEL_NAME} - Learning Rate vs Performance', fontsize=14, fontweight='bold')\n","        ax.grid(True, alpha=0.3)\n","        cbar = plt.colorbar(scatter, ax=ax)\n","        cbar.set_label('mAP@0.5', fontsize=10)\n","        plt.tight_layout()\n","\n","        lr_impact_img = TUNE_DIR / 'report_lr_impact.png'\n","        plt.savefig(lr_impact_img, dpi=150, bbox_inches='tight')\n","        plt.close()\n","\n","        story.append(Image(str(lr_impact_img), width=6.5*inch, height=3.25*inch))\n","        story.append(Spacer(1, 15))\n","        print(f'‚úì Learning rate impact chart saved: {lr_impact_img}')\n","\n","    # 5.3 Optimizer Comparison\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.3 Optimizer Performance Comparison', styles['Heading3']))\n","\n","    if 'optimizer' in completed_trials_df.columns:\n","        fig, ax = plt.subplots(figsize=(10, 5))\n","\n","        optimizer_stats = completed_trials_df.groupby('optimizer')['mAP@0.5'].agg(['mean', 'max', 'count'])\n","        optimizer_stats = optimizer_stats.sort_values('mean', ascending=False)\n","\n","        x_pos = range(len(optimizer_stats))\n","        ax.bar(x_pos, optimizer_stats['mean'], alpha=0.7, color='#3498db',\n","               label='Mean mAP@0.5', edgecolor='black', linewidth=1)\n","        ax.scatter(x_pos, optimizer_stats['max'], color='#e74c3c', s=100,\n","                  label='Max mAP@0.5', zorder=5, edgecolors='black', linewidth=1)\n","\n","        ax.set_xlabel('Optimizer', fontsize=12, fontweight='bold')\n","        ax.set_ylabel('mAP@0.5', fontsize=12, fontweight='bold')\n","        ax.set_title(f'{MODEL_NAME} - Optimizer Performance Comparison', fontsize=14, fontweight='bold')\n","        ax.set_xticks(x_pos)\n","        ax.set_xticklabels(optimizer_stats.index, rotation=45, ha='right')\n","        ax.legend(fontsize=10)\n","        ax.grid(True, alpha=0.3, axis='y')\n","\n","        # Add count annotations\n","        for i, (opt, row) in enumerate(optimizer_stats.iterrows()):\n","            ax.text(i, row['mean'] + 0.002, f\"n={int(row['count'])}\",\n","                   ha='center', va='bottom', fontsize=9)\n","\n","        plt.tight_layout()\n","\n","        optimizer_comp_img = TUNE_DIR / 'report_optimizer_comparison.png'\n","        plt.savefig(optimizer_comp_img, dpi=150, bbox_inches='tight')\n","        plt.close()\n","\n","        story.append(Image(str(optimizer_comp_img), width=6.5*inch, height=3.25*inch))\n","        story.append(Spacer(1, 15))\n","        print(f'‚úì Optimizer comparison chart saved: {optimizer_comp_img}')\n","\n","    # 5.4 Augmentation Parameters vs Performance\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.4 Augmentation Parameters Impact', styles['Heading3']))\n","\n","    # Create 2x2 subplot for key augmentation parameters\n","    aug_params = ['mixup', 'mosaic', 'degrees', 'scale']\n","    available_aug_params = [p for p in aug_params if p in completed_trials_df.columns]\n","\n","    if len(available_aug_params) >= 2:\n","        n_plots = min(len(available_aug_params), 4)\n","        fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n","        axes = axes.flatten()\n","\n","        for idx, param in enumerate(available_aug_params[:4]):\n","            ax = axes[idx]\n","            scatter = ax.scatter(completed_trials_df[param], completed_trials_df['mAP@0.5'],\n","                               c=completed_trials_df['mAP@0.5'], cmap='RdYlGn',\n","                               s=60, alpha=0.6, edgecolors='black', linewidth=0.5)\n","            ax.set_xlabel(param, fontsize=10, fontweight='bold')\n","            ax.set_ylabel('mAP@0.5', fontsize=10, fontweight='bold')\n","            ax.set_title(f'{param.capitalize()} Impact', fontsize=11, fontweight='bold')\n","            ax.grid(True, alpha=0.3)\n","\n","        # Hide unused subplots\n","        for idx in range(len(available_aug_params), 4):\n","            axes[idx].axis('off')\n","\n","        plt.tight_layout()\n","\n","        aug_impact_img = TUNE_DIR / 'report_augmentation_impact.png'\n","        plt.savefig(aug_impact_img, dpi=150, bbox_inches='tight')\n","        plt.close()\n","\n","        story.append(Image(str(aug_impact_img), width=6.5*inch, height=5.2*inch))\n","        story.append(Spacer(1, 15))\n","        print(f'‚úì Augmentation impact chart saved: {aug_impact_img}')\n","\n","    # 5.5 Weight Decay and Momentum vs Performance\n","    story.append(PageBreak())\n","    story.append(Paragraph('5.5 Regularization Parameters Impact', styles['Heading3']))\n","\n","    if 'weight_decay' in completed_trials_df.columns and 'momentum' in completed_trials_df.columns:\n","        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n","\n","        # Weight Decay\n","        scatter1 = ax1.scatter(completed_trials_df['weight_decay'], completed_trials_df['mAP@0.5'],\n","                              c=completed_trials_df['mAP@0.5'], cmap='RdYlGn',\n","                              s=80, alpha=0.6, edgecolors='black', linewidth=0.5)\n","        ax1.set_xlabel('Weight Decay', fontsize=11, fontweight='bold')\n","        ax1.set_ylabel('mAP@0.5', fontsize=11, fontweight='bold')\n","        ax1.set_title('Weight Decay Impact', fontsize=12, fontweight='bold')\n","        ax1.grid(True, alpha=0.3)\n","\n","        # Momentum\n","        scatter2 = ax2.scatter(completed_trials_df['momentum'], completed_trials_df['mAP@0.5'],\n","                              c=completed_trials_df['mAP@0.5'], cmap='RdYlGn',\n","                              s=80, alpha=0.6, edgecolors='black', linewidth=0.5)\n","        ax2.set_xlabel('Momentum', fontsize=11, fontweight='bold')\n","        ax2.set_ylabel('mAP@0.5', fontsize=11, fontweight='bold')\n","        ax2.set_title('Momentum Impact', fontsize=12, fontweight='bold')\n","        ax2.grid(True, alpha=0.3)\n","\n","        plt.tight_layout()\n","\n","        reg_impact_img = TUNE_DIR / 'report_regularization_impact.png'\n","        plt.savefig(reg_impact_img, dpi=150, bbox_inches='tight')\n","        plt.close()\n","\n","        story.append(Image(str(reg_impact_img), width=6.5*inch, height=2.6*inch))\n","        story.append(Spacer(1, 15))\n","        print(f'‚úì Regularization impact chart saved: {reg_impact_img}')\n","\n","    print('‚úì All custom visualizations generated for PDF report')\n","else:\n","    story.append(Paragraph('No completed trials available for visualization.', styles['Normal']))\n","\n","# ===== SECTION 6: ALL TRIALS SUMMARY =====\n","story.append(PageBreak())\n","story.append(Paragraph('6. All Trials Summary', heading_style))\n","\n","# Statistics\n","completed_df = df_trials_sorted[df_trials_sorted['state'] == 'COMPLETE']\n","if len(completed_df) > 0:\n","    stats_data = [\n","        ['Metric', 'Value'],\n","        ['Completed Trials', str(len(completed_df))],\n","        ['Best mAP@0.5', f\"{completed_df['mAP@0.5'].max():.4f}\"],\n","        ['Worst mAP@0.5', f\"{completed_df['mAP@0.5'].min():.4f}\"],\n","        ['Mean mAP@0.5', f\"{completed_df['mAP@0.5'].mean():.4f}\"],\n","        ['Std Dev mAP@0.5', f\"{completed_df['mAP@0.5'].std():.4f}\"],\n","        ['Median mAP@0.5', f\"{completed_df['mAP@0.5'].median():.4f}\"],\n","    ]\n","\n","    stats_table = Table(stats_data, colWidths=[2.5*inch, 3.5*inch])\n","    stats_table.setStyle(TableStyle([\n","        ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#e74c3c')),\n","        ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n","        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n","        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n","        ('FONTSIZE', (0, 0), (-1, -1), 10),\n","        ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n","        ('TOPPADDING', (0, 0), (-1, -1), 6),\n","        ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n","        ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n","    ]))\n","    story.append(stats_table)\n","\n","# Build PDF\n","try:\n","    doc.build(story)\n","    print(f'\\n‚úì Comprehensive PDF report generated: {pdf_report_path}')\n","    print(f'  Size: {pdf_report_path.stat().st_size / (1024*1024):.1f} MB')\n","    print(f'  Sections: Overview, Configuration, Best Hyperparameters, Top 10 Trials,')\n","    print(f'            Optimization Visualizations (3 charts), All Trials Summary')\n","except Exception as pdf_error:\n","    print(f'\\n‚ö†Ô∏è  Error generating PDF: {pdf_error}')\n","    import traceback\n","    traceback.print_exc()\n","\n","print('=' * 80)"]},{"cell_type":"markdown","id":"c5ff99f5","metadata":{"id":"c5ff99f5"},"source":["## 13. Analyze Best Hyperparameters"]},{"cell_type":"code","execution_count":null,"id":"f3823505","metadata":{"id":"f3823505"},"outputs":[],"source":["# DISPLAY BEST HYPERPARAMETERS\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('BEST HYPERPARAMETERS')\n","print('=' * 80)\n","\n","print(f'\\nBest Trial Number: {study.best_trial.number}')\n","print(f'Best mAP@0.5: {study.best_value:.4f}')\n","print('\\nOptimized Hyperparameters:')\n","print(json.dumps(study.best_params, indent=2))\n","print('=' * 80)"]},{"cell_type":"markdown","id":"1900ad83","metadata":{"id":"1900ad83"},"source":["## 13. Create Trials Summary"]},{"cell_type":"code","execution_count":null,"id":"2c210c33","metadata":{"id":"2c210c33"},"outputs":[],"source":["# CREATE TRIALS SUMMARY AND DATAFRAME (SHARED RESOURCE)\n","# ============================================================================\n","\n","print('\\n' + '=' * 80)\n","print('TRIALS SUMMARY')\n","print('=' * 80)\n","\n","# Compile all trial data (used by multiple sections)\n","trials_data = []\n","for trial in study.trials:\n","    trial_info = {\n","        'trial': trial.number,\n","        'mAP@0.5': trial.value if trial.value else 0.0,\n","        'state': trial.state.name,\n","        'duration_seconds': (trial.datetime_complete - trial.datetime_start).total_seconds() if trial.datetime_complete else None,\n","    }\n","    # Add all parameters\n","    trial_info.update(trial.params)\n","    trials_data.append(trial_info)\n","\n","# Create DataFrame and sort by performance (used by PDF report and display)\n","df_trials = pd.DataFrame(trials_data)\n","df_trials_sorted = df_trials.sort_values('mAP@0.5', ascending=False)\n","\n","print('\\nüìä TOP 10 TRIALS:')\n","print('=' * 80)\n","# Display top 10 with selected columns\n","display_cols = ['trial', 'mAP@0.5', 'state', 'optimizer', 'lr0', 'momentum', 'weight_decay', 'mixup']\n","available_cols = [col for col in display_cols if col in df_trials_sorted.columns]\n","print(df_trials_sorted[available_cols].head(10).to_string(index=False))\n","print('=' * 80)\n","\n","# Save complete trials summary\n","trials_csv_path = TUNE_DIR / 'trials_summary.csv'\n","df_trials_sorted.to_csv(trials_csv_path, index=False)\n","print(f'\\n‚úì Complete trials summary saved to: {trials_csv_path}')\n","\n","# Save study object\n","study_path = TUNE_DIR / 'optuna_study.pkl'\n","with open(study_path, 'wb') as f:\n","    pickle.dump(study, f)\n","print(f'‚úì Optuna study object saved to: {study_path}')\n","\n","print('=' * 80)"]},{"cell_type":"markdown","id":"7d09278e","metadata":{"id":"7d09278e"},"source":["## 14. Final summary\n"]},{"cell_type":"code","execution_count":null,"id":"9e9576f4","metadata":{"id":"9e9576f4"},"outputs":[],"source":["# FINAL SUMMARY\n","# ============================================================================\n","\n","print('\\n\\n')\n","print('=' * 80)\n","print('HYPERPARAMETER OPTIMIZATION COMPLETE!')\n","print('=' * 80)\n","\n","print(f'\\nüìä Project: {MODEL_NAME} on {YOLO_DATASET_ROOT.name}')\n","print(f'üìÖ Date: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n","\n","print(f'\\nüî¨ Optimization Summary:')\n","print(f'  Total Trials: {len(study.trials)}')\n","print(f'  Completed: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}')\n","print(f'  Best Trial: {study.best_trial.number}')\n","print(f'  Best Trial mAP@0.5: {study.best_value:.4f}')\n","print(f'  Duration: {duration}')\n","\n","if 'final_metrics' in globals():\n","    print(f'\\nüéØ Final Model Performance:')\n","    print(f'  mAP@0.5: {final_metrics[\"map50\"]:.4f}')\n","    print(f'  mAP@0.5:0.95: {final_metrics[\"map50_95\"]:.4f}')\n","    print(f'  Precision: {final_metrics[\"precision\"]:.4f}')\n","    print(f'  Recall: {final_metrics[\"recall\"]:.4f}')\n","\n","print(f'\\nüìÅ Generated Files:')\n","print(f'\\n  üìä Tuning Results (in {TUNE_DIR}):')\n","print(f'    - best_hyperparameters.json')\n","print(f'    - best_hyperparameters.yaml')\n","print(f'    - trials_summary.csv')\n","print(f'    - optuna_study.pkl')\n","print(f'  üìà Tuning Visualizations:')\n","print(f'    - optimization_history.html / .png')\n","print(f'    - parameter_importance.html / .png')\n","print(f'    - parameter_slice.html / .png')\n","print(f'  üìÑ Tuning PDF Report:')\n","print(f'    - {MODEL_NAME}_tuning_report.pdf')\n","\n","print(f'\\nüìÇ All results saved to:')\n","print(f'  Tuning: {TUNE_DIR}')\n","\n","print(f'\\nüéì Top 5 Hyperparameters (by importance):')\n","try:\n","    importances = optuna.importance.get_param_importances(study)\n","    for i, (param, importance) in enumerate(list(importances.items())[:5], 1):\n","        print(f'  {i}. {param}: {importance:.4f}')\n","except:\n","    print('  (Not available - requires completed trials with variation)')\n","\n","print(f'\\nüöÄ Next Steps:')\n","print(f'  1. Review tuning PDF report: {TUNE_DIR / f\"{MODEL_NAME}_tuning_report.pdf\"}')\n","print(f'  2. Review optimization visualizations in: {TUNE_DIR}')\n","print(f'  3. Use best_hyperparameters.yaml for training in a separate notebook')\n","\n","print('\\n' + '=' * 80)\n","print('SUCCESS! ‚úì')\n","print('=' * 80)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"colab":{"provenance":[{"file_id":"1IknhmQGJ16M5M_kKwiL_l8vmYKqs5NZK","timestamp":1764322318885}],"gpuType":"A100"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"aca59875617646e68d8efc9b0e4c92a2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fba3b951317f43ce80e9d7fce06d5b98","IPY_MODEL_792dc260c93545598b0f4f8687222b6a","IPY_MODEL_44dfdc8ae50d49f29bb3b27fdb36dcd7"],"layout":"IPY_MODEL_fdd8a7f1f09a4e7bb78838dd76694e02"}},"fba3b951317f43ce80e9d7fce06d5b98":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a3c3832f4124785a09d38c8360977a9","placeholder":"‚Äã","style":"IPY_MODEL_1b79535acf014f099677439a29363375","value":"Best‚Äátrial:‚Äá0.‚ÄáBest‚Äávalue:‚Äá0.576928:‚Äá‚Äá42%"}},"792dc260c93545598b0f4f8687222b6a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_fdf1cfcc9c9e4f65ac7ee284fc17d45a","max":40,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b47d796eec3245ec8265a72d621583a7","value":17}},"44dfdc8ae50d49f29bb3b27fdb36dcd7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f3f2202eb1c4aa69f359a4957ac73a6","placeholder":"‚Äã","style":"IPY_MODEL_64d21409dabf43718cc561425a686ce7","value":"‚Äá17/40‚Äá[7:41:14&lt;10:30:29,‚Äá1644.77s/it,‚Äá27674.21/86400‚Äáseconds]"}},"fdd8a7f1f09a4e7bb78838dd76694e02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a3c3832f4124785a09d38c8360977a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b79535acf014f099677439a29363375":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fdf1cfcc9c9e4f65ac7ee284fc17d45a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b47d796eec3245ec8265a72d621583a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0f3f2202eb1c4aa69f359a4957ac73a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64d21409dabf43718cc561425a686ce7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}