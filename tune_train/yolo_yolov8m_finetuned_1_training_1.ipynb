{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b26f5d6",
   "metadata": {},
   "source": [
    "# YOLO Training\n",
    "- Support for YOLOv8, YOLOv9, YOLOv10, YOLO11, YOLO12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e53f76",
   "metadata": {},
   "source": [
    "# 1. Set Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c698714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directories\n",
    "# Detect environment: Colab or local\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "IS_COLAB = 'COLAB_GPU' in os.environ or os.path.exists('/content')\n",
    "\n",
    "USE_WANDB = True  # Set to False to disable W&B logging\n",
    "\n",
    "\n",
    "\n",
    "if IS_COLAB:\n",
    "    #Mount Google Drive if not already mounted\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/Drive', force_remount=True)\n",
    "    # Running in Google Colab\n",
    "    BASE_DIR = Path('/content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo')\n",
    "    \n",
    "    # Configure W&B API key\n",
    "    if USE_WANDB:\n",
    "        # In Colab, get API key from secrets\n",
    "        from google.colab import userdata\n",
    "        wandb_api_key = userdata.get('wandb_api_key')\n",
    "        os.environ['WANDB_API_KEY'] = wandb_api_key\n",
    "        print('‚úì W&B API key loaded from Colab secrets')\n",
    "\n",
    "    DATASET_BASE_DIR = Path('/computer_vision_yolo')\n",
    "\n",
    "else:\n",
    "    # Running locally\n",
    "    BASE_DIR = Path.cwd().parent\n",
    "    if USE_WANDB:\n",
    "        print('‚úì Running locally - W&B will use existing login or prompt')\n",
    "    \n",
    "    DATASET_BASE_DIR = Path.cwd().parent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8064a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ! cd /content/Drive/MyDrive/ksu_yolo_2025 && git clone https://github.com/m3mahdy/computer_vision_yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c67ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! cd {BASE_DIR} && pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f33666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download limited dataset\n",
    "# !mkdir {DATASET_BASE_DIR}\n",
    "# !cd {BASE_DIR}/dataset && cp 8_download_extract_other_datasets.py {DATASET_BASE_DIR} && cd {DATASET_BASE_DIR} && python 8_download_extract_other_datasets.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ddb177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "109394c4",
   "metadata": {},
   "source": [
    "## 2. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6f98f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries (uncomment if running in Colab)\n",
    "# !pip install -q ultralytics wandb pyyaml\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import yaml\n",
    "import json\n",
    "import torch\n",
    "import shutil\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import platform\n",
    "import psutil\n",
    "\n",
    "import wandb\n",
    "\n",
    "# YOLO imports\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ReportLab imports for PDF generation\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib import colors as rl_colors\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, Image, PageBreak\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.enums import TA_CENTER, TA_LEFT\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure matplotlib for notebook display\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "# Check GPU availability\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'‚úì Libraries imported successfully')\n",
    "print(f'‚úì Device: {device}')\n",
    "if device == 'cuda':\n",
    "    print(f'  GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'  CUDA Version: {torch.version.cuda}')\n",
    "    print(f'  Available Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2659c792",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d163f0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# Base directories\n",
    "# Detect environment: Colab or local\n",
    "\n",
    "IS_COLAB = 'COLAB_GPU' in os.environ or os.path.exists('/content')\n",
    "\n",
    "USE_WANDB = True  # Set to False to disable W&B logging\n",
    "\n",
    "if IS_COLAB:\n",
    "    #Mount Google Drive if not already mounted\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/Drive', force_remount=True)\n",
    "    # Running in Google Colab\n",
    "    BASE_DIR = Path('/content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo')\n",
    "    \n",
    "    # Configure W&B API key\n",
    "    if USE_WANDB:\n",
    "        # In Colab, get API key from secrets\n",
    "        from google.colab import userdata\n",
    "        wandb_api_key = userdata.get('wandb_api_key')\n",
    "        os.environ['WANDB_API_KEY'] = wandb_api_key\n",
    "        print('‚úì W&B API key loaded from Colab secrets')\n",
    "\n",
    "else:\n",
    "    # Running locally\n",
    "    BASE_DIR = Path.cwd().parent\n",
    "    if USE_WANDB:\n",
    "        print('‚úì Running locally - W&B will use existing login or prompt')\n",
    "class DatasetSplit:\n",
    "    \"\"\"Constants for dataset split names\"\"\"\n",
    "    TRAIN = \"train\"\n",
    "    VAL = \"val\"\n",
    "    TEST = \"test\"\n",
    "\n",
    "class ModelConfig:\n",
    "    \"\"\"Default model training configuration constants\"\"\"\n",
    "    # Image processing\n",
    "    DEFAULT_IMAGE_SIZE = 640  # Standard YOLO input size\n",
    "    \n",
    "    # Training workers\n",
    "    DEFAULT_WORKERS = 8  # Number of data loading workers\n",
    "    \n",
    "    # Early stopping and checkpointing\n",
    "    DEFAULT_PATIENCE = 10  # Epochs to wait before early stopping\n",
    "    DEFAULT_SAVE_PERIOD = 3  # Save checkpoint every N epochs\n",
    "    \n",
    "    # Augmentation timing\n",
    "    CLOSE_MOSAIC_EPOCHS = 10  # Disable mosaic augmentation in last N epochs\n",
    "    \n",
    "    # Data loading and caching\n",
    "    DEFAULT_CACHE = False  # Cache images for faster training (use True for small datasets)\n",
    "    DEFAULT_VAL = True  # Run validation during training\n",
    "    \n",
    "    # Warmup configuration\n",
    "    # MIN_WARMUP_EPOCHS = 0\n",
    "    # MAX_WARMUP_EPOCHS = 3\n",
    "    # MIN_WARMUP_MOMENTUM = 0.5\n",
    "    # MAX_WARMUP_MOMENTUM = 0.95\n",
    "    # MIN_WARMUP_BIAS_LR = 0.0\n",
    "\n",
    "    # MAX_WARMUP_BIAS_LR = 0.1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Model Selection - Choose one of the following:\n",
    "MODEL_NAME = \"yolov8m_finetuned_1\"\n",
    "\n",
    "#yolov10n is for testing purpose only\n",
    "#Mahdy will work yolov8m\n",
    "\n",
    "\n",
    "# Selected models, to choose from, based on the performance and size:\n",
    "# YOLOv8:  'yolov8s', 'yolov8m'\n",
    "\n",
    "# YOLOv10: 'yolov10s', 'yolov10m'\n",
    "\n",
    "# YOLO12: 'yolo12s'\n",
    "\n",
    "# Directory structure\n",
    "MODELS_DIR = BASE_DIR / 'models' / MODEL_NAME\n",
    "TMP_DIR = BASE_DIR / 'tmp' / MODEL_NAME\n",
    "\n",
    "# Dataset Selection\n",
    "# Option 1: Full dataset (~100k images) - for final optimization: \"bdd100k_yolo\"\n",
    "# Option 2: Limited dataset (representative samples) - for quick tuning: \"bdd100k_yolo_limited\"\n",
    "dataset_name = 'bdd100k_yolo_limited'\n",
    "\n",
    "\n",
    "YOLO_DATASET_ROOT = DATASET_BASE_DIR / dataset_name\n",
    "\n",
    "# data.yaml path\n",
    "DATA_YAML_PATH = YOLO_DATASET_ROOT / 'data.yaml'\n",
    "\n",
    "# Verify dataset exists\n",
    "if not DATA_YAML_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Dataset not found: {DATA_YAML_PATH}\\n\"\n",
    "        f\"Please prepare the dataset first using process_bdd100k_to_yolo_dataset.py\"\n",
    "    )\n",
    "\n",
    "# Update data.yaml path field for Colab compatibility\n",
    "with open(DATA_YAML_PATH, 'r') as yaml_file:\n",
    "    data_config = yaml.safe_load(yaml_file)\n",
    "\n",
    "# Validate required keys in data.yaml\n",
    "required_yaml_keys = ['nc', 'names', 'path']\n",
    "missing_keys = [key for key in required_yaml_keys if key not in data_config]\n",
    "if missing_keys:\n",
    "    raise ValueError(f\"Missing required keys in data.yaml: {missing_keys}\")\n",
    "\n",
    "# Update the 'path' field to use BASE_DIR\n",
    "data_config['path'] = str(YOLO_DATASET_ROOT)\n",
    "\n",
    "# Create a temporary data.yaml with corrected paths\n",
    "temp_data_yaml = TMP_DIR / 'data.yaml'\n",
    "TMP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "with open(temp_data_yaml, 'w') as yaml_output_file:\n",
    "    yaml.dump(data_config, yaml_output_file, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "# Use the temporary data.yaml for training\n",
    "DATA_YAML_PATH = temp_data_yaml\n",
    "\n",
    "# Training Configuration\n",
    "EPOCHS_FINAL_TRAINING = 150  # Training epochs for final model = 150\n",
    "BATCH_SIZE = 96  # Batch size for training\n",
    "# for T4 GPU:\n",
    "# 64 for 10n, 1 epoch 30 min\n",
    "# 32 for 8m, 1 epoch 45 min\n",
    "\n",
    "# for A100 GPU:\n",
    "# 64 for 10m 1 epoch 11 min, 5 epochs completed in 0.797 hours.\n",
    "# 96 for 8m , 1 epoch 10 min, 5 epochs completed in 0.866 hours.\n",
    "\n",
    "# NOTE: Image size (imgsz) is loaded from best hyperparameters if USE_DEFAULT_CONFIG=False\n",
    "# Defaults to 640 if using default configuration (USE_DEFAULT_CONFIG=True)\n",
    "\n",
    "# Weights & Biases (optional)\n",
    "USE_WANDB = True  # Set to True to enable W&B logging\n",
    "WANDB_PROJECT_TRAINING = f\"yolo-{YOLO_DATASET_ROOT.name}-training\"\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION MODE: DEFAULT vs TUNED HYPERPARAMETERS\n",
    "# ============================================================================\n",
    "# Set to True to use default YOLO configuration (no hyperparameter tuning)\n",
    "# Set to False to load hyperparameters from a tuning run\n",
    "# ============================================================================\n",
    "\n",
    "USE_DEFAULT_CONFIG = False  # Set to True to skip tuning and use default YOLO config\n",
    "\n",
    "# ============================================================================\n",
    "# TUNING RUN CONFIGURATION - SPECIFY WHICH TUNING RUN TO USE\n",
    "# ============================================================================\n",
    "# Specify the tuning run name to load best hyperparameters from\n",
    "# This should match the directory name in tune_train/tune/\n",
    "# \n",
    "# Example: TUNING_RUN_NAME = \"yolov10n_tune_20251125_143022\"\n",
    "# Leave as None to search for the latest tuning run for this model\n",
    "# Note: Only used if USE_DEFAULT_CONFIG = False\n",
    "# ============================================================================\n",
    "\n",
    "TUNING_RUN_NAME = \"yolov8m_finetuned_1_tune_20251127_230340\"  # Set to specific tuning run name, or None to auto-detect latest\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING RUN CONFIGURATION - RESUME OR CREATE NEW\n",
    "# ============================================================================\n",
    "# To RESUME an existing training run: Set RESUME_TRAINING_RUN_NAME to the run directory name\n",
    "# To START NEW training: Leave RESUME_TRAINING_RUN_NAME as None or empty string\n",
    "# \n",
    "# Example to resume: RESUME_TRAINING_RUN_NAME = \"yolov10n_train_20251125_150000\"\n",
    "# ============================================================================\n",
    "\n",
    "RESUME_TRAINING_RUN_NAME = None  # Set to run name to resume, or None to create new run\n",
    "\n",
    "# Find or verify tuning run (only if not using default config)\n",
    "TUNE_TRAIN_BASE = BASE_DIR / 'tune_train'\n",
    "TUNE_BASE_DIR = TUNE_TRAIN_BASE / 'tune'\n",
    "\n",
    "if USE_DEFAULT_CONFIG:\n",
    "    # Using default configuration - skip tuning run search\n",
    "    print('\\n‚öôÔ∏è  CONFIGURATION MODE: Using Default YOLO Configuration')\n",
    "    print('   No hyperparameter tuning will be applied')\n",
    "    TUNE_DIR = None\n",
    "    TUNING_RUN_NAME = None\n",
    "    best_hyperparams_path = None\n",
    "else:\n",
    "    # Using tuned hyperparameters - find or verify tuning run\n",
    "    print('\\n‚öôÔ∏è  CONFIGURATION MODE: Using Tuned Hyperparameters')\n",
    "    \n",
    "    if TUNING_RUN_NAME:\n",
    "        # Use specified tuning run\n",
    "        TUNE_DIR = TUNE_BASE_DIR / TUNING_RUN_NAME\n",
    "        if not TUNE_DIR.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"Specified tuning run not found: {TUNE_DIR}\\n\"\n",
    "                f\"Available runs in {TUNE_BASE_DIR}:\\n\" +\n",
    "                '\\n'.join(f\"  - {d.name}\" for d in TUNE_BASE_DIR.glob(f'{MODEL_NAME}_tune_*') if d.is_dir())\n",
    "            )\n",
    "        print(f'   üìÇ Using specified tuning run: {TUNING_RUN_NAME}')\n",
    "    else:\n",
    "        # Auto-detect latest tuning run for this model\n",
    "        tuning_runs = sorted(TUNE_BASE_DIR.glob(f'{MODEL_NAME}_tune_*'), key=lambda p: p.name, reverse=True)\n",
    "        if not tuning_runs:\n",
    "            raise FileNotFoundError(\n",
    "                f\"No tuning runs found for model {MODEL_NAME} in {TUNE_BASE_DIR}\\n\"\n",
    "                f\"Please run the tuning notebook first, specify TUNING_RUN_NAME, or set USE_DEFAULT_CONFIG=True\"\n",
    "            )\n",
    "        TUNE_DIR = tuning_runs[0]\n",
    "        TUNING_RUN_NAME = TUNE_DIR.name\n",
    "        print(f'   üîç Auto-detected latest tuning run: {TUNING_RUN_NAME}')\n",
    "\n",
    "    # Verify best hyperparameters exist\n",
    "    best_hyperparams_path = TUNE_DIR / 'best_hyperparameters.json'\n",
    "    if not best_hyperparams_path.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Best hyperparameters not found in tuning run: {best_hyperparams_path}\\n\"\n",
    "            f\"Please ensure the tuning run completed successfully\"\n",
    "        )\n",
    "\n",
    "    print(f'   ‚úì Found best hyperparameters: {best_hyperparams_path}')\n",
    "\n",
    "# Configure training run name\n",
    "if RESUME_TRAINING_RUN_NAME:\n",
    "    # Resume existing training run\n",
    "    RUN_NAME_TRAINING = RESUME_TRAINING_RUN_NAME\n",
    "    print(f'\\nüîÑ RESUME MODE: Will attempt to resume training run \"{RESUME_TRAINING_RUN_NAME}\"')\n",
    "else:\n",
    "    # Create new training run with timestamp\n",
    "    RUN_TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    RUN_NAME_TRAINING = f'{MODEL_NAME}_train_{RUN_TIMESTAMP}'\n",
    "    print(f'\\nüÜï NEW TRAINING MODE: Creating new run \"{RUN_NAME_TRAINING}\"')\n",
    "\n",
    "# Create training directory\n",
    "TRAIN_DIR = TUNE_TRAIN_BASE / 'training' / RUN_NAME_TRAINING\n",
    "TRAIN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Read dataset configuration\n",
    "NUM_CLASSES = data_config['nc']\n",
    "CLASS_NAMES = {i: name for i, name in enumerate(data_config['names'])}\n",
    "CLASS_NAME_TO_ID = {name: i for i, name in enumerate(data_config['names'])}\n",
    "\n",
    "print('=' * 80)\n",
    "print('CONFIGURATION SUMMARY')\n",
    "print('=' * 80)\n",
    "print(f'Environment: {\"Google Colab\" if \"COLAB_GPU\" in os.environ or os.path.exists(\"/content\") else \"Local\"}')\n",
    "print(f'Base Directory: {BASE_DIR}')\n",
    "print(f'Model: {MODEL_NAME}')\n",
    "print(f'Dataset: {YOLO_DATASET_ROOT.name}')\n",
    "print(f'Data YAML: {DATA_YAML_PATH}')\n",
    "print(f'  Dataset path in YAML: {data_config[\"path\"]}')\n",
    "print(f'Classes: {NUM_CLASSES}')\n",
    "print(f'Class Names: {CLASS_NAMES}')\n",
    "print(f'Device: {device}')\n",
    "print(f'Epochs Final Training: {EPOCHS_FINAL_TRAINING}')\n",
    "print(f'Batch Size: {BATCH_SIZE}')\n",
    "print(f'Configuration Mode: {\"Default (No Tuning)\" if USE_DEFAULT_CONFIG else \"Tuned Hyperparameters\"}')\n",
    "if not USE_DEFAULT_CONFIG:\n",
    "    print(f'Tuning Run: {TUNING_RUN_NAME}')\n",
    "print(f'Training Directory: {TRAIN_DIR}')\n",
    "if USE_WANDB:\n",
    "    print(f'W&B Logging: Enabled')\n",
    "    print(f'  Training Project: {WANDB_PROJECT_TRAINING}')\n",
    "else:\n",
    "    print(f'W&B Logging: Disabled')\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af35c3f",
   "metadata": {},
   "source": [
    "## 4. Load Base YOLO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deeda88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO model with automatic download\n",
    "model_path = MODELS_DIR / f'{MODEL_NAME}.pt'\n",
    "\n",
    "if not model_path.exists():\n",
    "    print(f'Model not found at {model_path}')\n",
    "    print(f'Downloading {MODEL_NAME} ...')\n",
    "    \n",
    "    try:\n",
    "        # Download model - ensure .pt extension for ultralytics\n",
    "        # Ultralytics expects model names with .pt extension for download\n",
    "        if not MODEL_NAME.endswith('.pt'):\n",
    "            model_name_for_download = MODEL_NAME + '.pt'\n",
    "        else:\n",
    "            model_name_for_download = MODEL_NAME\n",
    "            \n",
    "        print(f'  Requesting model: {model_name_for_download}')\n",
    "        model = YOLO(model_name_for_download)\n",
    "        \n",
    "        # Create models directory\n",
    "        MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save model to our directory using export/save\n",
    "        try:\n",
    "            # Try to save using the model's save method\n",
    "            if hasattr(model, 'save'):\n",
    "                model.save(str(model_path))\n",
    "                print(f'‚úì Model downloaded and saved to {model_path}')\n",
    "                print(f'  Size: {model_path.stat().st_size / (1024*1024):.1f} MB')\n",
    "            else:\n",
    "                # Fallback: copy from cache\n",
    "                cache_patterns = [\n",
    "                    str(Path.home() / '.cache' / 'ultralytics' / '**' / f'{MODEL_NAME}.pt'),\n",
    "                    str(Path.home() / '.config' / 'Ultralytics' / '**' / f'{MODEL_NAME}.pt'),\n",
    "                ]\n",
    "                \n",
    "                model_found = False\n",
    "                for pattern in cache_patterns:\n",
    "                    cache_paths = glob.glob(pattern, recursive=True)\n",
    "                    if cache_paths:\n",
    "                        shutil.copy(cache_paths[0], model_path)\n",
    "                        print(f'‚úì Model downloaded and saved to {model_path}')\n",
    "                        print(f'  Size: {model_path.stat().st_size / (1024*1024):.1f} MB')\n",
    "                        model_found = True\n",
    "                        break\n",
    "                \n",
    "                if not model_found:\n",
    "                    print(f'‚úì Model loaded from ultralytics cache')\n",
    "                    print(f'  Note: Model is in cache, not copied to {model_path}')\n",
    "                    print(f'  This is normal and the model will work correctly')\n",
    "        except Exception as save_error:\n",
    "            print(f'‚ö†Ô∏è  Could not save model to custom location: {save_error}')\n",
    "            print(f'‚úì Model loaded successfully from ultralytics cache')\n",
    "            \n",
    "    except Exception as download_error:\n",
    "        print(f'\\n‚ùå Error downloading model: {download_error}')\n",
    "        raise\n",
    "else:\n",
    "    model = YOLO(str(model_path))\n",
    "    print(f'‚úì Model loaded from {model_path}')\n",
    "\n",
    "# Get model information\n",
    "model_info_dict = {}\n",
    "model_info_result = model.info()\n",
    "model_info_keys = [\"layers\", \"params\", \"size(MB)\", \"FLOPs(G)\"]\n",
    "\n",
    "for info_key, info_value in zip(model_info_keys, model_info_result):\n",
    "    model_info_dict[info_key] = info_value\n",
    "    \n",
    "model_params = model_info_dict.get(\"params\", 0)\n",
    "model_size_mb = model_info_dict.get(\"size(MB)\", 0)\n",
    "flops_gflops = model_info_dict.get(\"FLOPs(G)\", 0)\n",
    "\n",
    "\n",
    "print(f'\\nüìä Model Information:')\n",
    "print(f'  Model: {MODEL_NAME}')\n",
    "print(f'  Classes in model: {len(model.names)}')\n",
    "print(f'  Task: {model.task}')\n",
    "print(f'  Parameters: {model_params / 1e6:.1f}M')\n",
    "print(f'  Model Size: {model_size_mb:.1f} MB')\n",
    "print(f'  FLOPs (640x640): {flops_gflops:.2f} GFLOPs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe0b94d",
   "metadata": {},
   "source": [
    "## 6. Verify Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b15401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VERIFY DATASET STRUCTURE\n",
    "# ============================================================================\n",
    "\n",
    "print('Verifying YOLO dataset structure...')\n",
    "print(f'\\nüìÅ Dataset Root: {YOLO_DATASET_ROOT}')\n",
    "\n",
    "# Check all splits using constants\n",
    "dataset_stats = {}\n",
    "for split in [DatasetSplit.TRAIN, DatasetSplit.VAL, DatasetSplit.TEST]:\n",
    "    images_dir = YOLO_DATASET_ROOT / 'images' / split\n",
    "    labels_dir = YOLO_DATASET_ROOT / 'labels' / split\n",
    "    \n",
    "    if images_dir.exists() and labels_dir.exists():\n",
    "        num_images = len(list(images_dir.glob('*.jpg'))) + len(list(images_dir.glob('*.png')))\n",
    "        num_labels = len(list(labels_dir.glob('*.txt')))\n",
    "        dataset_stats[split] = {'images': num_images, 'labels': num_labels}\n",
    "        print(f'  ‚úì {split:5s}: {num_images:6d} images, {num_labels:6d} labels')\n",
    "    else:\n",
    "        print(f'  ‚ö†Ô∏è  {split:5s}: Directory not found')\n",
    "        dataset_stats[split] = {'images': 0, 'labels': 0}\n",
    "\n",
    "print(f'\\nüìÑ Configuration: {DATA_YAML_PATH}')\n",
    "print(f'  Classes: {NUM_CLASSES}')\n",
    "print(f'  Names: {CLASS_NAMES}')\n",
    "\n",
    "total_images = sum(stats['images'] for stats in dataset_stats.values())\n",
    "print(f'\\n‚úì Dataset verified: {total_images:,} total images')\n",
    "print('‚úì Ready for training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03686b4",
   "metadata": {},
   "source": [
    "## 5. Load Best Hyperparameters from Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67e089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LOAD HYPERPARAMETERS (TUNED OR DEFAULT)\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "if USE_DEFAULT_CONFIG:\n",
    "    print('USING DEFAULT YOLO CONFIGURATION')\n",
    "    print('=' * 80)\n",
    "    print('No hyperparameter tuning applied - using YOLO defaults')\n",
    "    \n",
    "    # Use empty dict for hyperparameters - YOLO will use its defaults\n",
    "    best_params = {}\n",
    "    \n",
    "    print('\\n‚úì Training will use default YOLO hyperparameters')\n",
    "    print('   Default values will be applied by the YOLO model')\n",
    "    \n",
    "else:\n",
    "    print('LOADING BEST HYPERPARAMETERS FROM TUNING')\n",
    "    print('=' * 80)\n",
    "    print(f'Tuning Run: {TUNING_RUN_NAME}')\n",
    "    print(f'Hyperparameters Path: {best_hyperparams_path}')\n",
    "\n",
    "    # Load best hyperparameters from JSON\n",
    "    with open(best_hyperparams_path, 'r', encoding='utf-8') as f:\n",
    "        best_params_file = json.load(f)\n",
    "\n",
    "    # Extract only the actual hyperparameters (not metadata)\n",
    "    # The file structure has metadata fields and a 'hyperparameters' field with the actual params\n",
    "    if 'hyperparameters' in best_params_file:\n",
    "        # New format: metadata + hyperparameters nested\n",
    "        best_params = best_params_file['hyperparameters']\n",
    "        print('\\n‚úì Loaded hyperparameters from nested structure')\n",
    "    else:\n",
    "        # Old format: hyperparameters directly in root\n",
    "        # Filter out metadata fields that aren't YOLO parameters\n",
    "        metadata_keys = {'model', 'dataset_root', 'data_yaml_path', 'notes', \n",
    "                        'optimization_results', 'timestamp'}\n",
    "        best_params = {k: v for k, v in best_params_file.items() if k not in metadata_keys}\n",
    "        print('\\n‚úì Loaded hyperparameters from flat structure (filtered metadata)')\n",
    "\n",
    "    print('\\n‚úì Best Hyperparameters Loaded:')\n",
    "    for key, value in sorted(best_params.items()):\n",
    "        if isinstance(value, (int, float)):\n",
    "            if isinstance(value, float):\n",
    "                print(f'  {key:20s}: {value:.6f}')\n",
    "            else:\n",
    "                print(f'  {key:20s}: {value}')\n",
    "        else:\n",
    "            print(f'  {key:20s}: {value}')\n",
    "\n",
    "    # Load tuning metadata if available\n",
    "    tuning_metadata_path = TUNE_DIR / 'optimization_metadata.json'\n",
    "    if (not USE_DEFAULT_CONFIG and tuning_metadata_path.exists()):\n",
    "        with open(tuning_metadata_path, 'r', encoding='utf-8') as f:\n",
    "            tuning_metadata = json.load(f)\n",
    "        \n",
    "        print('\\nüìä Tuning Run Summary:')\n",
    "        print(f\"  Best Trial: {tuning_metadata.get('best_trial', 'N/A')}\")\n",
    "        print(f\"  Best mAP@0.5: {tuning_metadata.get('best_map50', 0):.4f}\")\n",
    "        print(f\"  Total Trials: {tuning_metadata.get('total_trials', 'N/A')}\")\n",
    "        print(f\"  Completed Trials: {tuning_metadata.get('completed_trials', 'N/A')}\")\n",
    "        \n",
    "        if 'optimization_duration' in tuning_metadata:\n",
    "            print(f\"  Duration: {tuning_metadata['optimization_duration']}\")\n",
    "\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83385af0",
   "metadata": {},
   "source": [
    "## 7. Train The Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0bc9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRAIN FINAL MODEL WITH OPTIMIZED HYPERPARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "if USE_DEFAULT_CONFIG:\n",
    "    print('TRAINING FINAL MODEL WITH DEFAULT CONFIGURATION')\n",
    "else:\n",
    "    print('TRAINING FINAL MODEL WITH OPTIMIZED HYPERPARAMETERS')\n",
    "print('=' * 80)\n",
    "\n",
    "# Check if resuming from previous training\n",
    "checkpoint_path = TRAIN_DIR / 'weights' / 'last.pt'\n",
    "training_log_path = TRAIN_DIR / 'training_log.json'\n",
    "is_resuming = checkpoint_path.exists()\n",
    "\n",
    "if is_resuming:\n",
    "    # Resume training\n",
    "    print('\\n' + '=' * 80)\n",
    "    print('üîÑ RESUMING PREVIOUS TRAINING')\n",
    "    print('=' * 80)\n",
    "    print(f'Checkpoint: {checkpoint_path}')\n",
    "    \n",
    "    # Load training log if available\n",
    "    if training_log_path.exists():\n",
    "        with open(training_log_path, 'r', encoding='utf-8') as f:\n",
    "            training_log = json.load(f)\n",
    "        \n",
    "        print(f'\\nüìä Previous Training Summary:')\n",
    "        print(f\"  Started: {training_log.get('start_time', 'N/A')}\")\n",
    "        if 'last_epoch' in training_log:\n",
    "            print(f\"  Last Epoch: {training_log['last_epoch']}\")\n",
    "        if 'best_map50' in training_log:\n",
    "            print(f\"  Best mAP@0.5: {training_log['best_map50']:.4f}\")\n",
    "        if 'last_checkpoint' in training_log:\n",
    "            print(f\"  Last Checkpoint: {training_log['last_checkpoint']}\")\n",
    "    \n",
    "    print(f'\\n‚û°Ô∏è  Resuming training from checkpoint')\n",
    "    print('=' * 80)\n",
    "    \n",
    "    # Load model from checkpoint\n",
    "    print(f'\\nüì¶ Loading model from checkpoint: {checkpoint_path}')\n",
    "    final_model = YOLO(str(checkpoint_path))\n",
    "    model_to_train = str(checkpoint_path)\n",
    "    resume_training = True\n",
    "    \n",
    "else:\n",
    "    # Start new training\n",
    "    print(f'\\nüì¶ Loading base model: {MODEL_NAME}')\n",
    "    final_model = YOLO(str(model_path))\n",
    "    model_to_train = str(model_path)\n",
    "    resume_training = False\n",
    "    \n",
    "    # Initialize training log\n",
    "    training_log = {\n",
    "        'start_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'model': MODEL_NAME,\n",
    "        'dataset': YOLO_DATASET_ROOT.name,\n",
    "        'config_mode': 'default' if USE_DEFAULT_CONFIG else 'tuned',\n",
    "        'tuning_run': TUNING_RUN_NAME if not USE_DEFAULT_CONFIG else None,\n",
    "        'best_hyperparameters': best_params,\n",
    "        'epochs': EPOCHS_FINAL_TRAINING,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'image_size': best_params.get('imgsz', 640)\n",
    "    }\n",
    "\n",
    "# Prepare training parameters\n",
    "# Note: Fixed parameters (not part of optimization) are always included\n",
    "# Optimization parameters are added via **best_params (empty if using defaults)\n",
    "# NOTE: 'imgsz' removed - will come from best_params if tuned, or YOLO default if not\n",
    "\n",
    "final_training_params = {\n",
    "    # ============================================================================\n",
    "    # FIXED PARAMETERS - Always passed, not part of hyperparameter optimization\n",
    "    # ============================================================================\n",
    "    'data': str(DATA_YAML_PATH),              # Dataset configuration file\n",
    "    'epochs': EPOCHS_FINAL_TRAINING,          # Number of training epochs\n",
    "    'batch': BATCH_SIZE,                       # Batch size\n",
    "    'device': device,                          # Training device (cuda/cpu)\n",
    "    'project': str(TRAIN_DIR.parent),         # Project directory\n",
    "    'name': TRAIN_DIR.name,                    # Run name\n",
    "    'exist_ok': True,                          # Overwrite existing project\n",
    "    'patience': ModelConfig.DEFAULT_PATIENCE,  # Early stopping patience\n",
    "    'save_period': ModelConfig.DEFAULT_SAVE_PERIOD,  # Save checkpoint frequency\n",
    "    'workers': ModelConfig.DEFAULT_WORKERS,    # Number of data loading workers\n",
    "    'verbose': True,                           # Verbose output\n",
    "    'seed': 42,                                # Random seed for reproducibility\n",
    "    'close_mosaic': ModelConfig.CLOSE_MOSAIC_EPOCHS,  # Disable mosaic in final epochs\n",
    "    'resume': resume_training,                 # Resume from checkpoint if exists\n",
    "    'cache': ModelConfig.DEFAULT_CACHE,        # Cache images for faster training\n",
    "    'val': ModelConfig.DEFAULT_VAL,            # Run validation during training\n",
    "    \n",
    "    # ============================================================================\n",
    "    # OPTIMIZATION PARAMETERS - From tuning (if USE_DEFAULT_CONFIG=False)\n",
    "    # ============================================================================\n",
    "    # Parameters like: lr0, lrf, momentum, weight_decay, warmup_epochs, etc.\n",
    "    **best_params  # Empty dict if USE_DEFAULT_CONFIG=True, tuned params otherwise\n",
    "}\n",
    "\n",
    "print(f'\\nüöÄ {\"Resuming\" if resume_training else \"Starting\"} training...')\n",
    "print(f'  Configuration: {\"Default YOLO\" if USE_DEFAULT_CONFIG else \"Tuned Hyperparameters\"}')\n",
    "print(f'  Epochs: {final_training_params[\"epochs\"]}')\n",
    "print(f'  Batch Size: {final_training_params[\"batch\"]}')\n",
    "print(f'  Dataset: {DATA_YAML_PATH}')\n",
    "print(f'  Device: {device}')\n",
    "print(f'  Resume: {resume_training}')\n",
    "\n",
    "if best_params:\n",
    "    print('\\nüìä Applied Hyperparameters:')\n",
    "    for key, value in sorted(best_params.items()):\n",
    "        if isinstance(value, float):\n",
    "            print(f'  {key:20s}: {value:.6f}')\n",
    "        else:\n",
    "            print(f'  {key:20s}: {value}')\n",
    "else:\n",
    "    print('\\nüìä Using YOLO default hyperparameters (no custom values)')\n",
    "\n",
    "print('\\nThis may take a while. Training progress will be displayed below.')\n",
    "print('=' * 80)\n",
    "\n",
    "# Initialize W&B for final training\n",
    "if USE_WANDB:\n",
    "    try:\n",
    "        wandb_config = {\n",
    "            'model': MODEL_NAME,\n",
    "            'dataset': YOLO_DATASET_ROOT.name,\n",
    "            'phase': 'final_training',\n",
    "            'config_mode': 'default' if USE_DEFAULT_CONFIG else 'tuned',\n",
    "            'tuning_run': TUNING_RUN_NAME if not USE_DEFAULT_CONFIG else None,\n",
    "            'epochs': final_training_params['epochs'],\n",
    "            'batch_size': final_training_params['batch'],\n",
    "            'resume': resume_training,\n",
    "            **best_params\n",
    "        }\n",
    "        \n",
    "        wandb_training_run = wandb.init(\n",
    "            project=WANDB_PROJECT_TRAINING,\n",
    "            name=RUN_NAME_TRAINING,\n",
    "            id=training_log.get('wandb_run_id') if is_resuming else None,\n",
    "            resume='allow' if is_resuming else None,\n",
    "            config=wandb_config,\n",
    "            group='final-training',\n",
    "            tags=['final', 'optimized' if not USE_DEFAULT_CONFIG else 'default', MODEL_NAME, YOLO_DATASET_ROOT.name]\n",
    "        )\n",
    "        \n",
    "        # Save W&B run ID for future resume\n",
    "        if not is_resuming:\n",
    "            training_log['wandb_run_id'] = wandb_training_run.id\n",
    "            with open(training_log_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(training_log, f, indent=2)\n",
    "        \n",
    "        print(f'‚úì W&B initialized: {WANDB_PROJECT_TRAINING}/{RUN_NAME_TRAINING}')\n",
    "    except Exception as wandb_error:\n",
    "        print(f'‚ö†Ô∏è  Could not initialize W&B: {wandb_error}')\n",
    "        wandb_training_run = None\n",
    "else:\n",
    "    wandb_training_run = None\n",
    "\n",
    "# Train model\n",
    "start_time = datetime.now()\n",
    "try:\n",
    "    final_results = final_model.train(**final_training_params)\n",
    "    \n",
    "    # Update training log with completion\n",
    "    training_log['end_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    training_log['status'] = 'completed'\n",
    "    training_log['duration'] = str(datetime.now() - start_time)\n",
    "    \n",
    "    # Save final metrics\n",
    "    if hasattr(final_results, 'results_dict'):\n",
    "        training_log['final_metrics'] = final_results.results_dict\n",
    "    \n",
    "    # Save updated training log\n",
    "    with open(training_log_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(training_log, f, indent=2)\n",
    "    \n",
    "    print('\\n‚úì Training completed successfully!')\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print('\\n‚ö†Ô∏è  Training interrupted by user')\n",
    "    print(f'üíæ Progress saved to: {TRAIN_DIR}')\n",
    "    print(f'   - Last checkpoint: {checkpoint_path}')\n",
    "    print(f'   - Training log: {training_log_path}')\n",
    "    print(f'\\nüîÑ To resume: Simply re-run this notebook')\n",
    "    \n",
    "    # Update training log\n",
    "    training_log['last_interrupt'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    training_log['status'] = 'interrupted'\n",
    "    training_log['end_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    with open(training_log_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(training_log, f, indent=2)\n",
    "    raise\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f'\\n‚ùå Training failed with error: {e}')\n",
    "    training_log['status'] = 'failed'\n",
    "    training_log['error'] = str(e)\n",
    "    training_log['end_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    with open(training_log_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(training_log, f, indent=2)\n",
    "    raise\n",
    "    \n",
    "finally:\n",
    "    if USE_WANDB and wandb_training_run is not None:\n",
    "        wandb_training_run.finish()\n",
    "        print('‚úì W&B run finished')\n",
    "\n",
    "end_time = datetime.now()\n",
    "duration = end_time - start_time\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('TRAINING SUMMARY')\n",
    "print('=' * 80)\n",
    "\n",
    "# Get final validation metrics\n",
    "print('\\nüìä Running final validation...')\n",
    "final_val_results = final_model.val(\n",
    "    data=str(DATA_YAML_PATH),\n",
    "    project=str(TRAIN_DIR),\n",
    "    name='final_val',\n",
    ")\n",
    "\n",
    "final_metrics = {\n",
    "    'map50': float(final_val_results.box.map50),\n",
    "    'map50_95': float(final_val_results.box.map),\n",
    "    'precision': float(final_val_results.box.mp),\n",
    "    'recall': float(final_val_results.box.mr),\n",
    "}\n",
    "\n",
    "print('\\nüìä Final Model Performance:')\n",
    "print(f\"  mAP@0.5: {final_metrics['map50']:.4f}\")\n",
    "print(f\"  mAP@0.5:0.95: {final_metrics['map50_95']:.4f}\")\n",
    "print(f\"  Precision: {final_metrics['precision']:.4f}\")\n",
    "print(f\"  Recall: {final_metrics['recall']:.4f}\")\n",
    "\n",
    "# Update training log with final metrics\n",
    "training_log['final_metrics'] = final_metrics\n",
    "training_log['best_model_path'] = str(TRAIN_DIR / 'weights' / 'best.pt')\n",
    "training_log['last_model_path'] = str(TRAIN_DIR / 'weights' / 'last.pt')\n",
    "\n",
    "# Save final training log\n",
    "with open(training_log_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(training_log, f, indent=2)\n",
    "\n",
    "print(f'\\nüíæ Training log saved: {training_log_path}')\n",
    "\n",
    "# Compare with tuning results if available\n",
    "if not USE_DEFAULT_CONFIG and tuning_metadata_path.exists():\n",
    "    tuning_best_map = tuning_metadata.get('best_map50', 0)\n",
    "    improvement = final_metrics['map50'] - tuning_best_map\n",
    "    print('\\nüìà Improvement vs Best Tuning Trial:')\n",
    "    print(f\"  Best Tuning mAP@0.5: {tuning_best_map:.4f}\")\n",
    "    print(f\"  Final Model mAP@0.5: {final_metrics['map50']:.4f}\")\n",
    "\n",
    "    print(f\"  Improvement: {improvement:+.4f} ({improvement/tuning_best_map*100:+.2f}%)\")\n",
    "    print('=' * 80)\n",
    "\n",
    "print(f'Last Weights: {TRAIN_DIR / \"weights\" / \"last.pt\"}')\n",
    "\n",
    "print('=' * 80)\n",
    "print(f'Best Weights: {TRAIN_DIR / \"weights\" / \"best.pt\"}')\n",
    "\n",
    "print(f'Training Directory: {TRAIN_DIR}')\n",
    "\n",
    "print(f'Start Time: {start_time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "print(f'Configuration: {\"Default YOLO\" if USE_DEFAULT_CONFIG else f\"Tuned ({TUNING_RUN_NAME})\"}')\n",
    "\n",
    "print(f'End Time: {end_time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "print(f'Duration: {duration}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b00a39",
   "metadata": {},
   "source": [
    "## 8. Save Final Model and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d959bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SAVE FINAL OPTIMIZED MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('SAVING FINAL OPTIMIZED MODEL')\n",
    "print('=' * 80)\n",
    "\n",
    "date_stamp = datetime.now().strftime('%Y%m%d')\n",
    "finetuned_model_name = f'{MODEL_NAME}_finetuned_{date_stamp}'\n",
    "\n",
    "# Create model directory if it doesn't exist\n",
    "model_save_dir = BASE_DIR / 'models' / finetuned_model_name\n",
    "model_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define paths for saving\n",
    "final_model_path = model_save_dir / f'{finetuned_model_name}.pt'\n",
    "metadata_path = model_save_dir / f'{finetuned_model_name}_metadata.json'\n",
    "\n",
    "# Copy best weights from training directory\n",
    "# Note: TRAIN_DIR already includes RUN_NAME_TRAINING\n",
    "weights_path = TRAIN_DIR / 'weights' / 'best.pt'\n",
    "\n",
    "if weights_path.exists():\n",
    "    shutil.copy(weights_path, final_model_path)\n",
    "    print(f'\\n‚úì Final model saved to: {final_model_path}')\n",
    "    print(f'  Size: {final_model_path.stat().st_size / (1024*1024):.1f} MB')\n",
    "else:\n",
    "    print(f'\\n‚ö†Ô∏è  Best weights not found at: {weights_path}')\n",
    "    print('  Attempting to save current model state...')\n",
    "    try:\n",
    "        # Save current model state if weights not found\n",
    "        final_model.save(str(final_model_path))\n",
    "        print(f'‚úì Model saved to: {final_model_path}')\n",
    "    except Exception as save_error:\n",
    "        print(f'‚ö†Ô∏è  Error saving model: {save_error}')\n",
    "\n",
    "# Prepare optimization metadata\n",
    "optimization_meta = {\n",
    "    'tuning_run': TUNING_RUN_NAME,\n",
    "    'tuning_run_path': str(TUNE_DIR),\n",
    "}\n",
    "\n",
    "# Add tuning details if available\n",
    "if not USE_DEFAULT_CONFIG and tuning_metadata_path.exists():\n",
    "    optimization_meta.update({\n",
    "        'n_trials': tuning_metadata.get('total_trials', 'N/A'),\n",
    "        'completed_trials': tuning_metadata.get('completed_trials', 'N/A'),\n",
    "        'best_trial': tuning_metadata.get('best_trial', 'N/A'),\n",
    "        'best_trial_map50': tuning_metadata.get('best_map50', 0),\n",
    "        'optimization_duration': tuning_metadata.get('optimization_duration', 'N/A'),\n",
    "    })\n",
    "\n",
    "# Calculate improvement if tuning metadata available\n",
    "improvement_value = 0\n",
    "if not USE_DEFAULT_CONFIG and tuning_metadata_path.exists():\n",
    "    tuning_best_map = tuning_metadata.get('best_map50', 0)\n",
    "    if tuning_best_map > 0:\n",
    "        improvement_value = float(final_metrics['map50'] - tuning_best_map)\n",
    "\n",
    "# Save model metadata\n",
    "metadata = {\n",
    "    'model_name': MODEL_NAME,\n",
    "    'finetuned_name': finetuned_model_name,\n",
    "    'model_path': str(final_model_path),\n",
    "    'dataset': str(YOLO_DATASET_ROOT),\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'training_run': RUN_NAME_TRAINING,\n",
    "    'training_run_path': str(TRAIN_DIR),\n",
    "    'optimization': optimization_meta,\n",
    "    'best_hyperparameters': best_params,\n",
    "    'training_params': {\n",
    "        'epochs': EPOCHS_FINAL_TRAINING,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'image_size': best_params.get('imgsz', 640),\n",
    "        'patience': ModelConfig.DEFAULT_PATIENCE,\n",
    "        'save_period': ModelConfig.DEFAULT_SAVE_PERIOD,\n",
    "    },\n",
    "    'final_metrics': final_metrics,\n",
    "    'improvement_vs_tuning': improvement_value,\n",
    "}\n",
    "\n",
    "with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f'‚úì Model metadata saved to: {metadata_path}')\n",
    "print('\\nüì¶ Final Model Package:')\n",
    "print(f'  Model: {final_model_path}')\n",
    "print(f'  Metadata: {metadata_path}')\n",
    "print(f'  Training Log: {training_log_path}')\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338ab57b",
   "metadata": {},
   "source": [
    "## 9. Test Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfc6346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN FINAL VALIDATION ON TEST SET (ENHANCED)\n",
    "# ============================================================================\n",
    "print('\\n' + '=' * 80)\n",
    "print('RUNNING FINAL VALIDATION ON TEST SET')\n",
    "print('=' * 80)\n",
    "\n",
    "results_summary = []\n",
    "IOU_THRESHOLDS = 0.5  # Could expand to [0.5, 0.55, 0.6] if needed\n",
    "\n",
    "# Verify that the final model exists before validation\n",
    "if not final_model_path.exists():\n",
    "    print(f\"‚ö†Ô∏è  Warning: Final model not found at {final_model_path}\")\n",
    "    print(f\"   Skipping test validation. Please complete training first.\")\n",
    "else:\n",
    "    # Add YOLO test scripts path safely\n",
    "    scrpt_dir = BASE_DIR / \"yolo_test\"\n",
    "    if str(scrpt_dir) not in sys.path:\n",
    "        sys.path.append(str(scrpt_dir))\n",
    "\n",
    "    try:\n",
    "        from run_yolo_detailed_testing_report import run_validation_pipeline\n",
    "\n",
    "        # Important: \n",
    "        # - Datasets are in DATASET_BASE_DIR (can be different in Colab)\n",
    "        # - Models are ALWAYS in BASE_DIR/models/\n",
    "        # \n",
    "        # Validation script uses base_dir for both:\n",
    "        #   - Dataset path: base_dir / dataset_name / data.yaml\n",
    "        #   - Model path: base_dir / models / model_name / model_name.pt\n",
    "        #\n",
    "        # Solution: Copy dataset to BASE_DIR temporarily, or use symlink\n",
    "        \n",
    "        # For Colab: Need to ensure model is accessible\n",
    "        if IS_COLAB:\n",
    "            # Check if dataset exists in BASE_DIR\n",
    "            base_dir_dataset = BASE_DIR / dataset_name\n",
    "            if not (base_dir_dataset / 'data.yaml').exists() and YOLO_DATASET_ROOT.exists():\n",
    "                print(f\"\\nüìÇ Dataset location mismatch detected\")\n",
    "                print(f\"   Dataset is in: {YOLO_DATASET_ROOT}\")\n",
    "                print(f\"   Validation expects: {base_dir_dataset}\")\n",
    "                print(f\"   Creating symbolic link...\")\n",
    "                try:\n",
    "                    import os\n",
    "                    if not base_dir_dataset.exists():\n",
    "                        os.symlink(str(YOLO_DATASET_ROOT), str(base_dir_dataset))\n",
    "                        print(f\"   ‚úì Symbolic link created\")\n",
    "                except Exception as symlink_error:\n",
    "                    print(f\"   ‚ö†Ô∏è  Could not create symlink: {symlink_error}\")\n",
    "                    print(f\"   Validation may fail if dataset path is incorrect\")\n",
    "            \n",
    "            validation_base_dir = BASE_DIR\n",
    "        else:\n",
    "            validation_base_dir = BASE_DIR\n",
    "        \n",
    "        print(f\"\\nüîç Validation Configuration:\")\n",
    "        print(f\"   Base Dir: {validation_base_dir}\")\n",
    "        print(f\"   Dataset: {dataset_name}\")\n",
    "        print(f\"   Model: {finetuned_model_name}\")\n",
    "        print(f\"   Expected dataset path: {validation_base_dir / dataset_name / 'data.yaml'}\")\n",
    "        print(f\"   Expected model path: {validation_base_dir / 'models' / finetuned_model_name / f'{finetuned_model_name}.pt'}\")\n",
    "        print(f\"   Actual model path: {final_model_path}\")\n",
    "        \n",
    "        # Verify paths\n",
    "        expected_model_path = validation_base_dir / 'models' / finetuned_model_name / f'{finetuned_model_name}.pt'\n",
    "        if final_model_path != expected_model_path and not expected_model_path.exists():\n",
    "            print(f\"\\nüì¶ Copying model to expected location...\")\n",
    "            expected_model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            shutil.copy(final_model_path, expected_model_path)\n",
    "            print(f\"   ‚úì Model copied to {expected_model_path}\")\n",
    "        \n",
    "        result = run_validation_pipeline(\n",
    "            model_name=finetuned_model_name,\n",
    "            dataset_name=dataset_name,\n",
    "            split=\"test\",\n",
    "            iou_threshold=IOU_THRESHOLDS,\n",
    "            base_dir=validation_base_dir,\n",
    "            use_wandb=True,\n",
    "            save_reports=True,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            include_training_exposure_analysis=True\n",
    "        )\n",
    "        \n",
    "        overall = result[\"metrics\"][\"overall\"]\n",
    "        yolo_overall = result[\"metrics\"][\"yolo_metrics\"]\n",
    "        \n",
    "        results_summary.append({\n",
    "            \"model_name\": finetuned_model_name,\n",
    "            \"dataset\": dataset_name,\n",
    "            \"split\": \"test\",\n",
    "            \"iou\": IOU_THRESHOLDS,\n",
    "            \"precision_confusion\": overall[\"precision\"],\n",
    "            \"recall_confusion\": overall[\"recall\"],\n",
    "            \"f1_confusion\": overall[\"f1\"],\n",
    "            \"precision_yolo\": yolo_overall[\"precision\"],\n",
    "            \"recall_yolo\": yolo_overall[\"recall\"],\n",
    "            \"map50\": yolo_overall[\"map50\"],\n",
    "            \"map50_95\": yolo_overall[\"map50_95\"],\n",
    "            \"params_m\": result[\"model_info\"][\"params\"] / 1e6,\n",
    "            \"size_mb\": result[\"model_info\"][\"size(MB)\"],\n",
    "            \"fps\": result[\"metrics\"][\"fps\"],\n",
    "            \"status\": \"ok\",\n",
    "            \"run_dir\": str(result[\"run_dir\"]),\n",
    "            \"hyperparameters\": final_training_params,  # traceable\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Model {finetuned_model_name} failed during validation: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        results_summary.append({\n",
    "            \"model_name\": finetuned_model_name,\n",
    "            \"dataset\": dataset_name,\n",
    "            \"split\": \"test\",\n",
    "            \"iou\": IOU_THRESHOLDS,\n",
    "            \"status\": \"error\",\n",
    "            \"error_message\": str(e)\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "if results_summary:\n",
    "    results_df = pd.DataFrame(results_summary)\n",
    "    print('\\nüìä Final Validation Results:')\n",
    "    display(results_df)\n",
    "else:\n",
    "    print('\\n‚ö†Ô∏è  No validation results - model training not completed yet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35471d99",
   "metadata": {},
   "source": [
    "## 10. Generate Training Report (PDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66f810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE COMPREHENSIVE TRAINING PDF REPORT\n",
    "# ============================================================================\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib import colors as rl_colors\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, Image, PageBreak\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.enums import TA_CENTER, TA_LEFT\n",
    "import platform\n",
    "import psutil\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('GENERATING COMPREHENSIVE TRAINING PDF REPORT')\n",
    "print('=' * 80)\n",
    "\n",
    "pdf_training_report_path = TRAIN_DIR / f'{MODEL_NAME}_training_report.pdf'\n",
    "doc = SimpleDocTemplate(str(pdf_training_report_path), pagesize=A4,\n",
    "                       rightMargin=30, leftMargin=30,\n",
    "                       topMargin=30, bottomMargin=30)\n",
    "story = []\n",
    "styles = getSampleStyleSheet()\n",
    "\n",
    "# Custom styles\n",
    "title_style = ParagraphStyle('Title', parent=styles['Heading1'], fontSize=24,\n",
    "                             textColor=rl_colors.HexColor('#2c3e50'), alignment=TA_CENTER, spaceAfter=20)\n",
    "heading_style = ParagraphStyle('Heading', parent=styles['Heading2'], fontSize=16,\n",
    "                               textColor=rl_colors.HexColor('#34495e'), spaceAfter=12, spaceBefore=20)\n",
    "normal_style = ParagraphStyle('Normal', parent=styles['Normal'], fontSize=10)\n",
    "\n",
    "# --- Title ---\n",
    "story.append(Paragraph(f'{MODEL_NAME} Final Training Report', title_style))\n",
    "story.append(Spacer(1, 12))\n",
    "\n",
    "# --- System Info ---\n",
    "story.append(Paragraph('System Information', heading_style))\n",
    "sys_info_data = [\n",
    "    ['OS', platform.system() + ' ' + platform.release()],\n",
    "    ['Python Version', platform.python_version()],\n",
    "    ['PyTorch Version', torch.__version__],\n",
    "    ['CUDA Available', str(torch.cuda.is_available())],\n",
    "    ['Device', device],\n",
    "    ['RAM (GB)', f\"{psutil.virtual_memory().total/1e9:.2f}\"],\n",
    "]\n",
    "sys_table = Table(sys_info_data, colWidths=[2.5*inch, 3.5*inch])\n",
    "sys_table.setStyle(TableStyle([\n",
    "    ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#95a5a6')),\n",
    "    ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n",
    "    ('GRID', (0,0), (-1,-1), 1, rl_colors.black),\n",
    "    ('FONTNAME', (0,0), (-1,0), 'Helvetica-Bold'),\n",
    "]))\n",
    "story.append(sys_table)\n",
    "story.append(Spacer(1, 12))\n",
    "\n",
    "# --- Dataset Info ---\n",
    "story.append(Paragraph('Dataset Information', heading_style))\n",
    "# Wrap class names text for better readability\n",
    "class_names_text = ', '.join(str(name) for name in CLASS_NAMES.values())\n",
    "class_names_wrapped = Paragraph(class_names_text, normal_style)\n",
    "\n",
    "dataset_info_data = [\n",
    "    ['Property', 'Value'],\n",
    "    ['Dataset', YOLO_DATASET_ROOT.name],\n",
    "    ['Number of Classes', str(NUM_CLASSES)],\n",
    "    ['Train Images', str(dataset_stats.get('train', {}).get('images', 'N/A'))],\n",
    "    ['Val Images', str(dataset_stats.get('val', {}).get('images', 'N/A'))],\n",
    "    ['Test Images', str(dataset_stats.get('test', {}).get('images', 'N/A'))],\n",
    "    ['Data YAML', str(DATA_YAML_PATH.name)],\n",
    "]\n",
    "dataset_table = Table(dataset_info_data, colWidths=[2*inch, 4*inch])\n",
    "dataset_table.setStyle(TableStyle([\n",
    "    ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#16a085')),\n",
    "    ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n",
    "    ('GRID', (0,0), (-1,-1), 1, rl_colors.black),\n",
    "]))\n",
    "story.append(dataset_table)\n",
    "story.append(Spacer(1, 6))\n",
    "# Add class names separately with wrapping\n",
    "story.append(Paragraph('<b>Classes:</b>', normal_style))\n",
    "story.append(class_names_wrapped)\n",
    "story.append(Spacer(1, 12))\n",
    "\n",
    "# --- Optimization Summary ---\n",
    "story.append(Paragraph('Optimization Summary', heading_style))\n",
    "opt_summary_data = [\n",
    "    ['Metric', 'Value'],\n",
    "    ['Tuning Run', TUNING_RUN_NAME],\n",
    "    ['Total Trials', str(tuning_metadata.get('total_trials', 'N/A')) if not USE_DEFAULT_CONFIG and  tuning_metadata_path.exists() else 'N/A'],\n",
    "    ['Completed Trials', str(tuning_metadata.get('completed_trials', 'N/A')) if not USE_DEFAULT_CONFIG and  tuning_metadata_path.exists() else 'N/A'],\n",
    "    ['Best Trial Number', str(tuning_metadata.get('best_trial', 'N/A')) if not USE_DEFAULT_CONFIG and  tuning_metadata_path.exists() else 'N/A'],\n",
    "    ['Best Trial mAP@0.5', f\"{tuning_metadata.get('best_map50', 0):.4f}\" if not USE_DEFAULT_CONFIG and tuning_metadata_path.exists() else 'N/A'],\n",
    "    ['Final Training Epochs', str(EPOCHS_FINAL_TRAINING)],\n",
    "]\n",
    "opt_table = Table(opt_summary_data, colWidths=[3*inch, 3*inch])\n",
    "opt_table.setStyle(TableStyle([\n",
    "    ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#f39c12')),\n",
    "    ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n",
    "    ('GRID', (0,0), (-1,-1), 1, rl_colors.black),\n",
    "]))\n",
    "story.append(opt_table)\n",
    "story.append(Spacer(1, 12))\n",
    "\n",
    "# --- Optimized Hyperparameters ---\n",
    "story.append(PageBreak())\n",
    "story.append(Paragraph('Optimized Hyperparameters Used', heading_style))\n",
    "hyperparam_data = [['Parameter', 'Value']]\n",
    "for key, value in best_params.items():\n",
    "    hyperparam_data.append([key, f\"{value:.6f}\" if isinstance(value, float) else str(value)])\n",
    "hyperparam_table = Table(hyperparam_data, colWidths=[3*inch, 3*inch])\n",
    "hyperparam_table.setStyle(TableStyle([\n",
    "    ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#3498db')),\n",
    "    ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n",
    "    ('GRID', (0,0), (-1,-1), 1, rl_colors.black),\n",
    "]))\n",
    "story.append(hyperparam_table)\n",
    "story.append(Spacer(1, 12))\n",
    "\n",
    "# --- Training Process Details ---\n",
    "story.append(PageBreak())\n",
    "story.append(Paragraph('Training Process Analysis', heading_style))\n",
    "\n",
    "# Try to load training results CSV for detailed epoch-by-epoch analysis\n",
    "# YOLO saves results.csv directly in the training run directory\n",
    "results_csv = TRAIN_DIR / 'results.csv'\n",
    "if results_csv.exists():\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        import matplotlib.pyplot as plt\n",
    "        import matplotlib\n",
    "        matplotlib.use('Agg')\n",
    "        \n",
    "        # Load results\n",
    "        training_results = pd.read_csv(results_csv)\n",
    "        training_results.columns = training_results.columns.str.strip()\n",
    "        \n",
    "        story.append(Paragraph('Epoch-by-Epoch Training Metrics', styles['Heading3']))\n",
    "        story.append(Spacer(1, 6))\n",
    "        \n",
    "        # Create comprehensive training curves\n",
    "        fig, axes = plt.subplots(3, 2, figsize=(12, 14))\n",
    "        fig.suptitle('Training Progress Over Epochs', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # 1. Loss Curves (Train/Box/Cls/DFL)\n",
    "        ax = axes[0, 0]\n",
    "        if 'train/box_loss' in training_results.columns:\n",
    "            ax.plot(training_results['epoch'], training_results['train/box_loss'], \n",
    "                   label='Box Loss', color='#e74c3c', linewidth=2)\n",
    "        if 'train/cls_loss' in training_results.columns:\n",
    "            ax.plot(training_results['epoch'], training_results['train/cls_loss'], \n",
    "                   label='Class Loss', color='#3498db', linewidth=2)\n",
    "        if 'train/dfl_loss' in training_results.columns:\n",
    "            ax.plot(training_results['epoch'], training_results['train/dfl_loss'], \n",
    "                   label='DFL Loss', color='#f39c12', linewidth=2)\n",
    "        ax.set_xlabel('Epoch', fontsize=10)\n",
    "        ax.set_ylabel('Loss', fontsize=10)\n",
    "        ax.set_title('Training Loss Components', fontsize=12, fontweight='bold')\n",
    "        ax.legend(loc='best', fontsize=9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. Validation Loss Curves\n",
    "        ax = axes[0, 1]\n",
    "        if 'val/box_loss' in training_results.columns:\n",
    "            ax.plot(training_results['epoch'], training_results['val/box_loss'], \n",
    "                   label='Box Loss', color='#e74c3c', linewidth=2, linestyle='--')\n",
    "        if 'val/cls_loss' in training_results.columns:\n",
    "            ax.plot(training_results['epoch'], training_results['val/cls_loss'], \n",
    "                   label='Class Loss', color='#3498db', linewidth=2, linestyle='--')\n",
    "        if 'val/dfl_loss' in training_results.columns:\n",
    "            ax.plot(training_results['epoch'], training_results['val/dfl_loss'], \n",
    "                   label='DFL Loss', color='#f39c12', linewidth=2, linestyle='--')\n",
    "        ax.set_xlabel('Epoch', fontsize=10)\n",
    "        ax.set_ylabel('Loss', fontsize=10)\n",
    "        ax.set_title('Validation Loss Components', fontsize=12, fontweight='bold')\n",
    "        ax.legend(loc='best', fontsize=9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. mAP Metrics Over Epochs\n",
    "        ax = axes[1, 0]\n",
    "        if 'metrics/mAP50(B)' in training_results.columns:\n",
    "            ax.plot(training_results['epoch'], training_results['metrics/mAP50(B)'], \n",
    "                   label='mAP@0.5', color='#27ae60', linewidth=2.5, marker='o', markersize=4)\n",
    "        if 'metrics/mAP50-95(B)' in training_results.columns:\n",
    "            ax.plot(training_results['epoch'], training_results['metrics/mAP50-95(B)'], \n",
    "                   label='mAP@0.5:0.95', color='#16a085', linewidth=2.5, marker='s', markersize=4)\n",
    "        ax.set_xlabel('Epoch', fontsize=10)\n",
    "        ax.set_ylabel('mAP', fontsize=10)\n",
    "        ax.set_title('mAP Progression', fontsize=12, fontweight='bold')\n",
    "        ax.legend(loc='best', fontsize=9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_ylim(0, 1)\n",
    "        \n",
    "        # 4. Precision and Recall\n",
    "        ax = axes[1, 1]\n",
    "        if 'metrics/precision(B)' in training_results.columns:\n",
    "            ax.plot(training_results['epoch'], training_results['metrics/precision(B)'], \n",
    "                   label='Precision', color='#9b59b6', linewidth=2.5, marker='^', markersize=4)\n",
    "        if 'metrics/recall(B)' in training_results.columns:\n",
    "            ax.plot(training_results['epoch'], training_results['metrics/recall(B)'], \n",
    "                   label='Recall', color='#e67e22', linewidth=2.5, marker='v', markersize=4)\n",
    "        ax.set_xlabel('Epoch', fontsize=10)\n",
    "        ax.set_ylabel('Score', fontsize=10)\n",
    "        ax.set_title('Precision & Recall Progression', fontsize=12, fontweight='bold')\n",
    "        ax.legend(loc='best', fontsize=9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_ylim(0, 1)\n",
    "        \n",
    "        # 5. Learning Rate Schedule\n",
    "        ax = axes[2, 0]\n",
    "        if 'lr/pg0' in training_results.columns:\n",
    "            ax.plot(training_results['epoch'], training_results['lr/pg0'], \n",
    "                   label='LR Group 0', color='#34495e', linewidth=2)\n",
    "        if 'lr/pg1' in training_results.columns:\n",
    "            ax.plot(training_results['epoch'], training_results['lr/pg1'], \n",
    "                   label='LR Group 1', color='#7f8c8d', linewidth=2)\n",
    "        if 'lr/pg2' in training_results.columns:\n",
    "            ax.plot(training_results['epoch'], training_results['lr/pg2'], \n",
    "                   label='LR Group 2', color='#95a5a6', linewidth=2)\n",
    "        ax.set_xlabel('Epoch', fontsize=10)\n",
    "        ax.set_ylabel('Learning Rate', fontsize=10)\n",
    "        ax.set_title('Learning Rate Schedule', fontsize=12, fontweight='bold')\n",
    "        ax.legend(loc='best', fontsize=9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 6. Combined Loss (Train vs Val)\n",
    "        ax = axes[2, 1]\n",
    "        # Calculate total train loss if components available\n",
    "        train_loss_cols = [col for col in training_results.columns if 'train/' in col and 'loss' in col]\n",
    "        val_loss_cols = [col for col in training_results.columns if 'val/' in col and 'loss' in col]\n",
    "        \n",
    "        if train_loss_cols:\n",
    "            train_total = training_results[train_loss_cols].sum(axis=1)\n",
    "            ax.plot(training_results['epoch'], train_total, \n",
    "                   label='Total Train Loss', color='#c0392b', linewidth=2.5)\n",
    "        if val_loss_cols:\n",
    "            val_total = training_results[val_loss_cols].sum(axis=1)\n",
    "            ax.plot(training_results['epoch'], val_total, \n",
    "                   label='Total Val Loss', color='#2980b9', linewidth=2.5, linestyle='--')\n",
    "        ax.set_xlabel('Epoch', fontsize=10)\n",
    "        ax.set_ylabel('Total Loss', fontsize=10)\n",
    "        ax.set_title('Total Loss: Train vs Validation', fontsize=12, fontweight='bold')\n",
    "        ax.legend(loc='best', fontsize=9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save training curves\n",
    "        training_curves_img = TRAIN_DIR / 'report_training_curves.png'\n",
    "        plt.savefig(training_curves_img, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Add to PDF\n",
    "        story.append(Image(str(training_curves_img), width=6.5*inch, height=7.5*inch))\n",
    "        story.append(Spacer(1, 12))\n",
    "        \n",
    "        # Epoch-by-Epoch Summary Table (First 10, Middle 5, Last 10)\n",
    "        story.append(PageBreak())\n",
    "        story.append(Paragraph('Detailed Epoch Metrics', styles['Heading3']))\n",
    "        story.append(Spacer(1, 6))\n",
    "        \n",
    "        # Select representative epochs\n",
    "        total_epochs = len(training_results)\n",
    "        if total_epochs <= 25:\n",
    "            selected_epochs = training_results\n",
    "        else:\n",
    "            # First 10, middle 5, last 10\n",
    "            first_10 = training_results.head(10)\n",
    "            middle_start = total_epochs // 2 - 2\n",
    "            middle_5 = training_results.iloc[middle_start:middle_start+5]\n",
    "            last_10 = training_results.tail(10)\n",
    "            selected_epochs = pd.concat([first_10, middle_5, last_10])\n",
    "        \n",
    "        # Build table with key metrics\n",
    "        epoch_table_data = [['Epoch', 'Train Loss', 'Val Loss', 'mAP@0.5', 'mAP@0.5:0.95', 'Precision', 'Recall']]\n",
    "        \n",
    "        for _, row in selected_epochs.iterrows():\n",
    "            epoch_num = int(row['epoch']) if 'epoch' in row else '?'\n",
    "            \n",
    "            # Calculate total losses\n",
    "            train_loss = sum([row.get(col, 0) for col in train_loss_cols]) if train_loss_cols else 'N/A'\n",
    "            val_loss = sum([row.get(col, 0) for col in val_loss_cols]) if val_loss_cols else 'N/A'\n",
    "            \n",
    "            map50 = f\"{row.get('metrics/mAP50(B)', 0):.4f}\" if 'metrics/mAP50(B)' in row else 'N/A'\n",
    "            map50_95 = f\"{row.get('metrics/mAP50-95(B)', 0):.4f}\" if 'metrics/mAP50-95(B)' in row else 'N/A'\n",
    "            precision = f\"{row.get('metrics/precision(B)', 0):.4f}\" if 'metrics/precision(B)' in row else 'N/A'\n",
    "            recall = f\"{row.get('metrics/recall(B)', 0):.4f}\" if 'metrics/recall(B)' in row else 'N/A'\n",
    "            \n",
    "            epoch_table_data.append([\n",
    "                str(epoch_num),\n",
    "                f\"{train_loss:.4f}\" if isinstance(train_loss, (int, float)) else train_loss,\n",
    "                f\"{val_loss:.4f}\" if isinstance(val_loss, (int, float)) else val_loss,\n",
    "                map50,\n",
    "                map50_95,\n",
    "                precision,\n",
    "                recall\n",
    "            ])\n",
    "        \n",
    "        epoch_table = Table(epoch_table_data, colWidths=[0.6*inch, 1*inch, 1*inch, 0.9*inch, 1.1*inch, 0.9*inch, 0.9*inch])\n",
    "        epoch_table.setStyle(TableStyle([\n",
    "            ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#8e44ad')),\n",
    "            ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n",
    "            ('FONTSIZE', (0,0), (-1,-1), 8),\n",
    "            ('GRID', (0,0), (-1,-1), 0.5, rl_colors.black),\n",
    "            ('FONTNAME', (0,0), (-1,0), 'Helvetica-Bold'),\n",
    "            ('ALIGN', (0,0), (-1,-1), 'CENTER'),\n",
    "        ]))\n",
    "        story.append(epoch_table)\n",
    "        story.append(Spacer(1, 12))\n",
    "        \n",
    "        # Training Summary Statistics\n",
    "        story.append(Paragraph('Training Statistics Summary', styles['Heading3']))\n",
    "        story.append(Spacer(1, 6))\n",
    "        \n",
    "        stats_data = [['Metric', 'Initial', 'Final', 'Best', 'Change']]\n",
    "        \n",
    "        # mAP@0.5\n",
    "        if 'metrics/mAP50(B)' in training_results.columns:\n",
    "            map50_col = training_results['metrics/mAP50(B)']\n",
    "            stats_data.append([\n",
    "                'mAP@0.5',\n",
    "                f\"{map50_col.iloc[0]:.4f}\",\n",
    "                f\"{map50_col.iloc[-1]:.4f}\",\n",
    "                f\"{map50_col.max():.4f}\",\n",
    "                f\"+{map50_col.iloc[-1] - map50_col.iloc[0]:.4f}\"\n",
    "            ])\n",
    "        \n",
    "        # mAP@0.5:0.95\n",
    "        if 'metrics/mAP50-95(B)' in training_results.columns:\n",
    "            map50_95_col = training_results['metrics/mAP50-95(B)']\n",
    "            stats_data.append([\n",
    "                'mAP@0.5:0.95',\n",
    "                f\"{map50_95_col.iloc[0]:.4f}\",\n",
    "                f\"{map50_95_col.iloc[-1]:.4f}\",\n",
    "                f\"{map50_95_col.max():.4f}\",\n",
    "                f\"+{map50_95_col.iloc[-1] - map50_95_col.iloc[0]:.4f}\"\n",
    "            ])\n",
    "        \n",
    "        # Precision\n",
    "        if 'metrics/precision(B)' in training_results.columns:\n",
    "            prec_col = training_results['metrics/precision(B)']\n",
    "            stats_data.append([\n",
    "                'Precision',\n",
    "                f\"{prec_col.iloc[0]:.4f}\",\n",
    "                f\"{prec_col.iloc[-1]:.4f}\",\n",
    "                f\"{prec_col.max():.4f}\",\n",
    "                f\"+{prec_col.iloc[-1] - prec_col.iloc[0]:.4f}\"\n",
    "            ])\n",
    "        \n",
    "        # Recall\n",
    "        if 'metrics/recall(B)' in training_results.columns:\n",
    "            recall_col = training_results['metrics/recall(B)']\n",
    "            stats_data.append([\n",
    "                'Recall',\n",
    "                f\"{recall_col.iloc[0]:.4f}\",\n",
    "                f\"{recall_col.iloc[-1]:.4f}\",\n",
    "                f\"{recall_col.max():.4f}\",\n",
    "                f\"+{recall_col.iloc[-1] - recall_col.iloc[0]:.4f}\"\n",
    "            ])\n",
    "        \n",
    "        stats_table = Table(stats_data, colWidths=[1.5*inch, 1*inch, 1*inch, 1*inch, 1*inch])\n",
    "        stats_table.setStyle(TableStyle([\n",
    "            ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#2ecc71')),\n",
    "            ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n",
    "            ('GRID', (0,0), (-1,-1), 1, rl_colors.black),\n",
    "            ('FONTNAME', (0,0), (-1,0), 'Helvetica-Bold'),\n",
    "            ('ALIGN', (1,1), (-1,-1), 'CENTER'),\n",
    "        ]))\n",
    "        story.append(stats_table)\n",
    "        story.append(Spacer(1, 12))\n",
    "        \n",
    "    except Exception as e:\n",
    "        story.append(Paragraph(f'Could not load detailed training results: {str(e)}', normal_style))\n",
    "        story.append(Spacer(1, 12))\n",
    "else:\n",
    "    story.append(Paragraph('Training results file (results.csv) not found. Train the model to generate detailed metrics.', normal_style))\n",
    "    story.append(Spacer(1, 12))\n",
    "\n",
    "# --- Final Model Performance ---\n",
    "if 'final_metrics' in globals():\n",
    "    story.append(PageBreak())\n",
    "    story.append(Paragraph('Final Model Performance', heading_style))\n",
    "    \n",
    "    perf_data = [\n",
    "        ['Metric', 'Value'],\n",
    "        ['mAP@0.5', f\"{final_metrics['map50']:.4f}\"],\n",
    "        ['mAP@0.5:0.95', f\"{final_metrics['map50_95']:.4f}\"],\n",
    "        ['Precision', f\"{final_metrics['precision']:.4f}\"],\n",
    "        ['Recall', f\"{final_metrics['recall']:.4f}\"],\n",
    "    ]\n",
    "    perf_table = Table(perf_data, colWidths=[3*inch, 3*inch])\n",
    "    perf_table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#27ae60')),\n",
    "        ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n",
    "        ('GRID', (0,0), (-1,-1), 1, rl_colors.black),\n",
    "    ]))\n",
    "    story.append(perf_table)\n",
    "    story.append(Spacer(1, 12))\n",
    "\n",
    "# --- Test Set Validation Results ---\n",
    "if 'result' in globals() and 'metrics' in result:\n",
    "    story.append(PageBreak())\n",
    "    story.append(Paragraph('Test Set Validation Results', heading_style))\n",
    "    story.append(Spacer(1, 6))\n",
    "    \n",
    "    # Test metrics summary\n",
    "    test_metrics = result['metrics']\n",
    "    test_overall = test_metrics['overall']\n",
    "    test_yolo = test_metrics['yolo_metrics']\n",
    "    test_model_info = result['model_info']\n",
    "    \n",
    "    # Model Architecture and Performance Summary\n",
    "    story.append(Paragraph('Model Architecture & Performance', styles['Heading3']))\n",
    "    model_arch_data = [\n",
    "        ['Metric', 'Value'],\n",
    "        ['Model Name', finetuned_model_name],\n",
    "        ['Parameters (M)', f\"{test_model_info.get('params', 0) / 1e6:.2f}\"],\n",
    "        ['Model Size (MB)', f\"{test_model_info.get('size(MB)', 0):.2f}\"],\n",
    "        ['FLOPs (G)', f\"{test_model_info.get('FLOPs(G)', 0):.2f}\"],\n",
    "        ['Layers', str(test_model_info.get('layers', 'N/A'))],\n",
    "        ['Inference Speed (FPS)', f\"{test_metrics['fps']:.2f}\"],\n",
    "        ['IoU Threshold', f\"{IOU_THRESHOLDS:.2f}\"],\n",
    "    ]\n",
    "    model_arch_table = Table(model_arch_data, colWidths=[2.5*inch, 3.5*inch])\n",
    "    model_arch_table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#34495e')),\n",
    "        ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n",
    "        ('GRID', (0,0), (-1,-1), 1, rl_colors.black),\n",
    "        ('FONTNAME', (0,0), (-1,0), 'Helvetica-Bold'),\n",
    "        ('ALIGN', (1,1), (-1,-1), 'CENTER'),\n",
    "    ]))\n",
    "    story.append(model_arch_table)\n",
    "    story.append(Spacer(1, 12))\n",
    "    \n",
    "    # Overall Performance Metrics\n",
    "    story.append(Paragraph('Overall Performance Metrics on Test Set', styles['Heading3']))\n",
    "    test_perf_data = [\n",
    "        ['Metric', 'Confusion Matrix', 'YOLO Validation'],\n",
    "        ['Precision', f\"{test_overall['precision']:.4f}\", f\"{test_yolo['precision']:.4f}\"],\n",
    "        ['Recall', f\"{test_overall['recall']:.4f}\", f\"{test_yolo['recall']:.4f}\"],\n",
    "        ['F1-Score', f\"{test_overall['f1']:.4f}\", 'N/A'],\n",
    "        ['mAP@0.5 (Overall)', 'N/A', f\"{test_yolo['map50']:.4f}\"],\n",
    "        ['mAP@0.5:0.95 (Overall)', 'N/A', f\"{test_yolo['map50_95']:.4f}\"],\n",
    "    ]\n",
    "    test_perf_table = Table(test_perf_data, colWidths=[2*inch, 2*inch, 2*inch])\n",
    "    test_perf_table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#e74c3c')),\n",
    "        ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n",
    "        ('GRID', (0,0), (-1,-1), 1, rl_colors.black),\n",
    "        ('FONTNAME', (0,0), (-1,0), 'Helvetica-Bold'),\n",
    "        ('ALIGN', (1,0), (-1,-1), 'CENTER'),\n",
    "    ]))\n",
    "    story.append(test_perf_table)\n",
    "    story.append(Spacer(1, 12))\n",
    "    \n",
    "    # Per-Class mAP@0.5 and Performance\n",
    "    if 'df_metrics' in result and not result['df_metrics'].empty:\n",
    "        story.append(PageBreak())\n",
    "        story.append(Paragraph('Per-Class Performance Metrics', styles['Heading3']))\n",
    "        story.append(Spacer(1, 6))\n",
    "        \n",
    "        df_metrics = result['df_metrics']\n",
    "        \n",
    "        # Per-class table with all metrics\n",
    "        per_class_data = [['Class', 'Precision', 'Recall', 'F1-Score', 'mAP@0.5', 'TP', 'FP', 'FN']]\n",
    "        for _, row in df_metrics.iterrows():\n",
    "            per_class_data.append([\n",
    "                str(row['Class']),\n",
    "                f\"{row['Precision']:.4f}\",\n",
    "                f\"{row['Recall']:.4f}\",\n",
    "                f\"{row['F1-Score']:.4f}\",\n",
    "                f\"{row['mAP@0.5']:.4f}\",\n",
    "                str(int(row['TP'])),\n",
    "                str(int(row['FP'])),\n",
    "                str(int(row['FN']))\n",
    "            ])\n",
    "        \n",
    "        per_class_table = Table(per_class_data, colWidths=[1.2*inch, 0.8*inch, 0.7*inch, 0.8*inch, 0.8*inch, 0.5*inch, 0.5*inch, 0.5*inch])\n",
    "        per_class_table.setStyle(TableStyle([\n",
    "            ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#9b59b6')),\n",
    "            ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n",
    "            ('FONTSIZE', (0,0), (-1,-1), 8),\n",
    "            ('GRID', (0,0), (-1,-1), 0.5, rl_colors.black),\n",
    "            ('FONTNAME', (0,0), (-1,0), 'Helvetica-Bold'),\n",
    "            ('ALIGN', (1,0), (-1,-1), 'CENTER'),\n",
    "        ]))\n",
    "        story.append(per_class_table)\n",
    "        story.append(Spacer(1, 12))\n",
    "        \n",
    "        # mAP@0.5 by Class visualization\n",
    "        map50_by_class_img = result['figures'].get('map50_by_class')\n",
    "        if map50_by_class_img and Path(map50_by_class_img).exists():\n",
    "            try:\n",
    "                story.append(Paragraph('mAP@0.5 Distribution by Class', styles['Heading4']))\n",
    "                story.append(Spacer(1, 4))\n",
    "                story.append(Image(str(map50_by_class_img), width=6.5*inch, height=4.5*inch))\n",
    "                story.append(Spacer(1, 12))\n",
    "            except Exception as img_error:\n",
    "                story.append(Paragraph(f'Could not load mAP by class chart: {str(img_error)}', normal_style))\n",
    "    \n",
    "    # IoU Information\n",
    "    story.append(PageBreak())\n",
    "    story.append(Paragraph('Intersection over Union (IoU) Analysis', styles['Heading3']))\n",
    "    story.append(Spacer(1, 6))\n",
    "    \n",
    "    iou_info_text = f\"\"\"\n",
    "    <b>IoU Threshold Used:</b> {IOU_THRESHOLDS:.2f}<br/>\n",
    "    <br/>\n",
    "    IoU (Intersection over Union) measures the overlap between predicted and ground truth bounding boxes.\n",
    "    A prediction is considered correct (True Positive) when IoU ‚â• {IOU_THRESHOLDS:.2f}.<br/>\n",
    "    <br/>\n",
    "    <b>Per-Class IoU Performance:</b><br/>\n",
    "    The confusion matrix and per-class metrics above show detection accuracy at IoU={IOU_THRESHOLDS:.2f} threshold.\n",
    "    Each class's True Positives (TP) represent detections with IoU ‚â• {IOU_THRESHOLDS:.2f}.\n",
    "    \"\"\"\n",
    "    story.append(Paragraph(iou_info_text, normal_style))\n",
    "    story.append(Spacer(1, 12))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    story.append(PageBreak())\n",
    "    story.append(Paragraph('Confusion Matrix (Test Set)', styles['Heading3']))\n",
    "    story.append(Spacer(1, 6))\n",
    "    \n",
    "    confusion_matrix_img = result['figures'].get('confusion_matrix')\n",
    "    if confusion_matrix_img and Path(confusion_matrix_img).exists():\n",
    "        try:\n",
    "            with PILImage.open(confusion_matrix_img) as img:\n",
    "                img_width, img_height = img.size\n",
    "                aspect_ratio = img_height / img_width\n",
    "                pdf_width = 6*inch\n",
    "                pdf_height = pdf_width * aspect_ratio\n",
    "                if pdf_height > 6*inch:\n",
    "                    pdf_height = 6*inch\n",
    "                    pdf_width = pdf_height / aspect_ratio\n",
    "                story.append(Image(str(confusion_matrix_img), width=pdf_width, height=pdf_height))\n",
    "                story.append(Spacer(1, 12))\n",
    "        except Exception as img_error:\n",
    "            story.append(Paragraph(f'Could not load confusion matrix: {str(img_error)}', normal_style))\n",
    "    else:\n",
    "        story.append(Paragraph('Confusion matrix image not available.', normal_style))\n",
    "    story.append(Spacer(1, 12))\n",
    "    \n",
    "    # Test Performance Curves - Only add section if curves exist\n",
    "    pr_curve_img = result['figures'].get('pr_curve')\n",
    "    f1_curve_img = result['figures'].get('f1_curve')\n",
    "    overall_metrics_img = result['figures'].get('overall_metrics')\n",
    "    \n",
    "    has_curves = (\n",
    "        (pr_curve_img and Path(pr_curve_img).exists()) or\n",
    "        (f1_curve_img and Path(f1_curve_img).exists()) or\n",
    "        (overall_metrics_img and Path(overall_metrics_img).exists())\n",
    "    )\n",
    "    \n",
    "    if has_curves:\n",
    "        story.append(PageBreak())\n",
    "        story.append(Paragraph('Test Set Performance Curves', styles['Heading3']))\n",
    "        story.append(Spacer(1, 6))\n",
    "        \n",
    "        # PR Curve\n",
    "        if pr_curve_img and Path(pr_curve_img).exists():\n",
    "            try:\n",
    "                story.append(Paragraph('Precision-Recall Curve', styles['Heading4']))\n",
    "                story.append(Image(str(pr_curve_img), width=6*inch, height=4*inch))\n",
    "                story.append(Spacer(1, 12))\n",
    "            except Exception as img_error:\n",
    "                story.append(Paragraph(f'Could not load PR curve: {str(img_error)}', normal_style))\n",
    "        \n",
    "        # F1 Curve\n",
    "        if f1_curve_img and Path(f1_curve_img).exists():\n",
    "            try:\n",
    "                story.append(Paragraph('F1-Score Curve', styles['Heading4']))\n",
    "                story.append(Image(str(f1_curve_img), width=6*inch, height=4*inch))\n",
    "                story.append(Spacer(1, 12))\n",
    "            except Exception as img_error:\n",
    "                story.append(Paragraph(f'Could not load F1 curve: {str(img_error)}', normal_style))\n",
    "        \n",
    "        # Overall Metrics\n",
    "        if overall_metrics_img and Path(overall_metrics_img).exists():\n",
    "            try:\n",
    "                story.append(Paragraph('Overall Metrics Visualization', styles['Heading4']))\n",
    "                story.append(Image(str(overall_metrics_img), width=6.5*inch, height=5*inch))\n",
    "                story.append(Spacer(1, 12))\n",
    "            except Exception as img_error:\n",
    "                story.append(Paragraph(f'Could not load overall metrics: {str(img_error)}', normal_style))\n",
    "    \n",
    "    # Sample Comparison Images\n",
    "    if 'comparison_data' in result and result['comparison_data']:\n",
    "        story.append(PageBreak())\n",
    "        story.append(Paragraph('Sample Predictions: Ground Truth vs Model Output', heading_style))\n",
    "        story.append(Spacer(1, 6))\n",
    "        \n",
    "        # Add up to 6 comparison images\n",
    "        for idx, comp in enumerate(result['comparison_data'][:6], 1):\n",
    "            comp_img_path = comp.get('comparison_image_path')\n",
    "            if comp_img_path and Path(comp_img_path).exists():\n",
    "                try:\n",
    "                    # Add attributes info\n",
    "                    attributes = comp.get('attributes', {})\n",
    "                    attr_text = f\"Sample {idx} - Weather: {attributes.get('weather', 'unknown')}, Scene: {attributes.get('scene', 'unknown')}, Time: {attributes.get('timeofday', 'unknown')}\"\n",
    "                    story.append(Paragraph(attr_text, normal_style))\n",
    "                    story.append(Spacer(1, 4))\n",
    "                    \n",
    "                    # Add comparison image\n",
    "                    with PILImage.open(comp_img_path) as img:\n",
    "                        img_width, img_height = img.size\n",
    "                        aspect_ratio = img_height / img_width\n",
    "                        pdf_width = 6.5*inch\n",
    "                        pdf_height = pdf_width * aspect_ratio\n",
    "                        if pdf_height > 4*inch:\n",
    "                            pdf_height = 4*inch\n",
    "                            pdf_width = pdf_height / aspect_ratio\n",
    "                        story.append(Image(str(comp_img_path), width=pdf_width, height=pdf_height))\n",
    "                    \n",
    "                    # Add object count info\n",
    "                    gt_count = comp.get('gt_count', 0)\n",
    "                    pred_count = comp.get('pred_count', 0)\n",
    "                    count_text = f\"Ground Truth: {gt_count} objects | Predictions: {pred_count} objects\"\n",
    "                    story.append(Paragraph(count_text, ParagraphStyle('Small', parent=normal_style, fontSize=8, textColor=rl_colors.grey)))\n",
    "                    story.append(Spacer(1, 15))\n",
    "                    \n",
    "                    # Page break after every 2 comparisons\n",
    "                    if idx % 2 == 0 and idx < len(result['comparison_data'][:6]):\n",
    "                        story.append(PageBreak())\n",
    "                        \n",
    "                except Exception as img_error:\n",
    "                    story.append(Paragraph(f'Could not load comparison {idx}: {str(img_error)}', normal_style))\n",
    "                    story.append(Spacer(1, 12))\n",
    "\n",
    "elif 'results_summary' in globals() and len(results_summary) > 0 and results_summary[0].get('status') == 'ok':\n",
    "    # Fallback: Show basic info from results_summary\n",
    "    story.append(PageBreak())\n",
    "    story.append(Paragraph('Test Set Validation Results', heading_style))\n",
    "    \n",
    "    res = results_summary[0]\n",
    "    fallback_data = [\n",
    "        ['Metric', 'Value'],\n",
    "        ['Model', res.get('model_name', 'N/A')],\n",
    "        ['Precision (YOLO)', f\"{res.get('precision_yolo', 0):.4f}\"],\n",
    "        ['Recall (YOLO)', f\"{res.get('recall_yolo', 0):.4f}\"],\n",
    "        ['mAP@0.5', f\"{res.get('map50', 0):.4f}\"],\n",
    "        ['mAP@0.5:0.95', f\"{res.get('map50_95', 0):.4f}\"],\n",
    "        ['Parameters (M)', f\"{res.get('params_m', 0):.2f}\"],\n",
    "        ['Size (MB)', f\"{res.get('size_mb', 0):.2f}\"],\n",
    "        ['FPS', f\"{res.get('fps', 0):.2f}\"],\n",
    "    ]\n",
    "    fallback_table = Table(fallback_data, colWidths=[3*inch, 3*inch])\n",
    "    fallback_table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#95a5a6')),\n",
    "        ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n",
    "        ('GRID', (0,0), (-1,-1), 1, rl_colors.black),\n",
    "    ]))\n",
    "    story.append(fallback_table)\n",
    "    story.append(Spacer(1, 12))\n",
    "    \n",
    "    # Try to load images from run_dir if available\n",
    "    if 'run_dir' in res:\n",
    "        run_dir = Path(res['run_dir'])\n",
    "        \n",
    "        # Try confusion matrix\n",
    "        confusion_img = run_dir / 'confusion_matrix.png'\n",
    "        if confusion_img.exists():\n",
    "            try:\n",
    "                story.append(PageBreak())\n",
    "                story.append(Paragraph('Confusion Matrix', styles['Heading3']))\n",
    "                story.append(Image(str(confusion_img), width=6*inch, height=5*inch))\n",
    "                story.append(Spacer(1, 12))\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Try comparison images\n",
    "        comparisons_dir = run_dir / 'sample_comparisons'\n",
    "        if comparisons_dir.exists():\n",
    "            comparison_imgs = sorted(comparisons_dir.glob('comparison_*.png'))[:4]\n",
    "            if comparison_imgs:\n",
    "                story.append(PageBreak())\n",
    "                story.append(Paragraph('Sample Predictions', styles['Heading3']))\n",
    "                for comp_img in comparison_imgs:\n",
    "                    try:\n",
    "                        story.append(Image(str(comp_img), width=6.5*inch, height=3.5*inch))\n",
    "                        story.append(Spacer(1, 10))\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "# --- Footer ---\n",
    "story.append(Spacer(1, 20))\n",
    "story.append(Paragraph('Generated by YOLO Training Notebook', ParagraphStyle('Footer', parent=styles['Normal'], alignment=TA_CENTER, textColor=rl_colors.grey)))\n",
    "story.append(Paragraph('BDD100K Dataset - Computer Vision Project', ParagraphStyle('Footer2', parent=styles['Normal'], alignment=TA_CENTER, textColor=rl_colors.grey)))\n",
    "\n",
    "# Build PDF\n",
    "try:\n",
    "    doc.build(story)\n",
    "    print(f'\\n‚úì Comprehensive Training PDF generated: {pdf_training_report_path}')\n",
    "except Exception as e:\n",
    "    print(f'\\n‚ùå Error generating PDF: {e}')\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d09278e",
   "metadata": {},
   "source": [
    "## 11. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9576f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n\\n')\n",
    "print('=' * 80)\n",
    "print('FINAL TRAINING COMPLETE!')\n",
    "print('=' * 80)\n",
    "\n",
    "print(f'\\nüìä Project: {MODEL_NAME} on {YOLO_DATASET_ROOT.name}')\n",
    "print(f'üìÖ Date: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "\n",
    "# Tuning Summary\n",
    "print(f'\\nüî¨ Tuning Run Used:')\n",
    "print(f'  Run Name: {TUNING_RUN_NAME}')\n",
    "print(f'  Run Path: {TUNE_DIR}')\n",
    "\n",
    "if not USE_DEFAULT_CONFIG and tuning_metadata_path.exists():\n",
    "    print(f'  Total Trials: {tuning_metadata.get(\"total_trials\", \"N/A\")}')\n",
    "    print(f'  Completed Trials: {tuning_metadata.get(\"completed_trials\", \"N/A\")}')\n",
    "    print(f'  Best Trial: {tuning_metadata.get(\"best_trial\", \"N/A\")}')\n",
    "    print(f'  Best Trial mAP@0.5: {tuning_metadata.get(\"best_map50\", 0):.4f}')\n",
    "    if 'optimization_duration' in tuning_metadata:\n",
    "        print(f'  Tuning Duration: {tuning_metadata[\"optimization_duration\"]}')\n",
    "\n",
    "# Training Summary\n",
    "print(f'\\nüéØ Training Run:')\n",
    "print(f'  Run Name: {RUN_NAME_TRAINING}')\n",
    "print(f'  Run Path: {TRAIN_DIR}')\n",
    "print(f'  Epochs: {EPOCHS_FINAL_TRAINING}')\n",
    "print(f'  Batch Size: {BATCH_SIZE}')\n",
    "\n",
    "if 'final_metrics' in globals():\n",
    "    print(f'\\nüéØ Final Model Performance:')\n",
    "    print(f'  mAP@0.5: {final_metrics[\"map50\"]:.4f}')\n",
    "    print(f'  mAP@0.5:0.95: {final_metrics[\"map50_95\"]:.4f}')\n",
    "    print(f'  Precision: {final_metrics[\"precision\"]:.4f}')\n",
    "    print(f'  Recall: {final_metrics[\"recall\"]:.4f}')\n",
    "    \n",
    "    # Show improvement if available\n",
    "    if not USE_DEFAULT_CONFIG and tuning_metadata_path.exists():\n",
    "        tuning_best_map = tuning_metadata.get('best_map50', 0)\n",
    "        if tuning_best_map > 0:\n",
    "            improvement = final_metrics['map50'] - tuning_best_map\n",
    "            print(f'\\nüìà Improvement vs Tuning:')\n",
    "            print(f'  Tuning Best: {tuning_best_map:.4f}')\n",
    "            print(f'  Training Final: {final_metrics[\"map50\"]:.4f}')\n",
    "            print(f'  Improvement: {improvement:+.4f} ({improvement/tuning_best_map*100:+.2f}%)')\n",
    "\n",
    "print(f'\\nüìÅ Generated Files:')\n",
    "if not USE_DEFAULT_CONFIG:\n",
    "    print(f'\\n  üìä Tuning Results (in {TUNE_DIR.name}):')\n",
    "    print(f'    - best_hyperparameters.json')\n",
    "    print(f'    - best_hparams.yaml')\n",
    "    print(f'    - checkpoint_log.json')\n",
    "    print(f'    - optuna_study.pkl')\n",
    "\n",
    "print(f'\\n  üéØ Training Results (in {TRAIN_DIR.name}):')\n",
    "print(f'    - training_log.json')\n",
    "print(f'    - weights/best.pt')\n",
    "print(f'    - weights/last.pt')\n",
    "print(f'    - results.csv')\n",
    "print(f'  üìÑ Training PDF Report:')\n",
    "print(f'    - {MODEL_NAME}_training_report.pdf')\n",
    "\n",
    "if 'final_model_path' in globals():\n",
    "    print(f'\\n  üéØ Final Model Package:')\n",
    "    print(f'    - {final_model_path.name}')\n",
    "    print(f'    - {metadata_path.name}')\n",
    "    print(f'    Location: {model_save_dir}')\n",
    "\n",
    "print(f'\\nüìÇ All results saved to:')\n",
    "print(f'  Tuning: {TUNE_DIR}')\n",
    "print(f'  Training: {TRAIN_DIR}')\n",
    "if 'model_save_dir' in globals():\n",
    "    print(f'  Final Model: {model_save_dir}')\n",
    "\n",
    "print(f'\\nüöÄ Next Steps:')\n",
    "print(f'  1. Review training PDF report: {TRAIN_DIR / f\"{MODEL_NAME}_training_report.pdf\"}')\n",
    "print(f'  2. Review training plots and metrics in: {TRAIN_DIR}')\n",
    "if 'final_model_path' in globals():\n",
    "    print(f'  3. Use final model for inference: {final_model_path}')\n",
    "    print(f'  4. Evaluate on test set using yolo_test scripts')\n",
    "else:\n",
    "    print(f'  3. Complete training to generate final model')\n",
    "print(f'  5. Consider fine-tuning with different datasets or model sizes')\n",
    "\n",
    "print('\\nüìù To Resume Training:')\n",
    "print(f'  Set RESUME_TRAINING_RUN_NAME = \"{RUN_NAME_TRAINING}\"')\n",
    "print(f'  Then re-run this notebook')\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('SUCCESS! ‚úì')\n",
    "print('=' * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
