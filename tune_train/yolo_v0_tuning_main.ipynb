{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b26f5d6",
   "metadata": {},
   "source": [
    "# YOLO Hyperparameter Tuning\n",
    "\n",
    "- Support for YOLOv8, YOLOv9, YOLOv10, YOLO11, YOLO12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68c7bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directories\n",
    "# Detect environment: Colab or local\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "IS_COLAB = 'COLAB_GPU' in os.environ or os.path.exists('/content')\n",
    "\n",
    "USE_WANDB = True  # Set to False to disable W&B logging\n",
    "\n",
    "\n",
    "\n",
    "if IS_COLAB:\n",
    "    #Mount Google Drive if not already mounted\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/Drive', force_remount=True)\n",
    "    # Running in Google Colab\n",
    "    BASE_DIR = Path('/content/Drive/MyDrive/ksu_yolo_tuning_2025/computer_vision_yolo')\n",
    "    \n",
    "    # Configure W&B API key\n",
    "    if USE_WANDB:\n",
    "        # In Colab, get API key from secrets\n",
    "        from google.colab import userdata\n",
    "        wandb_api_key = userdata.get('wandb_api_key')\n",
    "        os.environ['WANDB_API_KEY'] = wandb_api_key\n",
    "        print('âœ“ W&B API key loaded from Colab secrets')\n",
    "\n",
    "    DATASET_BASE_DIR = Path('/computer_vision_yolo')\n",
    "\n",
    "else:\n",
    "    # Running locally\n",
    "    BASE_DIR = Path.cwd().parent\n",
    "    if USE_WANDB:\n",
    "        print('âœ“ Running locally - W&B will use existing login or prompt')\n",
    "    \n",
    "    DATASET_BASE_DIR = Path.cwd().parent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c504221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! cd /content/Drive/MyDrive/ksu_yolo_tuning_2025 && git clone https://github.com/m3mahdy/computer_vision_yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde7425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! cd {BASE_DIR} && pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da27e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limited dataset\n",
    "# !mkdir {DATASET_BASE_DIR}\n",
    "# !cd {BASE_DIR}/dataset && cp 8_download_extract_other_datasets.py {DATASET_BASE_DIR} && cd {DATASET_BASE_DIR} && python 8_download_extract_other_datasets.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109394c4",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6f98f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries (uncomment if running in Colab)\n",
    "# !pip install -q ultralytics optuna plotly kaleido wandb pyyaml\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import yaml\n",
    "import json\n",
    "import torch\n",
    "import shutil\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import platform\n",
    "import psutil\n",
    "\n",
    "import wandb\n",
    "\n",
    "# YOLO and Optuna imports\n",
    "from ultralytics import YOLO\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances, plot_slice\n",
    "\n",
    "# ReportLab imports for PDF generation\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib import colors as rl_colors\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, Image, PageBreak\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.enums import TA_CENTER, TA_LEFT\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure matplotlib for notebook display\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "# Check GPU availability\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'âœ“ Libraries imported successfully')\n",
    "print(f'âœ“ Device: {device}')\n",
    "if device == 'cuda':\n",
    "    print(f'  GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'  CUDA Version: {torch.version.cuda}')\n",
    "    print(f'  Available Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0915be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# INSTALL AND VERIFY KALEIDO (Required for PNG export of Plotly figures)\n",
    "# ============================================================================\n",
    "# Run this cell to ensure kaleido is installed correctly\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Force reinstall kaleido with a specific compatible version\n",
    "print('ðŸ“¦ Installing kaleido (this may take a moment)...')\n",
    "result = subprocess.run(\n",
    "    [sys.executable, '-m', 'pip', 'install', '--upgrade', '--force-reinstall', 'kaleido==0.2.1'],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print('âœ“ Kaleido 0.2.1 installed successfully')\n",
    "else:\n",
    "    print(f'âš ï¸  Installation warning: {result.stderr}')\n",
    "\n",
    "# Try importing kaleido\n",
    "try:\n",
    "    import kaleido\n",
    "    print('âœ“ Kaleido module imported')\n",
    "except ImportError as e:\n",
    "    print(f'âŒ Failed to import kaleido: {e}')\n",
    "    print('   Please restart the runtime: Runtime > Restart Runtime')\n",
    "\n",
    "# Verify kaleido works with plotly\n",
    "print('\\nðŸ§ª Testing kaleido with Plotly...')\n",
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "    import plotly.io as pio\n",
    "    \n",
    "    # Create a simple test figure\n",
    "    test_fig = go.Figure(data=[go.Scatter(x=[1, 2, 3], y=[1, 2, 3])])\n",
    "    \n",
    "    # Try to convert to PNG bytes (doesn't write to disk)\n",
    "    img_bytes = test_fig.to_image(format=\"png\", width=100, height=100, engine=\"kaleido\")\n",
    "    print(f'âœ“ Kaleido is working correctly! (Generated {len(img_bytes)} bytes)')\n",
    "    print('âœ… PNG export is ready to use')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f'âŒ Kaleido test failed: {type(e).__name__}')\n",
    "    print(f'   Error: {e}')\n",
    "    print('\\nâš ï¸  ACTION REQUIRED:')\n",
    "    print('   1. Go to: Runtime > Restart Runtime')\n",
    "    print('   2. After restart, run all cells again')\n",
    "    print('   3. Kaleido should work after the runtime restart')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eda31f6",
   "metadata": {},
   "source": [
    "## 2. Constants and Enums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2031059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONSTANTS AND ENUMS\n",
    "# ============================================================================\n",
    "\n",
    "class TrialStatus:\n",
    "    \"\"\"Constants for trial execution status\"\"\"\n",
    "    COMPLETED = \"completed\"\n",
    "    FAILED = \"failed\"\n",
    "    PRUNED = \"pruned\"\n",
    "    RUNNING = \"running\"\n",
    "\n",
    "class DatasetSplit:\n",
    "    \"\"\"Constants for dataset split names\"\"\"\n",
    "    TRAIN = \"train\"\n",
    "    VAL = \"val\"\n",
    "    TEST = \"test\"\n",
    "\n",
    "class ModelConfig:\n",
    "    \"\"\"Default model training configuration constants\"\"\"    \n",
    "    # Training workers\n",
    "    DEFAULT_WORKERS = 8  # Number of data loading workers\n",
    "    \n",
    "    # Early stopping and checkpointing\n",
    "    DEFAULT_PATIENCE = 20  # Epochs to wait before early stopping\n",
    "    \n",
    "    # Augmentation timing\n",
    "    CLOSE_MOSAIC_EPOCHS = 10  # Disable mosaic augmentation in last N epochs\n",
    "\n",
    "print('âœ“ Constants and enums defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2659c792",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d163f0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "# Model Selection - Choose one of the following:\n",
    "MODEL_NAME = \"yolov8m_finetuned_1\"\n",
    "\n",
    "#yolov10n is for testing purpose only\n",
    "#Mahdy will work yolov8m\n",
    "\n",
    "\n",
    "# Selected models, to choose from, based on the performance and size:\n",
    "# YOLOv8:  'yolov8s', 'yolov8m'\n",
    "\n",
    "# YOLOv10: 'yolov10s', 'yolov10m'\n",
    "\n",
    "# YOLO12: 'yolo12s'\n",
    "\n",
    "# Directory structure\n",
    "MODELS_DIR = BASE_DIR / 'models' / MODEL_NAME\n",
    "TMP_DIR = BASE_DIR / 'tmp' / MODEL_NAME\n",
    "\n",
    "# Dataset Selection\n",
    "# Option 1: Full dataset (~100k images) - for final optimization: \"bdd100k_yolo\"\n",
    "# Option 2: Limited dataset (representative samples) - for quick tuning: \"bdd100k_yolo_limited\"\n",
    "dataset_name = 'bdd100k_yolo_limited'\n",
    "\n",
    "\n",
    "YOLO_DATASET_ROOT = DATASET_BASE_DIR / dataset_name\n",
    "\n",
    "# data.yaml path\n",
    "DATA_YAML_PATH = YOLO_DATASET_ROOT / 'data.yaml'\n",
    "\n",
    "# Verify dataset exists\n",
    "if not DATA_YAML_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Dataset not found: {DATA_YAML_PATH}\\n\"\n",
    "        f\"Please prepare the dataset first using process_bdd100k_to_yolo_dataset.py\"\n",
    "    )\n",
    "\n",
    "# Update data.yaml path field for Colab compatibility\n",
    "with open(DATA_YAML_PATH, 'r') as yaml_file:\n",
    "    data_config = yaml.safe_load(yaml_file)\n",
    "\n",
    "# Validate required keys in data.yaml\n",
    "required_yaml_keys = ['nc', 'names', 'path']\n",
    "missing_keys = [key for key in required_yaml_keys if key not in data_config]\n",
    "if missing_keys:\n",
    "    raise ValueError(f\"Missing required keys in data.yaml: {missing_keys}\")\n",
    "\n",
    "# Update the 'path' field to use BASE_DIR\n",
    "data_config['path'] = str(YOLO_DATASET_ROOT)\n",
    "\n",
    "# Create a temporary data.yaml with corrected paths\n",
    "temp_data_yaml = TMP_DIR / 'data.yaml'\n",
    "TMP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "with open(temp_data_yaml, 'w') as yaml_output_file:\n",
    "    yaml.dump(data_config, yaml_output_file, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "# Use the temporary data.yaml for training\n",
    "DATA_YAML_PATH = temp_data_yaml\n",
    "\n",
    "# Optimization Configuration\n",
    "N_TRIALS = 40  # Number of optimization trials = 50â€“70 trials\n",
    "TIMEOUT_HOURS = 24  # Maximum time for optimization (None for no limit)\n",
    "N_STARTUP_TRIALS = 10  # Random exploration trials before optimization =10\n",
    "EPOCHS_PER_TRIAL = 8  # Training epochs per trial = 50\n",
    "BATCH_SIZE = 96  # Batch size for training\n",
    "# for T4 GPU:\n",
    "# 64 for 10n, 1 epoch 30 min\n",
    "# 32 for 8m, 1 epoch 45 min\n",
    "\n",
    "# for A100 GPU:\n",
    "# 64 for 10m 1 epoch 11 min, 5 epochs completed in 0.797 hours.\n",
    "# 96 for 8m , 1 epoch 10 min, 5 epochs completed in 0.866 hours.\n",
    "\n",
    "\n",
    "\n",
    "# Weights & Biases (optional)\n",
    "USE_WANDB = True  # Set to True to enable W&B logging\n",
    "WANDB_PROJECT_TUNING = f\"yolo-{YOLO_DATASET_ROOT.name}-tuning\"\n",
    "\n",
    "# ============================================================================\n",
    "# RUN NAME CONFIGURATION - RESUME OR CREATE NEW\n",
    "# ============================================================================\n",
    "# To RESUME an existing run: Set RESUME_RUN_NAME to the run directory name\n",
    "# To START NEW run: Leave RESUME_RUN_NAME as None or empty string\n",
    "# \n",
    "# Example to resume: RESUME_RUN_NAME = \"yolov10n_tune_20251125_143022\"\n",
    "# ============================================================================\n",
    "\n",
    "RESUME_RUN_NAME = None  # Set to run name to resume, or None to create new run\n",
    "\n",
    "if RESUME_RUN_NAME:\n",
    "    # Resume existing run\n",
    "    RUN_NAME_TUNING = RESUME_RUN_NAME\n",
    "    print(f'\\nðŸ”„ RESUME MODE: Will attempt to resume run \"{RESUME_RUN_NAME}\"')\n",
    "else:\n",
    "    # Create new run with timestamp\n",
    "    RUN_TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    RUN_NAME_TUNING = f'{MODEL_NAME}_tune_{RUN_TIMESTAMP}'\n",
    "    print(f'\\nðŸ†• NEW RUN MODE: Creating new run \"{RUN_NAME_TUNING}\"')\n",
    "\n",
    "RUN_NAME_TRAINING = f'{MODEL_NAME}_train_{RUN_TIMESTAMP if not RESUME_RUN_NAME else RESUME_RUN_NAME}'\n",
    "\n",
    "# Create directories for tuning within tune_train folder\n",
    "# All paths are absolute to ensure consistency across environments (local/Colab)\n",
    "TUNE_TRAIN_BASE = BASE_DIR / 'tune_train'\n",
    "TUNE_DIR = TUNE_TRAIN_BASE / 'tune' / RUN_NAME_TUNING\n",
    "TUNE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Keep RUN_DIR for backward compatibility (points to tuning)\n",
    "RUN_DIR = TUNE_DIR\n",
    "# Keep RUN_DIR for backward compatibility (points to tuning)\n",
    "# Read dataset configuration\n",
    "NUM_CLASSES = data_config['nc']\n",
    "CLASS_NAMES = {i: name for i, name in enumerate(data_config['names'])}\n",
    "CLASS_NAME_TO_ID = {name: i for i, name in enumerate(data_config['names'])}\n",
    "\n",
    "print('=' * 80)\n",
    "print('CONFIGURATION SUMMARY')\n",
    "print('=' * 80)\n",
    "print(f'Environment: {\"Google Colab\" if \"COLAB_GPU\" in os.environ or os.path.exists(\"/content\") else \"Local\"}')\n",
    "print(f'Base Directory: {BASE_DIR}')\n",
    "print(f'Model: {MODEL_NAME}')\n",
    "print(f'Dataset: {YOLO_DATASET_ROOT.name}')\n",
    "print(f'Data YAML: {DATA_YAML_PATH}')\n",
    "print(f'  Dataset path in YAML: {data_config[\"path\"]}')\n",
    "print(f'Classes: {NUM_CLASSES}')\n",
    "print(f'Class Names: {CLASS_NAMES}')\n",
    "print(f'Device: {device}')\n",
    "print(f'Optimization Trials: {N_TRIALS}')\n",
    "print(f'Epochs per Trial: {EPOCHS_PER_TRIAL}')\n",
    "print(f'Batch Size: {BATCH_SIZE}')\n",
    "print(f'Timeout: {TIMEOUT_HOURS} hours' if TIMEOUT_HOURS else 'No timeout')\n",
    "print(f'Tuning Directory: {TUNE_DIR}')\n",
    "if USE_WANDB:\n",
    "    print(f'W&B Logging: Enabled')\n",
    "    print(f'  Tuning Project: {WANDB_PROJECT_TUNING}')\n",
    "else:\n",
    "    print(f'W&B Logging: Disabled')\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af35c3f",
   "metadata": {},
   "source": [
    "## 4. Load Base YOLO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deeda88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO model with automatic download\n",
    "model_path = MODELS_DIR / f'{MODEL_NAME}.pt'\n",
    "\n",
    "if not model_path.exists():\n",
    "    print(f'Model not found at {model_path}')\n",
    "    print(f'Downloading {MODEL_NAME} ...')\n",
    "    \n",
    "    try:\n",
    "        # Download model - ensure .pt extension for ultralytics\n",
    "        # Ultralytics expects model names with .pt extension for download\n",
    "        if not MODEL_NAME.endswith('.pt'):\n",
    "            model_name_for_download = MODEL_NAME + '.pt'\n",
    "        else:\n",
    "            model_name_for_download = MODEL_NAME\n",
    "            \n",
    "        print(f'  Requesting model: {model_name_for_download}')\n",
    "        model = YOLO(model_name_for_download)\n",
    "        \n",
    "        # Create models directory\n",
    "        MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save model to our directory using export/save\n",
    "        try:\n",
    "            # Try to save using the model's save method\n",
    "            if hasattr(model, 'save'):\n",
    "                model.save(str(model_path))\n",
    "                print(f'âœ“ Model downloaded and saved to {model_path}')\n",
    "                print(f'  Size: {model_path.stat().st_size / (1024*1024):.1f} MB')\n",
    "            else:\n",
    "                # Fallback: copy from cache\n",
    "                cache_patterns = [\n",
    "                    str(Path.home() / '.cache' / 'ultralytics' / '**' / f'{MODEL_NAME}.pt'),\n",
    "                    str(Path.home() / '.config' / 'Ultralytics' / '**' / f'{MODEL_NAME}.pt'),\n",
    "                ]\n",
    "                \n",
    "                model_found = False\n",
    "                for pattern in cache_patterns:\n",
    "                    cache_paths = glob.glob(pattern, recursive=True)\n",
    "                    if cache_paths:\n",
    "                        shutil.copy(cache_paths[0], model_path)\n",
    "                        print(f'âœ“ Model downloaded and saved to {model_path}')\n",
    "                        print(f'  Size: {model_path.stat().st_size / (1024*1024):.1f} MB')\n",
    "                        model_found = True\n",
    "                        break\n",
    "                \n",
    "                if not model_found:\n",
    "                    print(f'âœ“ Model loaded from ultralytics cache')\n",
    "                    print(f'  Note: Model is in cache, not copied to {model_path}')\n",
    "                    print(f'  This is normal and the model will work correctly')\n",
    "        except Exception as save_error:\n",
    "            print(f'âš ï¸  Could not save model to custom location: {save_error}')\n",
    "            print(f'âœ“ Model loaded successfully from ultralytics cache')\n",
    "            \n",
    "    except Exception as download_error:\n",
    "        print(f'\\nâŒ Error downloading model: {download_error}')\n",
    "        raise\n",
    "else:\n",
    "    model = YOLO(str(model_path))\n",
    "    print(f'âœ“ Model loaded from {model_path}')\n",
    "\n",
    "# Get model information\n",
    "model_info_dict = {}\n",
    "model_info_result = model.info()\n",
    "model_info_keys = [\"layers\", \"params\", \"size(MB)\", \"FLOPs(G)\"]\n",
    "\n",
    "for info_key, info_value in zip(model_info_keys, model_info_result):\n",
    "    model_info_dict[info_key] = info_value\n",
    "    \n",
    "model_params = model_info_dict.get(\"params\", 0)\n",
    "model_size_mb = model_info_dict.get(\"size(MB)\", 0)\n",
    "flops_gflops = model_info_dict.get(\"FLOPs(G)\", 0)\n",
    "\n",
    "\n",
    "print(f'\\nðŸ“Š Model Information:')\n",
    "print(f'  Model: {MODEL_NAME}')\n",
    "print(f'  Classes in model: {len(model.names)}')\n",
    "print(f'  Task: {model.task}')\n",
    "print(f'  Parameters: {model_params / 1e6:.1f}M')\n",
    "print(f'  Model Size: {model_size_mb:.1f} MB')\n",
    "print(f'  FLOPs (640x640): {flops_gflops:.2f} GFLOPs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe0b94d",
   "metadata": {},
   "source": [
    "## 5. Verify Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b15401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VERIFY DATASET STRUCTURE\n",
    "# ============================================================================\n",
    "\n",
    "print('Verifying YOLO dataset structure...')\n",
    "print(f'\\nðŸ“ Dataset Root: {YOLO_DATASET_ROOT}')\n",
    "\n",
    "# Check all splits using constants\n",
    "dataset_stats = {}\n",
    "for split in [DatasetSplit.TRAIN, DatasetSplit.VAL, DatasetSplit.TEST]:\n",
    "    images_dir = YOLO_DATASET_ROOT / 'images' / split\n",
    "    labels_dir = YOLO_DATASET_ROOT / 'labels' / split\n",
    "    \n",
    "    if images_dir.exists() and labels_dir.exists():\n",
    "        num_images = len(list(images_dir.glob('*.jpg'))) + len(list(images_dir.glob('*.png')))\n",
    "        num_labels = len(list(labels_dir.glob('*.txt')))\n",
    "        dataset_stats[split] = {'images': num_images, 'labels': num_labels}\n",
    "        print(f'  âœ“ {split:5s}: {num_images:6d} images, {num_labels:6d} labels')\n",
    "    else:\n",
    "        print(f'  âš ï¸  {split:5s}: Directory not found')\n",
    "        dataset_stats[split] = {'images': 0, 'labels': 0}\n",
    "\n",
    "print(f'\\nðŸ“„ Configuration: {DATA_YAML_PATH}')\n",
    "print(f'  Classes: {NUM_CLASSES}')\n",
    "print(f'  Names: {CLASS_NAMES}')\n",
    "\n",
    "total_images = sum(stats['images'] for stats in dataset_stats.values())\n",
    "print(f'\\nâœ“ Dataset verified: {total_images:,} total images')\n",
    "print('âœ“ Ready for hyperparameter optimization')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf76930",
   "metadata": {},
   "source": [
    "## 6. Define Hyperparameter Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d1ae35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DEFINE FOCUSED HYPERPARAMETER SEARCH SPACE \n",
    "# ============================================================================\n",
    "\n",
    "def define_hyperparameters(trial):\n",
    "    \"\"\"\n",
    "    Focused hyperparameter search for YOLO - only critical high-impact parameters.\n",
    "    \n",
    "    Args:\n",
    "        trial: Optuna trial object for sampling hyperparameters\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary of hyperparameters for YOLO training\n",
    "    \n",
    "    Tuning Strategy:\n",
    "    - Focus ONLY on parameters with proven high impact on performance\n",
    "    - Use YOLO defaults for well-calibrated parameters (HSV, loss weights)\n",
    "    - Reduces search space for faster convergence and better results\n",
    "    \n",
    "    Critical Parameters Tuned:\n",
    "    1. Image size (imgsz): 640, 768\n",
    "    2. Batch size: Dynamically adjusted based on image size (96 for 640, 64 for 768)\n",
    "    3. Optimizer choice (SGD/Adam/AdamW)\n",
    "    4. Initial learning rate (lr0): 1e-4 to 5e-3\n",
    "    5. Momentum/beta1: 0.85 to 0.97\n",
    "    6. Weight decay (regularization): 1e-5 to 1e-3\n",
    "    7. Warmup epochs: 0 to 3\n",
    "    8. Warmup momentum: 0.5 to 0.95\n",
    "    9. Warmup bias learning rate: 0.0 to 0.1\n",
    "    10. Mosaic augmentation strength: 0.5 to 1.0\n",
    "    11. Mixup augmentation strength: 0.0 to 0.2\n",
    "    \"\"\"\n",
    "    \n",
    "    if trial is None:\n",
    "        raise ValueError(\"Trial object cannot be None\")\n",
    "\n",
    "    # ---------------------------\n",
    "    # 1) Image Size\n",
    "    # ---------------------------\n",
    "    # Test different image sizes to find optimal accuracy/speed tradeoff\n",
    "    image_size = trial.suggest_categorical('imgsz', [640, 768])\n",
    "    \n",
    "    # ---------------------------\n",
    "    # 2) Batch Size (Dynamic based on image size)\n",
    "    # ---------------------------\n",
    "    # Larger images require more memory, so reduce batch size accordingly\n",
    "    if image_size == 640:\n",
    "        batch_size = 96  # Standard batch size for 640x640\n",
    "    else:  # 768\n",
    "        batch_size = 64  # Reduced batch size for larger images\n",
    "\n",
    "    # ---------------------------\n",
    "    # 3) Optimizer + Learning Rate \n",
    "    # ---------------------------\n",
    "    optimizer_choice = trial.suggest_categorical('optimizer', ['SGD', 'Adam', 'AdamW'])\n",
    "    lr0 = trial.suggest_float('lr0', 1e-4, 5e-3, log=True)\n",
    "\n",
    "    # ---------------------------\n",
    "    # 4) Regularization \n",
    "    # ---------------------------\n",
    "    momentum = trial.suggest_float('momentum', 0.85, 0.97)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n",
    "    \n",
    "    # ---------------------------\n",
    "    # 5) Warmup Configuration\n",
    "    # ---------------------------\n",
    "    warmup_epochs = trial.suggest_int('warmup_epochs', 0, 3)\n",
    "    warmup_momentum = trial.suggest_float('warmup_momentum', 0.5, 0.95)\n",
    "    warmup_bias_lr = trial.suggest_float('warmup_bias_lr', 0.0, 0.1)\n",
    "\n",
    "    # ---------------------------\n",
    "    # 6) Key Augmentation\n",
    "    # ---------------------------\n",
    "    # Mosaic and mixup have the highest impact on performance\n",
    "    mosaic = trial.suggest_float('mosaic', 0.5, 1.0)\n",
    "    mixup = trial.suggest_float('mixup', 0.0, 0.2)\n",
    "\n",
    "    # ---------------------------\n",
    "    # 7) Compile parameters\n",
    "    # ---------------------------\n",
    "    hyperparams = {\n",
    "        # ===== TUNED PARAMETERS (Critical for performance) =====\n",
    "        'imgsz': image_size,\n",
    "        'batch': batch_size,\n",
    "        'optimizer': optimizer_choice,\n",
    "        'lr0': lr0,\n",
    "        'momentum': momentum,\n",
    "        'weight_decay': weight_decay,\n",
    "        'warmup_epochs': warmup_epochs,\n",
    "        'warmup_momentum': warmup_momentum,\n",
    "        'warmup_bias_lr': warmup_bias_lr,\n",
    "        'mosaic': mosaic,\n",
    "        'mixup': mixup,\n",
    "\n",
    "        # ===== DEFAULT PARAMETERS (YOLO defaults work well) =====\n",
    "        # Learning rate decay: default 0.01 is well-calibrated\n",
    "        # HSV augmentation: defaults (0.015, 0.7, 0.4) are optimal for most cases\n",
    "        # Spatial augmentation: defaults for scale/translate work well\n",
    "        # Loss weights: YOLO defaults (7.5, 0.5, 1.5) are well-balanced\n",
    "\n",
    "        # ===== FIXED PARAMETERS =====\n",
    "        'epochs': EPOCHS_PER_TRIAL,\n",
    "        'device': device,\n",
    "        'val': True,\n",
    "        'patience': ModelConfig.DEFAULT_PATIENCE,\n",
    "        'save': True,\n",
    "        'plots': True,\n",
    "        'cache': False,\n",
    "        'workers': ModelConfig.DEFAULT_WORKERS,\n",
    "        'close_mosaic': ModelConfig.CLOSE_MOSAIC_EPOCHS,\n",
    "        'verbose': True,\n",
    "    }\n",
    "\n",
    "    return hyperparams\n",
    "\n",
    "\n",
    "print('âœ“ Hyperparameter search space defined')\n",
    "print('\\nðŸ“Š Focused Search Space Summary:')\n",
    "print('  Strategy: Tune ONLY critical high-impact parameters')\n",
    "print('  ðŸŽ¯ Tuned Parameters (11):')\n",
    "print('    - Image Size (imgsz): 640, 768')\n",
    "print('    - Batch Size: Dynamic (96 for 640, 64 for 768)')\n",
    "print('    - Optimizer: SGD, Adam, AdamW')\n",
    "print('    - Learning Rate (lr0): 1e-4 to 5e-3')\n",
    "print('    - Momentum: 0.85 to 0.97')\n",
    "print('    - Weight Decay: 1e-5 to 1e-3')\n",
    "print('    - Warmup Epochs: 0 to 3')\n",
    "print('    - Warmup Momentum: 0.5 to 0.95')\n",
    "print('    - Warmup Bias LR: 0.0 to 0.1')\n",
    "print('    - Mosaic: 0.5 to 1.0')\n",
    "print('    - Mixup: 0.0 to 0.2')\n",
    "print('  âš™ï¸  Fixed Parameters:')\n",
    "print(f'    - Epochs: {EPOCHS_PER_TRIAL}')\n",
    "print(f'    - Device: {device}')\n",
    "print('  ðŸ“Œ Using YOLO defaults for: HSV augmentation, spatial transforms, loss weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8326b5",
   "metadata": {},
   "source": [
    "## 7. Define Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5575796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE OBJECTIVE FUNCTION FOR OPTUNA\n",
    "# ============================================================================\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"Objective function for Optuna hyperparameter optimization.\n",
    "\n",
    "    Steps:\n",
    "    1. Sample hyperparameters for the current trial\n",
    "    2. Train a YOLO model with those hyperparameters\n",
    "    3. Evaluate the model on the validation set\n",
    "    4. Return validation mAP@0.5 (to maximize)\n",
    "    \"\"\"\n",
    "    # Get hyperparameters for this trial\n",
    "    hyperparameters = define_hyperparameters(trial)\n",
    "\n",
    "    # Create trial-specific directory (absolute path under BASE_DIR)\n",
    "    trial_dir = TUNE_DIR / f\"trial_{trial.number:03d}\"\n",
    "    trial_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    # Initialize W&B if enabled\n",
    "    wandb_run = None\n",
    "    if USE_WANDB:\n",
    "        try:\n",
    "            os.environ['WANDB_DIR'] = str(trial_dir)\n",
    "            wandb_run = wandb.init(\n",
    "                project=WANDB_PROJECT_TUNING,\n",
    "                name=f'{MODEL_NAME}_trial_{trial.number:03d}',\n",
    "                config=hyperparameters,\n",
    "                dir=str(trial_dir),\n",
    "                reinit=True\n",
    "            )\n",
    "        except Exception as wandb_error:\n",
    "            print(f'âš ï¸  W&B initialization failed: {wandb_error}')\n",
    "            wandb_run = None\n",
    "\n",
    "    # Print trial information\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"TRIAL {trial.number}/{N_TRIALS}\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    print(f\"ðŸŽ¯ Tuned Parameters:\")\n",
    "    print(f\"  Image Size: {hyperparameters['imgsz']}\")\n",
    "    print(f\"  Batch Size: {hyperparameters['batch']} (auto-adjusted for image size)\")\n",
    "    print(f\"  Optimizer: {hyperparameters['optimizer']}\")\n",
    "    print(f\"  Learning Rate: {hyperparameters['lr0']:.6f}\")\n",
    "    print(f\"  Momentum: {hyperparameters['momentum']:.4f}\")\n",
    "    print(f\"  Weight Decay: {hyperparameters['weight_decay']:.6f}\")\n",
    "    print(f\"  Warmup: epochs={hyperparameters['warmup_epochs']}, momentum={hyperparameters['warmup_momentum']:.2f}, bias_lr={hyperparameters['warmup_bias_lr']:.3f}\")\n",
    "    print(f\"  Mosaic: {hyperparameters['mosaic']:.2f}\")\n",
    "    print(f\"  Mixup: {hyperparameters['mixup']:.2f}\")\n",
    "    print(f\"âœ“ Using YOLO defaults for: HSV, spatial aug, loss weights, lrf\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "\n",
    "    trial_model = None\n",
    "    map50 = 0.001  # Default penalty for failed trials\n",
    "    \n",
    "    try:\n",
    "        # Load fresh model for this trial\n",
    "        trial_model = YOLO(str(model_path))\n",
    "        \n",
    "        # Train model with hyperparameters (W&B integration via wandb.init)\n",
    "        trial_run_name = f\"{MODEL_NAME}_trial_{trial.number:03d}\"\n",
    "        train_results = trial_model.train(\n",
    "            data=str(DATA_YAML_PATH),\n",
    "            project=str(trial_dir),\n",
    "            name=trial_run_name,\n",
    "            exist_ok=True,\n",
    "            **hyperparameters,\n",
    "        )\n",
    "        \n",
    "        # Validate model\n",
    "        validation_results = trial_model.val(\n",
    "            data=str(DATA_YAML_PATH),\n",
    "            split=\"val\",\n",
    "            project=str(trial_dir),\n",
    "            name=\"val\",\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        # Extract metrics\n",
    "        map50 = float(validation_results.box.map50)\n",
    "        map50_95 = float(validation_results.box.map)\n",
    "        precision = float(validation_results.box.mp)\n",
    "        recall = float(validation_results.box.mr)\n",
    "        \n",
    "        # Save training metrics if available\n",
    "        train_metrics = {}\n",
    "        if hasattr(train_results, 'results_dict'):\n",
    "            train_metrics = {key: float(value) if isinstance(value, (int,float,np.floating,np.integer)) else value\n",
    "                             for key,value in train_results.results_dict.items()\n",
    "                             if key not in ['fitness']}\n",
    "\n",
    "        # Save trial results JSON\n",
    "        trial_results = {\n",
    "            \"trial_number\": trial.number,\n",
    "            \"model_name\": MODEL_NAME,\n",
    "            \"dataset\": YOLO_DATASET_ROOT.name,\n",
    "            \"trial_directory\": str(trial_dir),\n",
    "            \"hyperparameters\": {k: float(v) if isinstance(v,(np.floating,np.integer)) else v for k,v in hyperparameters.items()},\n",
    "            \"validation_metrics\": {\"map50\": map50, \"map50_95\": map50_95, \"precision\": precision, \"recall\": recall},\n",
    "            \"training_metrics\": train_metrics,\n",
    "            \"training_config\": {\n",
    "                \"epochs\": EPOCHS_PER_TRIAL,\n",
    "                \"batch_size\": hyperparameters['batch'],\n",
    "                \"image_size\": hyperparameters['imgsz'],\n",
    "                \"device\": device,\n",
    "            },\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"status\": \"completed\"\n",
    "        }\n",
    "\n",
    "        trial_results_path = trial_dir / \"trial_results.json\"\n",
    "        with open(trial_results_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(trial_results, f, indent=2)\n",
    "\n",
    "        print(f'\\nâœ… Trial {trial.number} Completed')\n",
    "        print(f'  mAP@0.5: {map50:.4f}')\n",
    "        print(f'  mAP@0.5:0.95: {map50_95:.4f}')\n",
    "        print(f'  Precision: {precision:.4f}')\n",
    "        print(f'  Recall: {recall:.4f}')\n",
    "\n",
    "    except Exception as error:\n",
    "        print(f'\\nâŒ Trial {trial.number} Failed: {error}')\n",
    "        \n",
    "        # Save error information\n",
    "        trial_results = {\n",
    "            \"trial_number\": trial.number,\n",
    "            \"model_name\": MODEL_NAME,\n",
    "            \"dataset\": YOLO_DATASET_ROOT.name,\n",
    "            \"trial_directory\": str(trial_dir),\n",
    "            \"hyperparameters\": {k: float(v) if isinstance(v,(np.floating,np.integer)) else v for k,v in hyperparameters.items()},\n",
    "            \"error\": str(error),\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"status\": \"failed\"\n",
    "        }\n",
    "        \n",
    "        trial_results_path = trial_dir / \"trial_results.json\"\n",
    "        with open(trial_results_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(trial_results, f, indent=2)\n",
    "        \n",
    "        # Return small penalty value instead of raising exception\n",
    "        map50 = 0.001\n",
    "        \n",
    "    finally:\n",
    "        # Clean up\n",
    "        if wandb_run is not None:\n",
    "            wandb_run.finish()\n",
    "        \n",
    "        # Clean up trial model\n",
    "        if trial_model is not None:\n",
    "            del trial_model\n",
    "        \n",
    "        # Force garbage collection\n",
    "        gc.collect()\n",
    "        if device == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "            print(\"ðŸ§¹ CUDA cache cleared\")\n",
    "\n",
    "    return map50\n",
    "\n",
    "\n",
    "print('âœ“ Objective function defined')\n",
    "print('  Returns: mAP@0.5 (validation set)')\n",
    "print('  Goal: Maximize validation performance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b2c034",
   "metadata": {},
   "source": [
    "## 8. Run Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e116f130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN HYPERPARAMETER OPTIMIZATION WITH OPTUNA\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('STARTING HYPERPARAMETER OPTIMIZATION')\n",
    "print('=' * 80)\n",
    "print(f'Model: {MODEL_NAME}')\n",
    "print(f'Dataset: {YOLO_DATASET_ROOT.name}')\n",
    "print(f'Number of Trials: {N_TRIALS}')\n",
    "print(f'Epochs per Trial: {EPOCHS_PER_TRIAL}')\n",
    "print(f'Timeout: {TIMEOUT_HOURS} hours' if TIMEOUT_HOURS else 'No timeout')\n",
    "print(f'Device: {device}')\n",
    "print('=' * 80)\n",
    "\n",
    "# Check if resuming from previous run\n",
    "study_pkl_path = TUNE_DIR / 'optuna_study.pkl'\n",
    "checkpoint_log_path = TUNE_DIR / 'checkpoint_log.json'\n",
    "is_resuming = study_pkl_path.exists()\n",
    "\n",
    "if is_resuming:\n",
    "    # Load existing study\n",
    "    print('\\n' + '=' * 80)\n",
    "    print('ðŸ”„ RESUMING PREVIOUS OPTIMIZATION')\n",
    "    print('=' * 80)\n",
    "    \n",
    "    with open(study_pkl_path, 'rb') as f:\n",
    "        study = pickle.load(f)\n",
    "    \n",
    "    # Load checkpoint log\n",
    "    checkpoint_data = []\n",
    "    if checkpoint_log_path.exists():\n",
    "        with open(checkpoint_log_path, 'r', encoding='utf-8') as f:\n",
    "            checkpoint_data = json.load(f)\n",
    "    \n",
    "    # Display resume information\n",
    "    completed_trials = len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])\n",
    "    pruned_trials = len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])\n",
    "    failed_trials = len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL])\n",
    "    total_previous_trials = len(study.trials)\n",
    "    \n",
    "    print(f'\\nðŸ“Š Previous Run Summary:')\n",
    "    print(f'  Completed Trials: {completed_trials}')\n",
    "    print(f'  Pruned Trials: {pruned_trials}')\n",
    "    print(f'  Failed Trials: {failed_trials}')\n",
    "    print(f'  Total Previous Trials: {total_previous_trials}')\n",
    "    \n",
    "    if completed_trials > 0:\n",
    "        best_trial = study.best_trial\n",
    "        print(f'\\nðŸ† Best Result So Far:')\n",
    "        print(f'  Trial: {best_trial.number}')\n",
    "        print(f'  mAP@0.5: {best_trial.value:.4f}')\n",
    "        \n",
    "        # Show top 3 completed trials\n",
    "        completed_trial_list = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "        sorted_trials = sorted(completed_trial_list, key=lambda t: t.value, reverse=True)\n",
    "        top_3_trials = sorted_trials[:3]\n",
    "        \n",
    "        print(f'\\nðŸ“ˆ Top 3 Trials:')\n",
    "        for idx, trial in enumerate(top_3_trials, 1):\n",
    "            print(f'  {idx}. Trial {trial.number}: mAP@0.5 = {trial.value:.4f}')\n",
    "    \n",
    "    # Show last checkpoint info\n",
    "    if checkpoint_data:\n",
    "        last_checkpoint = checkpoint_data[-1]\n",
    "        print(f'\\nðŸ• Last Checkpoint:')\n",
    "        print(f'  Timestamp: {last_checkpoint[\"timestamp\"]}')\n",
    "        print(f'  Last Trial: {last_checkpoint[\"trial_number\"]}')\n",
    "        print(f'  Current Best mAP: {last_checkpoint[\"best_map\"]:.4f}')\n",
    "    \n",
    "    remaining_trials = N_TRIALS - total_previous_trials\n",
    "    print(f'\\nâž¡ï¸  Continuing optimization: {remaining_trials} trials remaining (of {N_TRIALS} total)')\n",
    "    print('=' * 80)\n",
    "    \n",
    "    # Store remaining trials for optimization\n",
    "    trials_to_run = remaining_trials\n",
    "    \n",
    "else:\n",
    "    # Create new Optuna study\n",
    "    print('\\nðŸ†• Creating new optimization study')\n",
    "    \n",
    "    study = optuna.create_study(\n",
    "        study_name=f'{MODEL_NAME}_optuna_{RUN_TIMESTAMP}',\n",
    "        direction='maximize',  # Maximize mAP@0.5\n",
    "        sampler=optuna.samplers.TPESampler(\n",
    "            seed=42,\n",
    "            n_startup_trials=N_STARTUP_TRIALS,  # Random trials before optimization\n",
    "            multivariate=True,  # Consider parameter interactions\n",
    "            group=True  # Group related parameters\n",
    "        ),\n",
    "        pruner=optuna.pruners.MedianPruner(\n",
    "            n_startup_trials=N_STARTUP_TRIALS,\n",
    "            n_warmup_steps=15,  # Wait before pruning\n",
    "            interval_steps=5  # Check every 5 steps\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Initialize checkpoint log\n",
    "    checkpoint_data = []\n",
    "    \n",
    "    # Store trials to run for new study\n",
    "    trials_to_run = N_TRIALS\n",
    "\n",
    "# Run optimization\n",
    "start_time = datetime.now()\n",
    "print(f'\\nðŸš€ Optimization started at {start_time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "\n",
    "# Define checkpoint callback\n",
    "def checkpoint_callback(study, trial):\n",
    "    \"\"\"Save checkpoint after each trial completion\"\"\"\n",
    "    print(f'\\nâœ“ Completed {len(study.trials)}/{N_TRIALS} trials')\n",
    "    \n",
    "    # Update checkpoint log\n",
    "    checkpoint_entry = {\n",
    "        'trial_number': trial.number,\n",
    "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'trial_state': trial.state.name,\n",
    "        'best_map': study.best_value if len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]) > 0 else 0.0,\n",
    "        'completed_trials': len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]),\n",
    "        'total_trials': len(study.trials)\n",
    "    }\n",
    "    checkpoint_data.append(checkpoint_entry)\n",
    "    \n",
    "    # Save checkpoint log\n",
    "    with open(checkpoint_log_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(checkpoint_data, f, indent=2)\n",
    "    \n",
    "    # Save study object\n",
    "    with open(study_pkl_path, 'wb') as f:\n",
    "        pickle.dump(study, f)\n",
    "    \n",
    "    # Force garbage collection\n",
    "    gc.collect()\n",
    "\n",
    "try:\n",
    "    study.optimize(\n",
    "        objective,\n",
    "        n_trials=trials_to_run,  # Use calculated remaining trials when resuming\n",
    "        timeout=TIMEOUT_HOURS * 3600 if TIMEOUT_HOURS else None,\n",
    "        show_progress_bar=True,\n",
    "        callbacks=[checkpoint_callback]\n",
    "    )\n",
    "except KeyboardInterrupt:\n",
    "    print('\\nâš ï¸  Optimization interrupted by user')\n",
    "    print(f'ðŸ’¾ Progress saved to: {TUNE_DIR}')\n",
    "    print(f'   - Study checkpoint: {study_pkl_path.name}')\n",
    "    print(f'   - Checkpoint log: {checkpoint_log_path.name}')\n",
    "    print(f'\\nðŸ”„ To resume: Simply re-run this notebook')\n",
    "except Exception as e:\n",
    "    print(f'\\nâŒ Optimization failed: {e}')\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "end_time = datetime.now()\n",
    "duration = end_time - start_time\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('OPTIMIZATION COMPLETED')\n",
    "print('=' * 80)\n",
    "print(f'Started: {start_time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "print(f'Ended: {end_time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "print(f'Duration: {duration}')\n",
    "print(f'Total Trials: {len(study.trials)}')\n",
    "print(f'Completed Trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}')\n",
    "print(f'Pruned Trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}')\n",
    "print(f'Failed Trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL])}')\n",
    "print(f'\\nBest Trial: {study.best_trial.number}')\n",
    "print(f'Best mAP@0.5: {study.best_value:.4f}')\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ab4d62",
   "metadata": {},
   "source": [
    "## 9. Save All Trials Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3c5d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE CONSOLIDATED SUMMARY OF ALL TRIALS\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('SAVING CONSOLIDATED TRIAL SUMMARY')\n",
    "print('=' * 80)\n",
    "\n",
    "# Collect all trial results dynamically from study\n",
    "all_trials_data = []\n",
    "\n",
    "for trial in study.trials:\n",
    "    trial_dir = TUNE_DIR / f\"trial_{trial.number:03d}\"\n",
    "    results_file = trial_dir / \"trial_results.json\"\n",
    "    \n",
    "    if results_file.exists():\n",
    "        try:\n",
    "            with open(results_file, 'r') as f:\n",
    "                trial_data = json.load(f)\n",
    "                all_trials_data.append(trial_data)\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸  Could not read trial {trial.number} results: {e}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸  No results file found for trial {trial.number}\")\n",
    "\n",
    "# Create comprehensive summary\n",
    "optimization_summary = {\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"dataset\": YOLO_DATASET_ROOT.name,\n",
    "    \"optimization_config\": {\n",
    "        \"n_trials\": N_TRIALS,\n",
    "        \"epochs_per_trial\": EPOCHS_PER_TRIAL,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"timeout_hours\": TIMEOUT_HOURS,\n",
    "        \"n_startup_trials\": N_STARTUP_TRIALS,\n",
    "    },\n",
    "    \"optimization_results\": {\n",
    "        \"start_time\": start_time.isoformat(),\n",
    "        \"end_time\": end_time.isoformat(),\n",
    "        \"duration_seconds\": duration.total_seconds(),\n",
    "        \"total_trials\": len(study.trials),\n",
    "        \"completed_trials\": len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]),\n",
    "        \"pruned_trials\": len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]),\n",
    "        \"failed_trials\": len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL]),\n",
    "        \"best_trial_number\": study.best_trial.number,\n",
    "        \"best_map50\": study.best_value,\n",
    "    },\n",
    "    \"best_hyperparameters\": study.best_params,\n",
    "    \"all_trials\": all_trials_data,\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "}\n",
    "\n",
    "# Save consolidated summary as JSON\n",
    "summary_path = TUNE_DIR / f\"{MODEL_NAME}_all_trials_summary.json\"\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(optimization_summary, f, indent=2)\n",
    "\n",
    "print(f'âœ“ Consolidated JSON summary saved: {summary_path}')\n",
    "print(f'  Total trials saved: {len(all_trials_data)}')\n",
    "\n",
    "# Create CSV summary for easy analysis\n",
    "csv_data = []\n",
    "for trial_data in all_trials_data:\n",
    "    row = {\n",
    "        'trial_number': trial_data.get('trial_number'),\n",
    "        'status': trial_data.get('status'),\n",
    "        'map50': trial_data.get('validation_metrics', {}).get('map50'),\n",
    "        'map50_95': trial_data.get('validation_metrics', {}).get('map50_95'),\n",
    "        'precision': trial_data.get('validation_metrics', {}).get('precision'),\n",
    "        'recall': trial_data.get('validation_metrics', {}).get('recall'),\n",
    "        'error_type': trial_data.get('error_type', '')  # Include error type if failed\n",
    "    }\n",
    "    # Add hyperparameters\n",
    "    for key, value in trial_data.get('hyperparameters', {}).items():\n",
    "        row[f'hp_{key}'] = value\n",
    "    # Flag best trial\n",
    "    row['best_trial'] = trial_data.get('trial_number') == study.best_trial.number\n",
    "    csv_data.append(row)\n",
    "\n",
    "df_trials = pd.DataFrame(csv_data)\n",
    "\n",
    "# Sort CSV by mAP@0.5 descending (best first)\n",
    "df_trials.sort_values(by='map50', ascending=False, inplace=True)\n",
    "\n",
    "# Save CSV\n",
    "csv_path = TUNE_DIR / f\"{MODEL_NAME}_all_trials_summary.csv\"\n",
    "df_trials.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f'âœ“ CSV summary saved: {csv_path}')\n",
    "print(f'  Columns: {len(df_trials.columns)}, Rows: {len(df_trials)}')\n",
    "print('=' * 80)\n",
    "\n",
    "# Display summary statistics\n",
    "if len(df_trials) > 0:\n",
    "    print('\\nðŸ“Š Trial Summary Statistics:')\n",
    "    print(f'  Completed Trials: {len(df_trials[df_trials[\"status\"] == \"completed\"])}')\n",
    "    print(f'  Failed Trials: {len(df_trials[df_trials[\"status\"] == \"failed\"])}')\n",
    "    \n",
    "    completed_trials = df_trials[df_trials['status'] == 'completed']\n",
    "    if len(completed_trials) > 0:\n",
    "        best_trial_row = completed_trials.loc[completed_trials[\"map50\"].idxmax()]\n",
    "        print(f'\\n  mAP@0.5 Statistics:')\n",
    "        print(f'    Best: {best_trial_row[\"map50\"]:.4f} (Trial {best_trial_row[\"trial_number\"]})')\n",
    "        print(f'    Worst: {completed_trials[\"map50\"].min():.4f}')\n",
    "        print(f'    Mean: {completed_trials[\"map50\"].mean():.4f}')\n",
    "        print(f'    Std: {completed_trials[\"map50\"].std():.4f}')\n",
    "        print(f'    Median: {completed_trials[\"map50\"].median():.4f}')\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923833ab",
   "metadata": {},
   "source": [
    "## 10. Save Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d702ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE BEST HYPERPARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('SAVING BEST HYPERPARAMETERS')\n",
    "print('=' * 80)\n",
    "\n",
    "# Extract best parameters from study\n",
    "best_params = study.best_params\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(f'\\nðŸ† Best Trial: {best_trial.number}')\n",
    "print(f'   Best mAP@0.5: {study.best_value:.4f}')\n",
    "print('\\nðŸ“‹ Best Hyperparameters:')\n",
    "for param_name, param_value in best_params.items():\n",
    "    print(f'   {param_name}: {param_value}')\n",
    "\n",
    "# Save best hyperparameters to JSON\n",
    "best_params_json = TUNE_DIR / 'best_hyperparameters.json'\n",
    "with open(best_params_json, 'w') as f:\n",
    "    json.dump({\n",
    "        'model': MODEL_NAME,\n",
    "        'dataset_root': str(YOLO_DATASET_ROOT),\n",
    "        'data_yaml_path': str(DATA_YAML_PATH),\n",
    "        'optimization_results': {\n",
    "            'best_trial': study.best_trial.number,\n",
    "            'best_map50': study.best_value,\n",
    "            'total_trials': len(study.trials),\n",
    "            'optimization_duration': str(duration),\n",
    "        },\n",
    "        'hyperparameters': best_params,\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'notes': 'Use these hyperparameters for training. Add epochs, batch, imgsz, device, and other training settings.'\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f'\\nâœ“ Best hyperparameters saved to: {best_params_json}')\n",
    "\n",
    "# Save to YAML format (ready for YOLO training)\n",
    "best_params_yaml = TUNE_DIR / 'best_hyperparameters.yaml'\n",
    "with open(best_params_yaml, 'w') as f:\n",
    "    yaml.dump(best_params, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(f'âœ“ Best hyperparameters saved to: {best_params_yaml}')\n",
    "\n",
    "print('\\nðŸ“‹ Best Hyperparameters Summary:')\n",
    "print(f'  Optimizer: {best_params.get(\"optimizer\", \"N/A\")}')\n",
    "print(f'  Learning Rate: {best_params.get(\"lr0\", 0):.6f}')\n",
    "print(f'  Momentum: {best_params.get(\"momentum\", 0):.4f}')\n",
    "print(f'  Weight Decay: {best_params.get(\"weight_decay\", 0):.6f}')\n",
    "\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aed975",
   "metadata": {},
   "source": [
    "## 11. Visualize Optimization Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abf24a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# WORKAROUND: Convert Plotly figures to PNG without kaleido\n",
    "# ============================================================================\n",
    "# This cell provides an alternative to save PNG images when kaleido doesn't work\n",
    "\n",
    "def save_plotly_as_png_alternative(fig, output_path, width=1200, height=800):\n",
    "    \"\"\"\n",
    "    Alternative method to save Plotly figure as PNG without kaleido.\n",
    "    Uses matplotlib as a fallback by converting through static image.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Method 1: Try orca (older engine, might be available)\n",
    "        try:\n",
    "            fig.write_image(str(output_path), width=width, height=height, scale=2, engine=\"orca\")\n",
    "            return True, \"orca\"\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Method 2: Save as SVG then convert (requires cairosvg)\n",
    "        try:\n",
    "            import cairosvg\n",
    "            svg_path = str(output_path).replace('.png', '_temp.svg')\n",
    "            fig.write_image(svg_path, width=width, height=height, format='svg')\n",
    "            cairosvg.svg2png(url=svg_path, write_to=str(output_path), output_width=width, output_height=height)\n",
    "            os.remove(svg_path)\n",
    "            return True, \"svg+cairosvg\"\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Method 3: Use selenium/chrome (Colab has chrome)\n",
    "        try:\n",
    "            import plotly.io as pio\n",
    "            pio.kaleido.scope.chromium_args = tuple([arg for arg in pio.kaleido.scope.chromium_args if arg != \"--disable-dev-shm-usage\"])\n",
    "            fig.write_image(str(output_path), width=width, height=height, scale=2)\n",
    "            return True, \"kaleido-fixed\"\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        # Method 4: Just save high-quality HTML (can be converted later)\n",
    "        html_path = str(output_path).replace('.png', '_hq.html')\n",
    "        fig.write_html(\n",
    "            html_path,\n",
    "            config={'toImageButtonOptions': {'format': 'png', 'width': width, 'height': height, 'scale': 2}}\n",
    "        )\n",
    "        print(f'   â„¹ï¸  Saved high-quality HTML instead: {html_path}')\n",
    "        print(f'      You can open it and use the camera icon to download PNG')\n",
    "        return False, \"html-fallback\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'   âŒ All conversion methods failed: {e}')\n",
    "        return False, \"failed\"\n",
    "\n",
    "print('âœ“ PNG conversion workaround functions loaded')\n",
    "print('  Use save_plotly_as_png_alternative(fig, path) to save PNG files')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6162db87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SIMPLE SOLUTION: Manually download PNGs from the interactive plots above\n",
    "# ============================================================================\n",
    "# Since kaleido isn't working, here's what to do:\n",
    "# \n",
    "# 1. Scroll up to the interactive Plotly visualizations displayed above\n",
    "# 2. Hover over each plot and you'll see a camera icon in the top-right\n",
    "# 3. Click the camera icon to download the PNG file\n",
    "# 4. The files will be saved to your Downloads folder\n",
    "# 5. Upload them to your Colab files or Drive if needed\n",
    "#\n",
    "# Or, use this cell to get download links for the HTML files:\n",
    "\n",
    "print('ðŸ“Š Your visualization files:')\n",
    "print('=' * 80)\n",
    "\n",
    "# Find the latest HTML files\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "tune_dir = Path(TUNE_DIR)\n",
    "html_files = {\n",
    "    'Optimization History': sorted(tune_dir.glob('optimization_history_*.html'))[-1:],\n",
    "    'Parameter Importance': sorted(tune_dir.glob('parameter_importance_*.html'))[-1:],\n",
    "    'Parameter Slice': sorted(tune_dir.glob('parameter_slice_*.html'))[-1:]\n",
    "}\n",
    "\n",
    "for title, files in html_files.items():\n",
    "    if files:\n",
    "        file_path = files[0]\n",
    "        print(f'\\n{title}:')\n",
    "        print(f'  ðŸ“ {file_path}')\n",
    "        print(f'  ðŸ’¡ Open this file in Colab and click the camera icon to download PNG')\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('ðŸ“ To download PNG files:')\n",
    "print('  1. Open each HTML file by double-clicking it in the Files panel')\n",
    "print('  2. The interactive plot will open in a new tab')\n",
    "print('  3. Hover over the plot and click the camera icon (ðŸ“·) in the toolbar')\n",
    "print('  4. The PNG will download automatically')\n",
    "print('\\nðŸ’¡ Alternative: Run the plots again after restarting runtime')\n",
    "print('   (Your study results are saved in the .pkl file, so they won\\'t be lost!)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d33d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZE OPTIMIZATION RESULTS: HISTORY, PARAMETER IMPORTANCE, SLICE PLOTS\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('GENERATING OPTIMIZATION VISUALIZATIONS')\n",
    "print('=' * 80)\n",
    "\n",
    "if len(study.trials) == 0:\n",
    "    print(\"âš ï¸  No trials found in study, skipping visualization.\")\n",
    "else:\n",
    "    timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "    # -----------------------------\n",
    "    # 1ï¸âƒ£ Optimization History Plot\n",
    "    # -----------------------------\n",
    "    try:\n",
    "        print('\\nðŸ“ˆ Creating optimization history plot...')\n",
    "        fig_history = plot_optimization_history(study)\n",
    "        fig_history.update_layout(\n",
    "            title=f'{MODEL_NAME} - Hyperparameter Optimization History',\n",
    "            xaxis_title='Trial Number',\n",
    "            yaxis_title='mAP@0.5',\n",
    "            template='plotly_white',\n",
    "            width=1200,\n",
    "            height=600\n",
    "        )\n",
    "        fig_history.show()\n",
    "\n",
    "        # Save HTML with timestamp\n",
    "        optimization_history_path = TUNE_DIR / f'optimization_history_{timestamp_str}.html'\n",
    "        fig_history.write_html(str(optimization_history_path))\n",
    "        print(f'âœ“ HTML saved to: {optimization_history_path}')\n",
    "\n",
    "    except Exception as history_error:\n",
    "        print(f'âŒ Failed to create optimization history plot: {history_error}')\n",
    "\n",
    "    # -----------------------------\n",
    "    # 2ï¸âƒ£ Parameter Importance Plot\n",
    "    # -----------------------------\n",
    "    try:\n",
    "        print('\\nðŸ“Š Creating parameter importance plot...')\n",
    "        fig_importance = plot_param_importances(study)\n",
    "        fig_importance.update_layout(\n",
    "            title=f'{MODEL_NAME} - Hyperparameter Importance',\n",
    "            xaxis_title='Importance',\n",
    "            yaxis_title='Parameter',\n",
    "            template='plotly_white',\n",
    "            width=1200,\n",
    "            height=800\n",
    "        )\n",
    "        fig_importance.show()\n",
    "\n",
    "        # Save HTML with timestamp\n",
    "        param_importance_path = TUNE_DIR / f'parameter_importance_{timestamp_str}.html'\n",
    "        fig_importance.write_html(str(param_importance_path))\n",
    "        print(f'âœ“ HTML saved to: {param_importance_path}')\n",
    "\n",
    "        # Save PNG with timestamp AND consistent name\n",
    "        try:\n",
    "            # Try kaleido first\n",
    "            param_importance_img_ts = TUNE_DIR / f'parameter_importance_{timestamp_str}.png'\n",
    "            fig_importance.write_image(str(param_importance_img_ts), width=1200, height=800, scale=2)\n",
    "            print(f'âœ“ PNG saved to: {param_importance_img_ts}')\n",
    "            \n",
    "            # Consistent name for PDF report\n",
    "            param_importance_img = TUNE_DIR / 'parameter_importance.png'\n",
    "            fig_importance.write_image(str(param_importance_img), width=1200, height=800, scale=2)\n",
    "            print(f'âœ“ PNG saved to: {param_importance_img} (for PDF report)')\n",
    "        except Exception as png_error:\n",
    "            print(f'âš ï¸  Could not save PNG: {png_error}')\n",
    "            print(f'   Error type: {type(png_error).__name__}')\n",
    "            import traceback\n",
    "            print(f'   Details: {traceback.format_exc()}')\n",
    "            param_importance_img = None\n",
    "\n",
    "    except (RuntimeError, ValueError) as importance_error:\n",
    "        print(f'âš ï¸  Could not generate parameter importance plot: {importance_error}')\n",
    "        print('  (This can happen when trials have insufficient data variation)')\n",
    "        param_importance_img = None\n",
    "\n",
    "    # -----------------------------\n",
    "    # 3ï¸âƒ£ Parameter Slice Plots\n",
    "    # -----------------------------\n",
    "    try:\n",
    "        print('\\nðŸ” Creating parameter slice plots...')\n",
    "        fig_slice = plot_slice(study)\n",
    "        fig_slice.update_layout(\n",
    "            title=f'{MODEL_NAME} - Parameter Slice Plot',\n",
    "            template='plotly_white',\n",
    "            width=1400,\n",
    "            height=1000\n",
    "        )\n",
    "        fig_slice.show()\n",
    "\n",
    "        # Save HTML with timestamp\n",
    "        slice_path = TUNE_DIR / f'parameter_slice_{timestamp_str}.html'\n",
    "        fig_slice.write_html(str(slice_path))\n",
    "        print(f'âœ“ HTML saved to: {slice_path}')\n",
    "\n",
    "        # Save PNG with timestamp AND consistent name\n",
    "        try:\n",
    "            # Try kaleido\n",
    "            slice_img_path_ts = TUNE_DIR / f'parameter_slice_{timestamp_str}.png'\n",
    "            fig_slice.write_image(str(slice_img_path_ts), width=1400, height=1000, scale=2)\n",
    "            print(f'âœ“ PNG saved to: {slice_img_path_ts}')\n",
    "            \n",
    "            # Consistent name for PDF report\n",
    "            slice_img_path = TUNE_DIR / 'parameter_slice.png'\n",
    "            fig_slice.write_image(str(slice_img_path), width=1400, height=1000, scale=2)\n",
    "            print(f'âœ“ PNG saved to: {slice_img_path} (for PDF report)')\n",
    "        except Exception as png_error:\n",
    "            print(f'âš ï¸  Could not save PNG: {png_error}')\n",
    "            print(f'   Error type: {type(png_error).__name__}')\n",
    "            import traceback\n",
    "            print(f'   Details: {traceback.format_exc()}')\n",
    "\n",
    "    except Exception as slice_error:\n",
    "        print(f'âš ï¸  Could not generate parameter slice plot: {slice_error}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585a97a5",
   "metadata": {},
   "source": [
    "## 12. Generate Tuning PDF Report\n",
    "\n",
    "Create a comprehensive PDF report with optimization results, visualizations, and model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3c3580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE Tuning PDF REPORT\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('GENERATING COMPREHENSIVE TUNING PDF REPORT')\n",
    "print('=' * 80)\n",
    "\n",
    "# Use already extracted best parameters and trial data from previous sections\n",
    "best_params = study.best_params\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(f'\\nðŸ“Š Preparing comprehensive report with {len(study.trials)} trials')\n",
    "print(f'   Best Trial: {best_trial.number}')\n",
    "print(f'   Best mAP@0.5: {study.best_value:.4f}')\n",
    "\n",
    "# Compile all trials data into DataFrame for PDF report\n",
    "print('\\nðŸ“‹ Compiling trials data for report...')\n",
    "trials_data_for_pdf = []\n",
    "\n",
    "for trial in study.trials:\n",
    "    # Create row with trial info and hyperparameters directly from trial.params\n",
    "    row_data = {\n",
    "        'trial': trial.number,\n",
    "        'state': trial.state.name,\n",
    "        'mAP@0.5': trial.value if trial.value is not None else 0.0,\n",
    "    }\n",
    "    \n",
    "    # Add all hyperparameters directly from trial.params\n",
    "    row_data.update(trial.params)\n",
    "    \n",
    "    trials_data_for_pdf.append(row_data)\n",
    "\n",
    "# Create DataFrame and sort by mAP@0.5\n",
    "df_trials = pd.DataFrame(trials_data_for_pdf)\n",
    "df_trials_sorted = df_trials.sort_values('mAP@0.5', ascending=False)\n",
    "\n",
    "print(f'âœ“ Compiled {len(df_trials)} trials for report')\n",
    "print(f'   Available columns: {list(df_trials.columns)}')\n",
    "\n",
    "# Create tuning PDF report\n",
    "pdf_report_path = TUNE_DIR / f'{MODEL_NAME}_tuning_report.pdf'\n",
    "\n",
    "doc = SimpleDocTemplate(str(pdf_report_path), pagesize=A4,\n",
    "                       rightMargin=30, leftMargin=30,\n",
    "                       topMargin=30, bottomMargin=30)\n",
    "\n",
    "story = []\n",
    "styles = getSampleStyleSheet()\n",
    "\n",
    "# Custom styles\n",
    "title_style = ParagraphStyle(\n",
    "    'CustomTitle',\n",
    "    parent=styles['Heading1'],\n",
    "    fontSize=18,\n",
    "    textColor=rl_colors.HexColor('#2c3e50'),\n",
    "    spaceAfter=30,\n",
    "    alignment=TA_CENTER\n",
    ")\n",
    "\n",
    "heading_style = ParagraphStyle(\n",
    "    'CustomHeading',\n",
    "    parent=styles['Heading2'],\n",
    "    fontSize=16,\n",
    "    textColor=rl_colors.HexColor('#34495e'),\n",
    "    spaceAfter=12,\n",
    "    spaceBefore=20\n",
    ")\n",
    "\n",
    "small_style = ParagraphStyle(\n",
    "    'SmallText',\n",
    "    parent=styles['Normal'],\n",
    "    fontSize=7,\n",
    "    wordWrap='CJK'\n",
    ")\n",
    "\n",
    "# Title\n",
    "story.append(Paragraph(f'{MODEL_NAME} Hyperparameter Tuning Report', title_style))\n",
    "story.append(Paragraph(f'Generated: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}', styles['Normal']))\n",
    "story.append(Spacer(1, 20))\n",
    "\n",
    "# ===== SECTION 1: OVERVIEW =====\n",
    "story.append(Paragraph('1. Optimization Overview', heading_style))\n",
    "\n",
    "info_data = [\n",
    "    ['Property', 'Value'],\n",
    "    ['Model', MODEL_NAME],\n",
    "    ['Dataset', YOLO_DATASET_ROOT.name],\n",
    "    ['Total Trials', str(len(study.trials))],\n",
    "    ['Completed Trials', str(len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]))],\n",
    "    ['Failed Trials', str(len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL]))],\n",
    "    ['Best Trial', str(study.best_trial.number)],\n",
    "    ['Best mAP@0.5', f'{study.best_value:.4f}'],\n",
    "    ['Optimization Duration', str(duration)],\n",
    "]\n",
    "\n",
    "info_table = Table(info_data, colWidths=[2.5*inch, 3.5*inch])\n",
    "info_table.setStyle(TableStyle([\n",
    "    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#2c3e50')),\n",
    "    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n",
    "    ('BACKGROUND', (0, 1), (-1, -1), rl_colors.HexColor('#ecf0f1')),\n",
    "    ('TEXTCOLOR', (0, 1), (-1, -1), rl_colors.black),\n",
    "    ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n",
    "    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "    ('FONTNAME', (0, 1), (0, -1), 'Helvetica-Bold'),\n",
    "    ('FONTSIZE', (0, 0), (-1, -1), 10),\n",
    "    ('BOTTOMPADDING', (0, 0), (-1, -1), 8),\n",
    "    ('TOPPADDING', (0, 0), (-1, -1), 8),\n",
    "    ('GRID', (0, 0), (-1, -1), 1, rl_colors.grey)\n",
    "]))\n",
    "story.append(info_table)\n",
    "story.append(Spacer(1, 20))\n",
    "\n",
    "# ===== SECTION 2: CONFIGURATION =====\n",
    "story.append(Paragraph('2. Optimization Configuration', heading_style))\n",
    "\n",
    "opt_config_data = [\n",
    "    ['Parameter', 'Value'],\n",
    "    ['Total Trials', str(N_TRIALS)],\n",
    "    ['Epochs per Trial', str(EPOCHS_PER_TRIAL)],\n",
    "    ['Batch Size', str(BATCH_SIZE)],\n",
    "    ['Startup Trials (TPE)', str(N_STARTUP_TRIALS)],\n",
    "    ['Device', device],\n",
    "    ['Number of Classes', str(NUM_CLASSES)],\n",
    "    ['Train Images', str(dataset_stats.get('train', {}).get('images', 'N/A'))],\n",
    "    ['Val Images', str(dataset_stats.get('val', {}).get('images', 'N/A'))],\n",
    "]\n",
    "\n",
    "opt_config_table = Table(opt_config_data, colWidths=[3*inch, 3*inch])\n",
    "opt_config_table.setStyle(TableStyle([\n",
    "    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#95a5a6')),\n",
    "    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n",
    "    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "    ('FONTSIZE', (0, 0), (-1, 0), 11),\n",
    "    ('FONTSIZE', (0, 1), (-1, -1), 9),\n",
    "    ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n",
    "    ('TOPPADDING', (0, 0), (-1, -1), 6),\n",
    "    ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n",
    "    ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n",
    "]))\n",
    "story.append(opt_config_table)\n",
    "story.append(Spacer(1, 20))\n",
    "\n",
    "# ===== SECTION 2.5: EXECUTIVE SUMMARY & KEY FINDINGS =====\n",
    "story.append(PageBreak())\n",
    "story.append(Paragraph('2.5 Executive Summary & Key Findings', heading_style))\n",
    "\n",
    "# Calculate key statistics\n",
    "completed_df_summary = df_trials_sorted[df_trials_sorted['state'] == 'COMPLETE']\n",
    "best_map = completed_df_summary['mAP@0.5'].max()\n",
    "worst_map = completed_df_summary['mAP@0.5'].min()\n",
    "mean_map = completed_df_summary['mAP@0.5'].mean()\n",
    "improvement_pct = ((best_map - worst_map) / worst_map) * 100 if worst_map > 0 else 0\n",
    "\n",
    "# Calculate optimizer statistics\n",
    "if 'optimizer' in completed_df_summary.columns:\n",
    "    opt_stats = completed_df_summary.groupby('optimizer')['mAP@0.5'].agg(['mean', 'count'])\n",
    "    best_opt = opt_stats['mean'].idxmax()\n",
    "    best_opt_mean = opt_stats.loc[best_opt, 'mean']\n",
    "else:\n",
    "    best_opt = 'N/A'\n",
    "    best_opt_mean = 0\n",
    "\n",
    "# Calculate image size impact\n",
    "if 'imgsz' in completed_df_summary.columns:\n",
    "    img_stats = completed_df_summary.groupby('imgsz')['mAP@0.5'].mean()\n",
    "    best_imgsz = img_stats.idxmax()\n",
    "    imgsz_improvement = ((img_stats.max() - img_stats.min()) / img_stats.min()) * 100 if len(img_stats) > 1 else 0\n",
    "else:\n",
    "    best_imgsz = 'N/A'\n",
    "    imgsz_improvement = 0\n",
    "\n",
    "# Create findings summary\n",
    "findings_data = [\n",
    "    ['Metric', 'Value'],\n",
    "    ['ðŸ† Best Performance', f'Trial #{study.best_trial.number}: mAP@0.5 = {best_map:.4f}'],\n",
    "    ['ðŸ“Š Performance Range', f'{worst_map:.4f} to {best_map:.4f} ({improvement_pct:.1f}% improvement)'],\n",
    "    ['ðŸ“ˆ Mean Performance', f'{mean_map:.4f} across {len(completed_df_summary)} trials'],\n",
    "    ['âš¡ Best Optimizer', f'{best_opt} (mean: {best_opt_mean:.4f})'],\n",
    "    ['ðŸ–¼ï¸ Optimal Image Size', f'{int(best_imgsz)}px ({imgsz_improvement:.2f}% better)' if best_imgsz != 'N/A' else 'N/A'],\n",
    "    ['â±ï¸ Optimization Time', str(duration)],\n",
    "    ['âœ… Success Rate', f'{len(completed_df_summary)}/{len(study.trials)} trials ({len(completed_df_summary)/len(study.trials)*100:.1f}%)'],\n",
    "]\n",
    "\n",
    "findings_table = Table(findings_data, colWidths=[2.5*inch, 3.5*inch])\n",
    "findings_table.setStyle(TableStyle([\n",
    "    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#27ae60')),\n",
    "    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n",
    "    ('BACKGROUND', (0, 1), (-1, -1), rl_colors.HexColor('#ecf9f2')),\n",
    "    ('ALIGN', (0, 0), (-1, 0), 'CENTER'),\n",
    "    ('ALIGN', (0, 1), (0, -1), 'LEFT'),\n",
    "    ('ALIGN', (1, 1), (1, -1), 'LEFT'),\n",
    "    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "    ('FONTSIZE', (0, 0), (-1, 0), 11),\n",
    "    ('FONTSIZE', (0, 1), (-1, -1), 9),\n",
    "    ('BOTTOMPADDING', (0, 0), (-1, -1), 8),\n",
    "    ('TOPPADDING', (0, 0), (-1, -1), 8),\n",
    "    ('GRID', (0, 0), (-1, -1), 1, rl_colors.black),\n",
    "    ('LINEBELOW', (0, 0), (-1, 0), 2, rl_colors.HexColor('#27ae60'))\n",
    "]))\n",
    "story.append(findings_table)\n",
    "story.append(Spacer(1, 15))\n",
    "\n",
    "# Add key insights text\n",
    "insights_text = f\"\"\"\n",
    "<b>Key Insights:</b><br/>\n",
    "â€¢ The optimization process successfully explored {len(study.trials)} trials, achieving a {improvement_pct:.1f}% performance improvement from worst to best.<br/>\n",
    "â€¢ <b>{best_opt}</b> optimizer demonstrated superior performance with mean mAP@0.5 of {best_opt_mean:.4f}.<br/>\n",
    "â€¢ Image size of <b>{int(best_imgsz)}px</b> provided optimal accuracy-efficiency tradeoff.<br/>\n",
    "â€¢ High consistency achieved: mean performance ({mean_map:.4f}) close to best ({best_map:.4f}), indicating robust hyperparameter space.\n",
    "\"\"\"\n",
    "story.append(Paragraph(insights_text, styles['Normal']))\n",
    "story.append(Spacer(1, 20))\n",
    "\n",
    "print(f'âœ“ Executive summary generated')\n",
    "\n",
    "# ===== SECTION 3: BEST HYPERPARAMETERS =====\n",
    "story.append(PageBreak())\n",
    "story.append(Paragraph('3. Best Hyperparameters', heading_style))\n",
    "\n",
    "hyperparam_data = [['Parameter', 'Value', 'Description']]\n",
    "param_descriptions = {\n",
    "    'optimizer': 'Optimization algorithm',\n",
    "    'lr0': 'Initial learning rate',\n",
    "    'lrf': 'Final learning rate factor',\n",
    "    'momentum': 'SGD momentum / Adam beta1',\n",
    "    'weight_decay': 'Weight decay (L2 penalty)',\n",
    "    'warmup_epochs': 'Warmup epochs',\n",
    "    'warmup_momentum': 'Warmup momentum',\n",
    "    'box': 'Box loss gain',\n",
    "    'cls': 'Classification loss gain',\n",
    "    'dfl': 'Distribution focal loss gain',\n",
    "    'hsv_h': 'HSV-Hue augmentation',\n",
    "    'hsv_s': 'HSV-Saturation augmentation',\n",
    "    'hsv_v': 'HSV-Value augmentation',\n",
    "    'degrees': 'Rotation augmentation',\n",
    "    'translate': 'Translation augmentation',\n",
    "    'scale': 'Scale augmentation',\n",
    "    'shear': 'Shear augmentation',\n",
    "    'perspective': 'Perspective augmentation',\n",
    "    'flipud': 'Vertical flip probability',\n",
    "    'fliplr': 'Horizontal flip probability',\n",
    "    'mosaic': 'Mosaic augmentation',\n",
    "    'mixup': 'Mixup augmentation',\n",
    "    'copy_paste': 'Copy-paste augmentation',\n",
    "}\n",
    "\n",
    "for param_key, param_value in best_params.items():\n",
    "    desc = param_descriptions.get(param_key, '')\n",
    "    formatted_value = f'{param_value:.6f}' if isinstance(param_value, float) else str(param_value)\n",
    "    hyperparam_data.append([param_key, formatted_value, desc])\n",
    "\n",
    "hyperparam_table = Table(hyperparam_data, colWidths=[1.8*inch, 1.5*inch, 2.7*inch])\n",
    "hyperparam_table.setStyle(TableStyle([\n",
    "    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#3498db')),\n",
    "    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n",
    "    ('ALIGN', (0, 0), (1, -1), 'CENTER'),\n",
    "    ('ALIGN', (2, 1), (2, -1), 'LEFT'),\n",
    "    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "    ('FONTSIZE', (0, 0), (-1, 0), 10),\n",
    "    ('FONTSIZE', (0, 1), (-1, -1), 8),\n",
    "    ('BOTTOMPADDING', (0, 0), (-1, -1), 5),\n",
    "    ('TOPPADDING', (0, 0), (-1, -1), 5),\n",
    "    ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n",
    "    ('GRID', (0, 0), (-1, -1), 1, rl_colors.black),\n",
    "    ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n",
    "]))\n",
    "story.append(hyperparam_table)\n",
    "story.append(Spacer(1, 20))\n",
    "\n",
    "# ===== SECTION 4: TOP 20 TRIALS WITH HYPERPARAMETERS =====\n",
    "story.append(PageBreak())\n",
    "story.append(Paragraph('4. Top 20 Trials Performance', heading_style))\n",
    "\n",
    "# Create detailed top trials table with key hyperparameters\n",
    "print(f'   DataFrame columns: {list(df_trials_sorted.columns)}')\n",
    "print(f'   Sample row keys: {list(df_trials_sorted.head(1).iloc[0].keys())}')\n",
    "\n",
    "top_trials_data = [['#', 'mAP@0.5', 'ImgSz', 'Opt', 'lr0', 'mom', 'mixup', 'mosaic']]\n",
    "for idx, (_, row) in enumerate(df_trials_sorted.head(20).iterrows(), 1):\n",
    "    # Use pd.notna() to check if value exists and is not NaN\n",
    "    img_val = str(int(row['imgsz'])) if 'imgsz' in row and pd.notna(row['imgsz']) else 'N/A'\n",
    "    opt_val = row.get('optimizer', 'N/A')\n",
    "    lr0_val = f\"{row['lr0']:.4f}\" if 'lr0' in row and pd.notna(row['lr0']) else 'N/A'\n",
    "    mom_val = f\"{row['momentum']:.3f}\" if 'momentum' in row and pd.notna(row['momentum']) else 'N/A'\n",
    "    mix_val = f\"{row['mixup']:.2f}\" if 'mixup' in row and pd.notna(row['mixup']) else 'N/A'\n",
    "    mos_val = f\"{row['mosaic']:.2f}\" if 'mosaic' in row and pd.notna(row['mosaic']) else 'N/A'\n",
    "    \n",
    "    top_trials_data.append([\n",
    "        str(idx),\n",
    "        f\"{row['mAP@0.5']:.4f}\",\n",
    "        img_val,\n",
    "        str(opt_val)[:4] if opt_val != 'N/A' else 'N/A',\n",
    "        lr0_val,\n",
    "        mom_val,\n",
    "        mix_val,\n",
    "        mos_val,\n",
    "    ])\n",
    "\n",
    "top_trials_table = Table(top_trials_data, colWidths=[0.3*inch, 0.8*inch, 0.6*inch, 0.6*inch, 0.7*inch, 0.7*inch, 0.7*inch, 0.7*inch])\n",
    "top_trials_table.setStyle(TableStyle([\n",
    "    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#27ae60')),\n",
    "    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n",
    "    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "    ('FONTSIZE', (0, 0), (-1, 0), 9),\n",
    "    ('FONTSIZE', (0, 1), (-1, -1), 7),\n",
    "    ('BOTTOMPADDING', (0, 0), (-1, -1), 4),\n",
    "    ('TOPPADDING', (0, 0), (-1, -1), 4),\n",
    "    ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n",
    "    ('GRID', (0, 0), (-1, -1), 0.5, rl_colors.black)\n",
    "]))\n",
    "story.append(top_trials_table)\n",
    "story.append(Spacer(1, 15))\n",
    "\n",
    "# Detailed hyperparameters for top 5 trials\n",
    "story.append(PageBreak())\n",
    "story.append(Paragraph('4.1 Detailed Hyperparameters - Top 5 Trials', heading_style))\n",
    "\n",
    "print(f'   Creating detailed params for top 5 trials...')\n",
    "for rank, (_, row) in enumerate(df_trials_sorted.head(5).iterrows(), 1):\n",
    "    story.append(Paragraph(f'<b>Rank {rank}: Trial {int(row[\"trial\"])} (mAP@0.5: {row[\"mAP@0.5\"]:.4f})</b>', styles['Normal']))\n",
    "    \n",
    "    trial_params_text = []\n",
    "    # Get all parameter columns (exclude trial, state, mAP@0.5)\n",
    "    param_cols = [col for col in df_trials_sorted.columns if col not in ['trial', 'state', 'mAP@0.5']]\n",
    "    \n",
    "    for param_key in sorted(param_cols):\n",
    "        if param_key in row and pd.notna(row[param_key]):\n",
    "            value = row[param_key]\n",
    "            formatted_val = f'{value:.6f}' if isinstance(value, float) else str(value)\n",
    "            trial_params_text.append(f'{param_key}={formatted_val}')\n",
    "    \n",
    "    if trial_params_text:\n",
    "        params_str = ', '.join(trial_params_text)\n",
    "        story.append(Paragraph(params_str, small_style))\n",
    "    else:\n",
    "        story.append(Paragraph('No parameter data available', small_style))\n",
    "    story.append(Spacer(1, 10))\n",
    "\n",
    "print(f'   âœ“ Top 5 trials details added')\n",
    "\n",
    "# ===== SECTION 5: OPTIMIZATION VISUALIZATIONS =====\n",
    "story.append(PageBreak())\n",
    "story.append(Paragraph('5. Optimization Visualizations & Analysis', heading_style))\n",
    "\n",
    "print('\\nðŸ“Š Generating custom visualizations for PDF report...')\n",
    "\n",
    "# Prepare data for completed trials only\n",
    "completed_trials_df = df_trials_sorted[df_trials_sorted['state'] == 'COMPLETE'].copy()\n",
    "\n",
    "print(f'   Completed trials: {len(completed_trials_df)}')\n",
    "print(f'   Columns available: {list(completed_trials_df.columns)}')\n",
    "\n",
    "if len(completed_trials_df) == 0:\n",
    "    story.append(Paragraph('No completed trials available for visualization.', styles['Normal']))\n",
    "    print('   âš ï¸ No completed trials found!')\n",
    "else:\n",
    "    # 5.0 Performance Distribution Box Plot\n",
    "    story.append(Paragraph('5.0 Performance Distribution Analysis', styles['Heading3']))\n",
    "    \n",
    "    print(f'   Creating performance distribution box plot...')\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Box plot for overall distribution\n",
    "    bp = ax1.boxplot([completed_trials_df['mAP@0.5']], vert=True, patch_artist=True,\n",
    "                     labels=['All Trials'], widths=0.5)\n",
    "    bp['boxes'][0].set_facecolor('#3498db')\n",
    "    bp['boxes'][0].set_alpha(0.7)\n",
    "    bp['medians'][0].set_color('#e74c3c')\n",
    "    bp['medians'][0].set_linewidth(2)\n",
    "    \n",
    "    # Add statistics annotations\n",
    "    q1 = completed_trials_df['mAP@0.5'].quantile(0.25)\n",
    "    median = completed_trials_df['mAP@0.5'].median()\n",
    "    q3 = completed_trials_df['mAP@0.5'].quantile(0.75)\n",
    "    \n",
    "    ax1.text(1.3, q1, f'Q1: {q1:.4f}', fontsize=9, va='center')\n",
    "    ax1.text(1.3, median, f'Median: {median:.4f}', fontsize=9, va='center', fontweight='bold', color='#e74c3c')\n",
    "    ax1.text(1.3, q3, f'Q3: {q3:.4f}', fontsize=9, va='center')\n",
    "    ax1.text(1.3, completed_trials_df['mAP@0.5'].min(), f'Min: {completed_trials_df[\"mAP@0.5\"].min():.4f}', \n",
    "            fontsize=8, va='center', color='gray')\n",
    "    ax1.text(1.3, completed_trials_df['mAP@0.5'].max(), f'Max: {completed_trials_df[\"mAP@0.5\"].max():.4f}', \n",
    "            fontsize=8, va='center', color='gray')\n",
    "    \n",
    "    ax1.set_ylabel('mAP@0.5', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('Overall Performance Distribution', fontsize=13, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Histogram with KDE\n",
    "    ax2.hist(completed_trials_df['mAP@0.5'], bins=15, alpha=0.7, color='#3498db', \n",
    "            edgecolor='black', linewidth=1)\n",
    "    ax2.axvline(median, color='#e74c3c', linestyle='--', linewidth=2, label=f'Median: {median:.4f}')\n",
    "    ax2.axvline(study.best_value, color='#27ae60', linestyle='--', linewidth=2, label=f'Best: {study.best_value:.4f}')\n",
    "    ax2.set_xlabel('mAP@0.5', fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title('Performance Histogram', fontsize=13, fontweight='bold')\n",
    "    ax2.legend(fontsize=10)\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    perf_dist_img = TUNE_DIR / 'report_performance_distribution.png'\n",
    "    plt.savefig(perf_dist_img, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    story.append(Image(str(perf_dist_img), width=6.5*inch, height=2.7*inch))\n",
    "    story.append(Spacer(1, 15))\n",
    "    print(f'âœ“ Performance distribution chart saved: {perf_dist_img}')\n",
    "    \n",
    "    # Add distribution statistics table\n",
    "    dist_stats_data = [\n",
    "        ['Statistic', 'Value'],\n",
    "        ['Mean', f'{completed_trials_df[\"mAP@0.5\"].mean():.4f}'],\n",
    "        ['Median', f'{median:.4f}'],\n",
    "        ['Std Dev', f'{completed_trials_df[\"mAP@0.5\"].std():.4f}'],\n",
    "        ['IQR (Q3-Q1)', f'{q3-q1:.4f}'],\n",
    "        ['Range', f'{completed_trials_df[\"mAP@0.5\"].max() - completed_trials_df[\"mAP@0.5\"].min():.4f}'],\n",
    "    ]\n",
    "    \n",
    "    dist_table = Table(dist_stats_data, colWidths=[2*inch, 2*inch])\n",
    "    dist_table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#3498db')),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "        ('FONTSIZE', (0, 0), (-1, 0), 10),\n",
    "        ('FONTSIZE', (0, 1), (-1, -1), 9),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n",
    "        ('TOPPADDING', (0, 0), (-1, -1), 6),\n",
    "        ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n",
    "        ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n",
    "    ]))\n",
    "    story.append(dist_table)\n",
    "    story.append(Spacer(1, 15))\n",
    "    \n",
    "    # 5.1 Parameter Correlation Heatmap\n",
    "    story.append(PageBreak())\n",
    "    story.append(Paragraph('5.1 Parameter Correlation Analysis', styles['Heading3']))\n",
    "    \n",
    "    print(f'   Creating parameter correlation heatmap...')\n",
    "    \n",
    "    # Select numeric columns for correlation\n",
    "    numeric_cols = ['mAP@0.5']\n",
    "    param_cols = ['lr0', 'momentum', 'weight_decay', 'mixup', 'mosaic']\n",
    "    available_params = [col for col in param_cols if col in completed_trials_df.columns and completed_trials_df[col].notna().any()]\n",
    "    \n",
    "    if len(available_params) >= 2:\n",
    "        corr_cols = numeric_cols + available_params\n",
    "        corr_data = completed_trials_df[corr_cols].corr()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        im = ax.imshow(corr_data, cmap='RdYlGn', aspect='auto', vmin=-1, vmax=1)\n",
    "        \n",
    "        # Set ticks and labels\n",
    "        ax.set_xticks(range(len(corr_cols)))\n",
    "        ax.set_yticks(range(len(corr_cols)))\n",
    "        ax.set_xticklabels(corr_cols, rotation=45, ha='right', fontsize=10)\n",
    "        ax.set_yticklabels(corr_cols, fontsize=10)\n",
    "        \n",
    "        # Add correlation values as text\n",
    "        for i in range(len(corr_cols)):\n",
    "            for j in range(len(corr_cols)):\n",
    "                value = corr_data.iloc[i, j]\n",
    "                color = 'white' if abs(value) > 0.5 else 'black'\n",
    "                ax.text(j, i, f'{value:.2f}', ha='center', va='center', \n",
    "                       color=color, fontsize=9, fontweight='bold')\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(im, ax=ax)\n",
    "        cbar.set_label('Correlation Coefficient', fontsize=11, fontweight='bold')\n",
    "        \n",
    "        ax.set_title(f'{MODEL_NAME} - Parameter Correlation with Performance', \n",
    "                    fontsize=13, fontweight='bold', pad=20)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        corr_img = TUNE_DIR / 'report_correlation_heatmap.png'\n",
    "        plt.savefig(corr_img, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        story.append(Image(str(corr_img), width=6*inch, height=4.8*inch))\n",
    "        story.append(Spacer(1, 15))\n",
    "        print(f'âœ“ Correlation heatmap saved: {corr_img}')\n",
    "        \n",
    "        # Add interpretation\n",
    "        map_corr = corr_data['mAP@0.5'].drop('mAP@0.5')\n",
    "        strongest_pos = map_corr.idxmax() if map_corr.max() > 0 else None\n",
    "        strongest_neg = map_corr.idxmin() if map_corr.min() < 0 else None\n",
    "        \n",
    "        corr_text = f\"<b>Correlation Insights:</b><br/>\"\n",
    "        if strongest_pos:\n",
    "            corr_text += f\"â€¢ Strongest positive correlation: <b>{strongest_pos}</b> ({map_corr[strongest_pos]:.3f}) - Higher values tend to improve performance.<br/>\"\n",
    "        if strongest_neg:\n",
    "            corr_text += f\"â€¢ Strongest negative correlation: <b>{strongest_neg}</b> ({map_corr[strongest_neg]:.3f}) - Higher values tend to decrease performance.<br/>\"\n",
    "        corr_text += f\"â€¢ Green cells indicate positive correlation, red cells indicate negative correlation.\"\n",
    "        \n",
    "        story.append(Paragraph(corr_text, styles['Normal']))\n",
    "        story.append(Spacer(1, 15))\n",
    "    \n",
    "    # 5.2 Optimization Timeline & Convergence\n",
    "    story.append(PageBreak())\n",
    "    story.append(Paragraph('5.2 Optimization Timeline & Convergence', styles['Heading3']))\n",
    "    \n",
    "    print(f'   Creating optimization timeline chart...')\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    \n",
    "    # Sort by trial number for timeline\n",
    "    timeline_df = completed_trials_df.sort_values('trial')\n",
    "    \n",
    "    # Plot actual performance\n",
    "    ax.plot(timeline_df['trial'], timeline_df['mAP@0.5'], \n",
    "            marker='o', linestyle='-', linewidth=1.5, markersize=5, \n",
    "            color='#95a5a6', alpha=0.5, label='Trial Performance')\n",
    "    \n",
    "    # Calculate and plot moving average (window=5)\n",
    "    window = min(5, len(timeline_df))\n",
    "    if window > 1:\n",
    "        moving_avg = timeline_df['mAP@0.5'].rolling(window=window, min_periods=1).mean()\n",
    "        ax.plot(timeline_df['trial'], moving_avg, \n",
    "               linewidth=3, color='#3498db', label=f'{window}-Trial Moving Average')\n",
    "    \n",
    "    # Calculate and plot cumulative best\n",
    "    cumulative_best = timeline_df['mAP@0.5'].cummax()\n",
    "    ax.plot(timeline_df['trial'], cumulative_best, \n",
    "           linewidth=2.5, color='#27ae60', linestyle='--', \n",
    "           label='Cumulative Best', marker='*', markersize=8, markevery=cumulative_best.diff().fillna(1) != 0)\n",
    "    \n",
    "    # Mark best trial\n",
    "    best_trial_idx = timeline_df[timeline_df['mAP@0.5'] == study.best_value].iloc[0]\n",
    "    ax.scatter([best_trial_idx['trial']], [study.best_value], \n",
    "              s=300, color='#e74c3c', marker='*', zorder=5, \n",
    "              edgecolors='black', linewidth=2, label=f'Best Trial #{int(best_trial_idx[\"trial\"])}')\n",
    "    ax.annotate(f'Best: {study.best_value:.4f}', \n",
    "               xy=(best_trial_idx['trial'], study.best_value),\n",
    "               xytext=(10, 10), textcoords='offset points',\n",
    "               fontsize=10, fontweight='bold',\n",
    "               bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.7),\n",
    "               arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0', lw=2))\n",
    "    \n",
    "    ax.set_xlabel('Trial Number', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('mAP@0.5', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'{MODEL_NAME} - Optimization Progress & Convergence', fontsize=14, fontweight='bold')\n",
    "    ax.legend(fontsize=10, loc='lower right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    timeline_img = TUNE_DIR / 'report_optimization_timeline.png'\n",
    "    plt.savefig(timeline_img, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    story.append(Image(str(timeline_img), width=6.5*inch, height=2.7*inch))\n",
    "    story.append(Spacer(1, 15))\n",
    "    print(f'âœ“ Optimization timeline chart saved: {timeline_img}')\n",
    "    \n",
    "    # Add convergence analysis\n",
    "    best_found_at = int(best_trial_idx['trial'])\n",
    "    total_trials = len(timeline_df)\n",
    "    convergence_pct = (best_found_at / total_trials) * 100\n",
    "    \n",
    "    convergence_text = f\"\"\"<b>Convergence Analysis:</b><br/>\n",
    "â€¢ Best solution found at trial <b>#{best_found_at}</b> ({convergence_pct:.1f}% through optimization).<br/>\n",
    "â€¢ Moving average shows {'rapid early convergence' if convergence_pct < 40 else 'gradual improvement' if convergence_pct < 70 else 'late discovery'} pattern.<br/>\n",
    "â€¢ Cumulative best curve indicates {'efficient' if convergence_pct < 50 else 'moderate'} exploration of hyperparameter space.\n",
    "\"\"\"\n",
    "    story.append(Paragraph(convergence_text, styles['Normal']))\n",
    "    story.append(Spacer(1, 15))\n",
    "    \n",
    "    # 5.3 mAP@0.5 Progress Over Trials (original chart)\n",
    "    story.append(PageBreak())\n",
    "    story.append(Paragraph('5.3 mAP@0.5 Progress Over Trials', styles['Heading3']))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.plot(completed_trials_df['trial'], completed_trials_df['mAP@0.5'], \n",
    "            marker='o', linestyle='-', linewidth=2, markersize=6, color='#3498db', alpha=0.7)\n",
    "    ax.axhline(y=study.best_value, color='#e74c3c', linestyle='--', linewidth=2, \n",
    "               label=f'Best: {study.best_value:.4f}')\n",
    "    ax.set_xlabel('Trial Number', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('mAP@0.5', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'{MODEL_NAME} - mAP@0.5 Progress', fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    map_progress_img = TUNE_DIR / 'report_map_progress.png'\n",
    "    plt.savefig(map_progress_img, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    story.append(Image(str(map_progress_img), width=6.5*inch, height=3.25*inch))\n",
    "    story.append(Spacer(1, 15))\n",
    "    print(f'âœ“ mAP progress chart saved: {map_progress_img}')\n",
    "    \n",
    "    # 5.4 Learning Rate vs mAP@0.5\n",
    "    story.append(PageBreak())\n",
    "    story.append(Paragraph('5.4 Learning Rate Impact on Performance', styles['Heading3']))\n",
    "    \n",
    "    if 'lr0' in completed_trials_df.columns and completed_trials_df['lr0'].notna().any():\n",
    "        print(f'   Creating learning rate impact chart...')\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        scatter = ax.scatter(completed_trials_df['lr0'], completed_trials_df['mAP@0.5'],\n",
    "                           c=completed_trials_df['mAP@0.5'], cmap='RdYlGn', \n",
    "                           s=100, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "        ax.set_xlabel('Learning Rate (lr0)', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('mAP@0.5', fontsize=12, fontweight='bold')\n",
    "        ax.set_title(f'{MODEL_NAME} - Learning Rate vs Performance', fontsize=14, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        cbar = plt.colorbar(scatter, ax=ax)\n",
    "        cbar.set_label('mAP@0.5', fontsize=10)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        lr_impact_img = TUNE_DIR / 'report_lr_impact.png'\n",
    "        plt.savefig(lr_impact_img, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        story.append(Image(str(lr_impact_img), width=6.5*inch, height=3.25*inch))\n",
    "        story.append(Spacer(1, 15))\n",
    "        print(f'âœ“ Learning rate impact chart saved: {lr_impact_img}')\n",
    "    else:\n",
    "        story.append(Paragraph('Learning rate data not available for visualization.', styles['Normal']))\n",
    "        story.append(Spacer(1, 15))\n",
    "        print(f'   âš ï¸ lr0 column not found or empty')\n",
    "    \n",
    "    # 5.5 Optimizer Comparison\n",
    "    story.append(PageBreak())\n",
    "    story.append(Paragraph('5.5 Optimizer Performance Comparison', styles['Heading3']))\n",
    "    \n",
    "    if 'optimizer' in completed_trials_df.columns and completed_trials_df['optimizer'].notna().any():\n",
    "        print(f'   Creating optimizer comparison chart...')\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        \n",
    "        # Calculate comprehensive statistics\n",
    "        optimizer_stats = completed_trials_df.groupby('optimizer')['mAP@0.5'].agg(['mean', 'max', 'min', 'std', 'count'])\n",
    "        optimizer_stats = optimizer_stats.sort_values('mean', ascending=False)\n",
    "        \n",
    "        x_pos = range(len(optimizer_stats))\n",
    "        \n",
    "        # Create bars with gradient effect\n",
    "        bars = ax.bar(x_pos, optimizer_stats['mean'], alpha=0.8, \n",
    "                     color=['#2ecc71', '#3498db', '#9b59b6', '#e67e22'][:len(optimizer_stats)], \n",
    "                     edgecolor='black', linewidth=1.5, width=0.6)\n",
    "        \n",
    "        # Add max and min markers\n",
    "        ax.scatter(x_pos, optimizer_stats['max'], color='#27ae60', s=150, \n",
    "                  label='Max mAP@0.5', zorder=5, edgecolors='black', linewidth=1.5, marker='^')\n",
    "        ax.scatter(x_pos, optimizer_stats['min'], color='#e74c3c', s=150, \n",
    "                  label='Min mAP@0.5', zorder=5, edgecolors='black', linewidth=1.5, marker='v')\n",
    "        \n",
    "        # Add error bars for standard deviation\n",
    "        ax.errorbar(x_pos, optimizer_stats['mean'], yerr=optimizer_stats['std'], \n",
    "                   fmt='none', ecolor='gray', alpha=0.5, capsize=5, capthick=2, linewidth=2)\n",
    "        \n",
    "        ax.set_xlabel('Optimizer Type', fontsize=13, fontweight='bold')\n",
    "        ax.set_ylabel('mAP@0.5', fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'{MODEL_NAME} - Optimizer Performance Comparison (Mean Â± Std Dev)', \n",
    "                    fontsize=14, fontweight='bold')\n",
    "        ax.set_xticks(x_pos)\n",
    "        ax.set_xticklabels([])\n",
    "        ax.legend(fontsize=11, loc='lower left', framealpha=0.9, ncol=2)\n",
    "        ax.grid(True, alpha=0.3, axis='y', linestyle='--')\n",
    "        \n",
    "        # Add optimizer names inside bars\n",
    "        for i, (opt, row) in enumerate(optimizer_stats.iterrows()):\n",
    "            # Optimizer name inside bar (centered vertically)\n",
    "            ax.text(i, row['mean'] / 2, opt.upper(), \n",
    "                   ha='center', va='center', fontsize=12, fontweight='bold', \n",
    "                   color='white', rotation=0)\n",
    "            \n",
    "            # Mean value below optimizer name in bar\n",
    "            ax.text(i, row['mean'] / 2 - 0.02, f\"{row['mean']:.4f}\", \n",
    "                   ha='center', va='top', fontsize=9, fontweight='bold', \n",
    "                   color='white', alpha=0.9)\n",
    "            \n",
    "            # Trial count above max point\n",
    "            ax.text(i, row['max'] - 0.05, f\"n={int(row['count'])}\", \n",
    "                   ha='center', va='bottom', fontsize=10, fontweight='bold',\n",
    "                   bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7, edgecolor='black'))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        optimizer_comp_img = TUNE_DIR / 'report_optimizer_comparison.png'\n",
    "        plt.savefig(optimizer_comp_img, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        story.append(Image(str(optimizer_comp_img), width=6.5*inch, height=3.25*inch))\n",
    "        story.append(Spacer(1, 15))\n",
    "        print(f'âœ“ Optimizer comparison chart saved: {optimizer_comp_img}')\n",
    "        \n",
    "        # Add detailed statistics table for optimizers\n",
    "        optimizer_table_data = [['Optimizer', 'Mean', 'Max', 'Min', 'Std Dev', 'Trials']]\n",
    "        for opt, row in optimizer_stats.iterrows():\n",
    "            optimizer_table_data.append([\n",
    "                opt.upper(),\n",
    "                f\"{row['mean']:.4f}\",\n",
    "                f\"{row['max']:.4f}\",\n",
    "                f\"{row['min']:.4f}\",\n",
    "                f\"{row['std']:.4f}\",\n",
    "                str(int(row['count']))\n",
    "            ])\n",
    "        \n",
    "        opt_table = Table(optimizer_table_data, colWidths=[1.2*inch, 1.0*inch, 1.0*inch, 1.0*inch, 1.0*inch, 0.8*inch])\n",
    "        opt_table.setStyle(TableStyle([\n",
    "            ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#3498db')),\n",
    "            ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n",
    "            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "            ('FONTSIZE', (0, 0), (-1, 0), 10),\n",
    "            ('FONTSIZE', (0, 1), (-1, -1), 9),\n",
    "            ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n",
    "            ('TOPPADDING', (0, 0), (-1, -1), 6),\n",
    "            ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n",
    "            ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n",
    "        ]))\n",
    "        story.append(opt_table)\n",
    "        story.append(Spacer(1, 15))\n",
    "        \n",
    "        # Add interpretation text\n",
    "        best_optimizer = optimizer_stats.index[0]\n",
    "        best_mean = optimizer_stats.iloc[0]['mean']\n",
    "        interpretation = f\"<b>Analysis:</b> {best_optimizer.upper()} achieved the highest mean performance ({best_mean:.4f}) across {int(optimizer_stats.iloc[0]['count'])} trials. The error bars show the standard deviation, indicating performance consistency.\"\n",
    "        story.append(Paragraph(interpretation, styles['Normal']))\n",
    "        story.append(Spacer(1, 15))\n",
    "    else:\n",
    "        story.append(Paragraph('Optimizer data not available for visualization.', styles['Normal']))\n",
    "        story.append(Spacer(1, 15))\n",
    "        print(f'   âš ï¸ optimizer column not found or empty')\n",
    "    \n",
    "    # 5.6 Augmentation Parameters vs Performance\n",
    "    story.append(PageBreak())\n",
    "    story.append(Paragraph('5.6 Augmentation Parameters Impact', styles['Heading3']))\n",
    "    \n",
    "    # Create 2x2 subplot for key augmentation parameters\n",
    "    aug_params = ['mixup', 'mosaic', 'degrees', 'scale']\n",
    "    available_aug_params = [p for p in aug_params if p in completed_trials_df.columns and completed_trials_df[p].notna().any()]\n",
    "    \n",
    "    print(f'   Available augmentation params: {available_aug_params}')\n",
    "    \n",
    "    if len(available_aug_params) >= 2:\n",
    "        n_plots = min(len(available_aug_params), 4)\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for idx, param in enumerate(available_aug_params[:4]):\n",
    "            ax = axes[idx]\n",
    "            scatter = ax.scatter(completed_trials_df[param], completed_trials_df['mAP@0.5'],\n",
    "                               c=completed_trials_df['mAP@0.5'], cmap='RdYlGn',\n",
    "                               s=60, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "            ax.set_xlabel(param, fontsize=10, fontweight='bold')\n",
    "            ax.set_ylabel('mAP@0.5', fontsize=10, fontweight='bold')\n",
    "            ax.set_title(f'{param.capitalize()} Impact', fontsize=11, fontweight='bold')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Hide unused subplots\n",
    "        for idx in range(len(available_aug_params), 4):\n",
    "            axes[idx].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        aug_impact_img = TUNE_DIR / 'report_augmentation_impact.png'\n",
    "        plt.savefig(aug_impact_img, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        story.append(Image(str(aug_impact_img), width=6.5*inch, height=5.2*inch))\n",
    "        story.append(Spacer(1, 15))\n",
    "        print(f'âœ“ Augmentation impact chart saved: {aug_impact_img}')\n",
    "    else:\n",
    "        story.append(Paragraph(f'Insufficient augmentation parameter data for visualization. Found: {available_aug_params}', styles['Normal']))\n",
    "        story.append(Spacer(1, 15))\n",
    "        print(f'   âš ï¸ Not enough augmentation params available')\n",
    "    \n",
    "    # 5.7 Weight Decay and Momentum vs Performance\n",
    "    story.append(PageBreak())\n",
    "    story.append(Paragraph('5.7 Regularization Parameters Impact', styles['Heading3']))\n",
    "    \n",
    "    has_weight_decay = 'weight_decay' in completed_trials_df.columns and completed_trials_df['weight_decay'].notna().any()\n",
    "    has_momentum = 'momentum' in completed_trials_df.columns and completed_trials_df['momentum'].notna().any()\n",
    "    \n",
    "    if has_weight_decay and has_momentum:\n",
    "        print(f'   Creating regularization impact chart...')\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "        \n",
    "        # Weight Decay\n",
    "        scatter1 = ax1.scatter(completed_trials_df['weight_decay'], completed_trials_df['mAP@0.5'],\n",
    "                              c=completed_trials_df['mAP@0.5'], cmap='RdYlGn',\n",
    "                              s=80, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "        ax1.set_xlabel('Weight Decay', fontsize=11, fontweight='bold')\n",
    "        ax1.set_ylabel('mAP@0.5', fontsize=11, fontweight='bold')\n",
    "        ax1.set_title('Weight Decay Impact', fontsize=12, fontweight='bold')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Momentum\n",
    "        scatter2 = ax2.scatter(completed_trials_df['momentum'], completed_trials_df['mAP@0.5'],\n",
    "                              c=completed_trials_df['mAP@0.5'], cmap='RdYlGn',\n",
    "                              s=80, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "        ax2.set_xlabel('Momentum', fontsize=11, fontweight='bold')\n",
    "        ax2.set_ylabel('mAP@0.5', fontsize=11, fontweight='bold')\n",
    "        ax2.set_title('Momentum Impact', fontsize=12, fontweight='bold')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        reg_impact_img = TUNE_DIR / 'report_regularization_impact.png'\n",
    "        plt.savefig(reg_impact_img, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        story.append(Image(str(reg_impact_img), width=6.5*inch, height=2.6*inch))\n",
    "        story.append(Spacer(1, 15))\n",
    "        print(f'âœ“ Regularization impact chart saved: {reg_impact_img}')\n",
    "    else:\n",
    "        story.append(Paragraph(f'Regularization parameter data not available. weight_decay: {has_weight_decay}, momentum: {has_momentum}', styles['Normal']))\n",
    "        story.append(Spacer(1, 15))\n",
    "        print(f'   âš ï¸ weight_decay or momentum columns not found or empty')\n",
    "    \n",
    "    # 5.8 Image Size Impact on Performance\n",
    "    story.append(PageBreak())\n",
    "    story.append(Paragraph('5.8 Image Size Impact on Performance', styles['Heading3']))\n",
    "    \n",
    "    if 'imgsz' in completed_trials_df.columns and completed_trials_df['imgsz'].notna().any():\n",
    "        print(f'   Creating image size impact chart...')\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        \n",
    "        # Group by image size and calculate statistics\n",
    "        imgsz_stats = completed_trials_df.groupby('imgsz')['mAP@0.5'].agg(['mean', 'max', 'min', 'count'])\n",
    "        imgsz_stats = imgsz_stats.sort_index()\n",
    "        \n",
    "        x_pos = range(len(imgsz_stats))\n",
    "        bars = ax.bar(x_pos, imgsz_stats['mean'], alpha=0.7, color='#9b59b6', \n",
    "               label='Mean mAP@0.5', edgecolor='black', linewidth=1.5, width=0.6)\n",
    "        ax.scatter(x_pos, imgsz_stats['max'], color='#27ae60', s=120, \n",
    "                  label='Max mAP@0.5', zorder=5, edgecolors='black', linewidth=1, marker='^')\n",
    "        ax.scatter(x_pos, imgsz_stats['min'], color='#e74c3c', s=120, \n",
    "                  label='Min mAP@0.5', zorder=5, edgecolors='black', linewidth=1, marker='v')\n",
    "        \n",
    "        ax.set_xlabel('Image Size (pixels)', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('mAP@0.5', fontsize=12, fontweight='bold')\n",
    "        ax.set_title(f'{MODEL_NAME} - Image Size Impact on Performance', fontsize=14, fontweight='bold')\n",
    "        ax.set_xticks(x_pos)\n",
    "        ax.set_xticklabels([int(idx) for idx in imgsz_stats.index], fontsize=11, fontweight='bold')\n",
    "        ax.legend(fontsize=10, loc='best')\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add count and mean value annotations\n",
    "        for i, (imgsz, row) in enumerate(imgsz_stats.iterrows()):\n",
    "            # Mean value inside bar\n",
    "            ax.text(i, row['mean'] / 2, f\"{row['mean']:.4f}\", \n",
    "                   ha='center', va='center', fontsize=10, fontweight='bold', color='white')\n",
    "            # Count above bar\n",
    "            ax.text(i, row['max'] + 0.003, f\"n={int(row['count'])}\", \n",
    "                   ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        imgsz_impact_img = TUNE_DIR / 'report_imgsz_impact.png'\n",
    "        plt.savefig(imgsz_impact_img, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        story.append(Image(str(imgsz_impact_img), width=6.5*inch, height=3.25*inch))\n",
    "        story.append(Spacer(1, 15))\n",
    "        print(f'âœ“ Image size impact chart saved: {imgsz_impact_img}')\n",
    "        \n",
    "        # Add statistics table for image sizes\n",
    "        imgsz_table_data = [['Image Size', 'Mean mAP@0.5', 'Max mAP@0.5', 'Min mAP@0.5', 'Trials']]\n",
    "        for imgsz, row in imgsz_stats.iterrows():\n",
    "            imgsz_table_data.append([\n",
    "                str(int(imgsz)),\n",
    "                f\"{row['mean']:.4f}\",\n",
    "                f\"{row['max']:.4f}\",\n",
    "                f\"{row['min']:.4f}\",\n",
    "                str(int(row['count']))\n",
    "            ])\n",
    "        \n",
    "        imgsz_table = Table(imgsz_table_data, colWidths=[1.2*inch, 1.2*inch, 1.2*inch, 1.2*inch, 0.8*inch])\n",
    "        imgsz_table.setStyle(TableStyle([\n",
    "            ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#9b59b6')),\n",
    "            ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n",
    "            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "            ('FONTSIZE', (0, 0), (-1, 0), 10),\n",
    "            ('FONTSIZE', (0, 1), (-1, -1), 9),\n",
    "            ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n",
    "            ('TOPPADDING', (0, 0), (-1, -1), 6),\n",
    "            ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n",
    "            ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n",
    "        ]))\n",
    "        story.append(imgsz_table)\n",
    "        story.append(Spacer(1, 15))\n",
    "    else:\n",
    "        story.append(Paragraph('Image size data not available for visualization.', styles['Normal']))\n",
    "        story.append(Spacer(1, 15))\n",
    "        print(f'   âš ï¸ imgsz column not found or empty')\n",
    "    \n",
    "    print('âœ“ All custom visualizations generated for PDF report')\n",
    "\n",
    "# ===== SECTION 5.9: KEY INSIGHTS & RECOMMENDATIONS =====\n",
    "story.append(PageBreak())\n",
    "story.append(Paragraph('5.9 Key Insights & Production Recommendations', styles['Heading3']))\n",
    "\n",
    "print('   Generating key insights and recommendations...')\n",
    "\n",
    "# Generate comprehensive recommendations based on best trial\n",
    "best_trial_row = completed_trials_df[completed_trials_df['trial'] == study.best_trial.number].iloc[0]\n",
    "\n",
    "recommendations_text = f\"\"\"\n",
    "<b>ðŸŽ¯ Optimal Configuration for Production Deployment:</b><br/><br/>\n",
    "\n",
    "<b>1. Image Processing:</b><br/>\n",
    "   â€¢ Use <b>{int(best_trial_row.get('imgsz', 'N/A'))}px</b> input resolution for optimal accuracy<br/>\n",
    "   â€¢ Expected performance: <b>mAP@0.5 = {study.best_value:.4f}</b><br/>\n",
    "   â€¢ Tradeoff: Higher resolution improves accuracy but increases inference time<br/><br/>\n",
    "\n",
    "<b>2. Optimizer Configuration:</b><br/>\n",
    "   â€¢ Algorithm: <b>{best_trial_row.get('optimizer', 'N/A')}</b><br/>\n",
    "   â€¢ Learning rate (lr0): <b>{best_trial_row.get('lr0', 0):.6f}</b><br/>\n",
    "   â€¢ Momentum: <b>{best_trial_row.get('momentum', 0):.4f}</b><br/>\n",
    "   â€¢ Weight decay: <b>{best_trial_row.get('weight_decay', 0):.6f}</b><br/><br/>\n",
    "\n",
    "<b>3. Training Warmup:</b><br/>\n",
    "   â€¢ Warmup epochs: <b>{int(best_trial_row.get('warmup_epochs', 0))}</b><br/>\n",
    "   â€¢ Warmup momentum: <b>{best_trial_row.get('warmup_momentum', 0):.4f}</b><br/>\n",
    "   â€¢ Warmup bias lr: <b>{best_trial_row.get('warmup_bias_lr', 0):.6f}</b><br/><br/>\n",
    "\n",
    "<b>4. Data Augmentation:</b><br/>\n",
    "   â€¢ Mosaic augmentation: <b>{best_trial_row.get('mosaic', 0):.4f}</b> (strong augmentation for robustness)<br/>\n",
    "   â€¢ Mixup augmentation: <b>{best_trial_row.get('mixup', 0):.4f}</b> (light augmentation)<br/>\n",
    "   â€¢ Recommendation: Use these exact values for similar datasets<br/><br/>\n",
    "\n",
    "<b>5. Performance Metrics:</b><br/>\n",
    "   â€¢ Best trial found at <b>#{int(best_trial_row['trial'])}</b> out of {len(study.trials)} trials<br/>\n",
    "   â€¢ Performance improvement: <b>{improvement_pct:.1f}%</b> over worst trial<br/>\n",
    "   â€¢ Consistency: Mean mAP@0.5 = {mean_map:.4f} (Std = {completed_df_summary[\"mAP@0.5\"].std():.4f})<br/><br/>\n",
    "\n",
    "<b>6. Deployment Recommendations:</b><br/>\n",
    "\"\"\"\n",
    "\n",
    "# Add optimizer-specific recommendations\n",
    "if 'optimizer' in completed_df_summary.columns:\n",
    "    opt_comparison = completed_df_summary.groupby('optimizer')['mAP@0.5'].agg(['mean', 'std', 'count'])\n",
    "    recommendations_text += f\"   â€¢ <b>{best_opt}</b> optimizer demonstrated best performance (mean: {best_opt_mean:.4f})<br/>\"\n",
    "    \n",
    "    if len(opt_comparison) > 1:\n",
    "        other_opts = opt_comparison[opt_comparison.index != best_opt]\n",
    "        if len(other_opts) > 0:\n",
    "            worst_opt = other_opts['mean'].idxmin()\n",
    "            diff_pct = ((best_opt_mean - other_opts.loc[worst_opt, 'mean']) / other_opts.loc[worst_opt, 'mean']) * 100\n",
    "            recommendations_text += f\"   â€¢ <b>{best_opt}</b> outperformed {worst_opt} by {diff_pct:.1f}%<br/>\"\n",
    "\n",
    "# Add image size recommendations\n",
    "if 'imgsz' in completed_df_summary.columns and len(completed_df_summary['imgsz'].unique()) > 1:\n",
    "    imgsz_comparison = completed_df_summary.groupby('imgsz')['mAP@0.5'].mean()\n",
    "    recommendations_text += f\"   â€¢ For maximum accuracy, use {int(best_imgsz)}px images<br/>\"\n",
    "    if len(imgsz_comparison) > 1:\n",
    "        smaller_sizes = imgsz_comparison[imgsz_comparison.index < best_imgsz]\n",
    "        if len(smaller_sizes) > 0:\n",
    "            recommendations_text += f\"   â€¢ For faster inference with slight accuracy trade-off, consider {int(smaller_sizes.index[-1])}px (mAP: {smaller_sizes.iloc[-1]:.4f})<br/>\"\n",
    "\n",
    "recommendations_text += f\"\"\"<br/>\n",
    "<b>7. Next Steps:</b><br/>\n",
    "   â€¢ Train full model with these hyperparameters <br/>\n",
    "   â€¢ Monitor validation metrics for overfitting<br/>\n",
    "   â€¢ Consider ensemble methods for further improvement<br/><br/>\n",
    "\n",
    "<b>ðŸ“Š Confidence Level:</b><br/>\n",
    "   â€¢ Based on {len(completed_df_summary)} successful trials<br/>\n",
    "   â€¢ Optimization converged {'early' if convergence_pct < 40 else 'steadily'} (best at {convergence_pct:.1f}% through search)<br/>\n",
    "   â€¢ Standard deviation ({completed_df_summary['mAP@0.5'].std():.4f}) indicates {'high' if completed_df_summary['mAP@0.5'].std() < 0.02 else 'moderate'} consistency\n",
    "\"\"\"\n",
    "\n",
    "story.append(Paragraph(recommendations_text, styles['Normal']))\n",
    "story.append(Spacer(1, 20))\n",
    "\n",
    "# Add comparison table: Best vs Mean vs Worst\n",
    "comparison_data = [\n",
    "    ['Metric', 'Best Trial', 'Mean Performance', 'Worst Trial'],\n",
    "    ['mAP@0.5', f'{best_map:.4f}', f'{mean_map:.4f}', f'{worst_map:.4f}'],\n",
    "    ['Trial #', f'#{int(best_trial_row[\"trial\"])}', '-', f'#{int(completed_df_summary.loc[completed_df_summary[\"mAP@0.5\"].idxmin(), \"trial\"])}'],\n",
    "]\n",
    "\n",
    "# Add key parameters\n",
    "if 'lr0' in best_trial_row:\n",
    "    worst_trial_row = completed_df_summary.loc[completed_df_summary['mAP@0.5'].idxmin()]\n",
    "    comparison_data.append(['Learning Rate', f'{best_trial_row[\"lr0\"]:.6f}', \n",
    "                           f'{completed_df_summary[\"lr0\"].mean():.6f}', f'{worst_trial_row[\"lr0\"]:.6f}'])\n",
    "if 'momentum' in best_trial_row:\n",
    "    comparison_data.append(['Momentum', f'{best_trial_row[\"momentum\"]:.4f}', \n",
    "                           f'{completed_df_summary[\"momentum\"].mean():.4f}', f'{worst_trial_row[\"momentum\"]:.4f}'])\n",
    "\n",
    "comparison_table = Table(comparison_data, colWidths=[1.5*inch, 1.5*inch, 1.5*inch, 1.5*inch])\n",
    "comparison_table.setStyle(TableStyle([\n",
    "    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#e74c3c')),\n",
    "    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n",
    "    ('BACKGROUND', (1, 1), (1, -1), rl_colors.HexColor('#d5f4e6')),  # Highlight best column\n",
    "    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "    ('FONTSIZE', (0, 0), (-1, 0), 10),\n",
    "    ('FONTSIZE', (0, 1), (-1, -1), 9),\n",
    "    ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n",
    "    ('TOPPADDING', (0, 0), (-1, -1), 6),\n",
    "    ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n",
    "]))\n",
    "story.append(comparison_table)\n",
    "story.append(Spacer(1, 20))\n",
    "\n",
    "print('âœ“ Insights and recommendations section completed')\n",
    "\n",
    "# ===== SECTION 6: ALL TRIALS SUMMARY =====\n",
    "story.append(PageBreak())\n",
    "story.append(Paragraph('6. All Trials Summary', heading_style))\n",
    "\n",
    "# Statistics\n",
    "completed_df = df_trials_sorted[df_trials_sorted['state'] == 'COMPLETE']\n",
    "if len(completed_df) > 0:\n",
    "    stats_data = [\n",
    "        ['Metric', 'Value'],\n",
    "        ['Completed Trials', str(len(completed_df))],\n",
    "        ['Best mAP@0.5', f\"{completed_df['mAP@0.5'].max():.4f}\"],\n",
    "        ['Worst mAP@0.5', f\"{completed_df['mAP@0.5'].min():.4f}\"],\n",
    "        ['Mean mAP@0.5', f\"{completed_df['mAP@0.5'].mean():.4f}\"],\n",
    "        ['Std Dev mAP@0.5', f\"{completed_df['mAP@0.5'].std():.4f}\"],\n",
    "        ['Median mAP@0.5', f\"{completed_df['mAP@0.5'].median():.4f}\"],\n",
    "    ]\n",
    "    \n",
    "    stats_table = Table(stats_data, colWidths=[2.5*inch, 3.5*inch])\n",
    "    stats_table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#e74c3c')),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n",
    "        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "        ('FONTSIZE', (0, 0), (-1, -1), 10),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n",
    "        ('TOPPADDING', (0, 0), (-1, -1), 6),\n",
    "        ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n",
    "        ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n",
    "    ]))\n",
    "    story.append(stats_table)\n",
    "\n",
    "# Build PDF\n",
    "try:\n",
    "    doc.build(story)\n",
    "    print(f'\\nâœ“ Comprehensive PDF report generated: {pdf_report_path}')\n",
    "    print(f'  Size: {pdf_report_path.stat().st_size / (1024*1024):.1f} MB')\n",
    "    print(f'  Sections: Overview, Executive Summary, Best Hyperparameters, Top 20 Trials,')\n",
    "    print(f'            Performance Analysis (10 advanced visualizations), Key Insights,')\n",
    "    print(f'            Production Recommendations, All Trials Summary')\n",
    "    print(f'  Charts: Distribution, Correlation, Timeline, mAP Progress, Learning Rate,')\n",
    "    print(f'          Optimizer, Augmentation, Regularization, Image Size')\n",
    "except Exception as pdf_error:\n",
    "    print(f'\\nâš ï¸  Error generating PDF: {pdf_error}')\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ff99f5",
   "metadata": {},
   "source": [
    "## 13. Analyze Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3823505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISPLAY BEST HYPERPARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('BEST HYPERPARAMETERS')\n",
    "print('=' * 80)\n",
    "\n",
    "print(f'\\nBest Trial Number: {study.best_trial.number}')\n",
    "print(f'Best mAP@0.5: {study.best_value:.4f}')\n",
    "print('\\nOptimized Hyperparameters:')\n",
    "print(json.dumps(study.best_params, indent=2))\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1900ad83",
   "metadata": {},
   "source": [
    "## 13. Create Trials Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c210c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE TRIALS SUMMARY AND DATAFRAME (SHARED RESOURCE)\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('TRIALS SUMMARY')\n",
    "print('=' * 80)\n",
    "\n",
    "# Compile all trial data (used by multiple sections)\n",
    "trials_data = []\n",
    "for trial in study.trials:\n",
    "    trial_info = {\n",
    "        'trial': trial.number,\n",
    "        'mAP@0.5': trial.value if trial.value else 0.0,\n",
    "        'state': trial.state.name,\n",
    "        'duration_seconds': (trial.datetime_complete - trial.datetime_start).total_seconds() if trial.datetime_complete else None,\n",
    "    }\n",
    "    # Add all parameters\n",
    "    trial_info.update(trial.params)\n",
    "    trials_data.append(trial_info)\n",
    "\n",
    "# Create DataFrame and sort by performance (used by PDF report and display)\n",
    "df_trials = pd.DataFrame(trials_data)\n",
    "df_trials_sorted = df_trials.sort_values('mAP@0.5', ascending=False)\n",
    "\n",
    "print('\\nðŸ“Š TOP 10 TRIALS:')\n",
    "print('=' * 80)\n",
    "# Display top 10 with selected columns\n",
    "display_cols = ['trial', 'mAP@0.5', 'state', 'optimizer', 'lr0', 'momentum', 'weight_decay', 'mixup']\n",
    "available_cols = [col for col in display_cols if col in df_trials_sorted.columns]\n",
    "print(df_trials_sorted[available_cols].head(10).to_string(index=False))\n",
    "print('=' * 80)\n",
    "\n",
    "# Save complete trials summary\n",
    "trials_csv_path = TUNE_DIR / 'trials_summary.csv'\n",
    "df_trials_sorted.to_csv(trials_csv_path, index=False)\n",
    "print(f'\\nâœ“ Complete trials summary saved to: {trials_csv_path}')\n",
    "\n",
    "# Save study object\n",
    "study_path = TUNE_DIR / 'optuna_study.pkl'\n",
    "with open(study_path, 'wb') as f:\n",
    "    pickle.dump(study, f)\n",
    "print(f'âœ“ Optuna study object saved to: {study_path}')\n",
    "\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d09278e",
   "metadata": {},
   "source": [
    "## 14. Final summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9576f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n\\n')\n",
    "print('=' * 80)\n",
    "print('HYPERPARAMETER OPTIMIZATION COMPLETE!')\n",
    "print('=' * 80)\n",
    "\n",
    "print(f'\\nðŸ“Š Project: {MODEL_NAME} on {YOLO_DATASET_ROOT.name}')\n",
    "print(f'ðŸ“… Date: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "\n",
    "print(f'\\nðŸ”¬ Optimization Summary:')\n",
    "print(f'  Total Trials: {len(study.trials)}')\n",
    "print(f'  Completed: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}')\n",
    "print(f'  Best Trial: {study.best_trial.number}')\n",
    "print(f'  Best Trial mAP@0.5: {study.best_value:.4f}')\n",
    "print(f'  Duration: {duration}')\n",
    "\n",
    "if 'final_metrics' in globals():\n",
    "    print(f'\\nðŸŽ¯ Final Model Performance:')\n",
    "    print(f'  mAP@0.5: {final_metrics[\"map50\"]:.4f}')\n",
    "    print(f'  mAP@0.5:0.95: {final_metrics[\"map50_95\"]:.4f}')\n",
    "    print(f'  Precision: {final_metrics[\"precision\"]:.4f}')\n",
    "    print(f'  Recall: {final_metrics[\"recall\"]:.4f}')\n",
    "\n",
    "print(f'\\nðŸ“ Generated Files:')\n",
    "print(f'\\n  ðŸ“Š Tuning Results (in {TUNE_DIR}):')\n",
    "print(f'    - best_hyperparameters.json')\n",
    "print(f'    - best_hyperparameters.yaml')\n",
    "print(f'    - trials_summary.csv')\n",
    "print(f'    - optuna_study.pkl')\n",
    "print(f'  ðŸ“ˆ Tuning Visualizations:')\n",
    "print(f'    - optimization_history.html / .png')\n",
    "print(f'    - parameter_importance.html / .png')\n",
    "print(f'    - parameter_slice.html / .png')\n",
    "print(f'  ðŸ“„ Tuning PDF Report:')\n",
    "print(f'    - {MODEL_NAME}_tuning_report.pdf')\n",
    "\n",
    "print(f'\\nðŸ“‚ All results saved to:')\n",
    "print(f'  Tuning: {TUNE_DIR}')\n",
    "\n",
    "print(f'\\nðŸŽ“ Top 5 Hyperparameters (by importance):')\n",
    "try:\n",
    "    importances = optuna.importance.get_param_importances(study)\n",
    "    for i, (param, importance) in enumerate(list(importances.items())[:5], 1):\n",
    "        print(f'  {i}. {param}: {importance:.4f}')\n",
    "except:\n",
    "    print('  (Not available - requires completed trials with variation)')\n",
    "\n",
    "print(f'\\nðŸš€ Next Steps:')\n",
    "print(f'  1. Review tuning PDF report: {TUNE_DIR / f\"{MODEL_NAME}_tuning_report.pdf\"}')\n",
    "print(f'  2. Review optimization visualizations in: {TUNE_DIR}')\n",
    "print(f'  3. Use best_hyperparameters.yaml for training in a separate notebook')\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('SUCCESS! âœ“')\n",
    "print('=' * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
